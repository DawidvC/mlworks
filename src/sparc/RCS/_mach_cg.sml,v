head	1.248;
access;
symbols
	MLW_daveb_inline_1_4_99:1.248.1
	MLWorks_21c0_1999_03_25:1.248
	MLWorks_20c1_1998_08_20:1.248
	MLWorks_20c0_1998_08_04:1.248
	MLWorks_20b2c2_1998_06_19:1.248
	MLWorks_20b2_Windows_1998_06_12:1.248
	MLWorks_20b1c1_1998_05_07:1.248
	MLWorks_20b0_1998_04_07:1.248
	MLWorks_20b0_1998_03_20:1.248
	MLWorks_20m2_1998_02_16:1.247
	MLWorks_20m1_1997_10_23:1.245
	MLWorks_11r1:1.239.1.1.1.1.1
	MLWorks_workspace_97:1.244.2
	MLWorks_dt_wizard:1.244.1
	MLWorks_11c0_1997_09_09:1.239.1.1.1.1
	MLWorks_10r3:1.239.1.1.3
	MLWorks_10r2_551:1.239.1.1.2
	MLWorks_11:1.239.1.1.1
	MLWorks_1_0_r2c2_1997_07_28:1.239.1.1
	MLWorks_20m0_1997_06_20:1.241
	MLWorks_1_0_r2c2_1997_06_14:1.239.1.1
	MLWorks_1_0_r2c1_released_1997_05_23:1.239.1.1
	MLWorks_1_0_r2c1_1997_05_12:1.239.1
	MLWorks_BugFix_1997_04_24:1.239
	MLWorks_1_0_r2_Win32_1997_04_11:1.239
	MLWorks_1_0_r2_Unix_1997_04_04:1.239
	MLWorks_1_0_1_ULTRASPARC_1997_02_24:1.234.3.1.1
	MLWorks_gui_1996_12_18:1.234.4
	MLWorks_1_0_Win32_1996_12_17:1.234.3
	MLWorks_1_0_Irix_1996_11_28_released_1996_12_17:1.234.1.1.1.1
	MLWorks_1_0_Unix_1996_11_14_released_1996_12_17:1.234.1.1
	MLWorks_1_0_Irix_1996_11_28:1.234.1.1.1
	MLWorks_1_0_Win32_1996_11_22:1.234.2
	MLWorks_1_0_Unix_1996_11_14:1.234.1
	MLWorks_Open_Beta2_1996_10_11:1.231.3
	MLWorks_License_dev:1.231.2
	MLWorks_1_open_beta_1996_09_13:1.231.1
	MLWorks_Open_Beta_1996_08_22:1.231
	MLWorks_Beta_1996_07_02:1.230
	MLWorks_Beta_1996_06_07:1.230
	MLWorks_Beta_1996_06_06:1.230
	MLWorks_Beta_1996_06_05:1.230
	MLWorks_Beta_1996_06_03:1.230
	MLWorks_Beta_1996_05_31:1.230
	MLWorks_Beta_1996_05_30:1.229
	ML_beta_release_12/08/94:1.197
	ML_beta_release_03/08/94:1.197
	ML_revised_beta_release_25/05/94:1.187
	ML_final_beta_release_02/03/94:1.174
	mlworks-28-01-1994:1.172
	Release:1.163
	mlworks-beta-01-09-1993:1.163
	MLWorks-1-0-4-29/01/1993:1.145
	MLWorks-1-0-3-21/12/1992:1.142
	MLWorks-1-0-2-15/12/1992:1.141
	MLWorks-1-0-1-04/12/1992:1.139
	checkpoint_17_08_92:1.118;
locks; strict;
comment	@ * @;


1.248
date	98.02.20.09.31.47;	author mitchell;	state Exp;
branches
	1.248.1.1;
next	1.247;

1.247
date	98.01.30.09.48.22;	author johnh;	state Exp;
branches;
next	1.246;

1.246
date	97.11.13.11.21.00;	author jont;	state Exp;
branches;
next	1.245;

1.245
date	97.09.18.16.28.48;	author brucem;	state Exp;
branches;
next	1.244;

1.244
date	97.08.07.14.54.35;	author jont;	state Exp;
branches
	1.244.1.1
	1.244.2.1;
next	1.243;

1.243
date	97.08.06.12.16.36;	author jont;	state Exp;
branches;
next	1.242;

1.242
date	97.08.04.16.26.46;	author jont;	state Exp;
branches;
next	1.241;

1.241
date	97.05.30.11.52.29;	author jont;	state Exp;
branches;
next	1.240;

1.240
date	97.05.19.12.36.03;	author jont;	state Exp;
branches;
next	1.239;

1.239
date	97.03.26.14.06.50;	author matthew;	state Exp;
branches
	1.239.1.1;
next	1.238;

1.238
date	97.01.31.16.55.51;	author matthew;	state Exp;
branches;
next	1.237;

1.237
date	97.01.23.14.14.33;	author jont;	state Exp;
branches;
next	1.236;

1.236
date	97.01.17.17.23.23;	author matthew;	state Exp;
branches;
next	1.235;

1.235
date	97.01.16.16.41.55;	author matthew;	state Exp;
branches;
next	1.234;

1.234
date	96.11.06.14.38.45;	author jont;	state Exp;
branches
	1.234.1.1
	1.234.2.1
	1.234.3.1
	1.234.4.1;
next	1.233;

1.233
date	96.11.06.11.10.19;	author matthew;	state Exp;
branches;
next	1.232;

1.232
date	96.10.09.14.14.06;	author io;	state Exp;
branches;
next	1.231;

1.231
date	96.08.01.12.22.44;	author jont;	state Exp;
branches
	1.231.1.1
	1.231.2.1
	1.231.3.1;
next	1.230;

1.230
date	96.05.30.12.38.46;	author daveb;	state Exp;
branches;
next	1.229;

1.229
date	96.05.17.09.43.47;	author matthew;	state Exp;
branches;
next	1.228;

1.228
date	96.05.14.10.44.37;	author matthew;	state Exp;
branches;
next	1.227;

1.227
date	96.05.10.09.55.02;	author matthew;	state Exp;
branches;
next	1.226;

1.226
date	96.05.07.11.13.49;	author jont;	state Exp;
branches;
next	1.225;

1.225
date	96.04.30.17.05.20;	author jont;	state Exp;
branches;
next	1.224;

1.224
date	96.04.29.15.31.34;	author matthew;	state Exp;
branches;
next	1.223;

1.223
date	96.02.02.12.58.58;	author jont;	state Exp;
branches;
next	1.222;

1.222
date	95.12.22.13.10.25;	author jont;	state Exp;
branches;
next	1.221;

1.221
date	95.11.20.17.06.35;	author jont;	state Exp;
branches;
next	1.220;

1.220
date	95.09.22.15.53.01;	author jont;	state Exp;
branches;
next	1.219;

1.219
date	95.08.10.14.50.28;	author jont;	state Exp;
branches;
next	1.218;

1.218
date	95.07.28.10.13.27;	author matthew;	state Exp;
branches;
next	1.217;

1.217
date	95.07.28.03.01.51;	author io;	state Exp;
branches;
next	1.216;

1.216
date	95.07.25.13.47.19;	author jont;	state Exp;
branches;
next	1.215;

1.215
date	95.07.19.12.04.01;	author jont;	state Exp;
branches;
next	1.214;

1.214
date	95.07.11.16.19.37;	author jont;	state Exp;
branches;
next	1.213;

1.213
date	95.05.26.14.07.20;	author matthew;	state Exp;
branches;
next	1.212;

1.212
date	95.05.24.09.44.43;	author matthew;	state Exp;
branches;
next	1.211;

1.211
date	95.05.02.11.33.19;	author matthew;	state Exp;
branches;
next	1.210;

1.210
date	95.02.15.12.35.13;	author matthew;	state Exp;
branches;
next	1.209;

1.209
date	95.01.30.14.54.52;	author matthew;	state Exp;
branches;
next	1.208;

1.208
date	94.11.28.16.52.25;	author matthew;	state Exp;
branches;
next	1.207;

1.207
date	94.11.28.15.14.49;	author matthew;	state Exp;
branches;
next	1.206;

1.206
date	94.11.23.13.24.33;	author matthew;	state Exp;
branches;
next	1.205;

1.205
date	94.11.16.12.16.44;	author jont;	state Exp;
branches;
next	1.204;

1.204
date	94.10.13.11.23.04;	author matthew;	state Exp;
branches;
next	1.203;

1.203
date	94.10.05.12.02.37;	author jont;	state Exp;
branches;
next	1.202;

1.202
date	94.09.23.11.43.20;	author matthew;	state Exp;
branches;
next	1.201;

1.201
date	94.09.12.15.51.21;	author jont;	state Exp;
branches;
next	1.200;

1.200
date	94.09.02.15.27.11;	author jont;	state Exp;
branches;
next	1.199;

1.199
date	94.08.26.14.05.39;	author matthew;	state Exp;
branches;
next	1.198;

1.198
date	94.08.24.16.17.04;	author jont;	state Exp;
branches;
next	1.197;

1.197
date	94.07.25.11.07.05;	author matthew;	state Exp;
branches;
next	1.196;

1.196
date	94.07.22.16.04.48;	author nickh;	state Exp;
branches;
next	1.195;

1.195
date	94.07.22.15.03.04;	author jont;	state Exp;
branches;
next	1.194;

1.194
date	94.07.13.12.05.57;	author jont;	state Exp;
branches;
next	1.193;

1.193
date	94.06.24.14.17.36;	author jont;	state Exp;
branches;
next	1.192;

1.192
date	94.06.22.14.50.27;	author jont;	state Exp;
branches;
next	1.191;

1.191
date	94.06.22.13.48.32;	author jont;	state Exp;
branches;
next	1.190;

1.190
date	94.06.13.09.51.41;	author nickh;	state Exp;
branches;
next	1.189;

1.189
date	94.06.10.09.49.51;	author jont;	state Exp;
branches;
next	1.188;

1.188
date	94.05.27.15.11.34;	author jont;	state Exp;
branches;
next	1.187;

1.187
date	94.05.25.10.23.21;	author jont;	state Exp;
branches;
next	1.186;

1.186
date	94.05.23.17.23.50;	author jont;	state Exp;
branches;
next	1.185;

1.185
date	94.05.12.13.40.24;	author richard;	state Exp;
branches;
next	1.184;

1.184
date	94.04.07.09.52.05;	author jont;	state Exp;
branches;
next	1.183;

1.183
date	94.03.24.14.00.25;	author jont;	state Exp;
branches;
next	1.182;

1.182
date	94.03.23.16.15.12;	author matthew;	state Exp;
branches;
next	1.181;

1.181
date	94.03.23.15.29.11;	author nickh;	state Exp;
branches;
next	1.180;

1.180
date	94.03.18.18.43.33;	author jont;	state Exp;
branches;
next	1.179;

1.179
date	94.03.18.12.34.42;	author jont;	state Exp;
branches;
next	1.178;

1.178
date	94.03.11.12.09.36;	author jont;	state Exp;
branches;
next	1.177;

1.177
date	94.03.09.17.16.42;	author jont;	state Exp;
branches;
next	1.176;

1.176
date	94.03.08.18.20.01;	author jont;	state Exp;
branches;
next	1.175;

1.175
date	94.03.04.12.42.20;	author jont;	state Exp;
branches;
next	1.174;

1.174
date	94.02.28.09.40.45;	author nosa;	state Exp;
branches;
next	1.173;

1.173
date	94.02.25.13.54.18;	author daveb;	state Exp;
branches;
next	1.172;

1.172
date	94.01.18.11.45.50;	author daveb;	state Exp;
branches;
next	1.171;

1.171
date	94.01.18.11.45.50;	author daveb;	state Exp;
branches;
next	1.170;

1.170
date	93.12.17.10.38.42;	author io;	state Exp;
branches;
next	1.169;

1.169
date	93.12.10.13.57.30;	author jont;	state Exp;
branches;
next	1.168;

1.168
date	93.11.22.12.47.10;	author daveb;	state Exp;
branches;
next	1.167;

1.167
date	93.11.05.16.17.39;	author jont;	state Exp;
branches;
next	1.166;

1.166
date	93.11.04.16.46.11;	author jont;	state Exp;
branches;
next	1.165;

1.165
date	93.10.05.17.07.34;	author jont;	state Exp;
branches;
next	1.164;

1.164
date	93.09.06.09.51.10;	author nosa;	state Exp;
branches;
next	1.163;

1.163
date	93.08.26.13.19.57;	author jont;	state Exp;
branches
	1.163.1.1;
next	1.162;

1.162
date	93.08.13.14.01.15;	author simon;	state Exp;
branches;
next	1.161;

1.161
date	93.08.06.14.31.34;	author richard;	state Exp;
branches;
next	1.160;

1.160
date	93.07.29.15.37.17;	author nosa;	state Exp;
branches;
next	1.159;

1.159
date	93.07.23.16.12.49;	author jont;	state Exp;
branches;
next	1.158;

1.158
date	93.07.08.18.08.13;	author jont;	state Exp;
branches;
next	1.157;

1.157
date	93.05.18.16.22.48;	author jont;	state Exp;
branches;
next	1.156;

1.156
date	93.05.05.12.03.31;	author jont;	state Exp;
branches;
next	1.155;

1.155
date	93.04.27.10.58.48;	author richard;	state Exp;
branches;
next	1.154;

1.154
date	93.04.19.09.59.24;	author jont;	state Exp;
branches;
next	1.153;

1.153
date	93.04.16.16.03.30;	author jont;	state Exp;
branches;
next	1.152;

1.152
date	93.04.15.12.05.08;	author jont;	state Exp;
branches;
next	1.151;

1.151
date	93.03.23.16.04.31;	author jont;	state Exp;
branches;
next	1.150;

1.150
date	93.03.17.18.22.07;	author jont;	state Exp;
branches;
next	1.149;

1.149
date	93.03.12.11.49.59;	author matthew;	state Exp;
branches;
next	1.148;

1.148
date	93.03.05.12.57.26;	author matthew;	state Exp;
branches;
next	1.147;

1.147
date	93.03.01.15.27.33;	author matthew;	state Exp;
branches;
next	1.146;

1.146
date	93.02.10.13.58.35;	author jont;	state Exp;
branches;
next	1.145;

1.145
date	93.01.28.14.49.43;	author jont;	state Exp;
branches;
next	1.144;

1.144
date	93.01.05.16.14.20;	author jont;	state Exp;
branches;
next	1.143;

1.143
date	92.12.24.11.53.01;	author clive;	state Exp;
branches;
next	1.142;

1.142
date	92.12.17.16.39.38;	author matthew;	state Exp;
branches;
next	1.141;

1.141
date	92.12.15.10.48.04;	author clive;	state Exp;
branches;
next	1.140;

1.140
date	92.12.08.11.01.57;	author clive;	state Exp;
branches;
next	1.139;

1.139
date	92.12.03.11.58.29;	author clive;	state Exp;
branches;
next	1.138;

1.138
date	92.12.01.14.52.10;	author daveb;	state Exp;
branches;
next	1.137;

1.137
date	92.11.20.16.28.54;	author daveb;	state Exp;
branches;
next	1.136;

1.136
date	92.11.17.14.31.58;	author matthew;	state Exp;
branches;
next	1.135;

1.135
date	92.11.13.16.26.52;	author clive;	state Exp;
branches;
next	1.134;

1.134
date	92.11.03.11.53.23;	author jont;	state Exp;
branches;
next	1.133;

1.133
date	92.10.30.11.52.00;	author jont;	state Exp;
branches;
next	1.132;

1.132
date	92.10.09.10.53.07;	author clive;	state Exp;
branches;
next	1.131;

1.131
date	92.10.07.12.55.02;	author clive;	state Exp;
branches;
next	1.130;

1.130
date	92.10.05.10.12.36;	author clive;	state Exp;
branches;
next	1.129;

1.129
date	92.09.29.14.24.41;	author clive;	state Exp;
branches;
next	1.128;

1.128
date	92.09.22.11.11.28;	author clive;	state Exp;
branches;
next	1.127;

1.127
date	92.09.16.09.42.47;	author clive;	state Exp;
branches;
next	1.126;

1.126
date	92.09.15.11.36.07;	author clive;	state Exp;
branches;
next	1.125;

1.125
date	92.09.11.14.28.30;	author richard;	state Exp;
branches;
next	1.124;

1.124
date	92.09.09.17.01.55;	author jont;	state Exp;
branches;
next	1.123;

1.123
date	92.09.02.14.34.00;	author jont;	state Exp;
branches;
next	1.122;

1.122
date	92.08.26.16.34.31;	author jont;	state Exp;
branches;
next	1.121;

1.121
date	92.08.26.11.39.55;	author clive;	state Exp;
branches;
next	1.120;

1.120
date	92.08.25.16.19.18;	author richard;	state Exp;
branches;
next	1.119;

1.119
date	92.08.25.13.29.29;	author clive;	state Exp;
branches;
next	1.118;

1.118
date	92.08.14.13.46.12;	author davidt;	state Exp;
branches;
next	1.117;

1.117
date	92.08.07.18.18.38;	author davidt;	state Exp;
branches;
next	1.116;

1.116
date	92.08.04.16.42.39;	author jont;	state Exp;
branches;
next	1.115;

1.115
date	92.07.29.15.58.44;	author jont;	state Exp;
branches;
next	1.114;

1.114
date	92.07.23.15.35.32;	author jont;	state Exp;
branches;
next	1.113;

1.113
date	92.07.16.08.49.59;	author clive;	state Exp;
branches;
next	1.112;

1.112
date	92.07.14.16.16.26;	author richard;	state Exp;
branches;
next	1.111;

1.111
date	92.07.07.13.55.18;	author clive;	state Exp;
branches;
next	1.110;

1.110
date	92.07.03.14.50.53;	author jont;	state Exp;
branches;
next	1.109;

1.109
date	92.07.02.10.50.00;	author jont;	state Exp;
branches;
next	1.108;

1.108
date	92.07.01.17.03.44;	author jont;	state Exp;
branches;
next	1.107;

1.107
date	92.06.30.13.45.31;	author jont;	state Exp;
branches;
next	1.106;

1.106
date	92.06.29.14.37.22;	author jont;	state Exp;
branches;
next	1.105;

1.105
date	92.06.29.13.02.04;	author clive;	state Exp;
branches;
next	1.104;

1.104
date	92.06.25.16.58.11;	author jont;	state Exp;
branches;
next	1.103;

1.103
date	92.06.25.16.01.12;	author richard;	state Exp;
branches;
next	1.102;

1.102
date	92.06.22.13.26.34;	author richard;	state Exp;
branches;
next	1.101;

1.101
date	92.06.19.11.33.32;	author richard;	state Exp;
branches;
next	1.100;

1.100
date	92.06.18.15.19.32;	author jont;	state Exp;
branches;
next	1.99;

1.99
date	92.06.17.17.35.41;	author jont;	state Exp;
branches;
next	1.98;

1.98
date	92.06.17.15.45.18;	author richard;	state Exp;
branches;
next	1.97;

1.97
date	92.06.16.19.50.40;	author jont;	state Exp;
branches;
next	1.96;

1.96
date	92.06.12.17.26.20;	author jont;	state Exp;
branches;
next	1.95;

1.95
date	92.05.26.14.54.00;	author richard;	state Exp;
branches;
next	1.94;

1.94
date	92.05.21.18.13.52;	author jont;	state Exp;
branches;
next	1.93;

1.93
date	92.05.11.15.10.57;	author clive;	state Exp;
branches;
next	1.92;

1.92
date	92.05.11.13.31.13;	author jont;	state Exp;
branches;
next	1.91;

1.91
date	92.05.08.20.17.34;	author jont;	state Exp;
branches;
next	1.90;

1.90
date	92.05.06.10.51.41;	author richard;	state Exp;
branches;
next	1.89;

1.89
date	92.05.05.12.56.24;	author clive;	state Exp;
branches;
next	1.88;

1.88
date	92.04.29.15.27.40;	author jont;	state Exp;
branches;
next	1.87;

1.87
date	92.04.24.15.15.39;	author clive;	state Exp;
branches;
next	1.86;

1.86
date	92.04.14.11.40.10;	author clive;	state Exp;
branches;
next	1.85;

1.85
date	92.04.03.13.07.05;	author jont;	state Exp;
branches;
next	1.84;

1.84
date	92.03.31.17.51.51;	author jont;	state Exp;
branches;
next	1.83;

1.83
date	92.03.10.11.23.44;	author jont;	state Exp;
branches;
next	1.82;

1.82
date	92.03.05.11.28.53;	author clive;	state Exp;
branches;
next	1.81;

1.81
date	92.02.25.18.10.27;	author jont;	state Exp;
branches;
next	1.80;

1.80
date	92.02.11.10.51.10;	author clive;	state Exp;
branches;
next	1.79;

1.79
date	92.02.07.11.09.50;	author richard;	state Exp;
branches;
next	1.78;

1.78
date	92.02.06.14.28.04;	author clive;	state Exp;
branches;
next	1.77;

1.77
date	92.02.06.10.20.03;	author richard;	state Exp;
branches;
next	1.76;

1.76
date	92.02.03.16.57.17;	author clive;	state Exp;
branches;
next	1.75;

1.75
date	92.01.31.14.29.27;	author clive;	state Exp;
branches;
next	1.74;

1.74
date	92.01.24.09.47.39;	author clive;	state Exp;
branches;
next	1.73;

1.73
date	92.01.23.17.20.50;	author clive;	state Exp;
branches;
next	1.72;

1.72
date	92.01.21.15.40.09;	author clive;	state Exp;
branches;
next	1.71;

1.71
date	92.01.17.16.53.38;	author clive;	state Exp;
branches;
next	1.70;

1.70
date	92.01.16.16.24.17;	author clive;	state Exp;
branches;
next	1.69;

1.69
date	92.01.15.15.59.52;	author clive;	state Exp;
branches;
next	1.68;

1.68
date	92.01.15.15.16.56;	author richard;	state Exp;
branches;
next	1.67;

1.67
date	92.01.15.12.03.48;	author clive;	state Exp;
branches;
next	1.66;

1.66
date	92.01.14.15.34.56;	author clive;	state Exp;
branches;
next	1.65;

1.65
date	92.01.13.10.35.44;	author clive;	state Exp;
branches;
next	1.64;

1.64
date	92.01.10.17.39.54;	author clive;	state Exp;
branches;
next	1.63;

1.63
date	92.01.09.15.15.57;	author clive;	state Exp;
branches;
next	1.62;

1.62
date	92.01.08.18.23.55;	author jont;	state Exp;
branches;
next	1.61;

1.61
date	92.01.08.16.30.06;	author clive;	state Exp;
branches;
next	1.60;

1.60
date	92.01.07.16.48.30;	author clive;	state Exp;
branches;
next	1.59;

1.59
date	92.01.06.17.22.27;	author jont;	state Exp;
branches;
next	1.58;

1.58
date	92.01.03.12.49.08;	author richard;	state Exp;
branches;
next	1.57;

1.57
date	92.01.02.13.32.58;	author richard;	state Exp;
branches;
next	1.56;

1.56
date	91.12.19.16.56.30;	author richard;	state Exp;
branches;
next	1.55;

1.55
date	91.12.09.15.23.04;	author richard;	state Exp;
branches;
next	1.54;

1.54
date	91.12.06.17.47.29;	author jont;	state Exp;
branches;
next	1.53;

1.53
date	91.12.05.18.38.53;	author jont;	state Exp;
branches;
next	1.52;

1.52
date	91.12.04.19.15.41;	author jont;	state Exp;
branches;
next	1.51;

1.51
date	91.12.03.15.25.06;	author jont;	state Exp;
branches;
next	1.50;

1.50
date	91.12.02.20.26.17;	author jont;	state Exp;
branches;
next	1.49;

1.49
date	91.11.29.18.26.17;	author jont;	state Exp;
branches;
next	1.48;

1.48
date	91.11.28.18.37.45;	author jont;	state Exp;
branches;
next	1.47;

1.47
date	91.11.28.15.01.30;	author jont;	state Exp;
branches;
next	1.46;

1.46
date	91.11.27.19.42.01;	author jont;	state Exp;
branches;
next	1.45;

1.45
date	91.11.26.15.22.37;	author jont;	state Exp;
branches;
next	1.44;

1.44
date	91.11.25.19.09.05;	author jont;	state Exp;
branches;
next	1.43;

1.43
date	91.11.21.15.15.24;	author jont;	state Exp;
branches;
next	1.42;

1.42
date	91.11.20.17.13.34;	author jont;	state Exp;
branches;
next	1.41;

1.41
date	91.11.20.14.18.32;	author jont;	state Exp;
branches;
next	1.40;

1.40
date	91.11.18.16.24.42;	author jont;	state Exp;
branches;
next	1.39;

1.39
date	91.11.14.15.27.08;	author jont;	state Exp;
branches;
next	1.38;

1.38
date	91.11.14.10.54.50;	author richard;	state Exp;
branches;
next	1.37;

1.37
date	91.11.13.18.48.24;	author jont;	state Exp;
branches;
next	1.36;

1.36
date	91.11.12.16.25.34;	author jont;	state Exp;
branches;
next	1.35;

1.35
date	91.11.11.17.04.51;	author jont;	state Exp;
branches;
next	1.34;

1.34
date	91.11.08.18.21.16;	author jont;	state Exp;
branches;
next	1.33;

1.33
date	91.11.08.16.41.45;	author richard;	state Exp;
branches;
next	1.32;

1.32
date	91.11.08.14.58.09;	author jont;	state Exp;
branches;
next	1.31;

1.31
date	91.10.31.13.28.21;	author jont;	state Exp;
branches;
next	1.30;

1.30
date	91.10.30.17.47.54;	author jont;	state Exp;
branches;
next	1.29;

1.29
date	91.10.29.17.36.16;	author davidt;	state Exp;
branches;
next	1.28;

1.28
date	91.10.29.16.41.39;	author davidt;	state Exp;
branches;
next	1.27;

1.27
date	91.10.29.14.20.40;	author jont;	state Exp;
branches;
next	1.26;

1.26
date	91.10.28.16.10.01;	author richard;	state Exp;
branches;
next	1.25;

1.25
date	91.10.28.15.47.47;	author jont;	state Exp;
branches;
next	1.24;

1.24
date	91.10.28.11.24.52;	author davidt;	state Exp;
branches;
next	1.23;

1.23
date	91.10.25.17.01.51;	author davidt;	state Exp;
branches;
next	1.22;

1.22
date	91.10.24.16.56.42;	author jont;	state Exp;
branches;
next	1.21;

1.21
date	91.10.24.14.21.17;	author jont;	state Exp;
branches;
next	1.20;

1.20
date	91.10.24.10.48.49;	author jont;	state Exp;
branches;
next	1.19;

1.19
date	91.10.23.15.52.18;	author jont;	state Exp;
branches;
next	1.18;

1.18
date	91.10.22.18.15.06;	author jont;	state Exp;
branches;
next	1.17;

1.17
date	91.10.22.15.25.38;	author jont;	state Exp;
branches;
next	1.16;

1.16
date	91.10.21.15.51.53;	author jont;	state Exp;
branches;
next	1.15;

1.15
date	91.10.18.18.24.37;	author jont;	state Exp;
branches;
next	1.14;

1.14
date	91.10.18.16.23.30;	author jont;	state Exp;
branches;
next	1.13;

1.13
date	91.10.17.17.57.34;	author jont;	state Exp;
branches;
next	1.12;

1.12
date	91.10.16.14.13.33;	author jont;	state Exp;
branches;
next	1.11;

1.11
date	91.10.15.17.20.04;	author jont;	state Exp;
branches;
next	1.10;

1.10
date	91.10.14.15.03.10;	author jont;	state Exp;
branches;
next	1.9;

1.9
date	91.10.11.17.37.55;	author jont;	state Exp;
branches;
next	1.8;

1.8
date	91.10.11.10.59.31;	author richard;	state Exp;
branches;
next	1.7;

1.7
date	91.10.10.16.48.34;	author jont;	state Exp;
branches;
next	1.6;

1.6
date	91.10.10.15.15.38;	author jont;	state Exp;
branches;
next	1.5;

1.5
date	91.10.09.18.30.23;	author jont;	state Exp;
branches;
next	1.4;

1.4
date	91.10.08.19.05.25;	author jont;	state Exp;
branches;
next	1.3;

1.3
date	91.10.07.16.35.29;	author jont;	state Exp;
branches;
next	1.2;

1.2
date	91.10.07.12.16.04;	author richard;	state Exp;
branches;
next	1.1;

1.1
date	91.10.04.16.19.17;	author jont;	state Exp;
branches;
next	;

1.163.1.1
date	93.08.26.13.19.57;	author jont;	state Exp;
branches;
next	1.163.1.2;

1.163.1.2
date	93.10.05.13.24.30;	author jont;	state Exp;
branches;
next	;

1.231.1.1
date	96.09.13.11.26.30;	author hope;	state Exp;
branches;
next	;

1.231.2.1
date	96.10.07.16.17.01;	author hope;	state Exp;
branches;
next	;

1.231.3.1
date	96.10.17.11.36.40;	author hope;	state Exp;
branches;
next	;

1.234.1.1
date	96.11.14.13.04.38;	author hope;	state Exp;
branches
	1.234.1.1.1.1;
next	;

1.234.1.1.1.1
date	96.11.28.15.14.04;	author hope;	state Exp;
branches;
next	;

1.234.2.1
date	96.11.22.18.22.06;	author hope;	state Exp;
branches;
next	;

1.234.3.1
date	96.12.17.18.00.03;	author hope;	state Exp;
branches
	1.234.3.1.1.1;
next	;

1.234.3.1.1.1
date	97.02.24.11.51.43;	author hope;	state Exp;
branches;
next	;

1.234.4.1
date	96.12.18.09.55.26;	author hope;	state Exp;
branches;
next	;

1.239.1.1
date	97.05.12.10.50.07;	author hope;	state Exp;
branches
	1.239.1.1.1.1
	1.239.1.1.2.1
	1.239.1.1.3.1;
next	;

1.239.1.1.1.1
date	97.07.28.18.32.20;	author daveb;	state Exp;
branches
	1.239.1.1.1.1.1.1;
next	;

1.239.1.1.1.1.1.1
date	97.10.07.11.58.27;	author jkbrook;	state Exp;
branches;
next	;

1.239.1.1.2.1
date	97.09.08.17.25.35;	author daveb;	state Exp;
branches;
next	;

1.239.1.1.3.1
date	97.09.09.14.22.13;	author daveb;	state Exp;
branches;
next	;

1.244.1.1
date	97.09.10.19.41.17;	author brucem;	state Exp;
branches;
next	;

1.244.2.1
date	97.09.11.21.08.53;	author daveb;	state Exp;
branches;
next	1.244.2.2;

1.244.2.2
date	97.11.20.17.09.12;	author daveb;	state Exp;
branches;
next	;

1.248.1.1
date	99.04.01.18.07.43;	author daveb;	state Exp;
branches;
next	;


desc
@The machine dependent code generator for Sparc
@


1.248
log
@[Bug #30349]
Fix to avoid non-unit sequence warnings
@
text
@(* _mach_cg.sml the functor *)
(*
$Log: _mach_cg.sml,v $
 * Revision 1.247  1998/01/30  09:48:22  johnh
 * [Bug #30326]
 * Merge in change from branch MLWorks_workspace_97
 *
 * Revision 1.246  1997/11/13  11:21:00  jont
 * [Bug #30089]
 * Modify TIMER (from utils) to be INTERNAL_TIMER to keep bootstrap happy
 *
 * Revision 1.245  1997/09/18  16:28:48  brucem
 * [Bug #30153]
 * Remove references to Old.
 *
 * Revision 1.244.2.2  1997/11/20  17:09:12  daveb
 * [Bug #30326]
 *
 * Revision 1.244.2.1  1997/09/11  21:08:53  daveb
 * branched from trunk for label MLWorks_workspace_97
 *
 * Revision 1.244  1997/08/07  14:54:35  jont
 * [Bug #30243]
 * Remove tests for out of range shifts as we no longer generate them
 *
 * Revision 1.243  1997/08/06  12:16:36  jont
 * [Bug #50027]
 * Sort out bugs in NOT and NOT32 of constant (not that these should happen)
 *
 * Revision 1.242  1997/08/04  16:26:46  jont
 * [Bug #30215]
 * Remove BIC in favour of INTTAG
 *
 * Revision 1.241  1997/05/30  11:52:29  jont
 * [Bug #30076]
 * Modifications to allow stack based parameter passing on the I386
 *
 * Revision 1.240  1997/05/19  12:36:03  jont
 * [Bug #30090]
 * Translate output std_out to print
 *
 * Revision 1.239  1997/03/26  14:06:50  matthew
 * Reorder registers in integer multiply
 *
 * Revision 1.238  1997/01/31  16:55:51  matthew
 * Adding static flag to scheduler
 *
 * Revision 1.237  1997/01/23  14:14:33  jont
 * Modifying to protect allocate from lr, and redo switch to allow lr
 * except in leaf case
 *
 * Revision 1.236  1997/01/17  17:23:23  matthew
 * Adding multiply instructions
 *
 * Revision 1.235  1997/01/16  16:41:55  matthew
 * Changed tag option to tag list in tagged instructions
 *
 * Revision 1.234  1996/11/06  14:38:45  jont
 * [Bug #1730]
 * Sort out problem in FP_SPILL_SLOT calculation.
 *
 * Revision 1.233  1996/11/06  11:10:19  matthew
 * [Bug #1728]
 * __integer becomes __int
 *
 * Revision 1.232  1996/10/09  14:14:06  io
 * moving String from toplevel
 *
 * Revision 1.231  1996/08/01  12:22:44  jont
 * [Bug #1503]
 * Add field to FUNINFO to say if arg actually saved
 *
 * Revision 1.230  1996/05/30  12:38:46  daveb
 * The Ord exception is no longer at top level.
 *
 * Revision 1.229  1996/05/17  09:43:47  matthew
 * Moved Bits to MLWorks.Internal
 *
 * Revision 1.228  1996/05/14  10:44:37  matthew
 * Adding NOT32 MIR instruction
 *
 * Revision 1.227  1996/05/10  09:55:02  matthew
 * Fixing problem with unsigned comparison
 *
 * Revision 1.226  1996/05/07  11:13:49  jont
 * Array moving to MLWorks.Array
 *
 * Revision 1.225  1996/04/30  17:05:20  jont
 * String functions explode, implode, chr and ord now only available from String
 * io functions and types
 * instream, oustream, open_in, open_out, close_in, close_out, input, output and end_of_stream
 * now only available from MLWorks.IO
 *
 * Revision 1.224  1996/04/29  15:31:34  matthew
 * removing MLWorks.Integer
 *
 * Revision 1.223  1996/02/02  12:58:58  jont
 * Add implemetatins of ADDW and SUBW
 * These are like ADDS and SUBS, except that
 * they cannot use TADD etc because they are untagged
 * and also when they detect overflow they must clean
 * all registers involved in the operation
 *
Revision 1.222  1995/12/22  13:10:25  jont
Add extra field to procedure_parameters to contain old (pre register allocation)
spill sizes. This is for the i386, where spill assignment is done in the backend

Revision 1.221  1995/11/20  17:06:35  jont
Modification for improved runtime env spill offsets
to indicate the kind of data spilled

Revision 1.220  1995/09/22  15:53:01  jont
Fix bug in compiler crash when number of fp spill slots exceeded

Revision 1.219  1995/08/10  14:50:28  jont
Fix constant unsigned comparison case of MirTypes.TEST

Revision 1.218  1995/07/28  10:13:27  matthew
Putting sources registers for various instructions in correct order

Revision 1.217  1995/07/28  03:01:51  io
mirtypes.test confuses imm32 case

Revision 1.216  1995/07/25  13:47:19  jont
Add WORD to value_cg

Revision 1.215  1995/07/19  12:04:01  jont
Add CHAR to value_cg

Revision 1.214  1995/07/11  16:19:37  jont
Sort out shifts as per revised basis with range testing etc.

Revision 1.213  1995/05/26  14:07:20  matthew
Commenting out diagnostic stuff

Revision 1.212  1995/05/24  09:44:43  matthew
Adding needs_unaligned_zero

Revision 1.211  1995/05/02  11:33:19  matthew
Removing debug_polyvariables option

Revision 1.210  1995/02/15  12:35:13  matthew
Debugger_Types changes
Abstraction of debug information
Annotate CALL instruction

Revision 1.209  1995/01/30  14:54:52  matthew
Rationalizing debugger

Revision 1.208  1994/11/28  16:52:25  matthew
Change "real too big" message to "real unrepresentable"

Revision 1.207  1994/11/28  15:14:49  matthew
Fix problem with floor.

Revision 1.206  1994/11/23  13:24:33  matthew
Add ALLOC_VECTOR

Revision 1.205  1994/11/16  12:16:44  jont
Add support for immediate store operation

Revision 1.204  1994/10/13  11:23:04  matthew
Use pervasive Option.option for return values in NewMap

Revision 1.203  1994/10/05  12:02:37  jont
Changes for new NEW_HANDLER instruction

Revision 1.202  1994/09/23  11:43:20  matthew
Abstraction of debug information

Revision 1.201  1994/09/12  15:51:21  jont
Handle constant operands to tests

Revision 1.200  1994/09/02  15:27:11  jont
Remove checks for lr used in ALLOC

Revision 1.199  1994/08/26  14:05:39  matthew
Change to interface to stack extension

Revision 1.198  1994/08/24  16:17:04  jont
Remove dependence on mir optimiser for fp registers used

Revision 1.197  1994/07/25  11:07:05  matthew
Added register lists to BRANCH_AND_LINK, TAIL_CALL and ENTER instructions.

Revision 1.196  1994/07/22  16:04:48  nickh
Add new allocation routine.

Revision 1.195  1994/07/22  15:03:04  jont
Modify for new code_module

Revision 1.194  1994/07/13  12:05:57  jont
Fix to avoid lr unspilling alloc

Revision 1.193  1994/06/24  14:17:36  jont
Updates to use lr as unspill register

Revision 1.192  1994/06/22  14:50:27  jont
Update debugger information production

Revision 1.191  1994/06/22  13:48:32  jont
Added leaf case switches

Revision 1.190  1994/06/13  09:51:41  nickh
New runtime directory structure.

Revision 1.189  1994/06/10  09:49:51  jont
Restore floating point callee saves before tailing

Revision 1.188  1994/05/27  15:11:34  jont
Modify fp_save_start to be calculated from fp_save_offset, fp_save_size
and float_value_size, ensuring double alignment if necessary

Revision 1.187  1994/05/25  10:23:21  jont
Fix shift of constant by constant problems

Revision 1.186  1994/05/23  17:23:50  jont
Fix floating point spill alignment problem

Revision 1.185  1994/05/12  13:40:24  richard
Add loop entry to MirTypes.PROC_PARAMS.

Revision 1.184  1994/04/07  09:52:05  jont
Fixed stack initialisation to cope with starting on a non-aligned boundary

Revision 1.183  1994/03/24  14:00:25  jont
Work on avoiding initialisation of stack slots

Revision 1.182  1994/03/23  16:15:12  matthew
Changed the other restore instruction.

Revision 1.181  1994/03/23  15:29:11  nickh
Fix restore instruction to match that commonly generated.

Revision 1.180  1994/03/18  18:43:33  jont
Fix bug introduced in fp register saving by stack rationalisation

Revision 1.179  1994/03/18  12:34:42  jont
Fix bug in float spill area alignment
Rationalise stack layout information

Revision 1.178  1994/03/11  12:09:36  jont
Fix code generation of LEO for mutually recursive function case

Revision 1.177  1994/03/09  17:16:42  jont
Added code generation of load_offset.
Added handling of case where load_offset can't be one instruction
similar to case where adr expands to more than one

Revision 1.176  1994/03/08  18:20:01  jont
Remove module type to separate file

Revision 1.175  1994/03/04  12:42:20  jont
Moved machspec into main

Revision 1.174  1994/02/28  09:40:45  nosa
Debugger_info for some more debugger options.

Revision 1.173  1994/02/25  13:54:18  daveb
Preventing generation of unnecessary debug information.

Revision 1.172  1994/01/18  11:45:50  daveb
Dummy entry to keep in synch with Hope, after I accidentally checked in
an unchanged version to Hope.

Revision 1.171  1994/01/18  11:45:50  daveb
Added comment to FLOOR case.

Revision 1.171  1994/01/18  11:20:54  daveb
Added comment to FLOOR case.

Revision 1.170  1993/12/17  10:38:42  io
moved mach_cg to main/

Revision 1.169  1993/12/10  13:57:30  jont
Put in Simon's suggestions to use a common large number splitting
mechanism throughout, and spot the previously non-optimal case

Revision 1.168  1993/11/22  12:47:10  daveb
Replaced TADDCC instruction with TADDCCTV, and removed explicit exception
handling from built-in arithmetic operators.

Revision 1.167  1993/11/05  16:17:39  jont
Added proper compilation of INTERRUPT instruction

Revision 1.166  1993/11/04  16:46:11  jont
Added (currently trivial) code generation of INTERRUPT instruction

Revision 1.165  1993/10/05  17:07:34  jont
Merged in bug fixes

Revision 1.164  1993/09/06  09:51:10  nosa
Record compiler option debug_polyvariables in Debugger_Types.INFO
for recompilation purposes.

Revision 1.163.1.2  1993/10/05  13:24:30  jont
Put a handler around the part of value_cg dealing with reals to turn
conversion errors into compilation errors

Revision 1.163.1.1  1993/08/26  13:19:57  jont
Fork for bug fixing

Revision 1.163  1993/08/26  13:19:57  jont
Modified leaf test to look at the actual registers used by a function
rather than believing the output from the mir optimiser

Revision 1.162  1993/08/13  14:01:15  simon
Fixed extended-float save and restore.

Revision 1.161  1993/08/06  14:31:34  richard
Made NEW_HANDLER instruction force non-leaf.

Revision 1.160  1993/07/29  15:37:17  nosa
Debugger Environments and extra stack spills for local and closure
variable inspection in the debugger;
structure Option.

Revision 1.159  1993/07/23  16:12:49  jont
Fixed code generation of large integers to avoid stamping on other operands
by using G4 only when safe and using the result register otherwise.

Revision 1.158  1993/07/08  18:08:13  jont
Modified the TBINARY operations to shorten the normal (non-exceptional) path

Revision 1.157  1993/05/18  16:22:48  jont
Removed integer parameter

Revision 1.156  1993/05/05  12:03:31  jont
Improved coding of MirTypes.ENTRY so that simple stack requiring procedures
have a one instruction shorter entry sequence

Revision 1.155  1993/04/27  10:58:48  richard
Changed PROFILE instruction to INTERCEPT.

Revision 1.154  1993/04/19  09:59:24  jont
Added leaf raise code

Revision 1.153  1993/04/16  16:03:30  jont
Added some important comments about adr

Revision 1.152  1993/04/15  12:05:08  jont
OLD_HANDLER now generates handler chain pop

Revision 1.151  1993/03/23  16:04:31  jont
Changed bytearray implementation to use ref tags. Tidied up some
explicit integers into references to TAGS

Revision 1.150  1993/03/17  18:22:07  jont
Produced leaf and code vector intercept offset for each procedure
and added this into WORDSET

Revision 1.149  1993/03/12  11:49:59  matthew
Signature revisions

Revision 1.148  1993/03/05  12:57:26  matthew
Options & Info changes

Revision 1.147  1993/03/01  15:27:33  matthew
Changed value datatype
Added MLVALUEs

Revision 1.146  1993/02/10  13:58:35  jont
Changes for code vector reform.

Revision 1.145  1993/01/28  14:49:43  jont
Improved code generation of switches. Improved code generation of
sequences near calls and tails to allow better scheduling

Revision 1.144  1993/01/05  16:14:20  jont
Modified to return final machine code in an easily printed form

Revision 1.143  1992/12/24  11:53:01  clive
Fixed small bugs in arithmetic of two immediates

Revision 1.142  1992/12/17  16:39:38  matthew
Changed int and real scons to carry a location around

Revision 1.141  1992/12/15  10:48:04  clive
Raised Info.errors for overflow of constants during code generation

Revision 1.140  1992/12/08  11:01:57  clive
Changed the type of nop used for tracing to stop it being moved by the scheduler

Revision 1.139  1992/12/03  11:58:29  clive
Changed the sense of the branch in the stack-overflow checking code

Revision 1.138  1992/12/01  14:52:10  daveb
Changes to propagate compiler options as parameters instead of references.

Revision 1.137  1992/11/20  16:28:54  daveb
Replaced a call to Print.print with one to Diagnostic.output.

Revision 1.136  1992/11/17  14:31:58  matthew
Changed Error structure to Info

Revision 1.135  1992/11/13  16:26:52  clive
Added the generation of 3 NOP instructions for the purposes of tracing
(if the correct flag is set to true )

Revision 1.134  1992/11/03  11:53:23  jont
Reworked in terms of mononewmap

Revision 1.133  1992/10/30  11:52:00  jont
Changed maps used on tags to that provided by mirtypes for efficiency

Revision 1.132  1992/10/09  10:53:07  clive
Fixed bug in the size put in the header of a double

Revision 1.131  1992/10/07  12:55:02  clive
check_range did an abs which failed on most negative integer

Revision 1.130  1992/10/05  10:12:36  clive
Change to NewMap.empty which now takes < and = functions instead of the single-function

Revision 1.129  1992/09/29  14:24:41  clive
Got floor working

Revision 1.128  1992/09/22  11:11:28  clive
When ordof used, the exception in Ord needed to be caught instead of substring

Revision 1.127  1992/09/16  09:42:47  clive
Removed some handles of hashtable lookup exceptions

Revision 1.126  1992/09/15  11:36:07  clive
Added argument value checking to floor

Revision 1.125  1992/09/11  14:28:30  richard
Created a type `information' which wraps up the debugger information
needed in so many parts of the compiler.

Revision 1.124  1992/09/09  17:01:55  jont
Made all moves use OR instead of ADD

Revision 1.123  1992/09/02  14:34:00  jont
Changed mir register to mach register translation to array lookup

Revision 1.122  1992/08/26  16:34:31  jont
Removed some redundant structures and sharing

Revision 1.121  1992/08/26  11:39:55  clive
Samm bug fix - debug info was incremented but not stored back

Revision 1.120  1992/08/25  16:19:18  richard
Implemented ALLOC_BYTEARRAY, and the NULLARY operation CLEAN.

Revision 1.119  1992/08/25  13:29:29  clive
Added details about leafness to the debug information

Revision 1.118  1992/08/14  13:46:12  davidt
Changed ord(substring ...) to ordof.

Revision 1.117  1992/08/07  18:18:38  davidt
String structure is now pervasive.

Revision 1.116  1992/08/04  16:42:39  jont
Removed references to save

Revision 1.115  1992/07/29  15:58:44  jont
Added floating point save and restore code

Revision 1.114  1992/07/23  15:35:32  jont
Removed some messages

Revision 1.113  1992/07/16  08:49:59  clive
Corrected an uncaught MLWorks.String.Substring

Revision 1.112  1992/07/14  16:16:26  richard
Removed obsolete memory profiling code.

Revision 1.111  1992/07/07  13:55:18  clive
Added call point information recording

Revision 1.110  1992/07/03  14:50:53  jont
Modified stack clearing code to use double wort stores where possible

Revision 1.109  1992/07/02  10:50:00  jont
Allowed translation of tagged binary operations where both arguments
are constant

Revision 1.108  1992/07/01  17:03:44  jont
Fixed leaf case profiling so it refers to the correct closure register

Revision 1.107  1992/06/30  13:45:31  jont
Made TAIL_CALL allowable in leaf procedures

Revision 1.106  1992/06/29  14:37:22  jont
Changed to build sexpressions in order to avoid quadratic behaviour
of appends

Revision 1.105  1992/06/29  13:02:04  clive
Added type annotation information at application points

Revision 1.104  1992/06/25  16:58:11  jont
Corrected code to generate unary not. Split out of code for move

Revision 1.103  1992/06/25  16:01:12  richard
Reimplemented the allocation code to deal with large
constant-sized objects.  Also corrected some problems with
variable-sized objects.  The code should now be smaller and
faster.

Revision 1.102  1992/06/22  13:26:34  richard
Implemented tagged floating point instructions.  At the moment
they do not catch infinity.

Revision 1.101  1992/06/19  11:33:32  richard
Added parameter to RAISE once again, and changed leaf-case raise
to fetch from that parameter.

Revision 1.100  1992/06/18  15:19:32  jont
Added stuff to pass through interpretive externals,
and split raise code into leaf and non-leaf cases

Revision 1.99  1992/06/17  17:35:41  jont
Allowed leaf case raise. Doesn't work yet because of mirtables

Revision 1.98  1992/06/17  15:45:18  richard
Enabled leaf case allocation.

Revision 1.97  1992/06/16  19:50:40  jont
Changed stack overflow check to be unsigned.
Added (temporary) handling for externals defined by interpreter

Revision 1.96  1992/06/12  17:26:20  jont
Improved profiling so as not to affect leafness
Removed various redundant loads (should be expression analyser)

Revision 1.95  1992/05/26  14:54:00  richard
Changed gc_trans to deal with new types returned by MirTables.

Revision 1.94  1992/05/21  18:13:52  jont
Fixed problem in enter coding to ensure stack slots cleared.

Revision 1.93  1992/05/11  15:10:57  clive
Added memory profiling

Revision 1.92  1992/05/11  13:31:13  jont
Fixed up discrepancy between split_int and gp_check_range

Revision 1.91  1992/05/08  20:17:34  jont
Added bool ref do_timings to control printing of timings for various stages

Revision 1.90  1992/05/06  10:51:41  richard
Changed BalancedTree to generic Map

Revision 1.89  1992/05/05  12:56:24  clive
With the addition of the extra slots in the code and the addition of diagnostic information,
the tag offset calculations needed to be changed

Revision 1.88  1992/04/29  15:27:40  jont
Redid the reorderer for the lineariser efficiently

Revision 1.87  1992/04/24  15:15:39  clive
Fixed bug in array allocation: if a gc occurred inside the allocation, 2 words too few were allocated
Also added function name printing to the sparc code output

Revision 1.86  1992/04/14  11:40:10  clive
First version of the profiler

Revision 1.85  1992/04/03  13:07:05  jont
Removed some pervasive references to hd, length etc. Added a type
specifier to an overloaded use of +. Added error detection for
incorrect stack allocations

Revision 1.84  1992/03/31  17:51:51  jont
Forced relinearisation to fix up out of range ADRs to recalculate
the tag table

Revision 1.83  1992/03/10  11:23:44  jont
Fixed up problem with out of range ADR instructions by recursing the
lineariser

Revision 1.82  1992/03/05  11:28:53  clive
If there is a word added for double alignment, then this needs to be zeroed out
before it confuses the garbage collector

Revision 1.81  1992/02/25  18:10:27  jont
Added checking on the use use spill slots. Also avoided using
spill slot 0 as the address of the gc stack area.

Revision 1.80  1992/02/11  10:51:10  clive
New pervasive library code

Revision 1.79  1992/02/07  11:09:50  richard
Changed register lookup to use Map instead of Table.  See changes in
MirRegisters.  See mirregisters.sml revision 1.13.

Revision 1.78  1992/02/06  14:28:04  clive
Tail call to a tag had a baa followed by a restore instead of ba followed by restore

Revision 1.77  1992/02/06  10:20:03  richard
Removed obsolete PRESERVE_ALL_REGS and PREVIOUS_ENVIRONMENT
MIR instructions.

Revision 1.76  1992/02/03  16:57:17  clive
Tried to speed the file up (factor of 2-3) - removed invariant code
from function calls

Revision 1.75  1992/01/31  14:29:27  clive
Removed some redundant code

Revision 1.74  1992/01/24  09:47:39  clive
Fixed computed gotos

Revision 1.73  1992/01/23  17:20:50  clive
Removed the dummy instruction that is pushed onto blocks of the wrong size
to double-word align them - this is done elsewhere, and the blocks were
being thrown away anyway

Revision 1.72  1992/01/21  15:40:09  clive
Allocation wasn't working correctly

Revision 1.71  1992/01/17  16:53:38  clive
Added alignment check for alloc of an array

Revision 1.70  1992/01/16  16:24:17  clive
Added things needed to support arrays - rearranged link fields in references,
changed so that ALLOC(REF) can take a register value argument

Revision 1.69  1992/01/15  15:59:52  clive
TAIL_CALL of register had an offset of 4 instead of an offset of 3 (typo)

Revision 1.68  1992/01/15  15:16:56  richard
Added a missing factor of four when jumping to the raise code.

Revision 1.67  1992/01/15  12:03:48  clive
Code bodies tagged incorrectly with non_gc_spill_size instead of non_gc_stack_size

Revision 1.66  1992/01/14  15:34:56  clive
Added a non_gc number in front of each code object in a closure,
Got mutually recursive functions working as there were problems with
alignment in the existing implementation

Revision 1.65  1992/01/13  10:35:44  clive
A working version of the stack checking code, calling code on the implicit vector

Revision 1.64  1992/01/10  17:39:54  clive
More code for the stack limit checking added

Revision 1.63  1992/01/09  15:15:57  clive
Added check for header actually fitting immediate in do_header, and work on stack_limit
checking code

Revision 1.62  1992/01/08  18:23:55  jont
Added require for implicit

Revision 1.61  1992/01/08  16:30:06  clive
Started work on runtime stack limit checking, now gets offsets in implicit vector
from the structure defined in rts, adr took no notice of the tag argument

Revision 1.60  1992/01/07  16:48:30  clive
Started adding stack limit code on procedure entry

Revision 1.59  1992/01/06  17:22:27  jont
Changed all prints to Print.print

Revision 1.58  1992/01/03  12:49:08  richard
Added code to call ml_preserve for the PRESERVE opcode.

Revision 1.57  1992/01/02  13:32:58  richard
Removed the SAVE instruction generated by the PRESERVE instruction.
This will need to be replaced with something useful at some point.

Revision 1.56  1991/12/19  16:56:30  richard
Changed offsets in CALL instructions to point
to the right place.

Revision 1.55  91/12/09  15:23:04  richard
Added a missing NOP after the in-line CALL_C code.

Revision 1.54  91/12/06  17:47:29  jont
Removed some superfluous debugging output

Revision 1.53  91/12/05  18:38:53  jont
Fixed code to do stack initialisation, and added more optimal versions
where the size is small.

Revision 1.52  91/12/04  19:15:41  jont
Improved coding for tail calls by putting restore in delay slot

Revision 1.51  91/12/03  15:25:06  jont
Improved lineariser slightly

Revision 1.50  91/12/02  20:26:17  jont
Added implementation of tail call

Revision 1.49  91/11/29  18:26:17  jont
Fixed minor bug in continuation block spotting

Revision 1.48  91/11/28  18:37:45  jont
Added stack initialisation of gc areas.

Revision 1.47  91/11/28  15:01:30  jont
Fixed problem of procedures without exits (eg fun f x = raise Match)

Revision 1.46  91/11/27  19:42:01  jont
Improved lineariser by spotting blocks terminating with branches with
delay slots

Revision 1.45  91/11/26  15:22:37  jont
*** empty log message ***

Revision 1.44  91/11/25  19:09:05  jont
Minor changes. Experimenting with save/restore optimisation

Revision 1.43  91/11/21  15:15:24  jont
Added reference to save for optimising save/restore use (perhaps)

Revision 1.42  91/11/20  17:13:34  jont
Moved some functions out into MachTypes

Revision 1.41  91/11/20  14:18:32  jont
Changed coding of conversion operations
Added (unimplemented) exception generating fp opcodes

Revision 1.40  91/11/18  16:24:42  jont
Implemented FTEST. Added it to the lineariser

Revision 1.39  91/11/14  15:27:08  jont
Added more real stuff, plus translation of new CALL_C

Revision 1.38  91/11/14  10:54:50  richard
Removed references to fp_double registers.

Revision 1.37  91/11/13  18:48:24  jont
Added more floating point, unary, binary, more stores. Also added
support for symbolic values

Revision 1.36  91/11/12  16:25:34  jont
Added real loads, stores and conversion operations

Revision 1.35  91/11/11  17:04:51  jont
Added encoding and output of reals

Revision 1.34  91/11/08  18:21:16  jont
Added code for STACK_OPs. Added show_mach for controlling opcode listing

Revision 1.33  91/11/08  16:41:45  richard
Added extra argument to STACKOP, as yet unimplemented.

Revision 1.32  91/11/08  14:58:09  jont
Corrected pointers produced by ALLOCATE_STACK to be correctly tagged

Revision 1.31  91/10/31  13:28:21  jont
Added ALLOC_REAL

Revision 1.30  91/10/30  17:47:54  jont
Added ALLOCATE_STACK coding, plus use of various stack sizes provided
by previous stage.

Revision 1.29  91/10/29  17:36:16  davidt
Fixed printing of sparc assembly code.

Revision 1.28  91/10/29  16:41:39  davidt
Does proper check to see whether a preserve is required. Changed
various prints to Print.prints.

Revision 1.27  91/10/29  14:20:40  jont
Added improved linearisation top block choice.

Revision 1.26  91/10/28  16:10:01  richard
Changed the structure of the allocation instructions yet again. This
change is to allow offsets to be inserted for stack allocation. It's
also a bit more orthogonal.

Revision 1.25  91/10/28  15:47:47  jont
Fixed bug in instruction swapping where store interactions might occur
Added large constant handling everywhere
Started on better algorithm for choosing best next block for lineariser

Revision 1.24  91/10/28  11:24:52  davidt
Changed code generated for ALLOCATE to use the implicit vector to
call the garbage collector instead of having the garbage collector
mentioned in the function closure.

Revision 1.23  91/10/25  17:01:51  davidt
General tidy up and re-implementation of allocation code to use
the garbage collector entry point contained in the the implicit
vector. The global register is now used as a temporary so we
don't need a special temporary register (or call_c code either).

Revision 1.22  91/10/24  16:56:42  jont
Started adding code to deal with constants too large for the
instructions which require them.

Revision 1.21  91/10/24  14:21:17  jont
Updated to use the results of the instruction scheduler

Revision 1.20  91/10/24  10:48:49  jont
Added BTA and BNT for tagged value testing

Revision 1.19  91/10/23  15:52:18  jont
Added range checking on immediate values

Revision 1.18  91/10/22  18:15:06  jont
Added fall through branch elimination, along with block reordering
to make this more likely

Revision 1.17  91/10/22  15:25:38  jont
Added code to attempt fall through elimination.
Fixed faulty encoding of RESTORE

Revision 1.16  91/10/21  15:51:53  jont
Handled cgt. Modified call to strip out tag bits

Revision 1.15  91/10/18  18:24:37  jont
Got strings and procs incorrect order (strings first)

Revision 1.14  91/10/18  16:23:30  jont
Coded ALLOC_STRING.

Revision 1.13  91/10/17  17:57:34  jont
Revised code generation for linearisation to allow for mutually
recusrive functions. New ALLOC in place, ready for real calls to c

Revision 1.12  91/10/16  14:13:33  jont
Updated to reflect new simplified module structure
Added parameter to heap allocation to indicate position in closure
of call_c function

Revision 1.11  91/10/15  17:20:04  jont
Added code encapsulation code

Revision 1.10  91/10/14  15:03:10  jont
Got leaf procedures working. Optimised out MOV to self.
Did tagged operations and exception raising.

Revision 1.9  91/10/11  17:37:55  jont
Did load/store with register indexing, and reverse subtracts.
Also added stuff to spot procedures not requiring frames.

Revision 1.8  91/10/11  10:59:31  richard
Slight alterations to cope with new MirTypes.

Revision 1.7  91/10/10  16:48:34  jont
Added support for adr, and added delay slots to CALLs and JMPLs

Revision 1.6  91/10/10  15:15:38  jont
Added BLR and BSR. Altered to use new improved MirTypes

Revision 1.5  91/10/09  18:30:23  jont
More code generation, plus comments and linearisation

Revision 1.4  91/10/08  19:05:25  jont
More work on proc_cg
Pased results out into module structure

Revision 1.3  91/10/07  16:35:29  jont
Started on proc_cg

Revision 1.2  91/10/07  12:16:04  richard
Changed dependencies on MachRegisters to MachSpec.

Revision 1.1  91/10/04  16:19:17  jont
Initial revision

Copyright (c) 1991 Harlequin Ltd.
*)

require "$.basis.__int";
require "$.basis.__string";

require "../utils/print";
require "../utils/mlworks_timer";
require "../utils/lists";
require "../utils/crash";
require "../utils/diagnostic";
require "../utils/sexpr";
require "../basics/ident";
require "../main/reals";
require "../main/code_module";
require "../mir/mirtables";
require "../mir/mirregisters";
require "../rts/gen/implicit";
require "../rts/gen/tags";
require "../main/info";
require "../main/options";
require "../main/machspec";
require "sparc_schedule";
require "../main/mach_cg";

functor Mach_Cg(
  structure Tags : TAGS
  structure Print : PRINT
  structure Timer : INTERNAL_TIMER
  structure Lists : LISTS
  structure Crash : CRASH
  structure Info : INFO
  structure Options : OPTIONS
  structure Sexpr : SEXPR
  structure Reals : REALS
  structure Ident : IDENT
  structure MirTables : MIRTABLES
  structure MirRegisters : MIRREGISTERS
  structure MachSpec : MACHSPEC
  structure Code_Module : CODE_MODULE
  structure Sparc_Schedule : SPARC_SCHEDULE
  structure Implicit_Vector : IMPLICIT_VECTOR
  structure Diagnostic : DIAGNOSTIC

  sharing Info.Location = Ident.Location
  sharing MirTables.MirTypes.Set = MachSpec.Set
  sharing MirTables.MirTypes = MirRegisters.MirTypes = Sparc_Schedule.Sparc_Assembly.MirTypes

  sharing type Ident.SCon = MirTables.MirTypes.SCon

  sharing type Sparc_Schedule.Sparc_Assembly.Sparc_Opcodes.MachTypes.Sparc_Reg
    = MachSpec.register
     ) : MACH_CG =
struct
  structure Sparc_Assembly = Sparc_Schedule.Sparc_Assembly
  structure Sparc_Opcodes = Sparc_Assembly.Sparc_Opcodes
  structure MirTypes = MirTables.MirTypes
  structure MachTypes = Sparc_Opcodes.MachTypes
  structure MachSpec = MachSpec
  structure Diagnostic = Diagnostic
  structure Debugger_Types = MirTypes.Debugger_Types
  structure Map = MirTypes.Map
  structure Ident = Ident
  structure Set = MirTypes.Set
  structure Info = Info
  structure RuntimeEnv = Debugger_Types.RuntimeEnv
  structure Options = Options

  structure Bits = MLWorks.Internal.Bits

  type Module = Code_Module.Module
  type Opcode = Sparc_Assembly.opcode

  val do_timings = ref false

  val trace_dummy_instructions =
    [(Sparc_Assembly.other_nop_code,NONE,"Dummy instructions for tracing"),
     (Sparc_Assembly.other_nop_code,NONE,"Dummy instructions for tracing"),
     (Sparc_Assembly.other_nop_code,NONE,"Dummy instructions for tracing")]

  val do_diagnostic = false
  fun diagnostic_output level =
    if do_diagnostic then Diagnostic.output level else fn f => ()

  val print_code_size = ref false

  val arith_imm_limit = 4096 (* 2 ** 12 *)
  val branch_disp_limit = 512 * 4096 (* 2 ** 21 *)
  val call_disp_limit = 16 * 256 * 256 * 256 (* 2 ** 28 *)

  (* Note that this has been reduced in order to stay positive within *)
  (* our system, which allows30 bit signed integers *)

  fun contract_sexpr(Sexpr.NIL, [], acc) =
    Lists.reducel (fn (x, y) => y @@ x) ([], acc)
    | contract_sexpr(Sexpr.NIL, x :: xs, acc) = contract_sexpr(x, xs, acc)
    | contract_sexpr(Sexpr.ATOM x, to_do, acc) =
      contract_sexpr(Sexpr.NIL, to_do, x :: acc)
    | contract_sexpr(Sexpr.CONS(x, y), to_do, acc) =
      contract_sexpr(x, y :: to_do, acc)

  val contract_sexpr =
    fn x => contract_sexpr(x, [], [])

  (* This is intended to find the offset of the intercept instructions from *)
  (* the beginning of the code *)
  fun find_nop_offsets(_, []) = ~1
    | find_nop_offsets(offset, (opcode, _) :: rest) =
      if opcode = Sparc_Assembly.other_nop_code then
	offset
      else
	find_nop_offsets(offset+1, rest)

  val find_nop_offsets = fn (tag, code) => find_nop_offsets(0, code)

  fun check_range(i:int, signed, pos_limit) =
    if signed then
	(i >= 0 andalso i < pos_limit) orelse
	(i < 0 andalso i >= ~pos_limit)
    else i >= 0 andalso i < pos_limit

  fun fault_range(i, signed, pos_limit) =
    if check_range(i, signed, pos_limit) then i
    else
      (diagnostic_output 3
       (fn _ => ["fault_range called with value ",
		 Int.toString i,
		 " in positive range ",
		 Int.toString pos_limit]);
       Crash.impossible"Immediate constant out of range" )

  fun make_imm_fault(i, signed, max_pos) =
    let
      val _ = fault_range(i, signed, max_pos)
      val res = Sparc_Assembly.IMM i
    in
      res
    end

  fun mantissa_is_zero mantissa =
    let
      val exp_mant = explode mantissa
      fun exp_mant_is_zero [] = true
      | exp_mant_is_zero(#"0" :: xs) = exp_mant_is_zero xs
      | exp_mant_is_zero _ = false
    in
      exp_mant_is_zero exp_mant
    end

  fun binary_list_to_string(done, [], _, 128) = concat(rev done)
  | binary_list_to_string(_, [], _, l) =
    Crash.impossible("Binary_list_to_string length not 8, remainder length " ^
		     Int.toString l)
  | binary_list_to_string(done, x :: xs, digit, power) =
    let
      val x = MLWorks.String.ord x - ord #"0"
    in
      if power = 1 then
	binary_list_to_string(String.str(chr(digit + x)) :: done, xs, 0, 128)
      else
	binary_list_to_string(done, xs, digit + x * power, power div 2)
    end

  fun to_binary(digits, value) =
    let
      fun to_sub(0, _, done) = done
      | to_sub(digs_to_go, value, done) =
	let
	  val digit = String.str(chr(value mod 2 + ord #"0"))
	in
	  to_sub(digs_to_go - 1, value div 2, digit :: done)
	end
    in
      to_sub(digits, value, [])
    end

  fun n_zeroes(done, 0) = done
  | n_zeroes(done, n) = n_zeroes("0" :: done, n-1)

  fun adjust (error_info,x,location) (mantissa, exponent, max_exponent, bits) =
    if mantissa_is_zero mantissa then
      (mantissa, 0)
    else
      if exponent > 0 andalso exponent < max_exponent then
	(mantissa, exponent)
      else
	(* Need to handle subnormal numbers *)
	if exponent >= max_exponent then
	  Info.error'
          error_info
          (Info.FATAL,location,
           "Real number unrepresentable: " ^ x)
	else
	  if exponent < ~bits then (concat(n_zeroes([], bits)), 0)
	  else
	    (concat(n_zeroes([], abs exponent)) ^ mantissa, 0)

  fun to_single_string args (sign, mantissa, exponent) =
    let
      val real_exponent = exponent + 127
      val (mantissa, real_exponent) = adjust args (mantissa, real_exponent, 255, 23)
      val binary_list =
	(if sign then "1" else "0") ::
	   to_binary(8, real_exponent) @@
	   (map str (explode (MLWorks.String.substring (mantissa, 1, 23))))
    in
      binary_list_to_string([], binary_list, 0, 128)
    end

  fun to_double_string args (sign, mantissa, exponent) =
    let
      val real_exponent = exponent + 1023
      val (mantissa, real_exponent) = adjust args (mantissa, real_exponent, 2047, 52)
      val binary_list =
	(if sign then "1" else "0") ::
	   to_binary(11, real_exponent) @@
	   (map String.str
                (explode(MLWorks.String.substring (mantissa, 1, 52))))
    in
      binary_list_to_string([], binary_list, 0, 128)
    end

  fun to_extended_string args (sign, mantissa, exponent) =
    let
      val real_exponent = exponent + 16383
      val (mantissa, real_exponent) =
	adjust args (mantissa, real_exponent, 32767, 63)
      val binary_list =
	(if sign then "1" else "0") ::
	   to_binary(15, real_exponent) @@
	   n_zeroes([], 16) @@
	   (map String.str 
                (explode(MLWorks.String.substring (mantissa, 0, 64)))) @@
	   n_zeroes([], 32)	
    in
      binary_list_to_string([], binary_list, 0, 128)
    end

  fun value_cg(i, MirTypes.SCON (Ident.STRING x),_) = Code_Module.STRING(i, x)
    | value_cg(i, MirTypes.SCON (Ident.REAL(x,location)),error_info) =
      (let
	 val the_real = Reals.evaluate_real x
	 val (sign, mantissa, exponent) = Reals.find_real_components the_real
	 val encoding_function = case MachTypes.fp_used of
	   MachTypes.single => to_single_string (error_info,x,location)
	 | MachTypes.double => to_double_string (error_info,x,location)
	 | MachTypes.extended => to_extended_string (error_info,x,location)
       in
	 Code_Module.REAL(i, encoding_function(sign, mantissa, exponent))
       end handle MLWorks.Internal.StringToReal =>
	 Info.error'
	 error_info
	 (Info.FATAL, location, "Real number unrepresentable: " ^ x)
      )
    | value_cg(_, MirTypes.SCON (Ident.INT _),_) = Crash.impossible"VALUE(INT)"
    | value_cg(_, MirTypes.SCON (Ident.CHAR _),_) = Crash.impossible"VALUE(CHAR)"
    | value_cg(_, MirTypes.SCON (Ident.WORD _),_) = Crash.impossible"VALUE(WORD)"
    | value_cg (i,MirTypes.MLVALUE value,_) =
      Code_Module.MLVALUE (i,value)

  val absent = NONE

  (* A function to return the terminating branch of a block if one exists *)
  fun last_opcode [] = (Sparc_Assembly.nop, false)
    | last_opcode [elem as (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BA, _),
                            _, _)] =
      (elem, true)
    (* Computed GOTOS must be treated specially *)
    | last_opcode([(Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BA, _),
                            _, _),
                   elem as (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BA, _),
                            _, _)]) =
     (elem, true)
    | last_opcode([elem as (Sparc_Assembly.BRANCH(Sparc_Assembly.BA, _), _, _),
                   _]) =
      (elem, true)
  | last_opcode([elem as (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BA, _),
			  _, _),
		 _]) =
     (elem, true)
  | last_opcode(_ :: xs) = last_opcode xs

  fun make_proc_info(res as (main_tree, tag_tree), []) = res
    | make_proc_info((main_tree, tag_tree),
		     ((block_tag, opcode_list)) :: rest) =
      let
	val last_tag_exists as (tag, ok) = case last_opcode opcode_list of
	  ((_, SOME tag, _), true) => (tag, true)
	| _ => (block_tag, false)
      in
	make_proc_info
	((Map.define (main_tree, block_tag, last_tag_exists),
	  if ok then
	    Map.define (tag_tree, tag, 0)
	  else tag_tree), rest)
      end

  fun rev_app([], acc) = acc
    | rev_app(x :: xs, acc) = rev_app(xs, x :: acc)

  fun remove_trailing_branch(block_tag, opcode_list) =
    let
      val rev_opc = rev opcode_list
      val new_opc =
	case rev_opc of
	  (Sparc_Assembly.BRANCH_ANNUL _, _, _) :: rest => rest
	| (operation, opt, comment) :: (Sparc_Assembly.BRANCH _, _, _) :: rest =>
	    (operation, opt, comment ^ " preceding BA removed") :: rest
	| _ :: (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BA, _), _, _) :: rest => rest
	| _ =>
	    Crash.impossible"Remove trailing branch fails"
    in
      (block_tag, rev new_opc)
    end

  (* CT this now works on the continuer and non-continuer lists in turn *)
  fun find_dest_block(tag, [], [], x,y) = ((tag, []), false, x,y)
    | find_dest_block(dest_tag,
		      (block as (block_tag, opcode_list)) ::
		      rest,
		      other,
		      x , [] ) =
      if dest_tag = block_tag then
	(block, true, x @@ rest, other)
      else find_dest_block(dest_tag, rest, other, block :: x,[])

    | find_dest_block(dest_tag,
		      [],
		      (block as (block_tag, opcode_list)) ::
		      rest,
		      x , y ) =
      if dest_tag = block_tag then
	(block, true, x , y @@ rest)
      else find_dest_block(dest_tag, [], rest, x, block :: y)

    | find_dest_block _ =
      Crash.impossible "This should never happen in _mach_cg "

  (* Algorithm *)
  (* Start with the first block (entry block) *)
  (* Find the block it tails into, and append that *)
  (* Repeat until we end up with a block which either doesn't tail *)
  (* into an unused block (eg a loop), or doesn't tail at all (eg ret) *)
  (* Now find all blocks which tail into something *)
  (* and pick one from these which nothing tails into from these *)
  (* This is called a chain head *)
  (* Repeat as if we'd just started *)
  (* If no such block, pick one from the cycle and repeat as before *)
  (* If no blocks which tail at all, bung them on the end and finish *)
  (* A consequence of this algorithm is *)
  (* When searching for a new head of a chain, *)
  (* we need only check that a block which continues *)
  (* was never the target of another block (ie check at proc start) *)
  (* Because if it once was, and has now ceased to be *)
  (* Then it would have been processed already (reductio ad absurdum) *)
  fun reorder_blocks(proc as (proc_tag, block_list)) =
    (* Reorder the blocks for a proc so as to allow fall throughs *)
    (* Note that this will result in blocks with dangling ends *)
    (* So they must not be reordered again by any other means *)
    let
      val (proc_info, tag_tree) =
	make_proc_info((Map.empty , Map.empty), block_list)

      val proc_info_map = Map.tryApply proc_info
      val tag_tree_map = Map.tryApply tag_tree
      (* We don't have to repeatedly re-calculate the continuers lists *)
      fun do_fall_throughs_with_continuers_calculated(done, (block as (block_tag, opcode_list)),
                                                      continuers,non_continuers) =
        let
	  val (dest_tag, found_block) =
	    Map.apply_default'(proc_info, (block_tag, false), block_tag)

	  fun do_next() =
	    case continuers of
              (* CT this was rev(rev rest @@ (block :: done)), but
               rev(rev rest @@ (block::done)) = rev(block::done) @@ rest
               = rev( [block] @@ done) @@ rest = rev done @@ rev[block] @@ rest
               = rev done @@ (block :: rest)
               AND now rest = continuers @@ non-continuers *)
	      [] =>
		rev_app(done, (block :: non_continuers))
	    | _ =>
		let
		  val (next_block, continuers') =
		    (let
		       val (tag, _) = Lists.findp
			 (fn (x, _) =>
			  case tag_tree_map x of
			    NONE => true
			  | _ => false)
			 continuers
		       val (others,value) =
			 Lists.assoc_returning_others(tag,continuers)
		     in
		       ((tag, value),others)
		     end) handle Lists.Find =>
		       (Lists.hd continuers, Lists.tl continuers)
		in
		  do_fall_throughs_with_continuers_calculated(block :: done,
							      next_block,
                                                              continuers',
							      non_continuers)
		end
	in
	  if found_block then
	    let
	      val (dest_block, found_dest, non_continuers',continuers') =
		find_dest_block(dest_tag, non_continuers, continuers, [] , [])
	    in
	      if found_dest then
		do_fall_throughs_with_continuers_calculated
		(remove_trailing_branch block :: done,
		 dest_block, continuers', non_continuers')
	      else
		 do_next()
	    end
	  else
	     do_next()
	end

      fun do_fall_throughs(done, block, []) = rev(block :: done)
      | do_fall_throughs(done, block,rest) =
	let
	  fun continues(tag, _) =
	    case proc_info_map tag of
	      SOME (_, t) => t
	    | _ => false

	  val (continuers,non_continuers) =
	    Lists.partition continues rest
        in
          do_fall_throughs_with_continuers_calculated(done,block,continuers,non_continuers)
        end

      val (hd_block_list, tl_block_list) = case block_list of
	x :: y => (x, y)
      | _ => Crash.impossible"Empty block list"
    in
      (proc_tag, do_fall_throughs([], hd_block_list, tl_block_list))
    end

  fun tag_offsets([], offset, tag_env) = (offset, tag_env)
    | tag_offsets((tag, ho_list) :: rest, disp, tag_env) =
      tag_offsets(rest, disp + 4 * (length ho_list),
		  Map.define (tag_env, tag, disp))


  fun tag_offsets_for_list(_, [], env) = env
    | tag_offsets_for_list(offset, (_, proc) :: rest, env) =
      let
	val (next_offset, env) = tag_offsets(proc, offset, env)
	val next_offset' =
	  next_offset + 4 (* Back-pointer *) + 4 (* Procedure number within set *)
	val next_offset'' =
	  if next_offset' mod 8 = 4
	    then next_offset'+4
	  else next_offset'
      in
	tag_offsets_for_list(next_offset'', rest, env)
      end

  exception bad_offset of
  MirTypes.tag * (Sparc_Assembly.opcode * MirTypes.tag option * string) list

  fun do_little_block(block as (tag, opcode_list)) =
    case opcode_list of
      [ins,
       (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BA, i), SOME tag', comm),
       _] =>
      (tag,
       [(Sparc_Assembly.BRANCH(Sparc_Assembly.BA, i), SOME tag', comm),
	 ins])
     | _ => block

  fun reschedule_little_blocks(proc_tag, block_list) =
    (proc_tag, map do_little_block block_list)

  fun linearise_list proc_list =
    let
      val new_proc_list =
	Timer.xtime
	("reordering blocks", !do_timings,
	 fn () => map reorder_blocks proc_list)

      (* We'd now like to reschedule any small blocks that branch backwards *)

      val new_proc_list = map reschedule_little_blocks new_proc_list

      fun do_linearise proc_list =
	let

	  val tag_env = tag_offsets_for_list(0, proc_list, Map.empty)

	  val _ = diagnostic_output 3 (fn _ => ["Tag_env ="])
	  val _ =
	    diagnostic_output 3
	    (fn _ => (ignore(map
	     (fn (x, y) => Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ Int.toString y ^ "\n"))
		      (Map.to_list tag_env)) ;
		      [] ))

	  fun lookup_env tag = Map.tryApply'(tag_env,tag)

	  fun rev_map f arg =
	    let
	      fun map_sub([], acc) = acc
		| map_sub(x :: xs, acc) = map_sub(xs, f x :: acc)
	    in
	      map_sub arg
	    end

	  fun rev_app([], y) = y
	    | rev_app(x :: xs, y) = rev_app(xs, x :: y)

	  fun copy_n(n, from, acc, new_tail) =
	    if n < 0 then
	      Crash.impossible"copy_n negative arg"
	    else
	      if n = 0 then
		rev_app(acc, new_tail)
	      else
		case from of
		  (x :: xs) =>
		    copy_n(n-1, xs, x :: acc, new_tail)
		| _ => Crash.impossible"copy_n short list"

	  fun drop(n, the_list) =
	    if n < 0 then
	      Crash.impossible"drop negative arg"
	    else
	      if n = 0 then the_list
	      else
		case the_list of
		  [] => Crash.impossible"drop bad list"
		| _ :: rest => drop(n-1, rest)

	  fun linearise_proc(_, offset, [], done) = (offset, rev done)
	    | linearise_proc(proc_offset, start, blocks as (block :: block_list), done) =
	      let
		(* Insert algorithm for optimal linearisation of blocks here *)
		(* Present algorithm just uses the current order *)
		(* Also assumes NOPs inserted after all control transfers *)
		fun do_block(block_start, (block_tag, opcode_list), done) =
		  let
		    fun do_opcode((Sparc_Assembly.BRANCH(branch, i),
				   SOME tag, comment), offset) =
		      (case lookup_env tag of
			 SOME res =>
			   let
			     val disp =
			       fault_range(( res - offset) div 4,
					   true, branch_disp_limit)
			   in
			     (Sparc_Assembly.BRANCH(branch, disp), comment)
			   end
		       | NONE =>
			   Crash.impossible"Assoc do_opcode branch")

		      | do_opcode((Sparc_Assembly.BRANCH_ANNUL(branch, i),
			       SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp =
				 fault_range((res - offset) div 4,
					     true, branch_disp_limit)
			     in
                           (Sparc_Assembly.BRANCH_ANNUL(branch, disp), comment)
			     end
			 | NONE =>
			     (Crash.impossible"Assoc do_opcode branch_annul"))
		      | do_opcode((Sparc_Assembly.FBRANCH(branch, i),
			       SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp =
                             fault_range((res - offset) div 4,
                                         true, branch_disp_limit)
			     in
			       (Sparc_Assembly.FBRANCH(branch, disp), comment)
			     end
			 | NONE =>
			     Crash.impossible"Assoc do_opcode fbranch")
		      | do_opcode((Sparc_Assembly.FBRANCH_ANNUL(branch, i),
			       SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp =
				 fault_range((res - offset) div 4,
					     true, branch_disp_limit)
			     in
			       (Sparc_Assembly.FBRANCH_ANNUL(branch, disp), comment)
			     end
			 | NONE =>
			     Crash.impossible"Assoc do_opcode fbranch_annul")
		      | do_opcode((Sparc_Assembly.Call(Sparc_Assembly.CALL, i,debug_info),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp =
				 fault_range(( res + i - offset) div 4,
					     true, call_disp_limit)
			     in
			       (Sparc_Assembly.Call(Sparc_Assembly.CALL, disp,debug_info), comment)
			     end
			 | NONE => Crash.impossible "Assoc do_opcode Call")
		      | do_opcode((Sparc_Assembly.LOAD_OFFSET(Sparc_Assembly.LEO, rd, i),
				   SOME tag, comment), offset) =
			(* This will probably suffer the same problems as adr did *)
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = (res + i) - proc_offset
			     (* Must work relative to start of current proc in set *)
			     in
			       if check_range(disp, true, arith_imm_limit) then
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.OR, rd, MachTypes.G0, Sparc_Assembly.IMM disp),
				  comment)
			       else
				 let
				   val _ =
				     diagnostic_output 3
				     (fn _ => ["Found bad LEO, substituting\n"])
				   val head_size = (offset - block_start) div 4
				   val tail = drop(1 + head_size, opcode_list)
				   (* get the opcodes after this one *)
				   val new_comment = comment ^ " (expanded adr)"
				   val new_tail =
				     (Sparc_Assembly.SPECIAL_LOAD_OFFSET
				      (Sparc_Assembly.LOAD_OFFSET_HIGH, rd, MachTypes.G0, i),
				      SOME tag, new_comment) ::
				     (Sparc_Assembly.SPECIAL_LOAD_OFFSET
				      (Sparc_Assembly.LOAD_OFFSET_AND_MASK, rd, rd, i),
				      SOME tag, new_comment) :: tail
				 in
				   raise bad_offset
				     (block_tag,
				      copy_n(head_size, opcode_list, [], new_tail))
				 end
			     end
			 | NONE => Crash.impossible "Assoc do_opcode LEO")
		      | do_opcode((Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				   (Sparc_Assembly.ADD, rd,
				    rs1, Sparc_Assembly.IMM i),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - offset
			     in
			       if check_range(disp, true, arith_imm_limit) then
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, rd,
				   rs1, Sparc_Assembly.IMM disp),
				  comment)
			       else
				 let
				   val _ =
				     diagnostic_output 3
				     (fn _ => ["Found bad LEA, substituting\n"])
				   val head_size = (offset - block_start) div 4
				   val tail = drop(1 + head_size, opcode_list)
				   (* get the opcodes after this one *)
				   val _ =
				     if rs1 = rd then
				       Crash.impossible"ADR has dest in lr"
				     else ()
				   val new_comment = comment ^ " (expanded adr)"
				   val new_tail =
				     (Sparc_Assembly.SetHI
				      (Sparc_Assembly.SETHI, rd, i),
				      SOME tag, new_comment) ::
				     (Sparc_Assembly.SPECIAL_ARITHMETIC
				      (Sparc_Assembly.ADD_AND_MASK, rd,
				       rd, Sparc_Assembly.IMM(i + 4)),
				      SOME tag, new_comment) ::
				     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				      (Sparc_Assembly.ADD, rd,
				       rs1, Sparc_Assembly.REG rd),
				      NONE, new_comment) :: tail
				 in
				   raise bad_offset
				     (block_tag,
				      copy_n(head_size, opcode_list, [], new_tail))
				 end
			     end
			 | NONE =>
			     Crash.impossible"Assoc do_opcode arith")

		      | do_opcode((Sparc_Assembly.SPECIAL_ARITHMETIC
				   (_, rd, rs1, Sparc_Assembly.IMM i),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp =
				 make_imm_fault
				 ((res + i - offset) mod 1024,
				  true, arith_imm_limit)
			     in
			       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, rd, rs1, disp),
				comment)
			     end
			 | NONE =>
			     Crash.impossible"Assoc do_opcode arith")
		      | do_opcode((Sparc_Assembly.SPECIAL_LOAD_OFFSET(load, rd, rn, i),
				   SOME tag, comment), _) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - proc_offset
			     (* Must work relative to start of current proc in set *)
			     in
			       case load of
				 Sparc_Assembly.LOAD_OFFSET_HIGH =>
				   (Sparc_Assembly.SetHI
				    (Sparc_Assembly.SETHI, rd,
				     (disp div 1024) mod (1024 * 1024 * 4)),
				    comment)
			       | Sparc_Assembly.LOAD_OFFSET_AND_MASK =>
				   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				    (Sparc_Assembly.ADD, rd,
                                     rn,
				     make_imm_fault(disp mod 1024, true, arith_imm_limit)),
				    comment)
			     end
			 | NONE =>
			     Crash.impossible"Assoc do_opcode SPECIAL_LOAD_OFFSET")

		      | do_opcode((Sparc_Assembly.SetHI(_, rd, i),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - offset
			       val disp = (disp div 1024) mod (1024 * 1024 * 4)
			     (* Ensure positive *)
			     in
			       (Sparc_Assembly.SetHI(Sparc_Assembly.SETHI, rd, disp),
				comment)
			     end
			 | NONE =>
			     Crash.impossible"Assoc do_opcode arith")

		      | do_opcode((opcode, NONE, comment), offset) =
			(opcode, comment)
		      | do_opcode _ = Crash.impossible"Bad tagged instruction"

		    val (opcodes_and_offsets, next) =
		      Lists.number_from(opcode_list, block_start, 4, fn x => x)

		  in
		    (rev_map do_opcode (opcodes_and_offsets, done), next)
		  end
		val (so_far, next) = do_block(start, block, done)
	      in
		linearise_proc(proc_offset, next, block_list, so_far)
	      end

	  fun do_linearise_sub(_, []) = []
	    | do_linearise_sub(offset, ((tag, proc)(*,padded_name*)) :: rest) =
	      let
		val (offset', done') =
		  linearise_proc(offset, offset, proc, [])
		val offset'' =
		  offset' + 4 (* Back-pointer *) + 4 (* Procedure number within set *)
		val offset''' =
		  if offset'' mod 8 = 4
		    then offset'' + 4
		  else offset''
	      in
		(tag, done') :: do_linearise_sub(offset''', rest)
	      end

	  fun subst_bad_offset_block(proc_list, block as (tag, opcode_list)) =
	    let
	      fun remap(proc_tag, block_list) =
		(proc_tag,
		 map
		 (fn (block' as (block_tag, _)) =>
		  if block_tag = tag then block else block')
		 block_list)
	    in
	      map remap proc_list
	    end

	in
	  do_linearise_sub(0, proc_list)
	  handle bad_offset bad_offset_block =>
	    do_linearise (subst_bad_offset_block(proc_list, bad_offset_block))
	end
    in
      do_linearise new_proc_list
    end

  fun is_reg(MirTypes.GP_GC_REG reg) = true
    | is_reg(MirTypes.GP_NON_GC_REG reg) = true
    | is_reg _ = false

  fun move_reg(rd, rs) =
    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
     (Sparc_Assembly.OR, rd, rs, Sparc_Assembly.REG MachTypes.G0), absent, "")

  fun move_imm(rd, imm) =
    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
     (Sparc_Assembly.OR, rd, MachTypes.G0, Sparc_Assembly.IMM imm),
     absent, "")

  fun gp_from_reg(MirTypes.GC_REG reg) = MirTypes.GP_GC_REG reg
    | gp_from_reg(MirTypes.NON_GC_REG reg) = MirTypes.GP_NON_GC_REG reg

  datatype proc_stack =
    PROC_STACK of
    {non_gc_spill_size     : int, (* In words *)
     fp_spill_size         : int, (* In singles, doubles or extendeds as appropriate *)
     fp_save_size          : int, (* As for non_fp_spill_size *)
     gc_spill_size         : int, (* In words *)
     gc_stack_alloc_size   : int, (* In words *)
     register_save_size    : int, (* In bytes *)
     non_gc_spill_offset   : int, (* In bytes *)
     fp_spill_offset       : int, (* In bytes *)
     fp_save_offset        : int, (* In bytes*)
     gc_spill_offset       : int, (* In bytes *)
     gc_stack_alloc_offset : int, (* In bytes *)
     register_save_offset  : int, (* In bytes *)
     allow_fp_spare_slot   : bool, (* Do we need a slot for float to int conversion? *)
     float_value_size      : int  (* Number of bytes per float value *)
     }

  fun mach_cg
    error_info
    (Options.OPTIONS {compiler_options =
                      Options.COMPILEROPTIONS {generate_debug_info,
                                               debug_variables,
                                               generate_moduler,
                                               opt_leaf_fns, ...},
                      ...},
     MirTypes.CODE(MirTypes.REFS(loc_refs,
                                 {requires = ext_refs,
                                  vars = vars,
                                  exns = exns,
                                  strs = strs,
                                  funs = funs}),
                    value_list,
                    proc_list_list),
    (gc_map,
     non_gc_map,
     fp_map),
    debugging_map) =
    let
      val {gc, non_gc, fp} = MirRegisters.pack_next
      val gc_array = MLWorks.Internal.Array.array(gc, MachSpec.global)
      val _ =
	MirTypes.GC.Map.iterate
	(fn (mir_reg, reg) =>
	 MLWorks.Internal.Array.update(gc_array, MirTypes.GC.unpack mir_reg, reg))
	gc_map
      val non_gc_array = MLWorks.Internal.Array.array(non_gc, MachSpec.global)
      val _ =
	MirTypes.NonGC.Map.iterate
	(fn (mir_reg, reg) =>
	 MLWorks.Internal.Array.update(non_gc_array, MirTypes.NonGC.unpack mir_reg, reg))
	non_gc_map
      val fp_array = MLWorks.Internal.Array.array(fp, MachSpec.global)
      val _ =
	MirTypes.FP.Map.iterate
	(fn (mir_reg, reg) =>
	 MLWorks.Internal.Array.update(fp_array, MirTypes.FP.unpack mir_reg, reg))
	fp_map

      val debug_map = ref debugging_map

      val value_elements =
	(map
	(fn(MirTypes.VALUE(tag, x)) =>
	 value_cg(Lists.assoc(tag, loc_refs), x,error_info))
	value_list) handle Lists.Assoc => Crash.impossible"Assoc value_elements"

      fun symb_value(PROC_STACK
		     {non_gc_spill_size,
		      fp_spill_size,
		      fp_save_size,
		      gc_spill_size,
		      gc_stack_alloc_size,
		      register_save_size,
		      non_gc_spill_offset,
		      fp_spill_offset,
		      fp_save_offset,
		      gc_spill_offset,
		      gc_stack_alloc_offset,
		      register_save_offset,
		      allow_fp_spare_slot,
		      float_value_size
		      }) =
	let
	  fun symbolic_value MirTypes.GC_SPILL_SIZE = gc_spill_size * 4
	    | symbolic_value MirTypes.NON_GC_SPILL_SIZE =
	      non_gc_spill_size * 4
	    | symbolic_value(MirTypes.GC_SPILL_SLOT i) =
	      let
		fun resolve_value i =
		  if i >= gc_spill_size then
		    Crash.impossible
		    ("Spill slot " ^ Int.toString i ^
		     " requested, but only " ^ Int.toString gc_spill_size ^
		     " allocated\n")
		  else
		    ~(gc_spill_offset + 4 * (1 + i))
	      in
                (* If its a symbolic offset, update to the real offset *)
		case i of
		  MirTypes.DEBUG (spill as ref (RuntimeEnv.OFFSET1(i)), name) =>
		    let
                      val print = fn s => print(s ^ "\n")
                      val _ =
                        if i = 0 then print ("Zero spill for " ^ name)
                        (* else if i = 1 then print ("One spill for " ^ name) *) (* This seems to get used for call_code *)
                        else ()
                      val value = resolve_value i
                    in
                      spill := RuntimeEnv.OFFSET2(RuntimeEnv.GC, value);
                      value
                    end
		| MirTypes.DEBUG (ref(RuntimeEnv.OFFSET2(_, i)),name) => i
                | MirTypes.SIMPLE i => resolve_value i
	      end
	    | symbolic_value(MirTypes.NON_GC_SPILL_SLOT i) =
	      let
		fun resolve_value i =
		  let
		    val offset = if allow_fp_spare_slot then 1 else 0
		  in
		    if i >= non_gc_spill_size then
		      Crash.impossible
		      ("non gc spill slot " ^ Int.toString i ^
		       " requested, but only " ^
		       Int.toString non_gc_spill_size ^
		       " allocated\n")
		    else
		      ~(non_gc_spill_offset + 4 * (1 + offset + i))
		  end
	      in
		case i of
                  (* If its a symbolic offset, update to the real offset *)
		  MirTypes.DEBUG (spill as ref(RuntimeEnv.OFFSET1(i)),name) =>
                    let
                      val value = resolve_value i
                    in
                      spill := RuntimeEnv.OFFSET2(RuntimeEnv.NONGC, value);
                      value
                    end
                | MirTypes.DEBUG (ref(RuntimeEnv.OFFSET2(_, i)),name) => i
                | MirTypes.SIMPLE i => resolve_value i
	      end
	    | symbolic_value(MirTypes.FP_SPILL_SLOT i) =
	      let
		fun resolve_value i =
		  if i >= fp_spill_size then
		    Crash.impossible
		    ("fp spill slot " ^ Int.toString i ^
		     " requested, but only " ^
		     Int.toString fp_spill_size ^
		     " allocated\n")
		  else
		    ~(fp_spill_offset + float_value_size * (1 + i))
	      in
		case i of
                (* If its a symbolic offset, update to the real offset *)
		  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1(i)),name) =>
                    let
                      val value = resolve_value i
                    in
                      spill := RuntimeEnv.OFFSET2(RuntimeEnv.FP, value);
                      value
                    end
                | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(_, i)),name) => i
                | MirTypes.SIMPLE i => resolve_value i
	      end
	in
	  symbolic_value
	end

      (* utility functions for enter *)
      fun do_store(_, _, 0, done) = done
	| do_store(reg, offset, 1, done) =
	  (Sparc_Assembly.LOAD_AND_STORE
	   (Sparc_Assembly.ST, MachTypes.G0,
	    reg,
	    Sparc_Assembly.IMM offset), absent,
	   "Initialise a stack slot") :: done
	| do_store(reg, offset, n, done) =
	  if n < 0 then Crash.impossible"Do_store"
	  else
	    if offset mod 8 = 4 then
	      do_store(reg, offset+4, n-1,
		     (Sparc_Assembly.LOAD_AND_STORE
		      (Sparc_Assembly.ST, MachTypes.G0,
		       reg,
		       Sparc_Assembly.IMM offset), absent,
		      "Initialise one misaligned stack slot") :: done)
	    else
	      do_store(reg, offset+8, n-2,
		       (Sparc_Assembly.LOAD_AND_STORE
			(Sparc_Assembly.STD, MachTypes.G0,
			 reg,
			 Sparc_Assembly.IMM offset), absent,
			"Initialise two stack slots") :: done)
      (* revised version of n_stores running off sp *)
      fun n_stores(from, no_of_stores, end_tag) =
	let
	  val end_limit = from + (no_of_stores-1)*4
	  val end_instrs =
	    [(Sparc_Assembly.BRANCH_ANNUL
	      (Sparc_Assembly.BA, 0),
	      SOME end_tag,
	      "Finish cleaning stack"),
	     Sparc_Assembly.nop]
	in
	  if check_range(end_limit, true,
			 arith_imm_limit) then
	    do_store(MachTypes.sp, from, no_of_stores, end_instrs)
	  else
	    Crash.impossible
	    ("n_stores end_limit = " ^
	     Int.toString end_limit)
	end

(* new inline allocation routine uses tagged addition to cause a trap
 * if we need to do a GC *)

      fun inline_allocate (reg, tag, bytes, leaf, rest) =
        (* trapped add to test for allocation overflow *)
	((Sparc_Assembly.TAGGED_ARITHMETIC
	  (Sparc_Assembly.TADDCCTV, MachTypes.gc1, MachTypes.gc1, bytes),
	  absent, "Attempt to allocate some heap") ::
         (* tag the 'answer' *)
	 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
	  ((if leaf then
	      Sparc_Assembly.OR
	    else
	      Sparc_Assembly.ADD),
	      reg, MachTypes.gc2, Sparc_Assembly.IMM tag),
	      absent, "Tag allocated pointer") ::
         (* increment the allocation pointer *)
	 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
	  (Sparc_Assembly.ADD, MachTypes.gc2, MachTypes.gc2, bytes),
	  absent, "Advance allocation point") ::
	 rest)

      fun do_blocks(_, [], _, _, _, (*_, _, _, _,*) _) = []
      | do_blocks(needs_preserve, MirTypes.BLOCK(tag,opcodes) :: rest,
		  stack_layout as PROC_STACK
		  {non_gc_spill_size,
		   fp_spill_size,
		   fp_save_size,
		   gc_spill_size,
		   gc_stack_alloc_size,
		   register_save_size,
		   non_gc_spill_offset,
		   fp_spill_offset,
		   fp_save_offset,
		   gc_spill_offset,
		   gc_stack_alloc_offset,
		   register_save_offset,
		   allow_fp_spare_slot,
		   float_value_size
		   },
		  spills_need_init,
		  stack_need_init,
		  fps_to_preserve
		  ) =
	let
	  val frame_size = register_save_offset + register_save_size
	  val non_save_frame_size = register_save_offset

	  val symbolic_value = symb_value stack_layout

	  fun gp_check_range(MirTypes.GP_IMM_INT i, signed, pos_limit) =
	    check_range(i, signed, pos_limit div 4)
	    | gp_check_range(MirTypes.GP_IMM_ANY i, signed, pos_limit) =
	      check_range(i, signed, pos_limit)
	    | gp_check_range(MirTypes.GP_IMM_SYMB symb, signed, pos_limit) =
	      check_range(symbolic_value symb, signed, pos_limit)
	    | gp_check_range _ =
	      Crash.impossible"gp_check_range of non-immediate"

	  fun split_int(MirTypes.GP_IMM_INT i) =
	    (((i div (4096 div 4)) mod (256 * 256 * 16))*4,
	     (i mod (4096 div 4))*4)
	    | split_int(MirTypes.GP_IMM_ANY i) =
	      (((i div 4096) mod (256 * 256 * 16))*4, i mod 4096)
	    | split_int(MirTypes.GP_IMM_SYMB symb) =
	      let
		val i = symbolic_value symb
	      in
		(((i div 4096) mod (256 * 256 * 16))*4, i mod 4096)
	      end
	    | split_int _ = Crash.impossible"split_int of non-immediate"

	  fun load_large_number_into_register (reg, gp_operand) =
	    case split_int gp_operand of
	      (0, 0) =>
                [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                  (Sparc_Assembly.OR, reg,
                   MachTypes.G0, Sparc_Assembly.REG MachTypes.G0),
                  absent, "")]
	    | (0, lo) =>
                [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                  (Sparc_Assembly.OR, reg,
                   MachTypes.G0, Sparc_Assembly.IMM lo),
                  absent, "")]
	    | (hi, 0) =>
                [(Sparc_Assembly.SetHI
                  (Sparc_Assembly.SETHI, reg, hi),
                  absent, "Get high part")]
	    | (hi, lo) =>
                [(Sparc_Assembly.SetHI
                  (Sparc_Assembly.SETHI, reg, hi),
                  absent, "Get high part"),
                 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                  (Sparc_Assembly.ADD, reg,
                   reg, Sparc_Assembly.IMM lo),
                  absent, "Add in low part")]

	  fun make_imm_format3(MirTypes.GP_IMM_INT i) =
	    make_imm_fault(4 * i, true, arith_imm_limit)
	    | make_imm_format3(MirTypes.GP_IMM_ANY i) =
	      make_imm_fault(i, true, arith_imm_limit)
	    | make_imm_format3(MirTypes.GP_IMM_SYMB symb) =
	      make_imm_fault(symbolic_value symb, true, arith_imm_limit)
	    | make_imm_format3 _ = Crash.impossible"make_imm of non-immediate"

	  fun make_imm_for_store(MirTypes.GP_IMM_ANY i) =
	    make_imm_fault(i, true, arith_imm_limit)
	    | make_imm_for_store(MirTypes.GP_IMM_SYMB symb) =
	      make_imm_fault(symbolic_value symb, true, arith_imm_limit)
	    | make_imm_for_store _ =
	      Crash.impossible"make_imm_for_store(bad value)"

	  fun do_save_instrs(_, []) = []
	    | do_save_instrs(offset, fp :: rest) =
	      case MachTypes.fp_used of
		MachTypes.single =>
		  (Sparc_Assembly.LOAD_AND_STORE_FLOAT
		   (Sparc_Assembly.STF, fp, MachTypes.fp,
		    Sparc_Assembly.IMM offset), NONE,
		   "save float") :: do_save_instrs(offset+4, rest)
	      | MachTypes.double =>
		  (Sparc_Assembly.LOAD_AND_STORE_FLOAT
		   (Sparc_Assembly.STDF, fp, MachTypes.fp,
		    Sparc_Assembly.IMM offset), NONE,
		   "save float") :: do_save_instrs(offset+8, rest)
	      | MachTypes.extended =>
		  (Sparc_Assembly.LOAD_AND_STORE_FLOAT
		   (Sparc_Assembly.STDF, fp, MachTypes.fp,
		    Sparc_Assembly.IMM offset), NONE,
		   "save float") ::
		  (Sparc_Assembly.LOAD_AND_STORE_FLOAT
		   (Sparc_Assembly.STDF,
		    MachTypes.next_reg(MachTypes.next_reg fp),
		    MachTypes.fp, Sparc_Assembly.IMM (offset+8)), NONE,
		   "save float") ::
		  do_save_instrs(offset+16, rest)

	  fun do_restore_instrs(_, []) = []
	    | do_restore_instrs(offset, fp :: rest) =
	      case MachTypes.fp_used of
		MachTypes.single =>
		  (Sparc_Assembly.LOAD_AND_STORE_FLOAT
		   (Sparc_Assembly.LDF, fp, MachTypes.fp,
		    Sparc_Assembly.IMM offset), NONE,
		   "restore float") ::
		  do_restore_instrs(offset+4, rest)
	      | MachTypes.double =>
		  (Sparc_Assembly.LOAD_AND_STORE_FLOAT
		   (Sparc_Assembly.LDDF, fp, MachTypes.fp,
		    Sparc_Assembly.IMM offset), NONE,
		   "restore float") ::
		  do_restore_instrs(offset+8, rest)
	      | MachTypes.extended =>
		  (Sparc_Assembly.LOAD_AND_STORE_FLOAT
		   (Sparc_Assembly.LDDF, fp, MachTypes.fp,
		    Sparc_Assembly.IMM offset), NONE,
		   "restore float") ::
		  (Sparc_Assembly.LOAD_AND_STORE_FLOAT
		   (Sparc_Assembly.LDDF,
		    MachTypes.next_reg(MachTypes.next_reg fp),
		    MachTypes.fp, Sparc_Assembly.IMM (offset+8)), NONE,
		   "restore float") ::
		  do_restore_instrs(offset+16, rest)

	  val fp_save_start = fp_save_offset + fp_save_size * float_value_size
	  val save_fps = do_save_instrs(~fp_save_start, fps_to_preserve)

	  val restore_fps = do_restore_instrs(~fp_save_start, fps_to_preserve)

	  fun is_comment(MirTypes.COMMENT _) = true
	    | is_comment _ = false

	  fun do_everything
	    (_, tag, [], done, [], final_result) =
	    (tag, contract_sexpr done) :: final_result
	  | do_everything
	    (needs_preserve, tag, [], done,
	     MirTypes.BLOCK(tag',opcodes) :: blocks,
	     final_result) =
	    do_everything
	    (needs_preserve, tag', Lists.filter_outp is_comment opcodes, Sexpr.NIL, blocks,
	     (tag, contract_sexpr done) :: final_result)
	  | do_everything
	    (needs_preserve, tag, opcode :: opcode_list, done,
	     block_list, final_result) =
	    let
	      fun lookup_reg(reg, table) =
		let
		  val reg = MLWorks.Internal.Array.sub(table, reg)
		in
		  if needs_preserve then reg
		  else MachTypes.after_restore reg
		end

	      fun lookup_reg_operand(MirTypes.GC_REG reg) =
	        lookup_reg(MirTypes.GC.unpack reg, gc_array)
	      | lookup_reg_operand(MirTypes.NON_GC_REG reg) =
		lookup_reg(MirTypes.NonGC.unpack reg, non_gc_array)
		
	      fun lookup_gp_operand(MirTypes.GP_GC_REG reg) =
	        lookup_reg(MirTypes.GC.unpack reg, gc_array)
	      | lookup_gp_operand(MirTypes.GP_NON_GC_REG reg) =
		lookup_reg(MirTypes.NonGC.unpack reg, non_gc_array)
	      | lookup_gp_operand _ =
		Crash.impossible"lookup_gp_operand(constant)"

	      fun lookup_fp_operand(MirTypes.FP_REG reg) =
		MLWorks.Internal.Array.sub(fp_array, MirTypes.FP.unpack reg)
		
	      val (result_list, opcode_list, new_blocks, new_final_result) =
		case opcode of
		  MirTypes.TBINARY(tagged_binary_op, taglist, reg_operand,
				   gp_operand, gp_operand') =>
		  let
                    val tag = case taglist of [] => NONE | a::_ => SOME a
		    val rd = lookup_reg_operand reg_operand

		    fun preserve_order MirTypes.SUBS = true
		      | preserve_order MirTypes.DIVS = true
		      | preserve_order MirTypes.MODS = true
		      | preserve_order MirTypes.SUB32S = true
		      | preserve_order MirTypes.DIV32S = true
		      | preserve_order MirTypes.MOD32S = true
		      | preserve_order _ = false

		    val (gp_operand, gp_operand', redo) =
		      if is_reg gp_operand then
			(gp_operand, gp_operand', false)
		      else
                        if is_reg gp_operand'
                          then
                            if preserve_order tagged_binary_op
                              then
                                (gp_operand, gp_operand', true)
                            else
                              (gp_operand', gp_operand, false)
                        else
                          (* Both are immediate so no problem *)
                          (gp_operand, gp_operand', false)
		  in
		    if redo then
		      ([],
		       MirTypes.UNARY(MirTypes.MOVE,
				      MirTypes.GC_REG MirRegisters.global,
				      gp_operand) ::
		       MirTypes.TBINARY(tagged_binary_op, taglist, reg_operand,
					MirTypes.GP_GC_REG MirRegisters.global,
					gp_operand') ::
		       opcode_list, block_list, final_result)
		    else
		      if is_reg gp_operand then
			let
			  val rs1 = lookup_gp_operand gp_operand
			in
			  if is_reg gp_operand' orelse
			    gp_check_range(gp_operand', true,
					   arith_imm_limit) then
			    (* Actually making some code here *)
			    let
			      val reg_or_imm =
				if is_reg gp_operand' then
				  Sparc_Assembly.REG(lookup_gp_operand
						     gp_operand')
				else make_imm_format3 gp_operand'
			      val (use_traps,long_op) =
                                case tagged_binary_op of
                                  MirTypes.ADDS => (true,false)
                                | MirTypes.SUBS => (true,false)
                                | MirTypes.MULS => (false,false)
                                | MirTypes.DIVS => (false,false)
                                | MirTypes.MODS => (false,false)
                                | MirTypes.ADD32S => (false,true)
                                | MirTypes.SUB32S => (false,true)
                                | MirTypes.MUL32S => (false,true)
                                | MirTypes.DIV32S => (false,true)
                                | MirTypes.MOD32S => (false,true)
                                | MirTypes.DIVU => (false,false)
                                | MirTypes.MODU => (false,false)
                                | MirTypes.DIV32U => (false,true)
                                | MirTypes.MOD32U => (false,true)
			    in
			      if use_traps then
				let
				  val opcode = case tagged_binary_op of
				    MirTypes.ADDS =>
				      Sparc_Assembly.TADDCCTV
				  | MirTypes.SUBS =>
				      Sparc_Assembly.TSUBCCTV
				  | _ => Crash.impossible"do_opcodes(TBINARY)"
				in
				  ([(Sparc_Assembly.TAGGED_ARITHMETIC
				     (opcode, rd, rs1, reg_or_imm), absent, "")],
				   opcode_list,
				   block_list,
				   final_result)
				end
			      else
				(* Non-trapping version for 32 bit values *)
				(* All args are cleaned in case of overflow *)
				let
				  val (opcode, untag_arg) =
                                    case tagged_binary_op of
                                      MirTypes.ADD32S => (Sparc_Assembly.ADDCC,false)
                                    | MirTypes.SUB32S => (Sparc_Assembly.SUBCC,false)
                                    | MirTypes.MULS => (Sparc_Assembly.SMUL,true)
                                    | MirTypes.MUL32S => (Sparc_Assembly.SMUL,false)
                                    | _ => Crash.impossible"do_opcodes(TBINARY)"
				  val cont_tag = MirTypes.new_tag()
				  val clean_code =
                                    if not long_op
                                      then []
                                    else
                                    let
                                      val regs_to_clean = [rd, rs1]
                                      val regs_to_clean = case reg_or_imm of
                                        Sparc_Assembly.REG reg => reg :: regs_to_clean
                                      | _ => regs_to_clean
                                      val regs_to_clean = Lists.rev_remove_dups regs_to_clean
                                      val regs_to_clean =
                                        Lists.filterp
                                        (fn reg => reg <> MachTypes.G0 andalso
                                         reg <> MachTypes.global)
                                        regs_to_clean
                                        (* No point in cleaning global as it's non-gc *)
                                        (* g0 is already clean *)
                                    in
                                      map
                                      (fn reg =>
                                       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                        (Sparc_Assembly.OR, reg,
                                         MachTypes.G0, Sparc_Assembly.REG MachTypes.G0),
                                        absent, "Clean"))
                                      regs_to_clean
                                    end

                                  val error_block =
                                    clean_code @@
                                    [(Sparc_Assembly.BRANCH_ANNUL
                                      (Sparc_Assembly.BA, 0),
                                      tag, ""),
                                     Sparc_Assembly.nop]

                                  fun make_overflow_error () =
                                    ((Sparc_Assembly.BRANCH_ANNUL
                                      (Sparc_Assembly.BVC, 0),
                                      SOME cont_tag,
                                      "Branch if not overflow") ::
                                     Sparc_Assembly.nop ::
                                     error_block,
                                     [])

                                  fun make_multiply_error () =
                                    let
                                      val error_tag = MirTypes.new_tag()
                                      val main_code =
                                        (* result reg can't be global *)
                                        [(Sparc_Assembly.READ_STATE (Sparc_Assembly.RDY,
                                                                     MachTypes.global),
                                          NONE,"get high word of result"),
                                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                          (Sparc_Assembly.ADD,
                                           MachTypes.global,
                                           MachTypes.global,
                                           Sparc_Assembly.IMM 1),
                                          NONE,""),
                                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                          (Sparc_Assembly.SUBCC,
                                           MachTypes.G0,
                                           MachTypes.global,
                                           Sparc_Assembly.IMM 1),
                                          NONE,""),
                                         (Sparc_Assembly.BRANCH (Sparc_Assembly.BGU,0),
                                          SOME error_tag,""),
                                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                          (Sparc_Assembly.SUB,
                                           MachTypes.global,
                                           MachTypes.global,
                                           Sparc_Assembly.IMM 1),
                                          NONE,"adjust back"),
                                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                          (Sparc_Assembly.XORCC,
                                           MachTypes.G0,
                                           rd,
                                           Sparc_Assembly.REG MachTypes.global),
                                          NONE, ""),
                                         (Sparc_Assembly.BRANCH_ANNUL (Sparc_Assembly.BL,0),
                                          SOME error_tag,""),
                                         Sparc_Assembly.nop,
                                         (Sparc_Assembly.BRANCH_ANNUL (Sparc_Assembly.BA,0),
                                          SOME cont_tag,""),
                                         Sparc_Assembly.nop]
                                    in
                                      (main_code,
                                       [(error_tag,error_block)])
                                    end

                                  val (error_check, error_blocks) =
                                    case tagged_binary_op of
                                      MirTypes.ADD32S => make_overflow_error ()
                                    | MirTypes.SUB32S => make_overflow_error ()
                                    | MirTypes.MULS => make_multiply_error ()
                                    | MirTypes.MUL32S => make_multiply_error ()
                                    | _ => Crash.impossible"do_opcodes(TBINARY)"

				  val binary_operation =
                                    (if not untag_arg
                                      then
                                        [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                          (opcode, rd, rs1, reg_or_imm), absent, "")]
                                     else (* untag rs1 into result register *)
                                       let
                                         (* reg_or_imm shouldn't be the result reg if rs1 isn't *)
                                         val (rs1,reg_or_imm) =
                                           if rs1 = rd then (rs1,reg_or_imm)
                                           else
                                             case reg_or_imm of
                                               Sparc_Assembly.REG rs2 =>
                                                 if rd = rs2 then (rs2,Sparc_Assembly.REG rs1)
                                                 else (rs1,reg_or_imm)
                                             | _ => (rs1,reg_or_imm)
                                         val both_result_reg =
                                           rs1 = rd andalso
                                           (case reg_or_imm of
                                              Sparc_Assembly.REG rs2 => rs2 = rs1
                                            | _ => false)
                                         val shift_amount = if both_result_reg then 1 else 2
                                       in
                                         [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                           (Sparc_Assembly.SRA, rd, rs1, Sparc_Assembly.IMM shift_amount), absent, "untag argument"),
                                          (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                           (opcode, rd, rd, reg_or_imm), absent, "")]
                                       end) @@
                                       error_check
				in
				  (binary_operation,
				   [],
				   MirTypes.BLOCK(cont_tag, opcode_list) :: block_list,
				   error_blocks @@ final_result)
				end
			    end
			  else (* not (is_reg gp_operand') andalso
				  not (gp_check_range
				        (gp_operand', true, arith_imm_limit)) *)
			    ([],
			     (* Ok to use the global register here *)
			     (* Because it won't be the result *)
			     MirTypes.UNARY(MirTypes.MOVE,
					    MirTypes.GC_REG
					    MirRegisters.global,
					    gp_operand') ::
			     MirTypes.TBINARY(tagged_binary_op, taglist,
					      reg_operand,
					      gp_operand,
					      MirTypes.GP_GC_REG
					      MirRegisters.global) ::
			     opcode_list, block_list, final_result)
			end
		      else (* not (is_reg gp_operand) *)
			(* Oh dear, both operands gp *)
			(diagnostic_output 3
			  (fn _ => ["Mach_Cg(TBINARY) first arg not reg\n"]);
			 ([],
			  MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					 gp_operand) ::
			  MirTypes.TBINARY(tagged_binary_op, taglist,
					   reg_operand,
					   gp_from_reg reg_operand,
					   gp_operand') ::
			  opcode_list, block_list, final_result))
		  end
		| MirTypes.BINARY(binary_op, reg_operand, gp_operand,
				  gp_operand') =>
		  let
		    (* Shifts are difficult, we'll do them separately *)
		    fun is_shift MirTypes.ADDU = false
		      | is_shift MirTypes.SUBU = false
		      | is_shift MirTypes.MULU = false
		      | is_shift MirTypes.MUL32U = false
		      | is_shift MirTypes.AND = false
		      | is_shift MirTypes.OR = false
		      | is_shift MirTypes.EOR = false
		      | is_shift MirTypes.LSR = true
		      | is_shift MirTypes.ASL = true
		      | is_shift MirTypes.ASR = true

		    val rd = lookup_reg_operand reg_operand
		    val (opcode,untag_arg) =
		      case binary_op of
			MirTypes.ADDU => (Sparc_Assembly.ADD,false)
		      | MirTypes.SUBU => (Sparc_Assembly.SUB,false)
		      | MirTypes.MULU => (Sparc_Assembly.UMUL,true)
		      | MirTypes.MUL32U => (Sparc_Assembly.UMUL,false)
		      | MirTypes.AND => (Sparc_Assembly.AND,false)
		      | MirTypes.OR => (Sparc_Assembly.OR,false)
		      | MirTypes.EOR => (Sparc_Assembly.XOR,false)
		      | MirTypes.LSR => (Sparc_Assembly.SRL,false)
		      | MirTypes.ASL => (Sparc_Assembly.SLL,false)
		      | MirTypes.ASR => (Sparc_Assembly.SRA,false)

		    fun needs_reverse Sparc_Assembly.SUB = true
		      | needs_reverse Sparc_Assembly.SUBCC = true
		      | needs_reverse Sparc_Assembly.SUBX = true
		      | needs_reverse Sparc_Assembly.SUBXCC = true
		      | needs_reverse Sparc_Assembly.SRL = true
		      | needs_reverse Sparc_Assembly.SLL = true
		      | needs_reverse Sparc_Assembly.SRA = true
		      | needs_reverse _ = false

		    val (gp_operand, gp_operand', redo) =
		      if is_reg gp_operand then
			(gp_operand, gp_operand', false)
		      else
                        if is_reg gp_operand' then
			  if needs_reverse opcode then
			    (gp_operand, gp_operand', true)
			  else
			    (gp_operand', gp_operand, false)
                        else
                          (* Both immediate so no problem *)
                          (gp_operand, gp_operand', false)
		    val is_a_shift = is_shift binary_op
		  in
		    if redo andalso not is_a_shift then
		      let
			val inter_reg =
			  case gp_operand' of
			    MirTypes.GP_GC_REG r =>
			      (if r = MirRegisters.global then
				 (* The nasty case *)
				 (case reg_operand of
				    MirTypes.GC_REG r' =>
				      if r = r' then
					Crash.impossible
					"source and dest global with large int"
				      else
					r'
				  | MirTypes.NON_GC_REG _ =>
				      Crash.impossible"BINARY doesn't deliver GC")
			       else
				 MirRegisters.global)
			  | _ => Crash.impossible "BINARY has non-gc register"
		      in
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					MirTypes.GC_REG inter_reg,
					gp_operand) ::
			 MirTypes.BINARY(binary_op, reg_operand,
					 MirTypes.GP_GC_REG inter_reg,
					 gp_operand') ::
			 opcode_list, block_list, final_result)
		      end
		    else
		      if is_a_shift then
			(* Deal with possible out of range shifts *)
			(* and also bad code from LSR/ASR *)
			let
			  val const_shift = case gp_operand' of
			    MirTypes.GP_GC_REG _ => false
			  | MirTypes.GP_NON_GC_REG _ => false
			  | _ => true
			in
			  if const_shift then
			    let
			      val shift_size = make_imm_format3 gp_operand'

			      fun get_shift(Sparc_Assembly.IMM i) = i
				| get_shift _ =
				  Crash.impossible"mach_cg:non_constant in shift by constant"
			      val shift_val = get_shift shift_size
			    in
			      case binary_op of
				MirTypes.LSR =>
				  (* Deal with possible immediate value here *)
				  if is_reg gp_operand then
				    let
				      val rs1 = lookup_gp_operand gp_operand
				    in
				      ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					 (opcode, rd, rs1, shift_size),
					 absent, "")],
				       opcode_list, block_list, final_result)
				    end
				  else
				    (* A rare case, just replace by move *)
				    (* and shift the result *)
				    ([],
				     MirTypes.UNARY(MirTypes.MOVE,
						    MirTypes.GC_REG MirRegisters.global,
						    gp_operand) ::
				     MirTypes.BINARY(binary_op,
						     reg_operand,
						     MirTypes.GP_GC_REG MirRegisters.global,
						     gp_operand') ::
				     opcode_list,
				     block_list, final_result)
			      | MirTypes.ASR =>
				  if is_reg gp_operand then
				    let
				      val rs1 = lookup_gp_operand gp_operand
				    in
				      ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					 (opcode, rd, rs1, shift_size),
					 absent, "")],
				       opcode_list, block_list, final_result)
				    end
				  else
				    (* A rare case, just replace by move *)
				    (* and shift the result *)
				    ([],
				     MirTypes.UNARY(MirTypes.MOVE,
						    MirTypes.GC_REG MirRegisters.global,
						    gp_operand) ::
				     MirTypes.BINARY(binary_op,
						     reg_operand,
						     MirTypes.GP_GC_REG MirRegisters.global,
						     gp_operand') ::
				     opcode_list,
				     block_list, final_result)
			      | MirTypes.ASL =>
				    (* Deal with possible immediate value here *)
				    if is_reg gp_operand then
				      let
					val rs1 = lookup_gp_operand gp_operand
				      in
					([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					   (opcode, rd, rs1, shift_size),
					   absent, "")],
					 opcode_list, block_list, final_result)
				      end
				    else
				      (* A rare case, just replace by move *)
				      (* and shift the result *)
				      ([],
				       MirTypes.UNARY(MirTypes.MOVE,
						      MirTypes.GC_REG MirRegisters.global,
						      gp_operand) ::
				       MirTypes.BINARY(binary_op,
						       reg_operand,
						       MirTypes.GP_GC_REG MirRegisters.global,
						       gp_operand') ::
				       opcode_list,
				       block_list, final_result)
			      | _ => Crash.impossible"mach_cg: non-shift in shift case"
			    end
			  else
			    (* Need a range test to sort out shifts by large amounts *)
			    (* This includes the case of a constant shifted by a variable amount *)
			    let
			      val rs1 = lookup_gp_operand gp_operand'
			      val cont_tag = MirTypes.new_tag()
			      fun make_range_test limit =
				let
				  val bad_tag = MirTypes.new_tag()
				in
				  (bad_tag,
				   [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				     (Sparc_Assembly.SUBCC,
				      MachTypes.G0, rs1, Sparc_Assembly.IMM limit),
				     absent, "shift range test"),
				    (Sparc_Assembly.BRANCH_ANNUL
				     (Sparc_Assembly.BCC, 0),
				     SOME bad_tag, "branch if shift arg too big"),
				    Sparc_Assembly.nop])
				end

			      val continue =
				[(Sparc_Assembly.BRANCH_ANNUL
				  (Sparc_Assembly.BA, 0),
				  SOME cont_tag, ""),
				 Sparc_Assembly.nop]

			      fun constant_out_of_range_shift gp_op =
				case binary_op of
				  MirTypes.ASL => [move_imm(rd, 0)]
				| MirTypes.ASR =>
				    if gp_check_range(gp_op, false, arith_imm_limit) then
				      [move_imm(rd, 0)]
				    else
				      (case gp_operand of
					 MirTypes.GP_IMM_INT i =>
					   [move_imm(rd, if i < 0 then ~4 else 0)]
				       | MirTypes.GP_IMM_ANY i =>
					   [move_imm(rd, 0)]
				       | _ => Crash.impossible"Mach_cg:shift:bad constant")
				| MirTypes.LSR => [move_imm(rd, 0)]
				| _ => Crash.impossible"mach_cg: non-shift in shift case"
			      val shift_limit = case binary_op of
				MirTypes.ASL => 32
			      | MirTypes.ASR => 31
			      | MirTypes.LSR => 32
			      | _ => Crash.impossible"mach_cg: non-shift in shift case"

			      fun variable_out_of_range_shift gp_op =
				case binary_op of
				  MirTypes.ASL => [move_imm(rd, 0)]
				| MirTypes.ASR =>
				    (* Shift by 31 *)
				    [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				      (opcode, rd,lookup_gp_operand gp_op, Sparc_Assembly.IMM 31),
				      absent, "")]
				| MirTypes.LSR => [move_imm(rd, 0)]
				| _ => Crash.impossible"mach_cg: non-shift in shift case"

			      val (bad_tag, range_test) =
				make_range_test shift_limit
			      val shift_op =
				if is_reg gp_operand then
				  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				   (opcode, rd,
				    lookup_gp_operand gp_operand,
                                    Sparc_Assembly.REG rs1),
				   absent, "") :: continue
				else
				  load_large_number_into_register(rd, gp_operand) @@
				  ((Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				    (opcode, rd, rd, Sparc_Assembly.REG rs1),
				    absent, "") :: continue)
			    in
			      (range_test @@ shift_op @@ continue, [],
			       MirTypes.BLOCK(cont_tag, opcode_list) ::
			       block_list,
			       (bad_tag,
				(if is_reg gp_operand then
				   variable_out_of_range_shift gp_operand
				 else
				   constant_out_of_range_shift gp_operand) @@
				   continue) :: final_result)
			    end
			end
		      else
			if is_reg gp_operand then
			  let
			    val rs1 = lookup_gp_operand gp_operand
			  in
			    if is_reg gp_operand' orelse
			      gp_check_range(gp_operand', true,
					     arith_imm_limit) then
			      let
				val reg_or_imm =
				  if is_reg gp_operand' then
				    Sparc_Assembly.REG(lookup_gp_operand
						       gp_operand')
				  else make_imm_format3 gp_operand'
			      in
                                if not untag_arg
                                  then
                                    ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                       (opcode, rd, rs1, reg_or_imm), absent, "")],
                                     opcode_list, block_list, final_result)
                                else
                                  let
                                    val both_rd =
                                      rs1 = rd andalso
                                      (case reg_or_imm of
                                         Sparc_Assembly.REG rs2 => rs2 = rs1
                                       | _ => false)
                                    val shift_amount =
                                      if both_rd then 1 else 2
                                  in
                                    ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                       (Sparc_Assembly.SRA, rd, rs1, Sparc_Assembly.IMM shift_amount),
                                       absent, ""),
                                      (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                       (opcode, rd, rd, reg_or_imm), absent, "")],
                                     opcode_list, block_list, final_result)
                                  end
			      end
			    else
			      let
				val inter_reg =
				  case gp_operand of
				    MirTypes.GP_GC_REG r =>
				      (if r = MirRegisters.global then
					 (* The nasty case *)
					 (case reg_operand of
					    MirTypes.GC_REG r' =>
					      if r = r' then
						Crash.impossible
						"source and dest global with large int"
					      else
						r'
					  | MirTypes.NON_GC_REG _ =>
					      Crash.impossible"BINARY doesn't deliver GC")
				       else
					 MirRegisters.global)
				  | _ => Crash.impossible "BINARY has non-gc register"
			      in
				([],
				 MirTypes.UNARY(MirTypes.MOVE,
						MirTypes.GC_REG inter_reg,
						gp_operand') ::
				 MirTypes.BINARY(binary_op, reg_operand,
						 gp_operand,
						 MirTypes.GP_GC_REG inter_reg) ::
				 opcode_list, block_list, final_result)
			      end
			  end
			else
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  MirTypes.GC_REG MirRegisters.global,
					  gp_operand) ::
			   MirTypes.BINARY(binary_op, reg_operand,
					   MirTypes.GP_GC_REG MirRegisters.global,
					   gp_operand') ::
			   opcode_list, block_list, final_result)
		  end
		| MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand) =>
		  let
		    val rd = lookup_reg_operand reg_operand
		    val opcode = Sparc_Assembly.OR
		    val imm = Sparc_Assembly.REG MachTypes.G0
		    val code_list =
		      if is_reg gp_operand then
			let
			  val rs1 = lookup_gp_operand gp_operand
			in
			  if rd = rs1 then [] (* Null move rn -> rn *)
			  else
			    [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			      (opcode, rd, rs1, imm), absent, "")]
			end
		      else
			if gp_check_range(gp_operand, true,
					  arith_imm_limit) then
			  let
			    val imm = case make_imm_format3 gp_operand of
			      Sparc_Assembly.IMM 0 => imm (* MOVE 0 case *)
			    | non_zero_imm => non_zero_imm
			  in
			    [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			      (opcode, rd, MachTypes.G0, imm), absent, "")]
			  end
			else
			  load_large_number_into_register(rd, gp_operand)
		  in
		    (code_list, opcode_list, block_list, final_result)
		  end
		| MirTypes.UNARY(MirTypes.NOT, reg_operand, gp_operand) =>
		  let
		    val rd = lookup_reg_operand reg_operand
		    val opcode = Sparc_Assembly.XORN
		    val simple_imm = Sparc_Assembly.IMM 3
		  in
		    if is_reg gp_operand then
		      let
			val rs1 = lookup_gp_operand gp_operand
		      in
			([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (opcode, rd, rs1, simple_imm), absent, "")],
			 opcode_list, block_list, final_result)
		      end
		    else
		      ([], MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					  gp_operand) ::
		       MirTypes.UNARY(MirTypes.NOT, reg_operand,
					  gp_from_reg reg_operand) ::
		       opcode_list,
		       block_list, final_result)
		  end
                (* Don't mask out bottom two bits *)
		| MirTypes.UNARY(MirTypes.NOT32, reg_operand, gp_operand) =>
		  let
		    val rd = lookup_reg_operand reg_operand
		    val opcode = Sparc_Assembly.XORN
		    val simple_imm = Sparc_Assembly.IMM 0
		  in
		    if is_reg gp_operand then
		      let
			val rs1 = lookup_gp_operand gp_operand
		      in
			([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (opcode, rd, rs1, simple_imm), absent, "")],
			 opcode_list, block_list, final_result)
		      end
		    else
		      ([], MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					  gp_operand) ::
		       MirTypes.UNARY(MirTypes.NOT32, reg_operand,
					  gp_from_reg reg_operand) ::
		       opcode_list,
		       block_list, final_result)
		  end
		| MirTypes.UNARY(MirTypes.INTTAG, reg_operand, gp_operand) =>
		  let
		    val rd = lookup_reg_operand reg_operand
		    val opcode = Sparc_Assembly.ANDN
		    val simple_imm = Sparc_Assembly.IMM 3
		  in
		    if is_reg gp_operand then
		      let
			val rs1 = lookup_gp_operand gp_operand
		      in
			([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (opcode, rd, rs1, simple_imm), absent, "")],
			 opcode_list, block_list, final_result)
		      end
		    else
		      ([], MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					  gp_operand) ::
		       MirTypes.UNARY(MirTypes.INTTAG, reg_operand,
				      gp_from_reg reg_operand) ::
		       opcode_list,
		       block_list, final_result)
		  end
		| MirTypes.NULLARY(MirTypes.CLEAN, reg_operand) =>
                    ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                       (Sparc_Assembly.OR, lookup_reg_operand reg_operand,
                        MachTypes.G0, Sparc_Assembly.REG MachTypes.G0),
                       absent, "Clean")],
                    opcode_list, block_list, final_result)
		| MirTypes.BINARYFP(binary_fp_op, fp_operand, fp_operand',
				    fp_operand'') =>
		  let
		    val rd = lookup_fp_operand fp_operand
		    val rs1 = lookup_fp_operand fp_operand'
		    val rs2 = lookup_fp_operand fp_operand''
		    val operation = case (MachTypes.fp_used, binary_fp_op) of
		      (MachTypes.single, MirTypes.FADD) => Sparc_Assembly.FADDS
		    | (MachTypes.single, MirTypes.FSUB) => Sparc_Assembly.FSUBS
		    | (MachTypes.single, MirTypes.FMUL) => Sparc_Assembly.FMULS
		    | (MachTypes.single, MirTypes.FDIV) => Sparc_Assembly.FDIVS
		    | (MachTypes.double, MirTypes.FADD) => Sparc_Assembly.FADDD
		    | (MachTypes.double, MirTypes.FSUB) => Sparc_Assembly.FSUBD
		    | (MachTypes.double, MirTypes.FMUL) => Sparc_Assembly.FMULD
		    | (MachTypes.double, MirTypes.FDIV) => Sparc_Assembly.FDIVD
		    | (MachTypes.extended, MirTypes.FADD) =>
			Sparc_Assembly.FADDX
		    | (MachTypes.extended, MirTypes.FSUB) =>
			Sparc_Assembly.FSUBX
		    | (MachTypes.extended, MirTypes.FMUL) =>
			Sparc_Assembly.FMULX
		    | (MachTypes.extended, MirTypes.FDIV) =>
			Sparc_Assembly.FDIVX
		  in
		    ([(Sparc_Assembly.FBINARY(operation, rd, rs1, rs2), absent,
		       "")], opcode_list, block_list, final_result)
		  end
	        | MirTypes.UNARYFP(unary_fp_op, fp_operand, fp_operand') =>
		    let
		      val rd = lookup_fp_operand fp_operand
		      val rs2 = lookup_fp_operand fp_operand'
		      val (operation, extra_moves) =
			case (MachTypes.fp_used, unary_fp_op) of
			  (MachTypes.single, MirTypes.FSQRT) =>
			    (Sparc_Assembly.FSQRTS, 0)
			| (MachTypes.single, MirTypes.FMOVE) =>
			    (Sparc_Assembly.FMOV, 0)
			| (MachTypes.single, MirTypes.FABS) =>
			    (Sparc_Assembly.FABS, 0)
			| (MachTypes.single, MirTypes.FNEG) =>
			    (Sparc_Assembly.FNEG, 0)
			| (MachTypes.double, MirTypes.FSQRT) =>
			    (Sparc_Assembly.FSQRTD, 0)
			| (MachTypes.double, MirTypes.FMOVE) =>
			    (Sparc_Assembly.FMOV, 1)
			| (MachTypes.double, MirTypes.FABS) =>
			    (Sparc_Assembly.FABS, 1)
			| (MachTypes.double, MirTypes.FNEG) =>
			    (Sparc_Assembly.FNEG, 1)
			| (MachTypes.extended, MirTypes.FSQRT) =>
			    (Sparc_Assembly.FSQRTX, 0)
			| (MachTypes.extended, MirTypes.FMOVE) =>
			    (Sparc_Assembly.FMOV, 3)
			| (MachTypes.extended, MirTypes.FABS) =>
			    (Sparc_Assembly.FABS, 3)
			| (MachTypes.extended, MirTypes.FNEG) =>
			    (Sparc_Assembly.FNEG, 3)
			| _ =>
			    Crash.impossible"Bad unary fp generated"
		      fun add_moves(_, _, 0) = []
		      | add_moves(rd, rs2, moves) =
			let
			  val rd = MachTypes.next_reg rd
			  val rs2 = MachTypes.next_reg rs2
			in
			  (Sparc_Assembly.FUNARY(Sparc_Assembly.FMOV, rd, rs2),
			   absent, "") :: add_moves(rd, rs2, moves - 1)
			end
		      val extra_code = add_moves(rd, rs2, extra_moves)
		    in
		      ((Sparc_Assembly.FUNARY(operation, rd, rs2), absent,
			"") :: extra_code, opcode_list, block_list,
		       final_result)
		    end
		| MirTypes.TBINARYFP(tagged_binary_fp_op, taglist, fp_operand,
				     fp_operand', fp_operand'') =>
		  let
                    val tag = case taglist of [] => NONE | a::_ => SOME a
		    val rd = lookup_fp_operand fp_operand
		    val rs1 = lookup_fp_operand fp_operand'
		    val rs2 = lookup_fp_operand fp_operand''
		    val operation =
                      case (MachTypes.fp_used, tagged_binary_fp_op)
                      of (MachTypes.single, MirTypes.FADDV) =>
			Sparc_Assembly.FADDS
                      |  (MachTypes.single, MirTypes.FSUBV) =>
			Sparc_Assembly.FSUBS
                      |  (MachTypes.single, MirTypes.FMULV) =>
			Sparc_Assembly.FMULS
                      |  (MachTypes.single, MirTypes.FDIVV) =>
			Sparc_Assembly.FDIVS
                      |  (MachTypes.double, MirTypes.FADDV) =>
			Sparc_Assembly.FADDD
                      |  (MachTypes.double, MirTypes.FSUBV) =>
			Sparc_Assembly.FSUBD
                      |  (MachTypes.double, MirTypes.FMULV) =>
			Sparc_Assembly.FMULD
                      |  (MachTypes.double, MirTypes.FDIVV) =>
			Sparc_Assembly.FDIVD
                      |  (MachTypes.extended, MirTypes.FADDV) =>
			Sparc_Assembly.FADDX
                      |  (MachTypes.extended, MirTypes.FSUBV) =>
			Sparc_Assembly.FSUBX
                      |  (MachTypes.extended, MirTypes.FMULV) =>
			Sparc_Assembly.FMULX
                      |  (MachTypes.extended, MirTypes.FDIVV) =>
			Sparc_Assembly.FDIVX
		  in
		    ([(Sparc_Assembly.FBINARY(operation, rd, rs1, rs2),
		       absent, "")],
		     opcode_list, block_list, final_result)
		  end
		| MirTypes.TUNARYFP(tagged_unary_fp_op, tag, fp_operand,
				    fp_operand') =>
		    (* same as untagged case - overflows caught by hardware/OS
		       and handled in runtime system. *)
		    let
		      val rd = lookup_fp_operand fp_operand
		      val rs2 = lookup_fp_operand fp_operand'
		      val (operation, extra_moves) =
			case (MachTypes.fp_used, tagged_unary_fp_op) of
			  (MachTypes.single, MirTypes.FSQRTV) =>
			    (Sparc_Assembly.FSQRTS, 0)
			| (MachTypes.single, MirTypes.FABSV) =>
			    (Sparc_Assembly.FABS, 0)
			| (MachTypes.single, MirTypes.FNEGV) =>
			    (Sparc_Assembly.FNEG, 0)
			| (MachTypes.double, MirTypes.FSQRTV) =>
			    (Sparc_Assembly.FSQRTD, 0)
			| (MachTypes.double, MirTypes.FABSV) =>
			    (Sparc_Assembly.FABS, 1)
			| (MachTypes.double, MirTypes.FNEGV) =>
			    (Sparc_Assembly.FNEG, 1)
			| (MachTypes.extended, MirTypes.FSQRTV) =>
			    (Sparc_Assembly.FSQRTX, 0)
			| (MachTypes.extended, MirTypes.FABSV) =>
			    (Sparc_Assembly.FABS, 3)
			| (MachTypes.extended, MirTypes.FNEGV) =>
			    (Sparc_Assembly.FNEG, 3)
			| _ =>
			    Crash.impossible"Bad unary fp generated"
		      fun add_moves(_, _, 0) = []
		      | add_moves(rd, rs2, moves) =
			let
			  val rd = MachTypes.next_reg rd
			  val rs2 = MachTypes.next_reg rs2
			in
			  (Sparc_Assembly.FUNARY(Sparc_Assembly.FMOV, rd, rs2),
			   absent, "") :: add_moves(rd, rs2, moves - 1)
			end
		      val extra_code = add_moves(rd, rs2, extra_moves)
		    in
		      ((Sparc_Assembly.FUNARY(operation, rd, rs2), absent,
			"") :: extra_code, opcode_list, block_list,
		       final_result)
		    end
		| MirTypes.STACKOP(stack_op, reg_operand,
				   SOME offset) =>
		  let
		    val opcode = case stack_op of
		      MirTypes.PUSH => MirTypes.STREF
		    | MirTypes.POP => MirTypes.LDREF
		  val _ =
		    if offset > gc_stack_alloc_size then
		      Crash.impossible("Stack access at offset " ^
				       Int.toString offset ^
				       " requested, in total area of only " ^
				       Int.toString gc_stack_alloc_size ^
				       "\n")
		    else()
		  in
		    ([],
		     MirTypes.STOREOP(opcode, reg_operand,
				      MirTypes.GC_REG MirRegisters.fp,
				      MirTypes.GP_IMM_ANY
				      (~(gc_stack_alloc_offset + 4 * (offset + 1)))) ::
		     opcode_list, block_list, final_result)
		  end
		| MirTypes.STACKOP _ =>
		    Crash.impossible"Offset missing on STACK_OP"
		| opcode as MirTypes.IMMSTOREOP _ =>
		    Crash.impossible"IMMSTOREOP not supported on sparc"
		| opcode as MirTypes.STOREOP(store_op, reg_operand, reg_operand',
					     gp_operand) =>
		  let
		    val (shuffle, new_opcode_list) =
		      if is_reg gp_operand orelse
			gp_check_range(gp_operand, true, arith_imm_limit) then
			(
			 case opcode_list of
			   (store_op as MirTypes.STOREOP(MirTypes.LD, MirTypes.GC_REG g,
							 c_reg as MirTypes.GC_REG c,
							 MirTypes.GP_IMM_ANY ~1)) ::
			   (tail as (MirTypes.BRANCH_AND_LINK _ :: _)) =>
			     if g = MirRegisters.global andalso c = MirRegisters.caller_closure
			       andalso reg_operand' <> c_reg andalso reg_operand <> c_reg then
				 (true, store_op :: opcode :: tail)
			     else
			       (false, [])
			 | (store_op as MirTypes.STOREOP(MirTypes.LD, MirTypes.GC_REG g,
							 c_reg as MirTypes.GC_REG c,
							 MirTypes.GP_IMM_ANY ~1)) ::
			   (tail as (MirTypes.TAIL_CALL _ :: _)) =>
			     if (not needs_preserve) andalso
			       g = MirRegisters.global andalso c = MirRegisters.callee_closure
			       andalso reg_operand' <> c_reg andalso reg_operand <> c_reg then
			       (true, store_op :: opcode :: tail)
			     else
			       (false, [])
		         | (move_op as MirTypes.UNARY(MirTypes.MOVE, c_reg as MirTypes.GC_REG c,
						      MirTypes.GP_GC_REG r)) ::
			   (store_op as MirTypes.STOREOP(MirTypes.LD, MirTypes.GC_REG g,
							 MirTypes.GC_REG c',
							 MirTypes.GP_IMM_ANY ~1)) ::
			   (tail as (MirTypes.BRANCH_AND_LINK _ :: _)) =>
			     let
			       val r_reg = MirTypes.GC_REG r
			     in
			       if g = MirRegisters.global andalso c = MirRegisters.caller_closure
				 andalso c' = c
				 andalso reg_operand' <> c_reg
				 andalso reg_operand' <> r_reg
				 andalso reg_operand <> c_reg
				 andalso reg_operand <> r_reg then
				 (true, move_op :: store_op :: opcode :: tail)
			       else
				 (false, [])
			     end
		         | (move_op as MirTypes.UNARY(MirTypes.MOVE, c_reg as MirTypes.GC_REG c,
						      MirTypes.GP_GC_REG r)) ::
			   (store_op as MirTypes.STOREOP(MirTypes.LD, MirTypes.GC_REG g,
							 MirTypes.GC_REG c',
							 MirTypes.GP_IMM_ANY ~1)) ::
			   (tail as (MirTypes.TAIL_CALL _ :: _)) =>
			     let
			       val r_reg = MirTypes.GC_REG r
			     in
			       if (not needs_preserve) andalso
				 g = MirRegisters.global andalso c = MirRegisters.callee_closure
				 andalso c' = c
				 andalso reg_operand' <> c_reg
				 andalso reg_operand' <> r_reg
				 andalso reg_operand <> c_reg
				 andalso reg_operand <> r_reg then
				 (true, move_op :: store_op :: opcode :: tail)
			       else
				 (false, [])
			     end
			 | _ => (false, [])
			     )
		      else
			(false, [])
		    (* Don't bother if the store will use global, cos it won't work *)
		  in
		    if shuffle then
		      ([], new_opcode_list, block_list, final_result)
		    else
		      let
			val rd = lookup_reg_operand reg_operand
			val rs1 = lookup_reg_operand reg_operand'
			val store = case store_op of
			  MirTypes.LD => Sparc_Assembly.LD
			| MirTypes.ST => Sparc_Assembly.ST
			| MirTypes.LDB => Sparc_Assembly.LDUB
			| MirTypes.STB => Sparc_Assembly.STB
			| MirTypes.LDREF => Sparc_Assembly.LD
			| MirTypes.STREF => Sparc_Assembly.ST
		      in
			if is_reg gp_operand orelse
			  gp_check_range(gp_operand, true, arith_imm_limit) then
			  let
			    val reg_or_imm =
			      if is_reg gp_operand then
				Sparc_Assembly.REG(lookup_gp_operand gp_operand)
			      else make_imm_for_store gp_operand
			  in
			    ([(Sparc_Assembly.LOAD_AND_STORE(store, rd, rs1,
							     reg_or_imm), absent, "")],
			     opcode_list, block_list, final_result)
			  end
			else
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  MirTypes.GC_REG MirRegisters.global,
					  gp_operand) ::
			   MirTypes.STOREOP(store_op, reg_operand,
					    reg_operand',
					    MirTypes.GP_GC_REG
					    MirRegisters.global) ::
			   opcode_list, block_list, final_result)
		      end
		  end
		| MirTypes.STOREFPOP(store_fp_op, fp_operand, reg_operand,
				     gp_operand) =>
		  let
		    val frd = lookup_fp_operand fp_operand
		    val rs1 = lookup_reg_operand reg_operand
		    val (store, repeat) =
		      case (MachTypes.fp_used, store_fp_op) of
			(MachTypes.single, MirTypes.FLD) =>
			  (Sparc_Assembly.LDF, false)
		      | (MachTypes.single, MirTypes.FST) =>
			  (Sparc_Assembly.STF, false)
		      | (MachTypes.single, MirTypes.FLDREF) =>
			  (Sparc_Assembly.LDF, false)
		      | (MachTypes.single, MirTypes.FSTREF) =>
			  (Sparc_Assembly.STF, false)
		      | (MachTypes.double, MirTypes.FLD) =>
			  (Sparc_Assembly.LDDF, false)
		      | (MachTypes.double, MirTypes.FST) =>
			  (Sparc_Assembly.STDF, false)
		      | (MachTypes.double, MirTypes.FLDREF) =>
			  (Sparc_Assembly.LDDF, false)
		      | (MachTypes.double, MirTypes.FSTREF) =>
			  (Sparc_Assembly.STDF, false)
		      | (MachTypes.extended, MirTypes.FLD) =>
			  (Sparc_Assembly.LDDF, true)
		      | (MachTypes.extended, MirTypes.FST) =>
			  (Sparc_Assembly.STDF, true)
		      | (MachTypes.extended, MirTypes.FLDREF) =>
			  (Sparc_Assembly.LDDF, true)
		      | (MachTypes.extended, MirTypes.FSTREF) =>
			  (Sparc_Assembly.STDF, true)
		    val gp_op = case reg_operand of
		      MirTypes.GC_REG reg => MirTypes.GP_GC_REG reg
		    | MirTypes.NON_GC_REG reg => MirTypes.GP_NON_GC_REG reg
		    fun gp_op_is_large(arg as MirTypes.GP_IMM_ANY i) =
		      gp_check_range(arg, true, arith_imm_limit) andalso
		      gp_check_range(MirTypes.GP_IMM_INT(i+8), true,
				     arith_imm_limit)
		    | gp_op_is_large(MirTypes.GP_IMM_INT i) =
		      gp_op_is_large(MirTypes.GP_IMM_ANY(i*4))
		    | gp_op_is_large(arg as MirTypes.GP_IMM_SYMB symb) =
		      gp_op_is_large(MirTypes.GP_IMM_ANY(symbolic_value symb))
		    | gp_op_is_large(MirTypes.GP_GC_REG _) = true
		    | gp_op_is_large(MirTypes.GP_NON_GC_REG _) = true
		  in
		    if repeat then
		      if gp_op_is_large gp_operand then
			([],
			 MirTypes.BINARY(MirTypes.ADDU,
					 MirTypes.GC_REG MirRegisters.global,
					 gp_op,
					 gp_operand) ::
			 MirTypes.STOREFPOP(store_fp_op, fp_operand,
					    MirTypes.GC_REG
					    MirRegisters.global,
					    MirTypes.GP_IMM_ANY 0) ::
			 opcode_list, block_list, final_result)
		      else
			let
			  val (imm, arg) =
			    case make_imm_for_store gp_operand of
			      imm as Sparc_Assembly.IMM arg => (imm, arg)
			    | _ => Crash.impossible
				"make_imm_for_store fails to return IMM"
			  val imm' = Sparc_Assembly.IMM(arg+8)
			in
			  ([(Sparc_Assembly.LOAD_AND_STORE_FLOAT
			     (store, frd, rs1, imm),
			     absent, ""),
			    (Sparc_Assembly.LOAD_AND_STORE_FLOAT
			     (store,
			      MachTypes.next_reg(MachTypes.next_reg frd),
			      MachTypes.next_reg(MachTypes.next_reg rs1),
			      imm'),
			     absent, "")],
			  opcode_list, block_list, final_result)
			end
		    else
		      if is_reg gp_operand orelse
			gp_check_range(gp_operand, true, arith_imm_limit) then
			let
			  val reg_or_imm =
			    if is_reg gp_operand then
			      Sparc_Assembly.REG(lookup_gp_operand gp_operand)
			    else make_imm_for_store gp_operand
			in
			  ([(Sparc_Assembly.LOAD_AND_STORE_FLOAT(store, frd,
								 rs1,
								 reg_or_imm),
			     absent, "")],
			   opcode_list, block_list, final_result)
			end
		      else
			([],
			 MirTypes.BINARY(MirTypes.ADDU,
					 MirTypes.GC_REG MirRegisters.global,
					 gp_op,
					 gp_operand) ::
			 MirTypes.STOREFPOP(store_fp_op, fp_operand,
					    MirTypes.GC_REG
					    MirRegisters.global,
					    MirTypes.GP_IMM_ANY 0) ::
			 opcode_list, block_list, final_result)
		  end
		| MirTypes.REAL(int_to_float, fp_operand, gp_operand) =>
		    let
		      val operation = case MachTypes.fp_used of
			MachTypes.single => Sparc_Assembly.FITOS
		      | MachTypes.double => Sparc_Assembly.FITOD
		      | MachTypes.extended => Sparc_Assembly.FITOX
		      val rd = lookup_fp_operand fp_operand
		      val rs2 =
			if is_reg gp_operand then
			  lookup_gp_operand gp_operand
			else
			  MachTypes.global
		    in
		      if is_reg gp_operand then
			([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.SRA, MachTypes.global,
			    rs2, Sparc_Assembly.IMM 2), absent,
			   "Untag operand"),
			  (Sparc_Assembly.LOAD_AND_STORE(Sparc_Assembly.ST,
							 MachTypes.global,
							 MachTypes.fp,
							 Sparc_Assembly.IMM
							 ~4), absent,
			   "Store the value to be converted in spare slot"),
			  (Sparc_Assembly.LOAD_AND_STORE_FLOAT
			   (Sparc_Assembly.LDF, rd, MachTypes.fp,
			    Sparc_Assembly.IMM ~4), absent,
			   "And reload to fp register"),
			  (Sparc_Assembly.CONV_OP(operation, rd, rd),
			   absent, "")],
			 opcode_list, block_list, final_result)
		      else
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					MirTypes.GC_REG MirRegisters.global,
					gp_operand) ::
			 MirTypes.REAL(int_to_float, fp_operand,
				       MirTypes.GP_GC_REG
				       MirRegisters.global) ::
			 opcode_list, block_list, final_result)
		    end
		| MirTypes.FLOOR(float_to_int, tag, reg_operand, fp_operand) =>
		    let

		      val (operation,operation',test,subtract) =
                        case MachTypes.fp_used of
                          MachTypes.single => (Sparc_Assembly.FSTOI,Sparc_Assembly.FITOS,Sparc_Assembly.FCMPS,Sparc_Assembly.FSUBS)
                        | MachTypes.double => (Sparc_Assembly.FDTOI,Sparc_Assembly.FITOD,Sparc_Assembly.FCMPD,Sparc_Assembly.FSUBD)
                        | MachTypes.extended => (Sparc_Assembly.FXTOI,Sparc_Assembly.FITOX,Sparc_Assembly.FCMPX,Sparc_Assembly.FSUBX)
		      val rs2 = lookup_fp_operand fp_operand
		      val rd = lookup_reg_operand reg_operand
                      (* Branch here to finish *)
                      val finish_tag = MirTypes.new_tag()
                      val code_list =
                       [(* Test for a possible overflow if the number is too
                         big in magnitude.  Can't rely on hardware trap,
                         because our ints are only 30 bits. *)
                        (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                         (Sparc_Assembly.OR,MachTypes.global,
                          MachTypes.G0,Sparc_Assembly.IMM 1),absent,""),
                        (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                         (Sparc_Assembly.SLL,MachTypes.global,
                          MachTypes.global, Sparc_Assembly.IMM 29),absent,""),
                        (Sparc_Assembly.LOAD_AND_STORE
                         (Sparc_Assembly.ST,
                          MachTypes.global,
                          MachTypes.fp,
                          Sparc_Assembly.IMM ~4), absent,""),
                        (Sparc_Assembly.LOAD_AND_STORE_FLOAT
                         (Sparc_Assembly.LDF, MachTypes.fp_global,
                          MachTypes.fp,
                          Sparc_Assembly.IMM ~4), absent,
                         "Save converted value"),
                        (* Make 2**29 in fp_global *)
                        (Sparc_Assembly.CONV_OP(operation', MachTypes.fp_global,
						MachTypes.fp_global),
                         absent, ""),
                        (Sparc_Assembly.FUNARY(test, rs2, MachTypes.fp_global), absent, ""),
                        (* If rs2 >= 2**29 then error *)
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBGE, 0), SOME tag, ""),
                        Sparc_Assembly.nop,

                        (Sparc_Assembly.FUNARY(Sparc_Assembly.FNEG,
                                               MachTypes.fp_global, MachTypes.fp_global), absent, ""),
                        (Sparc_Assembly.FUNARY(test, rs2, MachTypes.fp_global), absent, ""),

                        (* If rs2 < -2**29 then error *)
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBL, 0), SOME tag, ""),
                        Sparc_Assembly.nop,

                        (* Do the conversion operation, result to fp_global *)
                        (Sparc_Assembly.CONV_OP(operation, MachTypes.fp_global, rs2),
			  absent, ""),

                        (* And store into the integer register *)
                        (Sparc_Assembly.LOAD_AND_STORE_FLOAT
                         (Sparc_Assembly.STF, MachTypes.fp_global, MachTypes.fp, Sparc_Assembly.IMM ~4),
                         absent,"Save converted value"),
                        (Sparc_Assembly.LOAD_AND_STORE
                         (Sparc_Assembly.LD,rd, MachTypes.fp,Sparc_Assembly.IMM ~4),
                         absent, "And reload into destination"),
			(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			 (Sparc_Assembly.SLL, rd, rd, Sparc_Assembly.IMM 2),
			 absent, "Tag the result"),

                        (* Now test for a negative quantity that needs decrementing *)
                        (* Put zero in fp_global *)
                        (Sparc_Assembly.FBINARY(subtract, MachTypes.fp_global, rs2, rs2),
                         absent, ""),
                        (Sparc_Assembly.FUNARY(test, rs2, MachTypes.fp_global), absent, ""),
                        (* Branch to finish if rs2 >= 0 *)
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBGE, 0), SOME finish_tag, ""),
                        Sparc_Assembly.nop,
                        (* If real (round rs2) = rs2 then no adjustment necessary *)
                        (* Get the rounded result back.  This is still in the stack slot *)
                        (Sparc_Assembly.LOAD_AND_STORE_FLOAT
                         (Sparc_Assembly.LDF, MachTypes.fp_global,MachTypes.fp,Sparc_Assembly.IMM ~4),
                         absent, "Load back converted value"),
                        (* Convert it to a float again *)
                        (Sparc_Assembly.CONV_OP
                         (operation', MachTypes.fp_global,MachTypes.fp_global),
                         absent, ""),
                        (* And compare with rs2 *)
                        (Sparc_Assembly.FUNARY(test, rs2, MachTypes.fp_global), absent, ""),
                        (* If equal then we are done *)
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBE, 0), SOME finish_tag, ""),
                        Sparc_Assembly.nop,
                        (* Else subtract one from result *)
                        (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			 (Sparc_Assembly.SUB, rd, rd, Sparc_Assembly.IMM 4),
			 absent, "Adjust the result"),
                        (* And branch to finish *)
                        (Sparc_Assembly.BRANCH_ANNUL (Sparc_Assembly.BA, 0),
                         SOME finish_tag,
                         "Done now"),
                        Sparc_Assembly.nop]
		    in
		      (code_list,[], MirTypes.BLOCK (finish_tag,opcode_list)::block_list, final_result)
		    end
		| MirTypes.BRANCH(branch, bl_dest) =>
		    ((case bl_dest of
		      MirTypes.REG reg =>
			[(Sparc_Assembly.JUMP_AND_LINK
			  (Sparc_Assembly.JMPL, MachTypes.G0,
			   lookup_reg_operand reg, Sparc_Assembly.IMM 0,
                           Debugger_Types.null_backend_annotation),
			  absent, "Branch indirect"),
			 Sparc_Assembly.nop]
		    | MirTypes.TAG tag =>
			[(Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BA, 0),
			  SOME tag, "Branch relative"),
			 Sparc_Assembly.nop]),
			opcode_list, block_list, final_result)

		| MirTypes.TEST(mn, tag, gp_operand, gp_operand') => let
		    val mn' = case mn of
		      MirTypes.BNT => Sparc_Assembly.BE
		    | MirTypes.BTA => Sparc_Assembly.BNE
		    | MirTypes.BEQ => Sparc_Assembly.BE
		    | MirTypes.BNE => Sparc_Assembly.BNE
		    | MirTypes.BHI => Sparc_Assembly.BGU
		    | MirTypes.BLS => Sparc_Assembly.BLEU
		    | MirTypes.BHS => Sparc_Assembly.BCC
		    | MirTypes.BLO => Sparc_Assembly.BCS
		    | MirTypes.BGT => Sparc_Assembly.BG
		    | MirTypes.BLE => Sparc_Assembly.BLE
		    | MirTypes.BGE => Sparc_Assembly.BGE
		    | MirTypes.BLT => Sparc_Assembly.BL

		    val redo = not (is_reg gp_operand) andalso (is_reg gp_operand')
		    val ok =   is_reg gp_operand andalso (not (is_reg gp_operand'))
		    val both = is_reg gp_operand andalso is_reg gp_operand'

		    val test = case mn of
		      MirTypes.BTA => Sparc_Assembly.ANDCC
		    | MirTypes.BNT => Sparc_Assembly.ANDCC
		    | _            => Sparc_Assembly.SUBCC
		  in
		    if redo (* lhs is imm *) then
		      if gp_check_range(gp_operand, true, arith_imm_limit) then let (* lhs imm16 *)
		      in
			([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (test, MachTypes.G0, lookup_gp_operand gp_operand',
                            make_imm_format3 gp_operand), absent, "test..."),
			  (Sparc_Assembly.BRANCH_ANNUL (Sparc_Assembly.reverse_branch mn', 0),
			   SOME tag, ""),
			  Sparc_Assembly.nop],
			opcode_list, block_list, final_result)
		      end
		      else
			([],
			 MirTypes.UNARY (MirTypes.MOVE,
					 MirTypes.GC_REG MirRegisters.global,
					 gp_operand)
			 :: MirTypes.TEST (mn, tag, MirTypes.GP_GC_REG MirRegisters.global, gp_operand')
			 :: opcode_list, block_list, final_result)
		    else if ok (* rhs is imm *) then
		      if gp_check_range (gp_operand', true, arith_imm_limit) (* rhs is imm16 *) then
			([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (test, MachTypes.G0, lookup_gp_operand gp_operand, make_imm_format3 gp_operand'), absent, "test..."),
			  (Sparc_Assembly.BRANCH_ANNUL (mn', 0), SOME tag, ""),
			  Sparc_Assembly.nop],
			opcode_list, block_list, final_result)
		      else (* rhs is imm32 *)
			([],
			 MirTypes.UNARY (MirTypes.MOVE,
					 MirTypes.GC_REG MirRegisters.global,
					 gp_operand')
			 :: MirTypes.TEST (mn, tag, gp_operand, MirTypes.GP_GC_REG MirRegisters.global)
			 :: opcode_list, block_list, final_result)
		      else if both (* both registers *) then
			([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (test, MachTypes.G0,lookup_gp_operand gp_operand,
                            Sparc_Assembly.REG (lookup_gp_operand gp_operand')), absent, "test..."),
			  (Sparc_Assembly.BRANCH_ANNUL (mn', 0), SOME tag, ""),
			  Sparc_Assembly.nop],
			opcode_list, block_list, final_result)
			else (* both constants ahhh *) let
                          fun gp_value(MirTypes.GP_IMM_INT i) = (i, 0)
                            | gp_value(MirTypes.GP_IMM_ANY i) = (i div 4, i mod 4)
                            | gp_value(MirTypes.GP_IMM_SYMB symb) = (symbolic_value symb, 0)
                            | gp_value _ = Crash.impossible "gp_value:non-constant operand"
			  val (gp_op as (hilhs, lolhs)) = gp_value gp_operand
			  val (gp_op' as (hirhs, lorhs)) = gp_value gp_operand'
                          infix less greater lesseq greatereq
                          fun n less m =
                            if n >= 0
                              then if m >=0 then n < m else true
                              else if m >= 0 then false else n > m
                          fun n lesseq m = n = m orelse n less m
                          fun n greater m = not (n lesseq m)
                          fun n greatereq m = not (n less m)
			  val pre = case mn of (* precalculating result *)
			    MirTypes.BGT => (hilhs > hirhs) orelse (hilhs = hirhs andalso lolhs > lorhs)
			  | MirTypes.BLE => (hilhs < hirhs) orelse (hilhs = hirhs andalso lolhs <= lorhs)
			  | MirTypes.BGE => (hilhs > hirhs) orelse (hilhs = hirhs andalso lolhs >= lorhs)
			  | MirTypes.BLT => (hilhs < hirhs) orelse (hilhs = hirhs andalso lolhs < lorhs)
			  | MirTypes.BNT => Bits.andb (lolhs, lorhs) = 0
			  | MirTypes.BTA => Bits.andb (lolhs, lorhs) <> 0
			  | MirTypes.BEQ => gp_op = gp_op' (* tricky *)
			  | MirTypes.BNE => gp_op <> gp_op'
                          (* unsigned operations *)
			  | MirTypes.BHI => (hilhs greater hirhs) orelse (hilhs = hirhs andalso lolhs greater lorhs)
			  | MirTypes.BLS => (hilhs less hirhs) orelse (hilhs = hirhs andalso lolhs lesseq lorhs)
			  | MirTypes.BHS => (hilhs greater hirhs) orelse (hilhs = hirhs andalso lolhs greatereq lorhs)
			  | MirTypes.BLO => (hilhs less hirhs) orelse (hilhs = hirhs andalso lolhs less lorhs)
			in
			  if pre (* jump directly to tag and drop other stuff *) then
			    ([],
			     [MirTypes.BRANCH(MirTypes.BRA, MirTypes.TAG tag)],
			     block_list, final_result)
			  else
			    ([], opcode_list, block_list, final_result)
			end
		  end
		
	      | MirTypes.FTEST(fcond_branch, tag, fp_operand,
			       fp_operand') =>
		  let
		    val branch = case fcond_branch of
		      MirTypes.FBEQ => Sparc_Assembly.FBE
		    | MirTypes.FBNE => Sparc_Assembly.FBNE
		    | MirTypes.FBLE => Sparc_Assembly.FBLE
		    | MirTypes.FBLT => Sparc_Assembly.FBL
		    val rs1 = lookup_fp_operand fp_operand
		    val rs2 = lookup_fp_operand fp_operand'
		    val test_instr = case MachTypes.fp_used of
		      MachTypes.single => Sparc_Assembly.FCMPS
		    | MachTypes.double => Sparc_Assembly.FCMPD
		    | MachTypes.extended => Sparc_Assembly.FCMPX
		  in
		    ([(Sparc_Assembly.FUNARY(test_instr, rs1, rs2),
		       absent, "Do the test"),
		      (Sparc_Assembly.FBRANCH_ANNUL(branch, 0),
		       SOME tag, "Do the branch"),
		      Sparc_Assembly.nop],
		    opcode_list, block_list, final_result)
		  end
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.REG reg_operand,debug_information,_) =>
		    ([(Sparc_Assembly.JUMP_AND_LINK
		      (Sparc_Assembly.JMPL, MachTypes.lr,
		       lookup_reg_operand reg_operand, Sparc_Assembly.IMM Tags.CODE_OFFSET,
                       debug_information),
		      absent, "Call to tagged value"),
		     Sparc_Assembly.nop],
		    opcode_list, block_list, final_result)
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.TAG tag,debug_info,_) =>
		    ([(Sparc_Assembly.Call (Sparc_Assembly.CALL, 0,debug_info),
                       SOME tag, "Call"),
                      Sparc_Assembly.nop],
		    opcode_list, block_list, final_result)
		| MirTypes.TAIL_CALL(_, bl_dest,_) =>
		    let
		      val restore =
			if needs_preserve then
			  (Sparc_Assembly.SAVE_AND_RESTORE
			   (Sparc_Assembly.RESTORE, MachTypes.G0,
			    MachTypes.G0, Sparc_Assembly.IMM 0),
			   absent,
			   "Restore in delay slot")
			else
			  Sparc_Assembly.nop
		      (* Restore floating point callee saves first *)
		      val fp_restore =
			if needs_preserve then restore_fps else []
		    in
		      (fp_restore @@
		       [(case bl_dest of
			   MirTypes.REG reg =>
			     (Sparc_Assembly.JUMP_AND_LINK
			      (Sparc_Assembly.JMPL, MachTypes.G0,
			       lookup_reg_operand reg, Sparc_Assembly.IMM Tags.CODE_OFFSET,
                               Debugger_Types.null_backend_annotation),
			      absent, "Branch indirect")
			 | MirTypes.TAG tag =>
			     (Sparc_Assembly.BRANCH(Sparc_Assembly.BA, 0),
			      SOME tag, "Branch relative (tail call)")
			     ), restore],
		      opcode_list, block_list, final_result)
		    end
		| MirTypes.SWITCH(computed_goto, reg_operand, tag_list) =>
		    let
		      val reg = lookup_reg_operand reg_operand
		      val _ =
			if reg = MachTypes.lr andalso not needs_preserve then
			  Crash.impossible "SWITCH from lr in leaf case"
			else
			  ()
		    in
		      if length tag_list <= 2 then
			let
			  val (numbered_tag_list, _) =
			    Lists.number_from(tag_list, 0, 4, fn x=> x)
			  fun do_tests(done, []) = rev done
			    | do_tests(done, (tag, imm) :: (rest as _ :: _)) =
			    do_tests((Sparc_Assembly.BRANCH
				      (Sparc_Assembly.BE, 0),
				      SOME tag, "Do the branch") ::
				     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				      (Sparc_Assembly.SUBCC, MachTypes.G0,
				       reg, Sparc_Assembly.IMM imm),
				      absent, "Do the test") :: done, rest)
			    | do_tests(done, (tag, imm) :: rest) =
			    do_tests((Sparc_Assembly.BRANCH_ANNUL
				      (Sparc_Assembly.BA, 0),
				      SOME tag, "Do the branch") ::
				     (Sparc_Assembly.nop_code, absent,
				      "No test required in final case") ::
				     done, rest)
			in
			  (do_tests([], numbered_tag_list),
			   opcode_list, block_list, final_result)
			end
		      else
			let
			  val switch_to_global = reg = MachTypes.lr
			  val final_instr =
			    if switch_to_global then
			      move_reg(MachTypes.lr, MachTypes.global)
			    else
			      Sparc_Assembly.nop
			  val reg =
			    if switch_to_global then MachTypes.global else reg
			  val instrs =
			    (Sparc_Assembly.Call (Sparc_Assembly.CALL, 2, Debugger_Types.null_backend_annotation),
			     absent, "Call self") ::
			    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (Sparc_Assembly.ADD, MachTypes.lr,
			      MachTypes.lr, Sparc_Assembly.IMM(4*4)),
			     absent,
			     "Offset to start of table") ::
			    (Sparc_Assembly.JUMP_AND_LINK
			     (Sparc_Assembly.JMPL, MachTypes.G0,
			      reg, Sparc_Assembly.REG MachTypes.lr,
			      Debugger_Types.null_backend_annotation), absent,
			     "Branch into table") ::
			    final_instr ::
			    map
			    (fn tag =>
			     (Sparc_Assembly.BRANCH_ANNUL
			      (Sparc_Assembly.BA, 0), SOME tag, ""))
			    tag_list
			  val instrs =
			    if switch_to_global then
			      move_reg(MachTypes.global, MachTypes.lr) :: instrs
			    else
			      instrs
			in
			  (instrs, opcode_list, block_list, final_result)
			end
		    end

		| MirTypes.ALLOCATE_STACK(allocate, reg_operand, alloc_size,
					  SOME fp_offset) =>
		  (if alloc_size + fp_offset > gc_stack_alloc_size then
		     Crash.impossible("Stack allocation of " ^
				      Int.toString alloc_size ^
				      " at offset " ^
				      Int.toString fp_offset ^
				      " requested, in total area of only " ^
				      Int.toString
				      gc_stack_alloc_size ^
				      "\n")
		   else();
		   case allocate of
		     MirTypes.ALLOC =>
		       ([],
			MirTypes.BINARY(MirTypes.SUBU, reg_operand,
					MirTypes.GP_GC_REG MirRegisters.fp,
					MirTypes.GP_IMM_ANY
					(gc_stack_alloc_offset +
					 4 * (fp_offset + alloc_size) - Tags.PAIRPTR)) ::
			(* Note tagging on pointer *)
			opcode_list, block_list, final_result)
		   | _ => Crash.impossible"ALLOCATE_STACK strange allocate")
		 | MirTypes.ALLOCATE_STACK _ =>
		     Crash.impossible"ALLOCATE_STACK with no offset from fp"
		 | MirTypes.DEALLOCATE_STACK _ =>
		     ([], opcode_list, block_list, final_result)
		 | MirTypes.ALLOCATE(allocate, reg_operand, gp_operand) =>
		     let
                       val rd = lookup_reg_operand reg_operand
		       val _ =
			 if rd = MachTypes.lr then Crash.impossible "ALLOC into lr" else ()
                       val (link, gc_entry) =
                         if needs_preserve then
                           (MachTypes.lr, Sparc_Assembly.IMM (4 * Implicit_Vector.gc))
                         else
                           (MachTypes.gc2, Sparc_Assembly.IMM (4 * Implicit_Vector.gc_leaf))
                       val needs_unaligned_zero =
                         (* for strings and bytearrays don't need to put a zero at the end *)
                         case allocate of
                           MirTypes.ALLOC_STRING => false
                         | MirTypes.ALLOC_BYTEARRAY => false
                         | _ => true
                       val allocation =
                         case gp_operand of
                           MirTypes.GP_IMM_INT size =>
                              let
                                val (bytes, primary, aligned, header) =
                                  case allocate of
                                    MirTypes.ALLOC =>
                                      if size = 2 then
                                        (8, Tags.PAIRPTR, true, 0)
                                      else
                                        (8 * ((size+2) div 2), Tags.POINTER,
                                         size mod 2 <> 0, 64*size+Tags.RECORD)
                                  (* Same as records but no pair case *)
                                  | MirTypes.ALLOC_VECTOR =>
                                      (8 * ((size+2) div 2), Tags.POINTER,
                                       size mod 2 <> 0, 64*size+Tags.RECORD)
                                  | MirTypes.ALLOC_STRING =>
                                      (((size+11) div 8) * 8,
                                       Tags.POINTER, true, 64*size+Tags.STRING)
                                  | MirTypes.ALLOC_REAL =>
                                      (case MachTypes.fp_used
                                         of MachTypes.single   => Crash.unimplemented "ALLOC_REAL single"
                                          | MachTypes.extended => Crash.unimplemented "ALLOC_REAL extended"
                                          | MachTypes.double   =>
                                              (16, Tags.POINTER, true,
                                               64*(16 - 4) + Tags.BYTEARRAY))
                                  | MirTypes.ALLOC_REF  =>
                                      (8 + 8*((size+2) div 2),
                                       Tags.REFPTR, size mod 2 <> 0, 64*size+Tags.ARRAY)
                                  | MirTypes.ALLOC_BYTEARRAY =>
                                      (((size+11) div 8) * 8, Tags.REFPTR, true,
                                       64*size+Tags.BYTEARRAY)

                                val header_code =
                                  if header = 0 then [] else
				    load_large_number_into_register
				    (MachTypes.global, MirTypes.GP_IMM_ANY header) @@
                                        [(Sparc_Assembly.LOAD_AND_STORE
                                          (Sparc_Assembly.ST, MachTypes.global, rd,
					   Sparc_Assembly.IMM (~primary)),
                                          absent, "Initialise header")]

                                val (high, low) = split_int (MirTypes.GP_IMM_ANY bytes)
                              in
                                if high = 0 then
				  inline_allocate
				  (rd, primary, Sparc_Assembly.IMM bytes, not needs_preserve,
				   (if aligned orelse not needs_unaligned_zero then
				      header_code
				    else
				      (Sparc_Assembly.LOAD_AND_STORE
				       (Sparc_Assembly.ST, MachTypes.G0, rd,
					Sparc_Assembly.IMM (bytes - primary - 4)),
				       absent, "Zero unaligned extra word") ::
				      header_code))
                                else
				  let val load_global1 =
				    (load_large_number_into_register
				     (MachTypes.global, MirTypes.GP_IMM_ANY bytes))
                                    val load_global2 =
				    (load_large_number_into_register
				     (MachTypes.global, MirTypes.GP_IMM_ANY (bytes - primary - 4)))
				  in
				    load_global1 @@
				    inline_allocate
				    (rd, primary,
				     Sparc_Assembly.REG MachTypes.global,
				     not needs_preserve,
				     if aligned orelse not needs_unaligned_zero then
				       header_code
				     else
				       load_global2 @@
				       ((Sparc_Assembly.LOAD_AND_STORE
					 (Sparc_Assembly.ST, MachTypes.G0, rd,
					  Sparc_Assembly.REG MachTypes.global),
					 absent, "Zero unaligned extra word")::
				       header_code))
				  end
                              end

                            | MirTypes.GP_GC_REG _ =>
                                let
				  val rs = lookup_gp_operand gp_operand
				  val _ =
				    if rs = MachTypes.lr then Crash.impossible"ALLOC from lr" else ()
                                  val (primary, secondary, length_code) =
                                    case allocate of
                                        MirTypes.ALLOC => Crash.unimplemented "ALLOC variable size"
                                      | MirTypes.ALLOC_VECTOR =>
                                        (Tags.POINTER,Tags.RECORD,
                                         [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                           (Sparc_Assembly.ADD, MachTypes.global, rs, Sparc_Assembly.IMM (4+7)),
                                            absent, "Calculate length of record"),
					  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					   (Sparc_Assembly.ANDN, MachTypes.global, MachTypes.global, Sparc_Assembly.IMM 7),
					   absent, "Calculate aligned size in bytes")])
                                       | MirTypes.ALLOC_STRING =>
                                         (Tags.POINTER, Tags.STRING,
                                          [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                            (Sparc_Assembly.SRL, MachTypes.global, rs, Sparc_Assembly.IMM 2),
                                            absent, "Calculate length of string"),
                                           (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                            (Sparc_Assembly.ADD, MachTypes.global, MachTypes.global, Sparc_Assembly.IMM (4+7)),
                                            absent, ""),
					   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					    (Sparc_Assembly.ANDN, MachTypes.global, MachTypes.global, Sparc_Assembly.IMM 7),
					    absent, "Calculate aligned size in bytes")])
                                       | MirTypes.ALLOC_REAL   => Crash.unimplemented "ALLOC_REAL variable size"
                                       | MirTypes.ALLOC_REF    =>
                                         (Tags.REFPTR, Tags.ARRAY,
                                          [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                            (Sparc_Assembly.ADD, MachTypes.global, rs, Sparc_Assembly.IMM (12+7)),
                                            absent, "Calculate length of Array"),
					  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					   (Sparc_Assembly.ANDN, MachTypes.global, MachTypes.global, Sparc_Assembly.IMM 7),
					   absent, "Calculate aligned size in bytes")])
                                       | MirTypes.ALLOC_BYTEARRAY =>
                                         (Tags.REFPTR, Tags.BYTEARRAY,
                                          [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                            (Sparc_Assembly.SRL, MachTypes.global, rs, Sparc_Assembly.IMM 2),
                                            absent, "Calculate length of ByteArray"),
                                           (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                            (Sparc_Assembly.ADD, MachTypes.global, MachTypes.global, Sparc_Assembly.IMM (4+7)),
                                            absent, ""),
					   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					    (Sparc_Assembly.ANDN, MachTypes.global, MachTypes.global, Sparc_Assembly.IMM 7),
					    absent, "Calculate aligned size in bytes")])
                                  val header_code =
                                    [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                      (Sparc_Assembly.SLL, MachTypes.global, rs, Sparc_Assembly.IMM 4),
                                      absent, ""),
                                    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                     (Sparc_Assembly.ADD, MachTypes.global, MachTypes.global, Sparc_Assembly.IMM secondary),
                                     absent, "Calculate header tag"),
                                    (Sparc_Assembly.LOAD_AND_STORE
                                     (Sparc_Assembly.ST, MachTypes.global, rd, Sparc_Assembly.IMM (~primary)),
                                     absent, "Initialise header tag")]
                                in
                                  length_code @@
				  inline_allocate
                                  (rd, primary, Sparc_Assembly.REG MachTypes.global,
				   not needs_preserve,
                                   if needs_unaligned_zero
                                     then
                                       length_code @@
                                       [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                         (Sparc_Assembly.ADD, MachTypes.global, MachTypes.global, Sparc_Assembly.REG rd),
                                         absent, "Calculate end of object"),
                                       (Sparc_Assembly.LOAD_AND_STORE
                                        (Sparc_Assembly.ST, MachTypes.G0, MachTypes.global, Sparc_Assembly.IMM (~4 - primary)),
                                        absent, "Zero last word in case it's unaligned")] @@
                                       header_code
                                   else header_code)
                                end
                            | _ => Crash.impossible "Strange parameter to ALLOCATE"
                     in
                       (allocation, opcode_list, block_list, final_result)
                     end
		 | MirTypes.ADR(adr, reg_operand, tag) =>
		     let
		       val rd = lookup_reg_operand reg_operand
		       val _ =
			 if rd = MachTypes.lr then Crash.impossible "ADR into lr" else ()
		     in
		       (case adr of
			  MirTypes.LEA =>
			    [(Sparc_Assembly.Call
			      (Sparc_Assembly.CALL, 2, Debugger_Types.null_backend_annotation),
			      absent, "Call self"),
			     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			      (Sparc_Assembly.ADD, rd,
			       MachTypes.lr, Sparc_Assembly.IMM 4),
			      SOME tag, "Update gc pointer")]
			(* Note that lr points to the call instruction *)
			(* Thus lr + 4, as computed by the ADD *)
			(* points to the ADD instruction, which is fixed *)
			(* up during linearisation *)
			| MirTypes.LEO =>
			    [(Sparc_Assembly.LOAD_OFFSET
			      (Sparc_Assembly.LEO, rd, 0),
			      SOME tag,
			      "Get offset of tag from procedure start")],
			    opcode_list, block_list, final_result)
		     end
(* Warning. If we ever make a leaf adr, we must ensure *)
(* handler continuations are done safely. This is not currently *)
(* true since they use o1 as the address. *)
(* But since handlers generate stack allocated stuff, they're unlikely to be leaf *)
                | MirTypes.INTERCEPT =>
		    (trace_dummy_instructions, opcode_list, block_list, final_result)

                | MirTypes.INTERRUPT =>
		    let
		      val continue_tag = MirTypes.new_tag() (* Normal flow *)
		      val check_instrs =
			[(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			  (Sparc_Assembly.ADDCC, MachTypes.G0,
			   MachTypes.stack_limit, Sparc_Assembly.IMM 1),
			  NONE, "check for interrupt"),
			 (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BNE, 0),
			  SOME continue_tag, "branch if no interrupt"),
			 Sparc_Assembly.nop]
		      val continue =
			[(Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BA, 0),
			  SOME continue_tag, "branch if no interrupt"),
			 Sparc_Assembly.nop]
		      val irupt_code =
			if needs_preserve then
			  (* Non-leaf case *)
			  (Sparc_Assembly.LOAD_AND_STORE
			   (Sparc_Assembly.LD, MachTypes.global,
			    MachTypes.implicit,
			    Sparc_Assembly.IMM (4 * Implicit_Vector.event_check)),
			   absent, "Get address of event check") ::
			  (Sparc_Assembly.JUMP_AND_LINK
			   (Sparc_Assembly.JMPL, MachTypes.lr,
			    MachTypes.global, Sparc_Assembly.IMM 0,
			    Debugger_Types.null_backend_annotation),
			   absent, "Do event_check") ::
			  Sparc_Assembly.nop :: continue
			else
			  (* Leaf case *)
			  (Sparc_Assembly.LOAD_AND_STORE
			   (Sparc_Assembly.LD, MachTypes.global,
			    MachTypes.implicit,
			    Sparc_Assembly.IMM (4 * Implicit_Vector.event_check_leaf)),
			   absent, "Get address of event check") ::
			  (Sparc_Assembly.JUMP_AND_LINK
			   (Sparc_Assembly.JMPL, MachTypes.global,
			    MachTypes.global, Sparc_Assembly.IMM 0,
			    Debugger_Types.null_backend_annotation),
			   absent, "Do event_check_leaf") ::
			  Sparc_Assembly.nop :: continue
		    in
		      (check_instrs @@ irupt_code, [],
		       MirTypes.BLOCK(continue_tag, opcode_list) :: block_list,
		       final_result)
		    end
		| MirTypes.ENTER _ =>
		    if needs_preserve then
		      let
			val gc_stack_slots =
			  (if stack_need_init then
			    gc_stack_alloc_size
			  else
			    0) +
			     (if spills_need_init then
				gc_spill_size
			      else
				0)
			val top_tag = MirTypes.new_tag()
			val end_tag = MirTypes.new_tag()
			val clean_start =
			  if stack_need_init then
			    register_save_size
			  else
			    register_save_size + 4 * gc_stack_alloc_size
			val (clean_stack, opcodes, block) =
			  if gc_stack_slots <= 10 then
			    if gc_stack_slots = 0 then
			      (false,
			       [(Sparc_Assembly.BRANCH_ANNUL
				 (Sparc_Assembly.BA, 0),
				 SOME end_tag,
				 "Finish cleaning stack"),
				Sparc_Assembly.nop],
			       (* The linearisation process will remove *)
			       (* this irrelevant block *)
			       (top_tag, []))
			    else
			      (false,
			       n_stores(clean_start, gc_stack_slots, end_tag),
			       (top_tag, []))
			  else
			    let
			      val branch_out =
				[(Sparc_Assembly.BRANCH_ANNUL
				  (Sparc_Assembly.BA, 0),
				  SOME top_tag,
				  "")]
			      val (clean_start, extra) =
				if clean_start mod 8 = 4 then
				  (clean_start - 4, 4)
				  (* Start one earlier if not aligned *)
				else
				  (clean_start, 0)
			      val load_limit =
				let
				  val the_limit =
				    let
				      val gc_stack_size =
					4 * gc_stack_slots + extra
				    in
				      if gc_stack_size mod 8 = 0 then
					gc_stack_size
				      else
					gc_stack_size+4
				    end
(* If not 0 mod 8, we just uselessly initialise an fp or non_gc slot *)
				in
				  if check_range(the_limit, true,
						 arith_imm_limit) then
				    move_imm(MachTypes.global,
					     the_limit) :: branch_out
				  else
				    load_large_number_into_register
				    (MachTypes.global, MirTypes.GP_IMM_ANY the_limit) @@
				    branch_out
				end
			      val load_start =
				(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				 (Sparc_Assembly.ADD, MachTypes.O2,
				  MachTypes.sp, Sparc_Assembly.IMM clean_start),
                                 absent,
				 "") ::
				load_limit
			      val store_loop =
				[(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.SUBCC, MachTypes.global,
				   MachTypes.global, Sparc_Assembly.IMM 8),
				  absent, "Update counter"),
				 (Sparc_Assembly.BRANCH_ANNUL
				  (Sparc_Assembly.BGE, 0),
				  SOME top_tag,
				  "Branch if not finished"),
				 (Sparc_Assembly.LOAD_AND_STORE
				  (Sparc_Assembly.STD, MachTypes.G0,
				   MachTypes.global,
				   Sparc_Assembly.REG MachTypes.O2),
				  absent,
				  "Initialise a stack slot (delay slot)"),
				 (Sparc_Assembly.BRANCH_ANNUL
				  (Sparc_Assembly.BA, 0),
				  SOME end_tag, ""),
				 Sparc_Assembly.nop]
			    in
			      (true, load_start, (top_tag, store_loop))
			    end
			val (opcode_list, block_list, final_result) =
			  if clean_stack then
			    ([],
			     (MirTypes.BLOCK(end_tag, opcode_list)) ::
			     block_list,
			     block :: final_result)
			  else (opcode_list, block_list, final_result)

			val ov_tag = MirTypes.new_tag()  (* Overflow case *)
			val non_ov_tag = MirTypes.new_tag()
			(* Non overflow case *)

			val join_tag = MirTypes.new_tag()
			val final_result = (join_tag, opcodes) :: final_result
			val immediate_size =
			  check_range(frame_size, true, arith_imm_limit)
			val test_opcodes =
			  [(Sparc_Assembly.BRANCH_ANNUL
			    (Sparc_Assembly.BLEU, 0),
			    SOME non_ov_tag,
			    "Unsigned stack overflow test"),
			   Sparc_Assembly.nop,
			   (Sparc_Assembly.BRANCH_ANNUL
			    (Sparc_Assembly.BA, 0),
			    SOME ov_tag, ""),
			   Sparc_Assembly.nop]
			val check_and_test_opcodes =
			  if non_save_frame_size = 0 then
			    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (Sparc_Assembly.SUBCC, MachTypes.G0,
			      MachTypes.stack_limit, Sparc_Assembly.REG MachTypes.sp),
			     absent,
			     "Compare stack size") ::
			    test_opcodes
			  else
			    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (Sparc_Assembly.SUB,
                              MachTypes.global,
                              MachTypes.sp,
			      if immediate_size then
				Sparc_Assembly.IMM frame_size
			      else
				Sparc_Assembly.REG MachTypes.G7),
			     absent, "Check the stack for underflow") ::
			    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (Sparc_Assembly.SUBCC, MachTypes.G0,
			      MachTypes.stack_limit,
			      Sparc_Assembly.REG(MachTypes.global)),
			     absent,
			     "Compare stack size") ::
			    test_opcodes
			val check_for_stack_overflow_wrap =
			  if immediate_size then
			    check_and_test_opcodes
			  else
			    load_large_number_into_register
			    (MachTypes.G7, MirTypes.GP_IMM_ANY frame_size) @@
			    check_and_test_opcodes
			val post_ov_code =
			  [(Sparc_Assembly.BRANCH_ANNUL
			    (Sparc_Assembly.BA, 0),
			    SOME non_ov_tag, ""),
			   Sparc_Assembly.nop]
			val post_ov_code =
			  if immediate_size then
			    post_ov_code
			  else
			    load_large_number_into_register
			    (MachTypes.G7, MirTypes.GP_IMM_ANY frame_size) @@
			    post_ov_code
			val post_ov_code =
			     (Sparc_Assembly.LOAD_AND_STORE
			      (Sparc_Assembly.LD, MachTypes.global,
			       MachTypes.implicit,
			       Sparc_Assembly.IMM (4 * Implicit_Vector.extend)),
			      absent, "Get address of stack_overflow") ::
			     (Sparc_Assembly.JUMP_AND_LINK
			      (Sparc_Assembly.JMPL, MachTypes.global,
			       MachTypes.global,Sparc_Assembly.IMM 0,
			       Debugger_Types.null_backend_annotation),
			      absent, "Do stack_overflow") ::
			     Sparc_Assembly.nop ::
			     post_ov_code
			val ov_tag_code =
			  if immediate_size then
			    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (Sparc_Assembly.OR, MachTypes.G7,
			      MachTypes.G0, Sparc_Assembly.IMM frame_size),
			     absent, "Set the required size in G7") :: post_ov_code
			  else
			    post_ov_code
		      in
			(check_for_stack_overflow_wrap,
			 [],
			 (case opcode_list of
			    [] => block_list
			  | _ =>
			      MirTypes.BLOCK(end_tag,opcode_list) ::
			      block_list),
			    (non_ov_tag,
			     (if immediate_size
				then []
			      else
				[(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.SUB, MachTypes.G7,
				   MachTypes.G0, Sparc_Assembly.REG(MachTypes.G7)),
				  absent, "Negate the frame size")]) @@
				((Sparc_Assembly.SAVE_AND_RESTORE
				  (Sparc_Assembly.SAVE, MachTypes.sp,
                                   MachTypes.sp,
				   if immediate_size
				     then Sparc_Assembly.IMM(~frame_size)
				   else Sparc_Assembly.REG MachTypes.G7),
                                  absent, "New frame") ::
				(save_fps @@
				 [(Sparc_Assembly.BRANCH_ANNUL
				   (Sparc_Assembly.BA, 0),
				   SOME join_tag, ""),
				  Sparc_Assembly.nop]))) ::
			    (ov_tag,ov_tag_code)  ::
			    final_result)
		      end
		    else
		      ([], opcode_list, block_list, final_result)

		| MirTypes.RTS =>
		    (if needs_preserve then
		       restore_fps @@
		       [(Sparc_Assembly.JUMP_AND_LINK
			 (Sparc_Assembly.JMPL, MachTypes.G0,
			  MachTypes.after_preserve MachTypes.lr,
			  Sparc_Assembly.IMM 8,
			  Debugger_Types.null_backend_annotation),
			 absent, "Scheduled return"),
		       (Sparc_Assembly.SAVE_AND_RESTORE
			(Sparc_Assembly.RESTORE, MachTypes.G0, MachTypes.G0,
			 Sparc_Assembly.IMM 0),
                        absent, "Restore in the delay slot")]
		     else
		       [(Sparc_Assembly.JUMP_AND_LINK
			 (Sparc_Assembly.JMPL, MachTypes.G0,
			  MachTypes.lr, Sparc_Assembly.IMM 8,
			  Debugger_Types.null_backend_annotation),
			 absent, "Ordinary return"),
			Sparc_Assembly.nop],
		       opcode_list, block_list, final_result)
		| MirTypes.NEW_HANDLER(handler_frame, tag) =>
		    ([(Sparc_Assembly.LOAD_AND_STORE
		       (Sparc_Assembly.ST, MachTypes.handler,
			lookup_reg_operand handler_frame,
			Sparc_Assembly.IMM(~1)),
		       absent,
		       "Insert pointer to previous handler"),
		      move_reg(MachTypes.handler, lookup_reg_operand handler_frame)],
		     opcode_list, block_list, final_result)
		| MirTypes.OLD_HANDLER =>
		    ([(Sparc_Assembly.LOAD_AND_STORE
		       (Sparc_Assembly.LD, MachTypes.handler, MachTypes.handler,
			Sparc_Assembly.IMM(~1)),
		       absent,
		       "Restore old handler")], opcode_list, block_list, final_result)
		| MirTypes.RAISE reg =>
		    let
		      val code =
			if needs_preserve then
			  [(Sparc_Assembly.LOAD_AND_STORE
			    (Sparc_Assembly.LD, MachTypes.global,
			     MachTypes.implicit,
			     Sparc_Assembly.IMM (4 * Implicit_Vector.raise_code)),
			    absent, "Get the handler"),
			  (Sparc_Assembly.JUMP_AND_LINK
			   (Sparc_Assembly.JMPL, MachTypes.lr,
			    MachTypes.G0, Sparc_Assembly.REG MachTypes.global,
			    Debugger_Types.null_backend_annotation),
			   absent, "Raise"),
			  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.OR, MachTypes.caller_arg,
                            lookup_reg_operand reg,
                            Sparc_Assembly.REG MachTypes.G0),
			   absent, "Move arg to raise into arg reg")]
			else
			  [(Sparc_Assembly.LOAD_AND_STORE
			    (Sparc_Assembly.LD, MachTypes.global,
			     MachTypes.implicit,
			     Sparc_Assembly.IMM (4 * Implicit_Vector.leaf_raise_code)),
			    absent, "Get the handler"),
			  (Sparc_Assembly.JUMP_AND_LINK
			   (Sparc_Assembly.JMPL, MachTypes.G0,
			    MachTypes.G0, Sparc_Assembly.REG MachTypes.global,
			    Debugger_Types.null_backend_annotation),
			   absent, "Raise"),
			  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.OR, MachTypes.caller_arg,
			    lookup_reg_operand reg,
			    Sparc_Assembly.REG MachTypes.G0),
			   absent,"Move arg to raise into arg reg")]
		     in
		       (code, opcode_list, block_list, final_result)
		    end
		| MirTypes.COMMENT string =>
		    Crash.impossible"MirTypes.COMMENT not filtered out"
		| MirTypes.CALL_C =>
		    ([(Sparc_Assembly.LOAD_AND_STORE
		       (Sparc_Assembly.LD, MachTypes.global,
			MachTypes.implicit, Sparc_Assembly.IMM (4 * Implicit_Vector.external)),
		       absent, "Get address of callc"),
		    (Sparc_Assembly.JUMP_AND_LINK
		     (Sparc_Assembly.JMPL, MachTypes.lr,
		      MachTypes.global,Sparc_Assembly.IMM 0, Debugger_Types.null_backend_annotation),
		     absent, "Do call_c"), Sparc_Assembly.nop],
		    opcode_list, block_list, final_result)
	    in
	      do_everything
	      (needs_preserve, tag, opcode_list,
	       Sexpr.CONS(done, Sexpr.ATOM result_list), new_blocks,
	       new_final_result)
	    end

	in
	  do_everything(needs_preserve, tag, Lists.filter_outp is_comment opcodes,
			Sexpr.NIL, rest, [])
	end

      (* Some stuff to do with optimising unconditional branches to returns *)

      fun exit_block [] = NONE
      | exit_block((block as MirTypes.BLOCK(tag, opcode_list)) :: rest) =
	if Lists.exists
	  (fn MirTypes.RTS => true | _ => false)
	  opcode_list
	  then SOME block
	else exit_block rest

      fun small_exit_block(MirTypes.BLOCK(tag,opcode_list)) =
        let
          fun less_than_three_opcodes_that_are_not_comments([],occ) = true
            | less_than_three_opcodes_that_are_not_comments(MirTypes.COMMENT _ :: rest,occ) =
              less_than_three_opcodes_that_are_not_comments(rest,occ)
            | less_than_three_opcodes_that_are_not_comments(_,2) = false
            | less_than_three_opcodes_that_are_not_comments(h::t,occ) =
              less_than_three_opcodes_that_are_not_comments(t,occ+1)
        in
          less_than_three_opcodes_that_are_not_comments(opcode_list,0)
        end

      fun append_small_exit(MirTypes.BLOCK(tag, opcode_list), block_list) =
	let
	  fun do_block(block as MirTypes.BLOCK(tag', opc_list)) =
	    if Lists.exists
	      (fn (MirTypes.BRANCH(MirTypes.BRA, MirTypes.TAG t)) => tag = t
	      | _ => false)
	      opc_list then
	      (* Difficult case. Append the exit block onto the block *)
	      (* branching to it, and remove the branch and tag *)
	      let
		val opc' = rev opc_list
		fun get_new_opc_list((comm as MirTypes.COMMENT _) :: rest) =
		  comm :: get_new_opc_list rest
		| get_new_opc_list(MirTypes.BRANCH(MirTypes.BRA,
						   MirTypes.TAG t) ::
				   rest) =
		  if t = tag then rest
		  else
		    Crash.impossible"get_new_opc fails to find proper branch"
		| get_new_opc_list _ =
		  Crash.impossible"get_new_opc fails to find proper branch"
		val new_opc = get_new_opc_list opc'
		fun rev_app([], x) = x
		| rev_app(y, []) = y
		| rev_app(y :: ys, x) = rev_app(ys, y :: x)
	      in
		MirTypes.BLOCK(tag', rev_app(new_opc, opcode_list))
	      end
	    else
	      block
	in
	  map do_block block_list
	end

      fun proc_cg(MirTypes.PROC
		  (procedure_name,
                   proc_tag,
                   MirTypes.PROC_PARAMS {spill_sizes, stack_allocated, ...},
		   block_list,runtime_env)) =
	let
	  val exit_block = exit_block block_list

	  val block_list =
	    case exit_block of
	      NONE => block_list
	    | SOME exit_block =>
		if small_exit_block exit_block then
		  append_small_exit(exit_block, block_list)
		else
		  block_list

	  fun define_fp(map, MirTypes.FP_REG fp) =
	    case MirTypes.FP.Map.tryApply'(map, fp) of
	      NONE => MirTypes.FP.Map.define(map, fp, true)
	    | _ => map

	  fun get_fps_from_opcode(map, MirTypes.TBINARYFP(_, _, fp1, fp2, fp3)) =
	    define_fp(define_fp(define_fp(map, fp1), fp2), fp3)
	    | get_fps_from_opcode(map, MirTypes.TUNARYFP(_, _, fp1, fp2)) =
	      define_fp(define_fp(map, fp1), fp2)
	    | get_fps_from_opcode(map, MirTypes.BINARYFP(_, fp1, fp2, fp3)) =
	      define_fp(define_fp(define_fp(map, fp1), fp2), fp3)
	    | get_fps_from_opcode(map, MirTypes.UNARYFP(_, fp1, fp2)) =
	      define_fp(define_fp(map, fp1), fp2)
	    | get_fps_from_opcode(map, MirTypes.STOREFPOP(_, fp1, _, _)) =
	      define_fp(map, fp1)
	    | get_fps_from_opcode(map, MirTypes.REAL(_, fp1, _)) =
	      define_fp(map, fp1)
	    | get_fps_from_opcode(map, MirTypes.FLOOR(_, _, _, fp1)) =
	      define_fp(map, fp1)
	    | get_fps_from_opcode(map, MirTypes.FTEST(_, _, fp1, fp2)) =
	      define_fp(define_fp(map, fp1), fp2)
	    | get_fps_from_opcode(map, _) = map

	  fun get_fps_from_block(map, MirTypes.BLOCK(_, instr_list)) =
	    Lists.reducel get_fps_from_opcode (map, instr_list)

	  val fp = MirTypes.FP.Map.domain(Lists.reducel get_fps_from_block (MirTypes.FP.Map.empty, block_list))

	  val fps = Set.list_to_set(map (fn r => MirTypes.FP.Map.apply'(fp_map, r)) fp)
	  val fps_to_preserve =
	    Set.set_to_list(Set.setdiff(fps,
					#fp MachSpec.corrupted_by_callee))
	
	  val fp_save_size = length fps_to_preserve
	  val preserve_fps = fp_save_size <> 0

	  fun check_instr(MirTypes.BRANCH_AND_LINK _) = true
	    | check_instr MirTypes.CALL_C = true
(*Now allowed to be leaf
	    | check_instr(MirTypes.SWITCH _) = true
*)
            | check_instr(MirTypes.NEW_HANDLER _) = true
	    | check_instr(MirTypes.ADR _) = true
(* Warning. If we ever make a leaf adr, we must ensure *)
(* handler continuations are done safely. This is not currently *)
(* true since they use o1 as the address. *)
            (* These need the extra slot for fp moves *)
            | check_instr (MirTypes.REAL _) = true
            | check_instr (MirTypes.FLOOR _) = true
            | check_instr (MirTypes.STACKOP _) = true
	    | check_instr _ = false

	  fun check_instr_block(MirTypes.BLOCK(_, instr_list)) =
	    Lists.exists check_instr instr_list

	  val stack_opt = stack_allocated
	  val stack_extra = case stack_opt of
	    SOME stack_extra => stack_extra
	  | _ =>  Crash.impossible"Stack size missing to mach_cg"

	  fun check_reg_op(MirTypes.GC_REG r) =
	    MachTypes.check_reg(MirTypes.GC.Map.apply'(gc_map, r))
	    | check_reg_op(MirTypes.NON_GC_REG r) =
	      MachTypes.check_reg(MirTypes.NonGC.Map.apply'(non_gc_map, r))

	  fun check_gp_op(MirTypes.GP_GC_REG r) =
	    MachTypes.check_reg(MirTypes.GC.Map.apply'(gc_map, r))
	    | check_gp_op(MirTypes.GP_NON_GC_REG r) =
	      MachTypes.check_reg(MirTypes.NonGC.Map.apply'(non_gc_map, r))
	    | check_gp_op(MirTypes.GP_IMM_INT _) = ()
	    | check_gp_op(MirTypes.GP_IMM_ANY _) = ()
	    | check_gp_op(MirTypes.GP_IMM_SYMB symbolic) =
	      case symbolic of
		MirTypes.GC_SPILL_SIZE => ()
	      | MirTypes.NON_GC_SPILL_SIZE => ()
	      | MirTypes.GC_SPILL_SLOT _ => raise MachTypes.NeedsPreserve
	      | MirTypes.NON_GC_SPILL_SLOT _ => raise MachTypes.NeedsPreserve
	      | MirTypes.FP_SPILL_SLOT _ => raise MachTypes.NeedsPreserve

	  fun check_instr_regs(MirTypes.TBINARY(_, _, reg_op, gp_op, gp_op')) =
	    (check_reg_op reg_op;
	     check_gp_op gp_op;
	     check_gp_op gp_op')
	    | check_instr_regs(MirTypes.BINARY(_, reg_op, gp_op, gp_op')) =
	      (check_reg_op reg_op;
	       check_gp_op gp_op;
	     check_gp_op gp_op')
	    | check_instr_regs(MirTypes.UNARY(_, reg_op, gp_op )) =
	      (check_reg_op reg_op;
	       check_gp_op gp_op)
	    | check_instr_regs(MirTypes.NULLARY(_, reg_op )) =
	      (check_reg_op reg_op)
	    | check_instr_regs(MirTypes.TBINARYFP _) = ()
	    | check_instr_regs(MirTypes.TUNARYFP _) = ()
	    | check_instr_regs(MirTypes.BINARYFP _) = ()
	    | check_instr_regs(MirTypes.UNARYFP _) = ()
	    | check_instr_regs(MirTypes.STACKOP _) =
	      raise MachTypes.NeedsPreserve
	    | check_instr_regs(MirTypes.IMMSTOREOP _) =
	      Crash.impossible"IMMSTOREOP not supported on sparc"
	    | check_instr_regs(MirTypes.STOREOP(_, reg_op, reg_op', gp_op )) =
	      (check_reg_op reg_op;
	       check_reg_op reg_op';
	       check_gp_op gp_op)
	    | check_instr_regs(MirTypes.STOREFPOP(_, _, reg_op, gp_op )) =
	      (check_reg_op reg_op;
	       check_gp_op gp_op)
	    | check_instr_regs(MirTypes.REAL _) =
	      raise MachTypes.NeedsPreserve
	    | check_instr_regs(MirTypes.FLOOR _) =
	      raise MachTypes.NeedsPreserve
	    | check_instr_regs(MirTypes.BRANCH(_, bl_dest )) =
	      (case bl_dest of
		 MirTypes.REG reg_op => (check_reg_op reg_op)
	       | _ => ())
	    | check_instr_regs(MirTypes.TEST(_, _, gp_op, gp_op')) =
	      (check_gp_op gp_op;
	     check_gp_op gp_op')
	    | check_instr_regs(MirTypes.FTEST _) = ()
	    | check_instr_regs(MirTypes.BRANCH_AND_LINK _) =
	      raise MachTypes.NeedsPreserve
	    | check_instr_regs(MirTypes.TAIL_CALL(_, bl_dest,_)) =
	      (case bl_dest of
		 MirTypes.REG reg_op => (check_reg_op reg_op)
	       | _ => ())
	    | check_instr_regs(MirTypes.CALL_C) =
	      raise MachTypes.NeedsPreserve
	    | check_instr_regs(MirTypes.SWITCH _) =
	      raise MachTypes.NeedsPreserve
	    | check_instr_regs(MirTypes.ALLOCATE(_, reg_op, gp_op )) =
	      (check_reg_op reg_op;
	       check_gp_op gp_op)
	    | check_instr_regs(MirTypes.ALLOCATE_STACK _) =
	      raise MachTypes.NeedsPreserve
	    | check_instr_regs(MirTypes.DEALLOCATE_STACK _) =
	      raise MachTypes.NeedsPreserve
	    | check_instr_regs(MirTypes.ADR _) =
	      raise MachTypes.NeedsPreserve
	    | check_instr_regs(MirTypes.INTERCEPT) = ()
	    | check_instr_regs(MirTypes.INTERRUPT) = ()
	    | check_instr_regs(MirTypes.ENTER _) = ()
	    | check_instr_regs(MirTypes.RTS) = ()
	    | check_instr_regs(MirTypes.NEW_HANDLER _) =
	      raise MachTypes.NeedsPreserve
	    | check_instr_regs(MirTypes.OLD_HANDLER) =
	      raise MachTypes.NeedsPreserve
	    | check_instr_regs(MirTypes.RAISE reg_op) =
	      (check_reg_op reg_op)
	    | check_instr_regs(MirTypes.COMMENT _) = ()

	  fun check_instr_block_regs(MirTypes.BLOCK(_, instr_list)) =
	    Lists.iterate check_instr_regs instr_list

	  val needs_preserve =
	    (* First check that leaf optimisation is allowed *)
	    not (opt_leaf_fns) orelse
	    (* Then see if any stack has been used *)
	    stack_extra <> 0 orelse (* This should catch the big procedures easily *)
	    (* Then see if any fps need perserving *)
	    preserve_fps orelse
	    (* Now see if any instructions force non-leaf *)
            Lists.exists check_instr_block block_list orelse
	    (* See if we use any non-leaf registers *)
	    ((Lists.iterate check_instr_block_regs block_list;
	      false) handle MachTypes.NeedsPreserve => true)

          val _ =
            if generate_debug_info orelse debug_variables orelse generate_moduler
              then
                debug_map := Debugger_Types.set_proc_data (procedure_name,
                                                           not needs_preserve,
							   true,
							   runtime_env,
                                                           !debug_map)
            else ()
	  val _ =
	    if needs_preserve then ()
	    else
	      diagnostic_output 3
	      (fn _ => [procedure_name, " is leaf\n"])

	  fun move_first (_, []) =
	      Crash.impossible "move_first"
	    | move_first (L, (t, code) :: rest) =
	      if t = proc_tag then (t, code) :: (L @@ rest)
	      else move_first ((t, code) :: L, rest)

	  fun block_needs_fp_spare(MirTypes.BLOCK(_, opc_list)) =
	    let
	      fun opc_needs_fp_spare [] = false
	      | opc_needs_fp_spare(MirTypes.REAL _ :: _) = true
	      | opc_needs_fp_spare(MirTypes.FLOOR _ :: _) = true
	      | opc_needs_fp_spare(_ :: rest) = opc_needs_fp_spare rest
	    in
	      opc_needs_fp_spare opc_list
	    end

	  fun proc_needs_fp_spare [] = false
	  | proc_needs_fp_spare(block :: block_list) =
	    block_needs_fp_spare block orelse proc_needs_fp_spare block_list

	  val needs_fp_spare = proc_needs_fp_spare block_list

	  (* Moved this from do_block as it's independent of block number *)
	  val spills_opt = spill_sizes
	  val (gc_spill_size, non_gc_spill_size, fp_spill_size) =
	    case spills_opt of
	      SOME{gc = gc_spill_size,
			       non_gc = non_gc_spill_size,
			       fp = fp_spill_size} =>
	      (gc_spill_size, non_gc_spill_size, fp_spill_size)
	     | _ => Crash.impossible"Spill sizes missing to mach_cg"
	  val non_gc_spill_size =
	    if needs_fp_spare then non_gc_spill_size + 1
	    else non_gc_spill_size
	  val float_value_size = case MachTypes.fp_used of
	    MachTypes.single => 4
	  | MachTypes.double => 8
	  | MachTypes.extended => 16
	  val total_fp_size = fp_spill_size + fp_save_size
	  val total_gc_size = gc_spill_size + stack_extra

	  val non_gc_spill_size =
	    if total_fp_size <> 0 andalso float_value_size <> 4 andalso
	      non_gc_spill_size mod 2 <> 0 then
	      non_gc_spill_size + 1
	    (* Allow an extra word to get alignment for floats *)
	    else
	      non_gc_spill_size
	  (* non_gc_spill_size * 4 is now *)
	  (* double aligned ready for floats if necessary *)

	  val needs_preserve = needs_preserve orelse needs_fp_spare

	  val non_gc_stack_size =
	    non_gc_spill_size * 4 + float_value_size * total_fp_size

	  val total = non_gc_stack_size + total_gc_size * 4
	  val non_gc_stack_size =
	    if total mod 8 = 0 then non_gc_stack_size else non_gc_stack_size + 4
	  (* Allow more non-gc space to get overall double alignment *)

	  val fp_spill_offset = non_gc_spill_size * 4
	  val fp_save_offset = fp_spill_offset + fp_spill_size * float_value_size
	  val gc_spill_offset  = non_gc_stack_size

	  val gc_stack_alloc_offset = gc_spill_offset + gc_spill_size * 4
	  val register_save_offset = gc_stack_alloc_offset + stack_extra * 4

	  val stack_layout =
	    PROC_STACK
	    {non_gc_spill_size = non_gc_spill_size,
	     fp_spill_size = fp_spill_size,
	     fp_save_size = fp_save_size,
	     gc_spill_size = gc_spill_size,
	     gc_stack_alloc_size = stack_extra,
	     register_save_size = 64,
	     non_gc_spill_offset = 0,
	     fp_spill_offset = fp_spill_offset,
	     fp_save_offset = fp_save_offset,
	     gc_spill_offset = gc_spill_offset,
	     gc_stack_alloc_offset = gc_stack_alloc_offset,
	     register_save_offset = register_save_offset,
	     allow_fp_spare_slot = needs_fp_spare,
	     float_value_size = float_value_size
	     }

(*
	  val _ = output(std_out, "non_gc_spill_size = " ^ Int.toString non_gc_spill_size ^ "\n")
	  val _ = output(std_out, "fp_spill_size = " ^ Int.toString fp_spill_size ^ "\n")
	  val _ = output(std_out, "fp_save_size = " ^ Int.toString fp_save_size ^ "\n")
	  val _ = output(std_out, "gc_spill_size = " ^ Int.toString gc_spill_size ^ "\n")
	  val _ = output(std_out, "stack_extra = " ^ Int.toString stack_extra ^ "\n")
	  val _ = output(std_out, "register_save_size = " ^ Int.toString 64 ^ "\n")
	  val _ = output(std_out, "non_gc_spill_offset = " ^ Int.toString 0 ^ "\n")
	  val _ = output(std_out, "fp_spill_offset = " ^ Int.toString fp_spill_offset ^ "\n")
	  val _ = output(std_out, "fp_save_offset = " ^ Int.toString fp_save_offset ^ "\n")
	  val _ = output(std_out, "gc_spill_offset = " ^ Int.toString gc_spill_offset ^ "\n")
	  val _ = output(std_out, "gc_stack_alloc_offset = " ^ Int.toString gc_stack_alloc_offset ^ "\n")
	  val _ = output(std_out, "register_save_offset = " ^ Int.toString register_save_offset ^ "\n")
*)

	  val block_tree =
	    Lists.reducel
	    (fn (map, MirTypes.BLOCK x) => MirTypes.Map.define'(map, x))
	    (MirTypes.Map.empty, block_list)

	  val spill_array = MLWorks.Internal.Array.array(gc_spill_size, true)
	  val stack_array = MLWorks.Internal.Array.array(stack_extra, true)

	  fun ok_store MirTypes.ST = true
	    | ok_store MirTypes.STREF = true
	    | ok_store _ = false

	  fun analyse_instr(_, MirTypes.TBINARY _) = ([], true)
	    | analyse_instr(_, MirTypes.TBINARYFP _) = ([], true)
	    | analyse_instr(_, MirTypes.TUNARYFP _) = ([], true)
	    | analyse_instr(_, MirTypes.REAL _) = ([], true)
	    | analyse_instr(_, MirTypes.FLOOR _) = ([], true)
	    | analyse_instr(_, MirTypes.BRANCH_AND_LINK _) = ([], true)
	    | analyse_instr(_, MirTypes.TAIL_CALL _) = ([], true)
	    | analyse_instr(_, MirTypes.CALL_C) = ([], true)
	    | analyse_instr(_, MirTypes.SWITCH _) = ([], true)
	    | analyse_instr(_, MirTypes.RAISE _) = ([], true)
	    | analyse_instr(_, MirTypes.INTERCEPT) = ([], true)
	    | analyse_instr(_, MirTypes.INTERRUPT) = ([], true)
	    | analyse_instr(_, MirTypes.BRANCH _) = ([], true)
	    | analyse_instr(_, MirTypes.TEST _) = ([], true)
	    | analyse_instr(_, MirTypes.FTEST _) = ([], true)
	    | analyse_instr(_, MirTypes.ALLOCATE _) = ([], true)
	    | analyse_instr(a as (list, x),
			    MirTypes.ALLOCATE_STACK(MirTypes.ALLOC, r, size, offset)) =
	      if x then a else
		let
		  val offset = case offset of
		    SOME x => x
		  | _ => Crash.impossible"offset missing from stack allocation"
		in
		  ((r, stack_extra - offset - size) :: list, false)
		end

	    | analyse_instr(a as (list, x), MirTypes.STOREOP(store, _, r2, g)) =
	      if x orelse not(ok_store store) then a else
		(case g of
		   MirTypes.GP_IMM_SYMB symb =>
		     (case symb of
			MirTypes.GC_SPILL_SLOT _ =>
			  let
			    val offset = symb_value stack_layout symb
			    val i = gc_spill_size + (offset + gc_spill_offset) div 4
			    (* Offset in words from top of the relevant region *)
			    val _ = MLWorks.Internal.Array.update(spill_array, gc_spill_size -1 - i, false)
			  in
			    a
			  end
		      | _ => a)
		 | MirTypes.GP_IMM_ANY i =>
		     (let
		       val start = Lists.assoc(r2, list)
		       val offset = (i + 1) div 4
		       val _ = MLWorks.Internal.Array.update(stack_array, offset+start, false)
		      in
			a
		      end
			handle Lists.Assoc => a)
		 | _ => a)
	    | analyse_instr(x, _) = x

	  fun analyse_block block_tag =
	    let
	      val instrs = MirTypes.Map.tryApply'(block_tree, block_tag)
	    in
	      case instrs of
		SOME instrs =>
		  Lists.reducel analyse_instr (([], false), instrs)
	      | _ => ([], false)
	    end

	  val _ = analyse_block proc_tag

	  fun needs_init(a, b) = a orelse b

	  val spills_need_init =
	    MLWorks.Internal.ExtendedArray.reducel needs_init (false, spill_array)

	  val stack_need_init =
	    MLWorks.Internal.ExtendedArray.reducel needs_init (false, stack_array)

	  val code =
	    move_first([], do_blocks(needs_preserve,
				     block_list,
				     stack_layout,
				     spills_need_init,
				     stack_need_init,
				     fps_to_preserve))

	  val code_len =
	    Lists.reducel op +
	    (0, map (fn (_, opcodes) => length opcodes) code)

          val padded_name =
            let
              fun generate_nulls 0 = ""
                | generate_nulls n = String.str (chr(0)) ^ generate_nulls (n-1)
              fun normalise_to_four_bytes (x) =
                x ^ generate_nulls((4 - ((size x) mod 4)) mod 4)
            in
              normalise_to_four_bytes(procedure_name ^ String.str(chr(0)))
            end

	in
	  {code=(proc_tag, code),
	   non_gc_area_size=non_gc_stack_size,
           name=procedure_name,
           padded_name=padded_name,
	   leaf=not needs_preserve,
	   parms=0}
	end

      fun remove_redundant_loads(acc, []) = rev acc
	| remove_redundant_loads(acc, arg as [x]) = rev(x :: acc)
	| remove_redundant_loads(acc, (ins1 as (Sparc_Assembly.LOAD_AND_STORE
						(Sparc_Assembly.ST, rd1, rs11, rs12),
						tag1, comment1)) ::
				 (ins2 as (Sparc_Assembly.LOAD_AND_STORE
					   (Sparc_Assembly.LD, rd2, rs21, rs22),
					   tag2, comment2)) :: rest) =
	  if rs11 = rs21 andalso rs12 = rs22 andalso rd1 = rd2 then
	    (diagnostic_output 3
	     (fn _ => ["Removing redundant load after store\n"]);
	     remove_redundant_loads(acc, ins1 :: rest))
	  else
	    remove_redundant_loads(ins2 :: ins1 :: acc, rest)
	| remove_redundant_loads(acc, x :: rest) = remove_redundant_loads(x :: acc, rest)

      val remove_redundant_loads = fn x => remove_redundant_loads([], x)

      fun remove_redundant_loads_from_block(tag, opcode_list) =
	(tag, remove_redundant_loads opcode_list)

      fun remove_redundant_loads_from_proc(tag, block_list) =
	(tag, map remove_redundant_loads_from_block block_list)

      fun list_proc_cg proc_list =
	let
	  fun print_unscheduled_code((tag, block_list),name) =
	    let
	      fun print_block(tag, opcode_list) =
		let
		  fun print_opcode(opcode, tag_opt, comment) =
		    Print.print(
			  Sparc_Assembly.print opcode ^
			  (case tag_opt of
			    SOME tag =>
			       " tag " ^ MirTypes.print_tag tag
			  | NONE => " no tag") ^
			     " ; " ^ comment ^ "\n")
		in
		  (Print.print("Block tag " ^ MirTypes.print_tag tag ^ "\n");
		   map print_opcode opcode_list)
		end
	    in
	      (Print.print("Procedure entry tag " ^ MirTypes.print_tag tag ^
                           " " ^ name ^
			   "\n");
	       map print_block block_list)
	    end

	  val temp_code_list =
	    Timer.xtime
	    ("main proc_cg stage", !do_timings,
	     fn () => map proc_cg proc_list)

	  val code_list =
            map (fn tuple=>remove_redundant_loads_from_proc (#code(tuple))) temp_code_list
          val procedure_name_list = map #name temp_code_list
	  val leaf_list = map #leaf temp_code_list
	  val stack_parameters = map #parms temp_code_list

	  val code_list' = code_list

	  val _ = diagnostic_output 3
	    (fn _ => ["Unscheduled code\n"])

	  val _ = diagnostic_output 3
	    (fn _ => (ignore(map print_unscheduled_code
                      (Lists.zip(code_list',procedure_name_list)));
		      []))

          fun is_static s =
            let
              fun is_prefix n =
                let
                  val l = size n
                in
                  size s > l andalso MLWorks.String.substring (s,0,l) = n
                end
            in
              is_prefix "<Setup>" orelse is_prefix "Functor "
            end

(*
          val is_static = fn s => (if is_static s then print (s ^ "is static\n") else print (s ^ " isn't static\n");
                                     is_static s)
*)
	  fun do_reschedule code_list =
	    let
	      val code_list' =
		Timer.xtime
		("rescheduling blocks", !do_timings,
		 fn () =>
		 map
		 (fn ((proc_tag, proc),name) =>
                  let
                    val static = is_static name
                  in
                    (proc_tag, map
                     (fn (tag, x) => (tag, Sparc_Schedule.reschedule_block (static,x)))
                     proc)
                  end)
		 (Lists.zip (code_list,procedure_name_list)))

	      val _ = diagnostic_output 3 (fn _ => ["Rescheduled at block level, now doing proc level\n"])
	      val _ = diagnostic_output 3 (fn _ => ["Result so far\n"])
	      val _ = diagnostic_output 3 (fn _ => (ignore(map print_unscheduled_code
                                                    (Lists.zip(code_list',procedure_name_list)));
						    []))

	      val code_list'' =
		Timer.xtime
		("rescheduling procs", !do_timings,
		 fn () => map Sparc_Schedule.reschedule_proc code_list')
	    in
	      code_list''
	    end

	  fun print_scheduled_code (code_list) =
	    let
	      fun print_proc((proc_tag, proc),name) =
		let
		  fun print_block(tag, opcode_list) =
		    let
		      fun print_opcode(opcode, tag_opt, comment) =
			Print.print(
			      Sparc_Assembly.print opcode ^
			      (case tag_opt of
				 SOME tag =>
				   " tag " ^ MirTypes.print_tag tag
			       | NONE => " no tag") ^
				 " ; " ^ comment ^ "\n")
		    in
		      (Print.print("Block tag " ^ MirTypes.print_tag tag ^ " " ^ name ^ "\n");
		       map print_opcode opcode_list)
		    end
		in
		  (Print.print("Procedure tag " ^ MirTypes.print_tag proc_tag ^ "\n");
		   map print_block proc)
		end
	    in
	      map print_proc code_list
	    end

	  val _ = diagnostic_output 3 (fn _ => (["Rescheduling code\n"]))

	  val new_code_list' =
	    Timer.xtime
	    ("rescheduling", !do_timings,
	     fn () => do_reschedule code_list')

	  val _ = diagnostic_output 3 (fn _ => ["Rescheduled code\n"])
	  val _ = diagnostic_output 3 (fn _ => (ignore(print_scheduled_code (Lists.zip(new_code_list',procedure_name_list)));
						 []))
	  val _ = diagnostic_output 3 (fn _ => ["Linearising\n"])

	  val linear_code' =
	    Timer.xtime
	    ("linearising", !do_timings,
	     fn () => linearise_list new_code_list')

	  val nop_offsets = map find_nop_offsets linear_code'
	  val _ = diagnostic_output 3 (fn _ => ["Linearised\n"])

	  val nop_instruction =
	    Sparc_Opcodes.output_opcode
	    (Sparc_Assembly.assemble (Sparc_Assembly.nop_code))
		
	  fun make_tagged_code linear_code =
            (map
	     (fn ((tag, code),{non_gc_area_size, padded_name, ...}) =>
		{a_clos=Lists.assoc(tag, loc_refs),
		 b_spills=non_gc_area_size,
		 c_saves=0,
		 d_code=
		 let
                   fun do_annotation (debug,count) =
                     let
                       val unpadded_name =
                         let
                           val s = size padded_name
                           fun check_index to =
                             if MLWorks.String.ordof(padded_name,to) = 0
                               then check_index(to-1)
                             else MLWorks.String.substring(padded_name,0,to+1)
                         in
                           check_index (s-1)
                           handle MLWorks.String.Substring => ""
                                | MLWorks.String.Ord => ""
                         end
                     in
                       debug_map := Debugger_Types.add_annotation (unpadded_name,
                                                                   count,
                                                                   debug,
                                                                   !debug_map)
                     end

                   fun annotation_points ([],_,res) = rev res
                     | annotation_points ((inst,_)::t,count,res) =
                       (case inst of
                          Sparc_Assembly.JUMP_AND_LINK (_,_,_,_,debug) => do_annotation (debug,count)
                        | Sparc_Assembly.Call (_,_,debug) => do_annotation (debug,count)
                        | _ => ();
                        annotation_points(t,count+4,
                                          Sparc_Opcodes.output_opcode(Sparc_Assembly.assemble inst)::res))
                   val code =
                     if generate_debug_info then
                       concat (annotation_points (code,0,[]))
                     else
                       concat
                       (map
                        (fn (x, _) =>
                         Sparc_Opcodes.output_opcode(Sparc_Assembly.assemble x))
                        code)

                   val padded_code =
                     if size code mod 8 = 4
                       then code ^ nop_instruction
                     else code
		 in
                   padded_code
		 end})
	       (Lists.zip(linear_code,temp_code_list)))
	      handle Lists.Assoc => Crash.impossible"Assoc tagged_code"
	    handle Lists.Assoc => Crash.impossible"Assoc tagged_code"

	  val tagged_code' = make_tagged_code linear_code'
	(* Here we have leaf_list corresponding to procedure_name_list *)
	in
	  (Code_Module.WORDSET(Code_Module.WORD_SET
			       {a_names=procedure_name_list,
				b=tagged_code',
				c_leafs=leaf_list,
				d_intercept=nop_offsets,
				e_stack_parameters=stack_parameters}),
	   Lists.zip(linear_code', procedure_name_list))
	end

      val (proc_elements, code_list) = Lists.unzip(map list_proc_cg proc_list_list)

      val _ =
        if ! print_code_size  then
	  print("Normalised code size is " ^
		Int.toString
		(Lists.reducel
		 (fn(x,Code_Module.WORDSET(Code_Module.WORD_SET{b=tagged_code', ...})) =>
		  (Lists.reducel (fn (x,{d_code=y, ...}) => (size y) + x) (x,tagged_code'))
	       | _ => Crash.impossible "what the ?")
		 (0,proc_elements)) ^ "\n")
        else ()

      fun make_external_refs(con, list) =
	map (fn (x, y) => con(y, x)) list

      val ext_elements = make_external_refs(Code_Module.EXTERNAL, ext_refs)
      val ext_vars = make_external_refs(Code_Module.VAR, vars)
      val ext_exns = make_external_refs(Code_Module.EXN, exns)
      val ext_strs = make_external_refs(Code_Module.STRUCT, strs)
      val ext_funs = make_external_refs(Code_Module.FUNCT, funs)

      val module =
	Code_Module.MODULE(value_elements @@
			 proc_elements @@
			 ext_elements @@
			 ext_vars @@
			 ext_exns @@
			 ext_strs @@
			 ext_funs)
    in
     ((module, !debug_map), code_list)
    end
end
@


1.248.1.1
log
@branched from trunk for label MLW_daveb_inline_1_4_99
@
text
@a3 4
 * Revision 1.248  1998/02/20  09:31:47  mitchell
 * [Bug #30349]
 * Fix to avoid non-unit sequence warnings
 *
@


1.247
log
@[Bug #30326]
Merge in change from branch MLWorks_workspace_97
@
text
@d4 4
d1353 1
a1353 1
	    (fn _ => (map
d1355 1
a1355 1
		      (Map.to_list tag_env) ;
d4730 2
a4731 2
	    (fn _ => (map print_unscheduled_code
                      (Lists.zip(code_list',procedure_name_list)) ;
d4769 2
a4770 2
	      val _ = diagnostic_output 3 (fn _ => (map print_unscheduled_code
                                                    (Lists.zip(code_list',procedure_name_list)) ;
d4815 1
a4815 1
	  val _ = diagnostic_output 3 (fn _ => (print_scheduled_code (Lists.zip(new_code_list',procedure_name_list)) ;
@


1.246
log
@[Bug #30089]
Modify TIMER (from utils) to be INTERNAL_TIMER to keep bootstrap happy
@
text
@d4 4
d12 6
d860 1
a860 1
require "../utils/timer";
@


1.245
log
@[Bug #30153]
Remove references to Old.
@
text
@d4 4
d871 1
a871 1
  structure Timer : TIMER
@


1.244
log
@[Bug #30243]
Remove tests for out of range shifts as we no longer generate them
@
text
@d4 4
d842 2
a843 1
require "../basis/__int";
a862 2
require "^.basis.__old";

d997 1
a997 1
	binary_list_to_string(Old.chr(digit + x) :: done, xs, 0, 128)
d1007 1
a1007 1
	  val digit = Old.chr(value mod 2 + ord #"0")
d1043 1
a1043 1
	   Old.explode (MLWorks.String.substring (mantissa, 1, 23))
d1055 2
a1056 1
	   Old.explode(MLWorks.String.substring (mantissa, 1, 52))
d1070 2
a1071 1
	   Old.explode(MLWorks.String.substring (mantissa, 0, 64)) @@
d4630 1
a4630 1
                | generate_nulls n = Old.chr(0) ^ generate_nulls (n-1)
d4634 1
a4634 1
              normalise_to_four_bytes(procedure_name ^ Old.chr(0))
@


1.244.2.1
log
@branched from trunk for label MLWorks_workspace_97
@
text
@a3 4
 * Revision 1.244  1997/08/07  14:54:35  jont
 * [Bug #30243]
 * Remove tests for out of range shifts as we no longer generate them
 *
@


1.244.2.2
log
@[Bug #30326]
@
text
@a3 3
 * Revision 1.244.2.1  1997/09/11  21:08:53  daveb
 * branched from trunk for label MLWorks_workspace_97
 *
d845 1
a845 1
require "../utils/mlworks_timer";
@


1.244.1.1
log
@branched from trunk for label MLWorks_dt_wizard
@
text
@a3 4
 * Revision 1.244  1997/08/07  14:54:35  jont
 * [Bug #30243]
 * Remove tests for out of range shifts as we no longer generate them
 *
@


1.243
log
@[Bug #50027]
Sort out bugs in NOT and NOT32 of constant (not that these should happen)
@
text
@d4 4
d2429 2
a2430 12
			      val shift_size =
				if gp_check_range(gp_operand', true,
						  arith_imm_limit) then
				  make_imm_format3 gp_operand'
				else
				  (* Out of range shift *)
				  Sparc_Assembly.IMM
				  (case binary_op of
				     MirTypes.LSR => 32
				   | MirTypes.ASR => 29
				   | MirTypes.ASL => 32
				   | _ => Crash.impossible"mach_cg: non-shift in shift case")
d2438 2
a2439 2
				  if shift_val >= 32 then
				    (* Out of range shift right, replace by zero *)
d2441 1
a2441 4
				      val new_opc =
					MirTypes.UNARY(MirTypes.MOVE,
						       reg_operand,
						       MirTypes.GP_IMM_INT 0)
d2443 4
a2446 2
				      ([], new_opc :: opcode_list,
				       block_list, final_result)
d2449 12
a2460 23
				    (* Deal with possible immediate value here *)
				    if is_reg gp_operand then
				      let
					val rs1 = lookup_gp_operand gp_operand
				      in
					([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					   (opcode, rd, rs1, shift_size),
					   absent, "")],
					 opcode_list, block_list, final_result)
				      end
				    else
				      (* A rare case, just replace by move *)
				      (* and shift the result *)
				      ([],
				       MirTypes.UNARY(MirTypes.MOVE,
						      MirTypes.GC_REG MirRegisters.global,
						      gp_operand) ::
				       MirTypes.BINARY(binary_op,
						       reg_operand,
						       MirTypes.GP_GC_REG MirRegisters.global,
						       gp_operand') ::
				       opcode_list,
				       block_list, final_result)
d2463 8
a2470 22
				    if shift_val >= 32 then
				      (* Out of range shift right, *)
				      (* replace by shift by 31 *)
				      let
					val new_opc =
					  MirTypes.BINARY(binary_op,
							  reg_operand,
							  gp_operand,
							  MirTypes.GP_IMM_ANY 31)
				      in
					([], new_opc :: opcode_list,
					 block_list, final_result)
				      end
				    else
				      let
					val rs1 = lookup_gp_operand gp_operand
				      in
					([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					   (opcode, rd, rs1, shift_size),
					   absent, "")],
					 opcode_list, block_list, final_result)
				      end
a2484 12
				  if shift_val >= 32 then
				    (* Out of range shift right, replace by zero *)
				    let
				      val new_opc =
					MirTypes.UNARY(MirTypes.MOVE,
						       reg_operand,
						       MirTypes.GP_IMM_INT 0)
				    in
				      ([], new_opc :: opcode_list,
				       block_list, final_result)
				    end
				  else
@


1.242
log
@[Bug #30215]
@
text
@d4 4
d2764 4
a2767 1
					  gp_operand) :: opcode_list,
d2787 4
a2790 1
					  gp_operand) :: opcode_list,
@


1.241
log
@[Bug #30076]
Modifications to allow stack based parameter passing on the I386
@
text
@d4 4
a2337 1
		      | is_shift MirTypes.BIC = false
a2351 1
		      | MirTypes.BIC => (Sparc_Assembly.ANDN,false)
d2412 1
a2412 1
			(* and also bad code from LSR/ASR :: BIC *)
d2714 5
a2718 36
		    let
		      val rd = lookup_reg_operand reg_operand
		      val opcode = Sparc_Assembly.OR
		      val imm = Sparc_Assembly.REG MachTypes.G0
		      val code_list =
			if is_reg gp_operand then
			  let
			    val rs1 = lookup_gp_operand gp_operand
			  in
			    if rd = rs1 then [] (* Null move rn -> rn *)
			    else
			      [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(opcode, rd, rs1, imm), absent, "")]
			  end
			else
			  if gp_check_range(gp_operand, true,
					    arith_imm_limit) then
			    let
			      val imm = case make_imm_format3 gp_operand of
				Sparc_Assembly.IMM 0 => imm (* MOVE 0 case *)
			      | non_zero_imm => non_zero_imm
			    in
			      [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(opcode, rd, MachTypes.G0, imm), absent, "")]
			    end
			  else
			    load_large_number_into_register(rd, gp_operand)
		    in
		      (code_list, opcode_list, block_list, final_result)
		    end
		| MirTypes.UNARY(MirTypes.NOT, reg_operand, gp_operand) =>
		    let
		      val rd = lookup_reg_operand reg_operand
		      val opcode = Sparc_Assembly.XORN
		      val simple_imm = Sparc_Assembly.IMM 3
		    in
d2723 4
a2726 3
			  ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (opcode, rd, rs1, simple_imm), absent, "")],
			   opcode_list, block_list, final_result)
d2729 34
a2762 4
			([], MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					    gp_operand) :: opcode_list,
			 block_list, final_result)
		    end
d2765 40
a2804 18
		    let
		      val rd = lookup_reg_operand reg_operand
		      val opcode = Sparc_Assembly.XORN
		      val simple_imm = Sparc_Assembly.IMM 0
		    in
		      if is_reg gp_operand then
			let
			  val rs1 = lookup_gp_operand gp_operand
			in
			  ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (opcode, rd, rs1, simple_imm), absent, "")],
			   opcode_list, block_list, final_result)
			end
		      else
			([], MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					    gp_operand) :: opcode_list,
			 block_list, final_result)
		    end
@


1.240
log
@[Bug #30090]
Translate output std_out to print
@
text
@d4 4
d874 1
a874 1
  sharing type Sparc_Schedule.Sparc_Assembly.Sparc_Opcodes.MachTypes.Sparc_Reg 
d905 1
a905 1
  fun diagnostic_output level = 
d947 1
a947 1
    else 
d1012 1
a1012 1
	  Info.error' 
d1055 1
a1055 1
	   n_zeroes([], 32)	   
d1072 1
a1072 1
	 Info.error' 
d1156 1
a1156 1
            
d1197 1
a1197 1
               rev(rev rest @@ (block::done)) = rev(block::done) @@ rest 
d1199 1
a1199 1
               = rev done @@ (block :: rest) 
d1221 1
a1221 1
							      next_block, 
d1251 1
a1251 1
	    Lists.partition continues rest 
d1255 1
a1255 1
      
d1369 1
a1369 1
			 SOME res => 
d1383 1
a1383 1
			   SOME res => 
d1396 1
a1396 1
			   SOME res => 
d1409 1
a1409 1
			   SOME res => 
d1422 1
a1422 1
			   SOME res => 
d1559 1
a1559 1
			   SOME res => 
d1656 1
a1656 1
  fun mach_cg 
d1658 1
a1658 1
    (Options.OPTIONS {compiler_options = 
d1726 1
a1726 1
	      let 
d1738 1
a1738 1
		  MirTypes.DEBUG (spill as ref (RuntimeEnv.OFFSET1(i)), name) => 
d1741 2
a1742 2
                      val _ = 
                        if i = 0 then print ("Zero spill for " ^ name) 
d1754 1
a1754 1
	      let 
d1782 1
a1782 1
	      let 
d1793 1
a1793 1
		case i of 
d1795 2
a1796 2
		  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1(i)),name) => 
                    let 
d1911 1
a1911 1
	      Crash.impossible"gp_check_range of non-immediate" 
d1924 1
a1924 1
	    | split_int _ = Crash.impossible"split_int of non-immediate" 
d2085 2
a2086 2
                            if preserve_order tagged_binary_op 
                              then 
d2088 1
a2088 1
                            else 
d2118 1
a2118 1
			      val (use_traps,long_op) = 
d2154 1
a2154 1
				  val (opcode, untag_arg) = 
d3198 1
a3198 1
			   (Sparc_Assembly.SRA, MachTypes.global, 
d3227 1
a3227 1
		      val (operation,operation',test,subtract) = 
d3250 1
a3250 1
                          Sparc_Assembly.IMM ~4), absent,""),                   
d3265 1
a3265 1
                        (Sparc_Assembly.FUNARY(Sparc_Assembly.FNEG, 
d3290 1
a3290 1
                        (Sparc_Assembly.FBINARY(subtract, MachTypes.fp_global, rs2, rs2), 
d3409 1
a3409 1
                            if n >= 0 
d3418 1
a3418 1
			  | MirTypes.BGE => (hilhs > hirhs) orelse (hilhs = hirhs andalso lolhs >= lorhs) 
d3437 2
a3438 2
		  end 
		    
d3463 1
a3463 1
		      (Sparc_Assembly.JMPL, MachTypes.lr,  
d3468 1
a3468 1
		    opcode_list, block_list, final_result) 
d3612 1
a3612 1
                       val needs_unaligned_zero = 
d3674 1
a3674 1
				  let val load_global1 = 
d3677 1
a3677 1
                                    val load_global2 = 
d3686 1
a3686 1
				     if aligned orelse not needs_unaligned_zero then 
d3688 1
a3688 1
				     else 
d3704 1
a3704 1
                                    case allocate of 
d3706 1
a3706 1
                                      | MirTypes.ALLOC_VECTOR => 
d3757 1
a3757 1
				  inline_allocate 
d3761 1
a3761 1
                                     then 
d3847 1
a3847 1
			    MachTypes.global, Sparc_Assembly.IMM 0, 
d3985 2
a3986 2
			     (Sparc_Assembly.SUBCC, MachTypes.G0, 
			      MachTypes.stack_limit, Sparc_Assembly.REG MachTypes.sp), 
d3996 1
a3996 1
				Sparc_Assembly.IMM frame_size 
d3998 1
a3998 1
				Sparc_Assembly.REG MachTypes.G7), 
d4042 1
a4042 1
			     (Sparc_Assembly.OR, MachTypes.G7, 
d4052 1
a4052 1
			  | _ => 
d4058 1
a4058 1
			      else 
d4061 1
a4061 1
				   MachTypes.G0, Sparc_Assembly.REG(MachTypes.G7)), 
d4097 1
a4097 1
			  MachTypes.lr, Sparc_Assembly.IMM 8, 
d4128 1
a4128 1
			    MachTypes.G0, Sparc_Assembly.REG MachTypes.global, 
d4144 1
a4144 1
			    MachTypes.G0, Sparc_Assembly.REG MachTypes.global, 
d4191 2
a4192 2
          fun less_than_three_opcodes_that_are_not_comments([],occ) = true 
            | less_than_three_opcodes_that_are_not_comments(MirTypes.COMMENT _ :: rest,occ) = 
d4195 1
a4195 1
            | less_than_three_opcodes_that_are_not_comments(h::t,occ) = 
d4237 1
a4237 1
                   proc_tag, 
d4284 1
a4284 1
	    
d4419 1
a4419 1
            if generate_debug_info orelse debug_variables orelse generate_moduler 
d4622 1
a4622 1
				     block_list, 
d4636 1
a4636 1
              fun normalise_to_four_bytes (x) = 
d4643 6
a4648 5
	  ((proc_tag, code), 
	   non_gc_stack_size,
           procedure_name,
           padded_name,
	   not needs_preserve)
d4700 1
a4700 1
	  val temp_code_list = 
d4705 5
a4709 4
	  val code_list = 
            map (fn tuple=>remove_redundant_loads_from_proc (#1(tuple))) temp_code_list
          val procedure_name_list = map #3 temp_code_list
	  val leaf_list = map #5 temp_code_list
d4717 1
a4717 1
	    (fn _ => (map print_unscheduled_code 
d4817 1
a4817 1
		    
d4820 1
a4820 1
	     (fn ((tag, code),(_,spills,_,padded_name,_)) =>
d4822 1
a4822 1
		 b_spills=spills,
d4832 1
a4832 1
                             if MLWorks.String.ordof(padded_name,to) = 0 
d4836 1
a4836 1
                           check_index (s-1) 
d4849 1
a4849 1
                       (case inst of 
d4855 1
a4855 1
                   val code = 
d4858 1
a4858 1
                     else 
d4883 2
a4884 1
				d_intercept=nop_offsets}),
d4891 1
a4891 1
        if ! print_code_size  then 
@


1.239
log
@Reorder registers in integer multiply
@
text
@d4 3
d1735 2
a1736 2
		    let 
                      fun print s = MLWorks.IO.output (MLWorks.IO.std_out,s ^ "\n")
d4885 7
a4891 7
	  MLWorks.IO.output(MLWorks.IO.std_out, "Normalised code size is " ^
                   Int.toString
		   (Lists.reducel
		    (fn(x,Code_Module.WORDSET(Code_Module.WORD_SET{b=tagged_code', ...})) =>
		     (Lists.reducel (fn (x,{d_code=y, ...}) => (size y) + x) (x,tagged_code'))
		  | _ => Crash.impossible "what the ?")
		    (0,proc_elements)) ^ "\n")
@


1.239.1.1
log
@branched from 1.239
@
text
@a3 3
 * Revision 1.239  1997/03/26  14:06:50  matthew
 * Reorder registers in integer multiply
 *
@


1.239.1.1.3.1
log
@branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_10r3
@
text
@a3 3
 * Revision 1.239.1.1  1997/05/12  10:50:07  hope
 * branched from 1.239
 *
@


1.239.1.1.2.1
log
@branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_10r2_551
@
text
@a3 3
 * Revision 1.239.1.1  1997/05/12  10:50:07  hope
 * branched from 1.239
 *
@


1.239.1.1.1.1
log
@branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_11
@
text
@a3 3
 * Revision 1.239.1.1  1997/05/12  10:50:07  hope
 * branched from 1.239
 *
@


1.239.1.1.1.1.1.1
log
@branched from MLWorks_11 for label MLWorks_11r1
@
text
@a3 3
 * Revision 1.239.1.1.1.1  1997/07/28  18:32:20  daveb
 * branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_11
 *
@


1.238
log
@Adding static flag to scheduler
@
text
@d4 3
d2258 9
@


1.237
log
@Modifying to protect allocate from lr, and redo switch to allow lr
except in leaf case
@
text
@d4 4
a3241 1
                        Sparc_Assembly.nop,
a3248 1
                        Sparc_Assembly.nop,
a3273 1
                        Sparc_Assembly.nop,
a3287 1
                        Sparc_Assembly.nop,
a3436 1
		      Sparc_Assembly.nop,
d4700 16
d4723 9
a4731 5
		 (fn (proc_tag, proc) =>
		  (proc_tag, map
		   (fn (tag, x) => (tag, Sparc_Schedule.reschedule_block x))
		   proc))
		 code_list)
@


1.236
log
@Adding multiply instructions
@
text
@d4 3
d3489 4
a3492 1
			if reg = MachTypes.lr then Crash.impossible "SWITCH from lr" else ()
d3500 7
a3506 7
			      do_tests((Sparc_Assembly.BRANCH
					 (Sparc_Assembly.BE, 0),
					 SOME tag, "Do the branch") ::
				       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					(Sparc_Assembly.SUBCC, MachTypes.G0,
					 reg, Sparc_Assembly.IMM imm),
					absent, "Do the test") :: done, rest)
d3508 6
a3513 6
			      do_tests((Sparc_Assembly.BRANCH_ANNUL
					(Sparc_Assembly.BA, 0),
					SOME tag, "Do the branch") ::
				       (Sparc_Assembly.nop_code, absent,
					"No test required in final case") ::
				       done, rest)
d3519 36
a3554 43
			if (not needs_preserve) andalso reg = MachTypes.global then
			  Crash.impossible"mach_cg: leaf switch on global"
			else
			  if reg = MachTypes.lr then
			    (* Put lr in global and redo *)
			    ([move_reg(MachTypes.global, MachTypes.lr)],
			     MirTypes.SWITCH(computed_goto,
					     MirTypes.GC_REG MirRegisters.global,
					     tag_list) :: opcode_list,
			     block_list, final_result)
			  else
			    let
			      val final_instr =
				if needs_preserve then
				  Sparc_Assembly.nop
				else
				  move_reg(MachTypes.global, MachTypes.lr)
			      val instrs =
				(Sparc_Assembly.Call (Sparc_Assembly.CALL, 2, Debugger_Types.null_backend_annotation),
				 absent, "Call self") ::
				(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				 (Sparc_Assembly.ADD, MachTypes.lr,
				  MachTypes.lr, Sparc_Assembly.IMM(4*4)),
                                 absent,
				 "Offset to start of table") ::
				(Sparc_Assembly.JUMP_AND_LINK
				 (Sparc_Assembly.JMPL, MachTypes.G0,
				  reg, Sparc_Assembly.REG MachTypes.lr,
				  Debugger_Types.null_backend_annotation), absent,
				 "Branch into table") ::
				final_instr ::
				map
				(fn tag =>
				 (Sparc_Assembly.BRANCH_ANNUL
				  (Sparc_Assembly.BA, 0), SOME tag, ""))
				tag_list
			    in
			      (if needs_preserve then
				 instrs
			       else
				 move_reg(MachTypes.lr, MachTypes.global) :: instrs,
				 opcode_list, block_list, final_result)
			    end
d3683 2
@


1.235
log
@Changed tag option to tag list in tagged instructions
@
text
@d4 3
d2101 16
a2116 16
			      val use_traps = case tagged_binary_op of
				MirTypes.ADDS => true
			      | MirTypes.SUBS => true
			      | MirTypes.MULS => true
			      | MirTypes.DIVS => true
			      | MirTypes.MODS => true
			      | MirTypes.ADD32S => false
			      | MirTypes.SUB32S => false
			      | MirTypes.MUL32S => false
			      | MirTypes.DIV32S => false
			      | MirTypes.MOD32S => false
                              | MirTypes.DIVU => true
                              | MirTypes.MODU => true
                              | MirTypes.DIV32U => true
                              | MirTypes.MOD32U => true

d2134 1
a2134 1
				(* Non-trapping version *)
d2137 103
a2239 4
				  val opcode = case tagged_binary_op of
                                    MirTypes.ADD32S => Sparc_Assembly.ADDCC
                                  | MirTypes.SUB32S => Sparc_Assembly.SUBCC
				  | _ => Crash.impossible"do_opcodes(TBINARY)"
a2240 27
				  val cont_tag = MirTypes.new_tag()
				  val regs_to_clean = [rd, rs1]
				  val regs_to_clean = case reg_or_imm of
				    Sparc_Assembly.REG reg => reg :: regs_to_clean
				  | _ => regs_to_clean
				  val regs_to_clean = Lists.rev_remove_dups regs_to_clean
				  val regs_to_clean =
				    Lists.filterp
				    (fn reg => reg <> MachTypes.G0 andalso
				     reg <> MachTypes.global)
				    regs_to_clean
				  (* No point in cleaning global as it's non-gc *)
				  (* g0 is already clean *)
				  val clean_block =
				    map
				    (fn reg =>
				     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				      (Sparc_Assembly.OR, reg,
				       MachTypes.G0, Sparc_Assembly.REG MachTypes.G0),
				      absent, "Clean"))
				    regs_to_clean
				  val clean_block =
				    clean_block @@
				    [(Sparc_Assembly.BRANCH_ANNUL
				      (Sparc_Assembly.BA, 0),
				      tag, ""),
				     Sparc_Assembly.nop]
d2242 19
a2260 8
				    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				     (opcode, rd, rs1, reg_or_imm), absent, "") ::
				    (Sparc_Assembly.BRANCH_ANNUL
				     (Sparc_Assembly.BVC, 0),
				     SOME cont_tag,
				     "Branch if not overflow") ::
				    Sparc_Assembly.nop ::
				    clean_block
d2265 1
a2265 1
				   final_result)
d2315 1
a2315 1
		    val opcode =
d2317 11
a2327 13
			MirTypes.ADDU => Sparc_Assembly.ADD
		      | MirTypes.SUBU => Sparc_Assembly.SUB
		      | MirTypes.MULU =>
			  Crash.unimplemented"MirTypes.MULU"
		      | MirTypes.MUL32U =>
			  Crash.unimplemented"MirTypes.MUL32U"
		      | MirTypes.AND => Sparc_Assembly.AND
		      | MirTypes.OR => Sparc_Assembly.OR
		      | MirTypes.BIC => Sparc_Assembly.ANDN
		      | MirTypes.EOR => Sparc_Assembly.XOR
		      | MirTypes.LSR => Sparc_Assembly.SRL
		      | MirTypes.ASL => Sparc_Assembly.SLL
		      | MirTypes.ASR => Sparc_Assembly.SRA
d2622 22
a2643 3
				([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				   (opcode, rd, rs1, reg_or_imm), absent, "")],
				 opcode_list, block_list, final_result)
@


1.234
log
@[Bug #1730]
Sort out problem in FP_SPILL_SLOT calculation.
@
text
@d4 4
d45 1
a45 1
 * These are like ADDV and SUBV, except that
d2045 1
a2045 1
		  MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
d2048 1
d2051 6
a2056 6
		    fun preserve_order MirTypes.SUBV = true
		      | preserve_order MirTypes.DIVV = true
		      | preserve_order MirTypes.MODV = true
		      | preserve_order MirTypes.SUBW = true
		      | preserve_order MirTypes.DIVW = true
		      | preserve_order MirTypes.MODW = true
d2079 1
a2079 1
		       MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
d2099 14
a2112 10
				MirTypes.ADDV => true
			      | MirTypes.SUBV => true
			      | MirTypes.MULV => true
			      | MirTypes.DIVV => true
			      | MirTypes.MODV => true
			      | MirTypes.ADDW => false
			      | MirTypes.SUBW => false
			      | MirTypes.MULW => false
			      | MirTypes.DIVW => false
			      | MirTypes.MODW => false
d2118 1
a2118 1
				    MirTypes.ADDV =>
d2120 1
a2120 1
				  | MirTypes.SUBV =>
d2122 1
a2122 16
				  | MirTypes.ADDW =>
				      Crash.impossible"do_opcodes(TBINARY(ADDW))"
				  | MirTypes.SUBW =>
				      Crash.impossible"do_opcodes(TBINARY(SUBW))"
				  | MirTypes.MULV =>
				      Crash.impossible"do_opcodes(TBINARY(MULV))"
				  | MirTypes.DIVV =>
				      Crash.impossible"do_opcodes(TBINARY(DIVV))"
				  | MirTypes.MODV =>
				      Crash.impossible"do_opcodes(TBINARY(MODV))"
				  | MirTypes.MULW =>
				      Crash.impossible"do_opcodes(TBINARY(MULV))"
				  | MirTypes.DIVW =>
				      Crash.impossible"do_opcodes(TBINARY(DIVV))"
				  | MirTypes.MODW =>
				      Crash.impossible"do_opcodes(TBINARY(MODV))"
d2135 3
a2137 20
				    MirTypes.ADDV =>
				      Crash.impossible"do_opcodes(TBINARY(ADDV))"
				  | MirTypes.SUBV =>
				      Crash.impossible"do_opcodes(TBINARY(SUBV))"
				  | MirTypes.ADDW =>
				      Sparc_Assembly.ADDCC
				  | MirTypes.SUBW =>
				      Sparc_Assembly.SUBCC
				  | MirTypes.MULV =>
				      Crash.impossible"do_opcodes(TBINARY(MULV))"
				  | MirTypes.DIVV =>
				      Crash.impossible"do_opcodes(TBINARY(DIVV))"
				  | MirTypes.MODV =>
				      Crash.impossible"do_opcodes(TBINARY(MODV))"
				  | MirTypes.MULW =>
				      Crash.impossible"do_opcodes(TBINARY(MULV))"
				  | MirTypes.DIVW =>
				      Crash.impossible"do_opcodes(TBINARY(DIVV))"
				  | MirTypes.MODW =>
				      Crash.impossible"do_opcodes(TBINARY(MODV))"
d2192 1
a2192 1
			     MirTypes.TBINARY(tagged_binary_op, tag,
d2206 1
a2206 1
			  MirTypes.TBINARY(tagged_binary_op, tag,
d2216 2
a2217 2
		    fun is_shift MirTypes.ADD = false
		      | is_shift MirTypes.SUB = false
d2219 1
a2219 5
		      | is_shift MirTypes.MULS = false
		      | is_shift MirTypes.DIVU = false
		      | is_shift MirTypes.DIVS = false
		      | is_shift MirTypes.MODU = false
		      | is_shift MirTypes.MODS = false
d2231 2
a2232 2
			MirTypes.ADD => Sparc_Assembly.ADD
		      | MirTypes.SUB => Sparc_Assembly.SUB
d2235 2
a2236 10
		      | MirTypes.MULS =>
			  Crash.unimplemented"MirTypes.MULS"
		      | MirTypes.DIVU =>
			  Crash.unimplemented"MirTypes.DIVU"
		      | MirTypes.DIVS =>
			  Crash.unimplemented"MirTypes.DIVS"
		      | MirTypes.MODU =>
			  Crash.unimplemented"MirTypes.MODU"
		      | MirTypes.MODS =>
			  Crash.unimplemented"MirTypes.MODS"
d2732 1
a2732 1
		| MirTypes.TBINARYFP(tagged_binary_fp_op, tag, fp_operand,
d2735 1
d2998 1
a2998 1
			 MirTypes.BINARY(MirTypes.ADD,
d3044 1
a3044 1
			 MirTypes.BINARY(MirTypes.ADD,
d3470 1
a3470 1
			MirTypes.BINARY(MirTypes.SUB, reg_operand,
@


1.234.4.1
log
@branched from 1.234
@
text
@a3 4
 * Revision 1.234  1996/11/06  14:38:45  jont
 * [Bug #1730]
 * Sort out problem in FP_SPILL_SLOT calculation.
 *
@


1.234.3.1
log
@branched from 1.234
@
text
@a3 4
 * Revision 1.234  1996/11/06  14:38:45  jont
 * [Bug #1730]
 * Sort out problem in FP_SPILL_SLOT calculation.
 *
@


1.234.3.1.1.1
log
@branched from 1.234.3.1
@
text
@a3 3
 * Revision 1.234.3.1  1996/12/17  18:00:03  hope
 * branched from 1.234
 *
@


1.234.2.1
log
@branched from 1.234
@
text
@a3 4
 * Revision 1.234  1996/11/06  14:38:45  jont
 * [Bug #1730]
 * Sort out problem in FP_SPILL_SLOT calculation.
 *
@


1.234.1.1
log
@branched from 1.234
@
text
@a3 4
 * Revision 1.234  1996/11/06  14:38:45  jont
 * [Bug #1730]
 * Sort out problem in FP_SPILL_SLOT calculation.
 *
@


1.234.1.1.1.1
log
@branched from 1.234.1.1
@
text
@a3 3
 * Revision 1.234.1.1  1996/11/14  13:04:38  hope
 * branched from 1.234
 *
@


1.233
log
@[Bug #1728]
__integer becomes __int
@
text
@d4 4
d1704 7
a1710 7
		  (if i >= gc_spill_size then
		     Crash.impossible
		     ("Spill slot " ^ Int.toString i ^
		      " requested, but only " ^ Int.toString gc_spill_size ^
		      " allocated\n")
		   else
		     ~(gc_spill_offset + 4 * (1 + i)))
d1735 8
a1742 8
		    (if i >= non_gc_spill_size then
		       Crash.impossible
		       ("non gc spill slot " ^ Int.toString i ^
			" requested, but only " ^
			Int.toString non_gc_spill_size ^
			" allocated\n")
		     else
		       ~(non_gc_spill_offset + 4 * (1 + offset + i)))
a1758 1
		val spare_size = if float_value_size >= 8 then 8 else 4
d1760 8
a1767 13
		  let
		    val offset = if allow_fp_spare_slot then 1 else 0
		  in
		    (if i >= fp_spill_size then
		       Crash.impossible
		       ("fp spill slot " ^ Int.toString i ^
			" requested, but only " ^
			Int.toString fp_spill_size ^
			" allocated\n")
		     else
		       ~(fp_spill_offset + float_value_size * (1 + i) +
			 offset * spare_size))
		  end
@


1.232
log
@moving String from toplevel
@
text
@d4 3
d798 1
a798 1
require "../basis/__integer";
@


1.231
log
@[Bug #1503]
Add field to FUNINFO to say if arg actually saved
@
text
@d4 4
d400 1
a400 1
Corrected an uncaught String.Substring
d815 1
d869 3
a871 3
    [(Sparc_Assembly.other_nop_code,MLWorks.Option.NONE,"Dummy instructions for tracing"),
     (Sparc_Assembly.other_nop_code,MLWorks.Option.NONE,"Dummy instructions for tracing"),
     (Sparc_Assembly.other_nop_code,MLWorks.Option.NONE,"Dummy instructions for tracing")]
d934 1
a934 1
      val exp_mant = MLWorks.String.explode mantissa
d936 1
a936 1
      | exp_mant_is_zero("0" :: xs) = exp_mant_is_zero xs
d942 1
a942 1
  fun binary_list_to_string(done, [], _, 128) = MLWorks.String.implode(rev done)
d948 1
a948 1
      val x = MLWorks.String.ord x - MLWorks.String.ord "0"
d951 1
a951 1
	binary_list_to_string(MLWorks.String.chr(digit + x) :: done, xs, 0, 128)
d961 1
a961 1
	  val digit = MLWorks.String.chr(value mod 2 + MLWorks.String.ord"0")
d986 1
a986 1
	  if exponent < ~bits then (MLWorks.String.implode(n_zeroes([], bits)), 0)
d988 1
a988 1
	    (MLWorks.String.implode(n_zeroes([], abs exponent)) ^ mantissa, 0)
d997 1
a997 1
	   MLWorks.String.explode(MLWorks.String.substring(mantissa, 1, 23))
d1009 1
a1009 1
	   MLWorks.String.explode(MLWorks.String.substring(mantissa, 1, 52))
d1023 1
a1023 1
	   MLWorks.String.explode(MLWorks.String.substring(mantissa, 0, 64)) @@
d1051 1
a1051 1
  val absent = MLWorks.Option.NONE
d1078 1
a1078 1
	  ((_, MLWorks.Option.SOME tag, _), true) => (tag, true)
d1179 1
a1179 1
			    MLWorks.Option.NONE => true
d1216 1
a1216 1
	      MLWorks.Option.SOME (_, t) => t
d1234 1
a1234 1
      tag_offsets(rest, disp + 4 * (Lists.length ho_list),
d1253 1
a1253 1
  MirTypes.tag * (Sparc_Assembly.opcode * MirTypes.tag MLWorks.Option.option * string) list
d1258 1
a1258 1
       (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BA, i), MLWorks.Option.SOME tag', comm),
d1261 1
a1261 1
       [(Sparc_Assembly.BRANCH(Sparc_Assembly.BA, i), MLWorks.Option.SOME tag', comm),
d1336 1
a1336 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1338 1
a1338 1
			 MLWorks.Option.SOME res => 
d1346 1
a1346 1
		       | MLWorks.Option.NONE =>
d1350 1
a1350 1
			       MLWorks.Option.SOME tag, comment), offset) =
d1352 1
a1352 1
			   MLWorks.Option.SOME res => 
d1360 1
a1360 1
			 | MLWorks.Option.NONE =>
d1363 1
a1363 1
			       MLWorks.Option.SOME tag, comment), offset) =
d1365 1
a1365 1
			   MLWorks.Option.SOME res => 
d1373 1
a1373 1
			 | MLWorks.Option.NONE =>
d1376 1
a1376 1
			       MLWorks.Option.SOME tag, comment), offset) =
d1378 1
a1378 1
			   MLWorks.Option.SOME res => 
d1386 1
a1386 1
			 | MLWorks.Option.NONE =>
d1389 1
a1389 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1391 1
a1391 1
			   MLWorks.Option.SOME res => 
d1399 1
a1399 1
			 | MLWorks.Option.NONE => Crash.impossible "Assoc do_opcode Call")
d1401 1
a1401 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1404 1
a1404 1
			   MLWorks.Option.SOME res =>
d1425 1
a1425 1
				      MLWorks.Option.SOME tag, new_comment) ::
d1428 1
a1428 1
				      MLWorks.Option.SOME tag, new_comment) :: tail
d1435 1
a1435 1
			 | MLWorks.Option.NONE => Crash.impossible "Assoc do_opcode LEO")
d1439 1
a1439 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1441 1
a1441 1
			   MLWorks.Option.SOME res =>
d1466 1
a1466 1
				      MLWorks.Option.SOME tag, new_comment) ::
d1470 1
a1470 1
				      MLWorks.Option.SOME tag, new_comment) ::
d1474 1
a1474 1
				      MLWorks.Option.NONE, new_comment) :: tail
d1481 1
a1481 1
			 | MLWorks.Option.NONE =>
d1486 1
a1486 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1488 1
a1488 1
			   MLWorks.Option.SOME res =>
d1499 1
a1499 1
			 | MLWorks.Option.NONE =>
d1502 1
a1502 1
				   MLWorks.Option.SOME tag, comment), _) =
d1504 1
a1504 1
			   MLWorks.Option.SOME res =>
d1522 1
a1522 1
			 | MLWorks.Option.NONE =>
d1526 1
a1526 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1528 1
a1528 1
			   MLWorks.Option.SOME res => 
d1537 1
a1537 1
			 | MLWorks.Option.NONE =>
d1540 1
a1540 1
		      | do_opcode((opcode, MLWorks.Option.NONE, comment), offset) =
d1816 1
a1816 1
	      MLWorks.Option.SOME end_tag,
d1947 1
a1947 1
		    Sparc_Assembly.IMM offset), MLWorks.Option.NONE,
d1952 1
a1952 1
		    Sparc_Assembly.IMM offset), MLWorks.Option.NONE,
d1957 1
a1957 1
		    Sparc_Assembly.IMM offset), MLWorks.Option.NONE,
d1962 1
a1962 1
		    MachTypes.fp, Sparc_Assembly.IMM (offset+8)), MLWorks.Option.NONE,
d1972 1
a1972 1
		    Sparc_Assembly.IMM offset), MLWorks.Option.NONE,
d1978 1
a1978 1
		    Sparc_Assembly.IMM offset), MLWorks.Option.NONE,
d1984 1
a1984 1
		    Sparc_Assembly.IMM offset), MLWorks.Option.NONE,
d1989 1
a1989 1
		    MachTypes.fp, Sparc_Assembly.IMM (offset+8)), MLWorks.Option.NONE,
d2193 1
a2193 1
				     MLWorks.Option.SOME cont_tag,
d2489 1
a2489 1
				     MLWorks.Option.SOME bad_tag, "branch if shift arg too big"),
d2496 1
a2496 1
				  MLWorks.Option.SOME cont_tag, ""),
d2848 1
a2848 1
				   MLWorks.Option.SOME offset) =>
d3167 1
a3167 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBGE, 0), MLWorks.Option.SOME tag, ""),
d3176 1
a3176 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBL, 0), MLWorks.Option.SOME tag, ""),
d3201 1
a3201 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBGE, 0), MLWorks.Option.SOME finish_tag, ""),
d3216 1
a3216 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBE, 0), MLWorks.Option.SOME finish_tag, ""),
d3224 1
a3224 1
                         MLWorks.Option.SOME finish_tag,
d3241 1
a3241 1
			  MLWorks.Option.SOME tag, "Branch relative"),
d3276 1
a3276 1
			   MLWorks.Option.SOME tag, ""),
d3291 1
a3291 1
			  (Sparc_Assembly.BRANCH_ANNUL (mn', 0), MLWorks.Option.SOME tag, ""),
d3305 1
a3305 1
			  (Sparc_Assembly.BRANCH_ANNUL (mn', 0), MLWorks.Option.SOME tag, ""),
d3366 1
a3366 1
		       MLWorks.Option.SOME tag, "Do the branch"),
d3380 1
a3380 1
                       MLWorks.Option.SOME tag, "Call"),
d3408 1
a3408 1
			      MLWorks.Option.SOME tag, "Branch relative (tail call)")
d3418 1
a3418 1
		      if Lists.length tag_list <= 2 then
d3426 1
a3426 1
					 MLWorks.Option.SOME tag, "Do the branch") ::
d3434 1
a3434 1
					MLWorks.Option.SOME tag, "Do the branch") ::
d3477 1
a3477 1
				  (Sparc_Assembly.BA, 0), MLWorks.Option.SOME tag, ""))
d3489 1
a3489 1
					  MLWorks.Option.SOME fp_offset) =>
d3701 1
a3701 1
			      MLWorks.Option.SOME tag, "Update gc pointer")]
d3709 1
a3709 1
			      MLWorks.Option.SOME tag,
d3727 1
a3727 1
			  MLWorks.Option.NONE, "check for interrupt"),
d3729 1
a3729 1
			  MLWorks.Option.SOME continue_tag, "branch if no interrupt"),
d3733 1
a3733 1
			  MLWorks.Option.SOME continue_tag, "branch if no interrupt"),
d3792 1
a3792 1
				 MLWorks.Option.SOME end_tag,
d3807 1
a3807 1
				  MLWorks.Option.SOME top_tag,
d3852 1
a3852 1
				  MLWorks.Option.SOME top_tag,
d3862 1
a3862 1
				  MLWorks.Option.SOME end_tag, ""),
d3886 1
a3886 1
			    MLWorks.Option.SOME non_ov_tag,
d3891 1
a3891 1
			    MLWorks.Option.SOME ov_tag, ""),
d3928 1
a3928 1
			    MLWorks.Option.SOME non_ov_tag, ""),
d3984 1
a3984 1
				   MLWorks.Option.SOME join_tag, ""),
d4092 1
a4092 1
      fun exit_block [] = MLWorks.Option.NONE
d4097 1
a4097 1
	  then MLWorks.Option.SOME block
d4156 2
a4157 2
	      MLWorks.Option.NONE => block_list
	    | MLWorks.Option.SOME exit_block =>
d4165 1
a4165 1
	      MLWorks.Option.NONE => MirTypes.FP.Map.define(map, fp, true)
d4196 1
a4196 1
	  val fp_save_size = Lists.length fps_to_preserve
d4220 1
a4220 1
	    MLWorks.Option.SOME stack_extra => stack_extra
d4370 1
a4370 1
	      MLWorks.Option.SOME{gc = gc_spill_size,
d4478 1
a4478 1
		    MLWorks.Option.SOME x => x
d4516 1
a4516 1
		MLWorks.Option.SOME instrs =>
d4541 1
a4541 1
	    (0, map (fn (_, opcodes) => Lists.length opcodes) code)
d4546 1
a4546 1
                | generate_nulls n = MLWorks.String.chr(0) ^ generate_nulls (n-1)
d4550 1
a4550 1
              normalise_to_four_bytes(procedure_name ^ MLWorks.String.chr(0))
d4595 1
a4595 1
			    MLWorks.Option.SOME tag =>
d4597 1
a4597 1
			  | MLWorks.Option.NONE => " no tag") ^
d4667 1
a4667 1
				 MLWorks.Option.SOME tag =>
d4669 1
a4669 1
			       | MLWorks.Option.NONE => " no tag") ^
d4746 1
a4746 1
                       MLWorks.String.implode (annotation_points (code,0,[]))
d4748 1
a4748 1
                       MLWorks.String.implode
@


1.231.3.1
log
@branched from 1.231
@
text
@a3 4
 * Revision 1.231  1996/08/01  12:22:44  jont
 * [Bug #1503]
 * Add field to FUNINFO to say if arg actually saved
 *
@


1.231.2.1
log
@branched from 1.231
@
text
@a3 4
 * Revision 1.231  1996/08/01  12:22:44  jont
 * [Bug #1503]
 * Add field to FUNINFO to say if arg actually saved
 *
@


1.231.1.1
log
@branched from 1.231
@
text
@a3 4
 * Revision 1.231  1996/08/01  12:22:44  jont
 * [Bug #1503]
 * Add field to FUNINFO to say if arg actually saved
 *
@


1.230
log
@The Ord exception is no longer at top level.
@
text
@d4 3
d4329 2
a4330 1
                                                           runtime_env,
@


1.229
log
@Moved Bits to MLWorks.Internal
@
text
@d4 3
d926 1
a926 1
      val exp_mant = String.explode mantissa
d934 1
a934 1
  fun binary_list_to_string(done, [], _, 128) = String.implode(rev done)
d940 1
a940 1
      val x = String.ord x - String.ord "0"
d943 1
a943 1
	binary_list_to_string(String.chr(digit + x) :: done, xs, 0, 128)
d953 1
a953 1
	  val digit = String.chr(value mod 2 + String.ord"0")
d978 1
a978 1
	  if exponent < ~bits then (String.implode(n_zeroes([], bits)), 0)
d980 1
a980 1
	    (String.implode(n_zeroes([], abs exponent)) ^ mantissa, 0)
d989 1
a989 1
	   String.explode(String.substring(mantissa, 1, 23))
d1001 1
a1001 1
	   String.explode(String.substring(mantissa, 1, 52))
d1015 1
a1015 1
	   String.explode(String.substring(mantissa, 0, 64)) @@
d4537 1
a4537 1
                | generate_nulls n = String.chr(0) ^ generate_nulls (n-1)
d4541 1
a4541 1
              normalise_to_four_bytes(procedure_name ^ String.chr(0))
d4712 1
a4712 1
                             if String.ordof(padded_name,to) = 0 
d4714 1
a4714 1
                             else String.substring(padded_name,0,to+1)
d4717 2
a4718 2
                           handle String.Substring => ""
                                | Ord => ""
d4737 1
a4737 1
                       String.implode (annotation_points (code,0,[]))
d4739 1
a4739 1
                       String.implode
@


1.228
log
@Adding NOT32 MIR instruction
@
text
@d4 3
d849 2
@


1.227
log
@Fixing problem with unsigned comparison
@
text
@d4 3
d2636 20
@


1.226
log
@Array moving to MLWorks.Array
@
text
@d4 3
a1859 5
	  fun gp_value(MirTypes.GP_IMM_INT i) = (i, 0)
	    | gp_value(MirTypes.GP_IMM_ANY i) = (i div 4, i mod 4)
	    | gp_value(MirTypes.GP_IMM_SYMB symb) = (symbolic_value symb, 0)
	    | gp_value _ = Crash.impossible "gp_value:non-constant operand"

d3270 4
d3276 8
d3293 5
a3297 4
			  | MirTypes.BHI => (hilhs > hirhs) orelse (hilhs = hirhs andalso lolhs > lorhs)
			  | MirTypes.BLS => (hilhs < hirhs) orelse (hilhs = hirhs andalso lolhs <= lorhs)
			  | MirTypes.BHS => (hilhs > hirhs) orelse (hilhs = hirhs andalso lolhs >= lorhs)
			  | MirTypes.BLO => (hilhs < hirhs) orelse (hilhs = hirhs andalso lolhs < lorhs)
@


1.225
log
@String functions explode, implode, chr and ord now only available from String
io functions and types
instream, oustream, open_in, open_out, close_in, close_out, input, output and end_of_stream
now only available from MLWorks.IO
@
text
@d4 6
d1625 1
a1625 1
      val gc_array = Array.array(gc, MachSpec.global)
d1629 1
a1629 1
	 Array.update(gc_array, MirTypes.GC.unpack mir_reg, reg))
d1631 1
a1631 1
      val non_gc_array = Array.array(non_gc, MachSpec.global)
d1635 1
a1635 1
	 Array.update(non_gc_array, MirTypes.NonGC.unpack mir_reg, reg))
d1637 1
a1637 1
      val fp_array = Array.array(fp, MachSpec.global)
d1641 1
a1641 1
	 Array.update(fp_array, MirTypes.FP.unpack mir_reg, reg))
d2000 1
a2000 1
		  val reg = Array.sub(table, reg)
d2019 1
a2019 1
		Array.sub(fp_array, MirTypes.FP.unpack reg)
d4399 2
a4400 2
	  val spill_array = Array.array(gc_spill_size, true)
	  val stack_array = Array.array(stack_extra, true)
d4443 1
a4443 1
			    val _ = Array.update(spill_array, gc_spill_size -1 - i, false)
d4452 1
a4452 1
		       val _ = Array.update(stack_array, offset+start, false)
d4475 1
a4475 1
	    MLWorks.ExtendedArray.reducel needs_init (false, spill_array)
d4478 1
a4478 1
	    MLWorks.ExtendedArray.reducel needs_init (false, stack_array)
@


1.224
log
@removing MLWorks.Integer
@
text
@d4 3
d906 1
a906 1
      val exp_mant = explode mantissa
d914 1
a914 1
  fun binary_list_to_string(done, [], _, 128) = implode(rev done)
d920 1
a920 1
      val x = ord x - ord "0"
d923 1
a923 1
	binary_list_to_string(chr(digit + x) :: done, xs, 0, 128)
d933 1
a933 1
	  val digit = chr(value mod 2 + ord"0")
d958 1
a958 1
	  if exponent < ~bits then (implode(n_zeroes([], bits)), 0)
d960 1
a960 1
	    (implode(n_zeroes([], abs exponent)) ^ mantissa, 0)
d969 1
a969 1
	   explode(String.substring(mantissa, 1, 23))
d981 1
a981 1
	   explode(String.substring(mantissa, 1, 52))
d995 1
a995 1
	   explode(String.substring(mantissa, 0, 64)) @@
d1681 1
a1681 1
                      fun print s = output (std_out,s ^ "\n")
d4489 1
a4489 1
                | generate_nulls n = chr(0) ^ generate_nulls (n-1)
d4493 1
a4493 1
              normalise_to_four_bytes(procedure_name ^ chr(0))
d4688 2
a4689 2
                     if generate_debug_info
                       then implode (annotation_points (code,0,[]))
d4691 1
a4691 1
                       implode
d4722 2
a4723 3
        if ! print_code_size 
          then 
            output(std_out, "Normalised code size is " ^
@


1.223
log
@Add implemetatins of ADDW and SUBW
These are like ADDV and SUBV, except that
they cannot use TADD etc because they are untagged
and also when they detect overflow they must clean
all registers involved in the operation
@
text
@d4 7
d767 2
d888 1
a888 1
		 MLWorks.Integer.makestring i,
d890 1
a890 1
		 MLWorks.Integer.makestring pos_limit]);
d914 1
a914 1
		     MLWorks.Integer.makestring l)
d1257 1
a1257 1
	     (fn (x, y) => Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ MLWorks.Integer.makestring y ^ "\n"))
d1668 2
a1669 2
		     ("Spill slot " ^ MLWorks.Integer.makestring i ^
		      " requested, but only " ^ MLWorks.Integer.makestring gc_spill_size ^
d1699 1
a1699 1
		       ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
d1701 1
a1701 1
			MLWorks.Integer.makestring non_gc_spill_size ^
d1728 1
a1728 1
		       ("fp spill slot " ^ MLWorks.Integer.makestring i ^
d1730 1
a1730 1
			MLWorks.Integer.makestring fp_spill_size ^
d1795 1
a1795 1
	     MLWorks.Integer.makestring end_limit)
d2810 1
a2810 1
				       MLWorks.Integer.makestring offset ^
d2812 1
a2812 1
				       MLWorks.Integer.makestring gc_stack_alloc_size ^
d3433 1
a3433 1
				      MLWorks.Integer.makestring alloc_size ^
d3435 1
a3435 1
				      MLWorks.Integer.makestring fp_offset ^
d3437 1
a3437 1
				      MLWorks.Integer.makestring
d4371 12
a4382 12
	  val _ = output(std_out, "non_gc_spill_size = " ^ MLWorks.Integer.makestring non_gc_spill_size ^ "\n")
	  val _ = output(std_out, "fp_spill_size = " ^ MLWorks.Integer.makestring fp_spill_size ^ "\n")
	  val _ = output(std_out, "fp_save_size = " ^ MLWorks.Integer.makestring fp_save_size ^ "\n")
	  val _ = output(std_out, "gc_spill_size = " ^ MLWorks.Integer.makestring gc_spill_size ^ "\n")
	  val _ = output(std_out, "stack_extra = " ^ MLWorks.Integer.makestring stack_extra ^ "\n")
	  val _ = output(std_out, "register_save_size = " ^ MLWorks.Integer.makestring 64 ^ "\n")
	  val _ = output(std_out, "non_gc_spill_offset = " ^ MLWorks.Integer.makestring 0 ^ "\n")
	  val _ = output(std_out, "fp_spill_offset = " ^ MLWorks.Integer.makestring fp_spill_offset ^ "\n")
	  val _ = output(std_out, "fp_save_offset = " ^ MLWorks.Integer.makestring fp_save_offset ^ "\n")
	  val _ = output(std_out, "gc_spill_offset = " ^ MLWorks.Integer.makestring gc_spill_offset ^ "\n")
	  val _ = output(std_out, "gc_stack_alloc_offset = " ^ MLWorks.Integer.makestring gc_stack_alloc_offset ^ "\n")
	  val _ = output(std_out, "register_save_offset = " ^ MLWorks.Integer.makestring register_save_offset ^ "\n")
d4722 1
a4722 1
                   MLWorks.Integer.makestring
@


1.222
log
@Add extra field to procedure_parameters to contain old (pre register allocation)
spill sizes. This is for the i386, where spill assignment is done in the backend
@
text
@d4 4
a2008 11
		    val opcode = case tagged_binary_op of
		      MirTypes.ADDV =>
			Sparc_Assembly.TADDCCTV
		    | MirTypes.SUBV =>
			Sparc_Assembly.TSUBCCTV
		    | MirTypes.MULV =>
			Crash.impossible"do_opcodes(TBINARY(MULV))"
		    | MirTypes.DIVV =>
			Crash.impossible"do_opcodes(TBINARY(DIVV))"
		    | MirTypes.MODV =>
			Crash.impossible"do_opcodes(TBINARY(MODV))"
d2011 6
a2016 3
		    | preserve_order MirTypes.DIVV = true
		    | preserve_order MirTypes.MODV = true
		    | preserve_order _ = false
d2057 12
d2070 98
a2167 5
			      ([(Sparc_Assembly.TAGGED_ARITHMETIC
				 (opcode, rd, rs1, reg_or_imm), absent, "")],
			       opcode_list,
			       block_list,
			       final_result)
@


1.221
log
@Modification for improved runtime env spill offsets
to indicate the kind of data spilled
@
text
@d4 4
a797 1
  sharing MirTables.MirTypes.Option = MirTables.MirTypes.Debugger_Types.RuntimeEnv.Option
a816 1
  structure Option = RuntimeEnv.Option
d825 3
a827 3
    [(Sparc_Assembly.other_nop_code,Option.ABSENT,"Dummy instructions for tracing"),
     (Sparc_Assembly.other_nop_code,Option.ABSENT,"Dummy instructions for tracing"),
     (Sparc_Assembly.other_nop_code,Option.ABSENT,"Dummy instructions for tracing")]
d1007 1
a1007 1
  val absent = Option.ABSENT
d1034 1
a1034 1
	  ((_, Option.PRESENT tag, _), true) => (tag, true)
d1209 1
a1209 1
  MirTypes.tag * (Sparc_Assembly.opcode * MirTypes.tag Option.opt * string) list
d1214 1
a1214 1
       (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BA, i), Option.PRESENT tag', comm),
d1217 1
a1217 1
       [(Sparc_Assembly.BRANCH(Sparc_Assembly.BA, i), Option.PRESENT tag', comm),
d1292 1
a1292 1
				   Option.PRESENT tag, comment), offset) =
d1306 1
a1306 1
			       Option.PRESENT tag, comment), offset) =
d1319 1
a1319 1
			       Option.PRESENT tag, comment), offset) =
d1332 1
a1332 1
			       Option.PRESENT tag, comment), offset) =
d1345 1
a1345 1
				   Option.PRESENT tag, comment), offset) =
d1357 1
a1357 1
				   Option.PRESENT tag, comment), offset) =
d1381 1
a1381 1
				      Option.PRESENT tag, new_comment) ::
d1384 1
a1384 1
				      Option.PRESENT tag, new_comment) :: tail
d1395 1
a1395 1
				   Option.PRESENT tag, comment), offset) =
d1422 1
a1422 1
				      Option.PRESENT tag, new_comment) ::
d1426 1
a1426 1
				      Option.PRESENT tag, new_comment) ::
d1430 1
a1430 1
				      Option.ABSENT, new_comment) :: tail
d1442 1
a1442 1
				   Option.PRESENT tag, comment), offset) =
d1458 1
a1458 1
				   Option.PRESENT tag, comment), _) =
d1482 1
a1482 1
				   Option.PRESENT tag, comment), offset) =
d1496 1
a1496 1
		      | do_opcode((opcode, Option.ABSENT, comment), offset) =
d1772 1
a1772 1
	      Option.PRESENT end_tag,
d1908 1
a1908 1
		    Sparc_Assembly.IMM offset), Option.ABSENT,
d1913 1
a1913 1
		    Sparc_Assembly.IMM offset), Option.ABSENT,
d1918 1
a1918 1
		    Sparc_Assembly.IMM offset), Option.ABSENT,
d1923 1
a1923 1
		    MachTypes.fp, Sparc_Assembly.IMM (offset+8)), Option.ABSENT,
d1933 1
a1933 1
		    Sparc_Assembly.IMM offset), Option.ABSENT,
d1939 1
a1939 1
		    Sparc_Assembly.IMM offset), Option.ABSENT,
d1945 1
a1945 1
		    Sparc_Assembly.IMM offset), Option.ABSENT,
d1950 1
a1950 1
		    MachTypes.fp, Sparc_Assembly.IMM (offset+8)), Option.ABSENT,
d2353 1
a2353 1
				     Option.PRESENT bad_tag, "branch if shift arg too big"),
d2360 1
a2360 1
				  Option.PRESENT cont_tag, ""),
d2692 1
a2692 1
				   Option.PRESENT offset) =>
d3011 1
a3011 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBGE, 0), Option.PRESENT tag, ""),
d3020 1
a3020 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBL, 0), Option.PRESENT tag, ""),
d3045 1
a3045 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBGE, 0), Option.PRESENT finish_tag, ""),
d3060 1
a3060 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBE, 0), Option.PRESENT finish_tag, ""),
d3068 1
a3068 1
                         Option.PRESENT finish_tag,
d3085 1
a3085 1
			  Option.PRESENT tag, "Branch relative"),
d3120 1
a3120 1
			   Option.PRESENT tag, ""),
d3135 1
a3135 1
			  (Sparc_Assembly.BRANCH_ANNUL (mn', 0), Option.PRESENT tag, ""),
d3149 1
a3149 1
			  (Sparc_Assembly.BRANCH_ANNUL (mn', 0), Option.PRESENT tag, ""),
d3197 1
a3197 1
		       Option.PRESENT tag, "Do the branch"),
d3211 1
a3211 1
                       Option.PRESENT tag, "Call"),
d3239 1
a3239 1
			      Option.PRESENT tag, "Branch relative (tail call)")
d3257 1
a3257 1
					 Option.PRESENT tag, "Do the branch") ::
d3265 1
a3265 1
					Option.PRESENT tag, "Do the branch") ::
d3308 1
a3308 1
				  (Sparc_Assembly.BA, 0), Option.PRESENT tag, ""))
d3320 1
a3320 1
					  Option.PRESENT fp_offset) =>
d3532 1
a3532 1
			      Option.PRESENT tag, "Update gc pointer")]
d3540 1
a3540 1
			      Option.PRESENT tag,
d3558 1
a3558 1
			  Option.ABSENT, "check for interrupt"),
d3560 1
a3560 1
			  Option.PRESENT continue_tag, "branch if no interrupt"),
d3564 1
a3564 1
			  Option.PRESENT continue_tag, "branch if no interrupt"),
d3623 1
a3623 1
				 Option.PRESENT end_tag,
d3638 1
a3638 1
				  Option.PRESENT top_tag,
d3683 1
a3683 1
				  Option.PRESENT top_tag,
d3693 1
a3693 1
				  Option.PRESENT end_tag, ""),
d3717 1
a3717 1
			    Option.PRESENT non_ov_tag,
d3722 1
a3722 1
			    Option.PRESENT ov_tag, ""),
d3759 1
a3759 1
			    Option.PRESENT non_ov_tag, ""),
d3815 1
a3815 1
				   Option.PRESENT join_tag, ""),
d3923 1
a3923 1
      fun exit_block [] = Option.ABSENT
d3928 1
a3928 1
	  then Option.PRESENT block
d3987 2
a3988 2
	      Option.ABSENT => block_list
	    | Option.PRESENT exit_block =>
d4051 1
a4051 1
	    Option.PRESENT stack_extra => stack_extra
d4200 1
a4200 1
	      Option.PRESENT{gc = gc_spill_size,
d4308 1
a4308 1
		    Option.PRESENT x => x
d4425 1
a4425 1
			    Option.PRESENT tag =>
d4427 1
a4427 1
			  | Option.ABSENT => " no tag") ^
d4497 1
a4497 1
				 Option.PRESENT tag =>
d4499 1
a4499 1
			       | Option.ABSENT => " no tag") ^
@


1.220
log
@Fix bug in compiler crash when number of fp spill slots exceeded
@
text
@d4 3
d1670 1
a1670 1
                      spill := RuntimeEnv.OFFSET2(value);
d1673 1
a1673 1
		| MirTypes.DEBUG (ref(RuntimeEnv.OFFSET2(i)),name) => i
d1698 1
a1698 1
                      spill := RuntimeEnv.OFFSET2(value);
d1701 1
a1701 1
                | MirTypes.DEBUG (ref(RuntimeEnv.OFFSET2(i)),name) => i
d1728 1
a1728 1
                      spill := RuntimeEnv.OFFSET2(value);
d1731 1
a1731 1
                | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(i)),name) => i
@


1.219
log
@Fix constant unsigned comparison case of MirTypes.TEST
@
text
@d4 3
d1710 1
a1710 1
		       ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
d1712 1
a1712 1
			MLWorks.Integer.makestring non_gc_spill_size ^
@


1.218
log
@Putting sources registers for various instructions in correct order
@
text
@d4 3
d3156 4
a3159 4
			  | MirTypes.BHI => Crash.impossible "const precalc on BHI"
			  | MirTypes.BLS => Crash.impossible "const precalc on BLS"
			  | MirTypes.BHS => Crash.impossible "const precalc on BHS"
			  | MirTypes.BLO => Crash.impossible "const precalc on BLO"
@


1.217
log
@mirtypes.test confuses imm32 case
@
text
@d4 6
d992 1
d1356 1
a1356 1
				  (Sparc_Assembly.OR, rd, Sparc_Assembly.IMM disp, MachTypes.G0),
d1382 2
a1383 2
				   (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM i,
				    rs1),
d1392 2
a1393 2
				  (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM disp,
				   rs1),
d1414 1
a1414 1
				       Sparc_Assembly.IMM(i + 4), rd),
d1418 1
a1418 1
				       Sparc_Assembly.REG rd, rs1),
d1430 1
a1430 1
				   (_, rd, Sparc_Assembly.IMM i, rs1),
d1441 1
a1441 1
				(Sparc_Assembly.ADD, rd, disp, rs1),
d1463 2
a1464 2
				     make_imm_fault(disp mod 1024, true, arith_imm_limit),
				     rn),
d1542 1
a1542 1
     (Sparc_Assembly.OR, rd, Sparc_Assembly.REG MachTypes.G0, rs), absent, "")
d1546 1
a1546 1
     (Sparc_Assembly.OR, rd, Sparc_Assembly.IMM imm, MachTypes.G0),
d1780 1
a1780 1
	  (Sparc_Assembly.TADDCCTV, MachTypes.gc1, bytes, MachTypes.gc1),
d1788 1
a1788 1
	      reg, Sparc_Assembly.IMM tag, MachTypes.gc2),
d1792 1
a1792 1
	  (Sparc_Assembly.ADD, MachTypes.gc2, bytes, MachTypes.gc2),
d1856 1
a1856 1
                   Sparc_Assembly.REG MachTypes.G0, MachTypes.G0),
d1861 1
a1861 1
                   Sparc_Assembly.IMM lo, MachTypes.G0),
d1873 1
a1873 1
                   Sparc_Assembly.IMM lo, reg),
d2052 1
a2052 1
				 (opcode, rd, reg_or_imm, rs1), absent, "")],
d2233 1
a2233 1
					   (opcode, rd, shift_size, rs1),
d2270 1
a2270 1
					   (opcode, rd, shift_size, rs1),
d2306 1
a2306 1
					   (opcode, rd, shift_size, rs1),
d2338 1
a2338 1
				      MachTypes.G0, Sparc_Assembly.IMM limit, rs1),
d2379 1
a2379 2
				      (opcode, rd, Sparc_Assembly.IMM 31,
				       lookup_gp_operand gp_op),
d2390 2
a2391 2
				    Sparc_Assembly.REG rs1,
				    lookup_gp_operand gp_operand),
d2396 1
a2396 1
				    (opcode, rd, Sparc_Assembly.REG rs1, rd),
d2426 1
a2426 1
				   (opcode, rd, reg_or_imm, rs1), absent, "")],
d2482 1
a2482 1
				(opcode, rd, imm, rs1), absent, "")]
d2493 1
a2493 1
				(opcode, rd, imm, MachTypes.G0), absent, "")]
d2511 1
a2511 1
			     (opcode, rd, simple_imm, rs1), absent, "")],
d2522 1
a2522 1
                        Sparc_Assembly.REG MachTypes.G0, MachTypes.G0),
d2936 1
a2936 1
			    Sparc_Assembly.IMM 2, rs2), absent,
d2979 1
a2979 1
                          Sparc_Assembly.IMM 1,MachTypes.G0),absent,""),
d2982 1
a2982 1
                          Sparc_Assembly.IMM 29,MachTypes.global),absent,""),
d3024 1
a3024 1
			 (Sparc_Assembly.SLL, rd, Sparc_Assembly.IMM 2, rd),
d3053 1
a3053 1
			 (Sparc_Assembly.SUB,rd,Sparc_Assembly.IMM 4,rd),
d3068 1
a3068 1
			   Sparc_Assembly.IMM 0, lookup_reg_operand reg,
d3106 2
a3107 2
			   (test, MachTypes.G0, make_imm_format3 gp_operand,
			    lookup_gp_operand gp_operand'), absent, "test..."),
d3123 1
a3123 2
			   (test, MachTypes.G0, make_imm_format3 gp_operand',
			    lookup_gp_operand gp_operand), absent, "test..."),
d3136 2
a3137 2
			   (test, MachTypes.G0, Sparc_Assembly.REG (lookup_gp_operand gp_operand'),
			    lookup_gp_operand gp_operand), absent, "test..."),
d3193 1
a3193 1
		       Sparc_Assembly.IMM Tags.CODE_OFFSET, lookup_reg_operand reg_operand,
d3209 1
a3209 1
			    Sparc_Assembly.IMM 0, MachTypes.G0),
d3223 1
a3223 1
			       Sparc_Assembly.IMM Tags.CODE_OFFSET, lookup_reg_operand reg,
d3249 1
a3249 1
					 Sparc_Assembly.IMM imm, reg),
d3285 2
a3286 2
				  Sparc_Assembly.IMM(4*4),
				  MachTypes.lr), absent,
d3290 1
a3290 1
				  Sparc_Assembly.REG MachTypes.lr, reg,
d3440 1
a3440 1
                                           (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.IMM (4+7), rs),
d3443 1
a3443 1
					   (Sparc_Assembly.ANDN, MachTypes.global, Sparc_Assembly.IMM 7, MachTypes.global),
d3448 1
a3448 1
                                            (Sparc_Assembly.SRL, MachTypes.global, Sparc_Assembly.IMM 2, rs),
d3451 1
a3451 1
                                            (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.IMM (4+7), MachTypes.global),
d3454 1
a3454 1
					    (Sparc_Assembly.ANDN, MachTypes.global, Sparc_Assembly.IMM 7, MachTypes.global),
d3460 1
a3460 1
                                            (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.IMM (12+7), rs),
d3463 1
a3463 1
					   (Sparc_Assembly.ANDN, MachTypes.global, Sparc_Assembly.IMM 7, MachTypes.global),
d3468 1
a3468 1
                                            (Sparc_Assembly.SRL, MachTypes.global, Sparc_Assembly.IMM 2, rs),
d3471 1
a3471 1
                                            (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.IMM (4+7), MachTypes.global),
d3474 1
a3474 1
					    (Sparc_Assembly.ANDN, MachTypes.global, Sparc_Assembly.IMM 7, MachTypes.global),
d3478 1
a3478 1
                                      (Sparc_Assembly.SLL, MachTypes.global, Sparc_Assembly.IMM 4, rs),
d3481 1
a3481 1
                                     (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.IMM secondary, MachTypes.global),
d3495 1
a3495 1
                                         (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.REG rd, MachTypes.global),
d3520 1
a3520 1
			       Sparc_Assembly.IMM 4, MachTypes.lr),
d3546 1
a3546 1
			   Sparc_Assembly.IMM 1, MachTypes.stack_limit),
d3565 1
a3565 1
			    Sparc_Assembly.IMM 0, MachTypes.global,
d3578 1
a3578 1
			    Sparc_Assembly.IMM 0, MachTypes.global,
d3661 2
a3662 2
				  Sparc_Assembly.IMM clean_start,
				  MachTypes.sp), absent,
d3668 1
a3668 2
				   Sparc_Assembly.IMM 8,
				   MachTypes.global),
d3717 1
a3717 1
			      Sparc_Assembly.REG(MachTypes.sp), MachTypes.stack_limit), 
d3723 3
a3725 1
			     (Sparc_Assembly.SUB, MachTypes.global, 
d3729 1
a3729 2
				Sparc_Assembly.REG MachTypes.G7, 
				MachTypes.sp),
d3733 2
a3734 2
			      Sparc_Assembly.REG(MachTypes.global),
			      MachTypes.stack_limit),
d3765 1
a3765 1
			       Sparc_Assembly.IMM 0, MachTypes.global,
d3774 1
a3774 1
			      Sparc_Assembly.IMM frame_size, MachTypes.G0), 
d3792 1
a3792 1
				   Sparc_Assembly.REG(MachTypes.G7), MachTypes.G0), 
d3796 1
d3799 2
a3800 2
				   else Sparc_Assembly.REG MachTypes.G7,
				     MachTypes.sp), absent, "New frame") ::
d3817 1
a3818 1
			  MachTypes.after_preserve MachTypes.lr,
d3822 3
a3824 3
			(Sparc_Assembly.RESTORE, MachTypes.G0,
			 Sparc_Assembly.IMM 0,
			 MachTypes.G0), absent, "Restore in the delay slot")]
d3828 1
a3828 1
			  Sparc_Assembly.IMM 8, MachTypes.lr,
d3859 1
a3859 1
			    Sparc_Assembly.REG MachTypes.global, MachTypes.G0,
d3864 2
a3865 2
			    Sparc_Assembly.REG MachTypes.G0,
			    lookup_reg_operand reg),
d3875 1
a3875 1
			    Sparc_Assembly.REG MachTypes.global, MachTypes.G0,
d3880 2
a3881 2
			    Sparc_Assembly.REG MachTypes.G0,
			    lookup_reg_operand reg),
d3895 1
a3895 1
		      Sparc_Assembly.IMM 0, MachTypes.global,Debugger_Types.null_backend_annotation),
@


1.216
log
@Add WORD to value_cg
@
text
@a985 1
    | value_cg(_, MirTypes.SCON (Ident.WORD _),_) = Crash.impossible"VALUE(WORD)"
d3071 3
a3073 3
		| MirTypes.TEST(cond_branch, tag, gp_operand, gp_operand') =>
		  let
		    val branch = case cond_branch of
d3086 9
a3094 12
		    val (branch, gp_op, gp_op') =
		      case gp_operand of
			MirTypes.GP_GC_REG _ =>
			  (branch, gp_operand, gp_operand')
		      | MirTypes.GP_NON_GC_REG _ =>
			  (branch, gp_operand, gp_operand')
		      | _ => (Sparc_Assembly.reverse_branch branch,
			      gp_operand', gp_operand)
		    val constant = case gp_op of
		      MirTypes.GP_GC_REG _ => false
		    | MirTypes.GP_NON_GC_REG _ => false
		    | _ => true
d3096 2
a3097 21
		    if constant then
		      let
			val gp1 as (gp11, gp12) = gp_value gp_operand
			val gp2 as (gp21, gp22) = gp_value gp_operand'
			val branch = case cond_branch of
			  MirTypes.BNT => Bits.andb(gp12, gp22) = 0
			| MirTypes.BTA => Bits.andb(gp12, gp22) <> 0
			| MirTypes.BEQ => gp1 = gp2
			| MirTypes.BNE => gp1 <> gp2
			| MirTypes.BHI => Crash.impossible"test:unsigned:constant operands"
			| MirTypes.BLS => Crash.impossible"test:unsigned:constant operands"
			| MirTypes.BHS => Crash.impossible"test:unsigned:constant operands"
			| MirTypes.BLO => Crash.impossible"test:unsigned:constant operands"
			| MirTypes.BGT =>
			    gp11 > gp21 orelse (gp11 = gp21 andalso gp12 > gp22)
			| MirTypes.BLE =>
			    gp11 < gp21 orelse (gp11 = gp21 andalso gp12 <= gp22)
			| MirTypes.BGE =>
			    gp11 > gp21 orelse (gp11 = gp21 andalso gp12 >= gp22)
			| MirTypes.BLT =>
			    gp11 < gp21 orelse (gp11 = gp21 andalso gp12 < gp22)
d3099 7
a3105 8
			if branch then
			  ([],
			   [MirTypes.BRANCH(MirTypes.BRA, MirTypes.TAG tag)],
			   block_list, final_result)
			  (* Remainder of opcode_list irrelevant here *)
			else
			  ([], opcode_list, block_list, final_result)
			  (* Branch is nop in this case *)
d3107 57
a3163 39
		    else
		      let
			val rs1 = lookup_gp_operand gp_op
			val test_instr = case cond_branch of
			  MirTypes.BTA => Sparc_Assembly.ANDCC
			| MirTypes.BNT => Sparc_Assembly.ANDCC
			| _ => Sparc_Assembly.SUBCC
		      in
			if is_reg gp_op' orelse
			  gp_check_range(gp_op', true, arith_imm_limit) then
			  let
			    val reg_or_imm =
			      if is_reg gp_op' then
				Sparc_Assembly.REG(lookup_gp_operand gp_op')
			      else
				make_imm_format3 gp_op'
			  in
			    ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			       (test_instr, MachTypes.G0,
				reg_or_imm, rs1),
			       absent, "Do the test"),
			      (Sparc_Assembly.BRANCH_ANNUL(branch, 0),
			       Option.PRESENT tag, "Do the branch"),
			      Sparc_Assembly.nop],
			    opcode_list, block_list, final_result)
			  end
			else
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  MirTypes.GC_REG
					  MirRegisters.global,
					  gp_op') ::
			   MirTypes.TEST(cond_branch, tag, gp_op,
					 MirTypes.GP_GC_REG MirRegisters.global) ::
			   opcode_list, block_list, final_result)
		      end
		  end
		| MirTypes.FTEST(fcond_branch, tag, fp_operand,
				 fp_operand') =>
@


1.215
log
@Add CHAR to value_cg
@
text
@d4 3
d986 1
@


1.214
log
@Sort out shifts as per revised basis with range testing etc.
@
text
@d4 3
d982 1
@


1.213
log
@Commenting out diagnostic stuff
@
text
@d4 3
d2076 17
a2114 2
		      (* Temporary conversion into SRA from SRL *)
		      (* And back again *)
d2119 7
a2125 7
		    | needs_reverse Sparc_Assembly.SUBCC = true
		    | needs_reverse Sparc_Assembly.SUBX = true
		    | needs_reverse Sparc_Assembly.SUBXCC = true
		    | needs_reverse Sparc_Assembly.SRL = true
		    | needs_reverse Sparc_Assembly.SLL = true
		    | needs_reverse Sparc_Assembly.SRA = true
		    | needs_reverse _ = false
d2131 6
a2136 7
                        if is_reg gp_operand'
                          then
                            if needs_reverse opcode then
                              (gp_operand, gp_operand', true)
                            else 
                              (gp_operand', gp_operand, false)
                        else 
d2139 1
d2141 1
a2141 1
		    if redo then
d2171 3
a2173 1
		      if is_reg gp_operand then
d2175 4
a2178 1
			  val rs1 = lookup_gp_operand gp_operand
d2180 1
a2180 3
			  if is_reg gp_operand' orelse
			    gp_check_range(gp_operand', true,
					   arith_imm_limit) then
d2182 16
a2197 5
			      val reg_or_imm =
				if is_reg gp_operand' then
				  Sparc_Assembly.REG(lookup_gp_operand
						     gp_operand')
				else make_imm_format3 gp_operand'
d2199 111
a2309 3
			      ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				 (opcode, rd, reg_or_imm, rs1), absent, "")],
			       opcode_list, block_list, final_result)
d2312 2
d2315 70
a2384 17
			      val inter_reg =
				case gp_operand of
				  MirTypes.GP_GC_REG r =>
				    (if r = MirRegisters.global then
				       (* The nasty case *)
				       (case reg_operand of
					  MirTypes.GC_REG r' =>
					    if r = r' then
					      Crash.impossible
					      "source and dest global with large int"
					    else
					      r'
					| MirTypes.NON_GC_REG _ =>
					    Crash.impossible"BINARY doesn't deliver GC")
				     else
				       MirRegisters.global)
				| _ => Crash.impossible "BINARY has non-gc register"
d2386 9
a2394 8
			      ([],
			       MirTypes.UNARY(MirTypes.MOVE,
					      MirTypes.GC_REG inter_reg,
					      gp_operand') ::
			       MirTypes.BINARY(binary_op, reg_operand,
					       gp_operand,
					       MirTypes.GP_GC_REG inter_reg) ::
			       opcode_list, block_list, final_result)
d2398 57
a2454 11
(*
			Crash.impossible"Mach_Cg(BINARY) first arg not reg"
*)
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					MirTypes.GC_REG MirRegisters.global,
					gp_operand) ::
			 MirTypes.BINARY(binary_op, reg_operand,
					 MirTypes.GP_GC_REG MirRegisters.global,
					 gp_operand') ::
			 opcode_list, block_list, final_result)
@


1.212
log
@Adding needs_unaligned_zero
@
text
@d4 3
d803 3
a805 1
  val diagnostic_output = Diagnostic.output
d812 1
a977 4

  type half_op = Sparc_Assembly.opcode * MirTypes.tag Option.opt
  type half_op_block = MirTypes.tag * half_op list
  (* A half compiled form with unresolved branches *)
@


1.211
log
@Removing debug_polyvariables option
@
text
@d4 3
d1759 1
a1759 1
(* trapped add to test for allocation overflow *)
d1763 1
a1763 1
(* tag the 'answer' *)
d1771 1
a1771 1
(* increment the allocation pointer *)
a3083 1

d3094 6
a3099 1

d3101 2
a3102 3
                         case gp_operand

                           of MirTypes.GP_IMM_INT size =>
d3147 1
a3147 1
				   (if aligned then
d3168 1
a3168 1
				     if aligned then 
a3182 7
(* This shouldn't be a problem now
				  val _ =
				    if rs = MachTypes.lr then
				      Crash.impossible "ALLOC size lr"
				    else ()
*)

d3225 4
a3228 15
                                in
                                  length_code @@
				  inline_allocate
				  (rd, primary, Sparc_Assembly.REG MachTypes.global,
				   not needs_preserve,
				   length_code @@
				   [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                     (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.REG rd, MachTypes.global),
                                     absent, "Calculate end of object"),
                                    (Sparc_Assembly.LOAD_AND_STORE
                                     (Sparc_Assembly.ST, MachTypes.G0, MachTypes.global, Sparc_Assembly.IMM (~4 - primary)),
                                     absent, "Zero last word in case it's unaligned"),
                                    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                     (Sparc_Assembly.SLL, MachTypes.global, Sparc_Assembly.IMM 4, rs),
                                     absent, ""),
d3234 17
a3250 1
                                     absent, "Initialise header tag")])
@


1.210
log
@Debugger_Types changes
Abstraction of debug information
Annotate CALL instruction
@
text
@d4 5
a1552 1
                                               debug_polyvariables,
d3894 1
a3894 1
            if generate_debug_info orelse debug_polyvariables orelse debug_variables orelse generate_moduler 
@


1.209
log
@Rationalizing debugger
@
text
@d4 3
d731 1
d744 1
d780 1
a780 2
  structure Options = Debugger_Types.Options
  structure NewMap = Debugger_Types.NewMap
d813 2
d1306 1
a1306 1
		      | do_opcode((Sparc_Assembly.Call(Sparc_Assembly.CALL, i),
d1315 1
a1315 1
			       (Sparc_Assembly.Call(Sparc_Assembly.CALL, disp), comment)
d1546 5
a1550 1
                      Options.COMPILEROPTIONS {debug, debug_variables, debug_polyvariables, generate_moduler, opt_leaf_fns, ...},
d2940 4
a2943 5
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.TAG tag,_,_) =>
		    ([(Sparc_Assembly.Call
		      (Sparc_Assembly.CALL, 0),
		      Option.PRESENT tag, "Call"),
		     Sparc_Assembly.nop],
d3023 1
a3023 2
				(Sparc_Assembly.Call
				 (Sparc_Assembly.CALL, 2),
d3257 1
a3257 1
			      (Sparc_Assembly.CALL, 2),
d3890 1
a3890 1
            if debug orelse debug_polyvariables orelse debug_variables orelse generate_moduler 
d4274 21
d4298 2
a4299 20
                          Sparc_Assembly.JUMP_AND_LINK (_,_,_,_,debug) =>        
                            let
                              val unpadded_name =
                                let
                                  val s = size padded_name
                                  fun check_index to =
                                    if String.ordof(padded_name,to) = 0 
                                      then check_index(to-1)
                                    else String.substring(padded_name,0,to+1)
                                in
                                  check_index (s-1) 
                                  handle String.Substring => ""
                                       | Ord => ""
                                end
			     in
                               debug_map := Debugger_Types.add_annotation (unpadded_name,
                                                                           count,
                                                                           debug,
                                                                           !debug_map)
                            end
d4301 2
a4302 2
                            annotation_points(t,count+4,
                                              Sparc_Opcodes.output_opcode(Sparc_Assembly.assemble inst)::res))
d4304 1
a4304 1
                     if debug
@


1.208
log
@Change "real too big" message to "real unrepresentable"
@
text
@d4 3
a1599 1

d1605 1
a1605 1
		fun symbolic_value i =
d1612 1
a1612 3
		     ();
		     ~(gc_spill_offset + 4 * (1 + i))
		     )
d1614 1
d1616 14
a1629 4
		  MirTypes.DEBUG (spill as ref(RuntimeEnv.OFFSET1(i)),name) => 
		    (fn value => (spill := RuntimeEnv.OFFSET2(value);value)) (symbolic_value i)
		  | MirTypes.DEBUG (ref(RuntimeEnv.OFFSET2(i)),name) => i
		  | MirTypes.SIMPLE i => symbolic_value i
d1633 1
a1633 1
		fun symbolic_value i =
d1644 1
a1644 3
		       ();
		       ~(non_gc_spill_offset + 4 * (1 + offset + i))
		       )
d1648 10
a1657 5
		  MirTypes.DEBUG (spill as ref(RuntimeEnv.OFFSET1(i)),name) => 
		    (fn value => (spill := RuntimeEnv.OFFSET2(value);value))
		    (symbolic_value i)
		  | MirTypes.DEBUG (ref(RuntimeEnv.OFFSET2(i)),name) => i
		  | MirTypes.SIMPLE i => symbolic_value i
d1662 1
a1662 1
		fun symbolic_value i =
a1672 1
		       ();
d1674 1
a1674 2
			 offset * spare_size)
		       )
d1678 1
d1680 8
a1687 4
		    (fn value => (spill := RuntimeEnv.OFFSET2(value);value)) 
		    (symbolic_value i)
		  | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(i)),name) => i
		  | MirTypes.SIMPLE i => symbolic_value i
d3882 6
a3887 16
            if debug orelse debug_polyvariables orelse debug_variables orelse generate_moduler then
            let
              val Debugger_Types.INFO i = !debug_map
            in
              (case NewMap.tryApply' (i, procedure_name) of
                 MLWorks.Option.SOME ((a, b, c),_, is_exn) =>
                   debug_map := 
                   (Debugger_Types.INFO (NewMap.define(i, 
                         procedure_name,((a,if needs_preserve then b
                                            else true,c),runtime_env, is_exn))))
               | _ => 
                   debug_map := 
                   (Debugger_Types.INFO (NewMap.define(i, 
                         procedure_name,((Debugger_Types.null_type,false,nil),
                                         runtime_env, false)))))
            end
d4269 1
a4269 2
                          Sparc_Assembly.JUMP_AND_LINK (_,_,_,_,Debugger_Types.Nop) => ()        
                        | Sparc_Assembly.JUMP_AND_LINK (_,_,_,_,debug) =>        
a4282 1
                              val Debugger_Types.INFO i = !debug_map
d4284 4
a4287 8
			       case NewMap.tryApply'(i, unpadded_name) of
				 MLWorks.Option.SOME ((ty,leaf,annotations),runtime_env, is_exn) =>
				   debug_map :=
                                     Debugger_Types.INFO
                                     (NewMap.define(i, unpadded_name, 
                                        ((ty,leaf,(count,debug)::annotations),
					 runtime_env, is_exn)))
			       | _ => ()
@


1.207
log
@Fix problem with floor.
@
text
@d4 3
d891 1
a891 1
           "Real number too big : " ^ x)
d950 1
a950 1
	 (Info.FATAL, location, "Real number too big : " ^ x)
@


1.206
log
@Add ALLOC_VECTOR
@
text
@d4 3
d2677 6
a2682 6

		    in
		      ([
                        (* Test for a possible overflow if the number is too
			   big in magnitude.  Can't rely on hardware trap,
			   because our ints are only 30 bits. *)
a2688 3
                        (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                         (Sparc_Assembly.SUB,MachTypes.global,
                          Sparc_Assembly.IMM 1,MachTypes.global),absent,""),
d2699 1
d2705 3
a2707 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBG, 0), Option.PRESENT tag, ""),
d2713 2
a2715 5

                        (* Test for a negative quantity *)
                        (Sparc_Assembly.FBINARY(subtract, MachTypes.fp_global, MachTypes.fp_global, MachTypes.fp_global), 
                         absent, ""),
                       (Sparc_Assembly.FUNARY(test, rs2, MachTypes.fp_global), absent, ""),
a2716 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBGE, 6), Option.ABSENT, ""),
d2718 3
a2720 19
                        (* Negative so subtract one *)
                        (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                         (Sparc_Assembly.OR,MachTypes.global,
                          Sparc_Assembly.IMM 1,MachTypes.G0),absent,""),
                        (Sparc_Assembly.LOAD_AND_STORE
                         (Sparc_Assembly.ST,
                          MachTypes.global,
                          MachTypes.fp,
                          Sparc_Assembly.IMM ~4), absent,""),                   
                        (Sparc_Assembly.LOAD_AND_STORE_FLOAT
                         (Sparc_Assembly.LDF, MachTypes.fp_global,
                          MachTypes.fp,
                          Sparc_Assembly.IMM ~4), absent,
                         "Save converted value"),
                        (Sparc_Assembly.CONV_OP(operation', MachTypes.fp_global,
						MachTypes.fp_global),
                         absent, ""),
                        (Sparc_Assembly.FBINARY(subtract, rs2, rs2, MachTypes.fp_global), 
                         absent, ""),
d2722 1
a2722 4
                        (* Do the conversion operation *)
                        (Sparc_Assembly.CONV_OP(operation, MachTypes.fp_global,
						rs2),
			  absent, ""),
d2724 5
a2728 9
                         (Sparc_Assembly.STF, MachTypes.fp_global,
                          MachTypes.fp,
                          Sparc_Assembly.IMM ~4), absent,
                         "Save converted value"),
                        (Sparc_Assembly.LOAD_AND_STORE(Sparc_Assembly.LD,
                                                       rd, MachTypes.fp,
                                                       Sparc_Assembly.IMM
                                                       ~4), absent,
                        "And reload into destination"),
d2731 37
a2767 2
			 absent, "Tag the result")],
		      opcode_list, block_list, final_result)
@


1.205
log
@Add support for immediate store operation
@
text
@d4 3
d3056 27
a3082 23
                                  case allocate
                                    of MirTypes.ALLOC =>
                                       if size = 2 then
                                         (8, Tags.PAIRPTR, true, 0)
                                       else
                                         (8 * ((size+2) div 2), Tags.POINTER,
					  size mod 2 <> 0, 64*size+Tags.RECORD)
                                     | MirTypes.ALLOC_STRING =>
					 (((size+11) div 8) * 8,
					  Tags.POINTER, true, 64*size+Tags.STRING)
                                     | MirTypes.ALLOC_REAL =>
                                       (case MachTypes.fp_used
                                          of MachTypes.single   => Crash.unimplemented "ALLOC_REAL single"
                                           | MachTypes.extended => Crash.unimplemented "ALLOC_REAL extended"
                                           | MachTypes.double   =>
					       (16, Tags.POINTER, true,
						64*(16 - 4) + Tags.BYTEARRAY))
                                     | MirTypes.ALLOC_REF  =>
					 (8 + 8*((size+2) div 2),
					  Tags.REFPTR, size mod 2 <> 0, 64*size+Tags.ARRAY)
                                     | MirTypes.ALLOC_BYTEARRAY =>
					 (((size+11) div 8) * 8, Tags.REFPTR, true,
					  64*size+Tags.BYTEARRAY)
d3142 21
a3162 3
                                    case allocate
                                      of MirTypes.ALLOC        => Crash.unimplemented "ALLOC variable size"
                                       | MirTypes.ALLOC_STRING => Crash.unimplemented "ALLOC_STRING variable size"
@


1.204
log
@Use pervasive Option.option for return values in NewMap
@
text
@d4 3
d2404 2
d3757 2
@


1.203
log
@Changes for new NEW_HANDLER instruction
@
text
@d4 3
d1076 1
a1076 1
			    Map.NO => true
d1113 1
a1113 1
	      Map.YES(_, t) => t
d1235 1
a1235 1
			 Map.YES res => 
d1243 1
a1243 1
		       | Map.NO =>
d1249 1
a1249 1
			   Map.YES res => 
d1257 1
a1257 1
			 | Map.NO =>
d1262 1
a1262 1
			   Map.YES res => 
d1270 1
a1270 1
			 | Map.NO =>
d1275 1
a1275 1
			   Map.YES res => 
d1283 1
a1283 1
			 | Map.NO =>
d1288 1
a1288 1
			   Map.YES res => 
d1296 1
a1296 1
			 | Map.NO => Crash.impossible "Assoc do_opcode Call")
d1301 1
a1301 1
			   Map.YES res =>
d1332 1
a1332 1
			 | Map.NO => Crash.impossible "Assoc do_opcode LEO")
d1338 1
a1338 1
			   Map.YES res =>
d1378 1
a1378 1
			 | Map.NO =>
d1385 1
a1385 1
			   Map.YES res =>
d1396 1
a1396 1
			 | Map.NO =>
d1401 1
a1401 1
			   Map.YES res =>
d1419 1
a1419 1
			 | Map.NO =>
d1425 1
a1425 1
			   Map.YES res => 
d1434 1
a1434 1
			 | Map.NO =>
d3656 1
a3656 1
	      MirTypes.FP.Map.NO => MirTypes.FP.Map.define(map, fp, true)
d3824 1
a3824 1
                 NewMap.YES((a, b, c),_, is_exn) =>
d4014 1
a4014 1
		MirTypes.Map.YES instrs =>
d4234 1
a4234 1
				 NewMap.YES((ty,leaf,annotations),runtime_env, is_exn) =>
@


1.202
log
@Abstraction of debug information
@
text
@d4 3
d3501 9
a3509 2
		| MirTypes.NEW_HANDLER tag =>
		    ([], opcode_list, block_list, final_result)
@


1.201
log
@Handle constant operands to tests
@
text
@d4 3
d733 1
a733 1
  sharing MirTables.MirTypes.Option = MirTables.MirTypes.RuntimeEnv.Option
a738 2
  sharing type MirTables.MirTypes.RuntimeEnv.debugger_env = 
    MirTables.MirTypes.Debugger_Types.Debugger_Env.debugger_env
d752 1
a752 1
  structure RuntimeEnv = MirTypes.RuntimeEnv
d1597 4
a1600 4
		  Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
		    (fn value => (spill := Option.SOME2(value);value)) (symbolic_value i)
		  | Option.SOME1(ref(Option.SOME2(i)),name) => i
		  | Option.SOME2(i) => symbolic_value i
d1621 2
a1622 2
		  Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
		    (fn value => (spill := Option.SOME2(value);value))
d1624 2
a1625 2
		  | Option.SOME1(ref(Option.SOME2(i)),name) => i
		  | Option.SOME2(i) => symbolic_value i
d1648 2
a1649 2
		  Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
		    (fn value => (spill := Option.SOME2(value);value)) 
d1651 2
a1652 2
		  | Option.SOME1(ref(Option.SOME2(i)),name) => i
		  | Option.SOME2(i) => symbolic_value i
@


1.200
log
@Remove checks for lr used in ALLOC
@
text
@d4 3
d1752 5
d2757 1
a2757 2
		| MirTypes.TEST(cond_branch, tag, gp_operand,
				gp_operand') =>
d2780 4
a2783 9
		    val _ = case gp_op of
		      MirTypes.GP_GC_REG _ => ()
		    | MirTypes.GP_NON_GC_REG _ => ()
		    | _ => Crash.impossible"Two constant operands to test"
		    val rs1 = lookup_gp_operand gp_op
		    val test_instr = case cond_branch of
		      MirTypes.BTA => Sparc_Assembly.ANDCC
		    | MirTypes.BNT => Sparc_Assembly.ANDCC
		    | _ => Sparc_Assembly.SUBCC
d2785 1
a2785 2
		    if is_reg gp_op' orelse
		      gp_check_range(gp_op', true, arith_imm_limit) then
d2787 19
a2805 5
			val reg_or_imm =
			  if is_reg gp_op' then
			    Sparc_Assembly.REG(lookup_gp_operand gp_op')
			  else
			    make_imm_format3 gp_op'
d2807 8
a2814 8
			([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (test_instr, MachTypes.G0,
			    reg_or_imm, rs1),
			   absent, "Do the test"),
			  (Sparc_Assembly.BRANCH_ANNUL(branch, 0),
			   Option.PRESENT tag, "Do the branch"),
			  Sparc_Assembly.nop],
			opcode_list, block_list, final_result)
d2817 35
a2851 8
		      ([],
		       MirTypes.UNARY(MirTypes.MOVE,
				      MirTypes.GC_REG
				      MirRegisters.global,
				      gp_op') ::
		       MirTypes.TEST(cond_branch, tag, gp_op,
				     MirTypes.GP_GC_REG MirRegisters.global) ::
		       opcode_list, block_list, final_result)
@


1.199
log
@Change to interface to stack extension
@
text
@d4 3
d3073 1
d3078 2
a3079 1
				      
@


1.198
log
@Remove dependence on mir optimiser for fp registers used
@
text
@d4 3
d3043 1
a3043 1
				  let val load_global = 
d3046 3
d3050 1
a3050 1
				    load_global @@
d3058 1
a3058 1
				       load_global @@
d3278 1
a3278 1
				 (Sparc_Assembly.ADD, MachTypes.I2,
d3296 1
a3296 1
				   Sparc_Assembly.REG MachTypes.I2),
d3338 1
a3338 1
			     "Compare the required stack size with the calculated") ::
d3346 1
a3346 1
				Sparc_Assembly.REG MachTypes.O3, 
d3354 1
a3354 1
			     "Compare the required stack size with the calculated") ::
d3361 1
a3361 1
			    (MachTypes.O3, MirTypes.GP_IMM_ANY frame_size) @@
d3373 1
a3373 1
			    (MachTypes.O3, MirTypes.GP_IMM_ANY frame_size) @@
d3382 1
a3382 1
			      (Sparc_Assembly.JMPL, MachTypes.O4,
d3391 1
a3391 1
			     (Sparc_Assembly.OR, MachTypes.O3, 
d3393 1
a3393 1
			     absent, "Set the required size in O3") :: post_ov_code
d3409 2
a3410 2
				  (Sparc_Assembly.SUB, MachTypes.O3,
				   Sparc_Assembly.REG(MachTypes.O3), MachTypes.G0), 
d3416 1
a3416 1
				   else Sparc_Assembly.REG MachTypes.O3,
d3466 1
a3466 1
			    absent, "Do all the work of getting to the handler"),
d3482 1
a3482 1
			    absent, "Do all the work of getting to the handler"),
d3578 2
a3579 2
                   proc_tag, MirTypes.PROC_PARAMS
		   {leaf, spill_sizes, stack_allocated, ...},
a3627 3

	  fun ch f s =
	    (Set.map f s; false) handle MachTypes.NeedsPreserve => true
@


1.197
log
@Added register lists to BRANCH_AND_LINK, TAIL_CALL and ENTER instructions.
@
text
@d4 3
d3573 1
a3573 3
		   {leaf, registers_used = Option.PRESENT
		    {fp, gc, non_gc},
		    spill_sizes, stack_allocated, ...},
d3586 30
a3615 1
	  val fps = Set.map (fn r => MirTypes.FP.Map.apply'(fp_map, r)) fp
a3993 1
	| proc_cg _ = Crash.impossible "mach_cg.proc_cg"
@


1.196
log
@Add new allocation routine.
@
text
@d4 3
d2825 1
a2825 1
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.REG reg_operand,debug_information) =>
d2833 1
a2833 1
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.TAG tag,_) =>
d2839 1
a2839 1
		| MirTypes.TAIL_CALL(_, bl_dest) =>
d3196 1
a3196 1
		| MirTypes.ENTER =>
d3679 1
a3679 1
	    | check_instr_regs(MirTypes.TAIL_CALL(_, bl_dest )) =
d3698 1
a3698 1
	    | check_instr_regs(MirTypes.ENTER) = ()
@


1.195
log
@Modify for new code_module
@
text
@d4 3
d1687 22
d3023 10
a3032 31
                                  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                   (Sparc_Assembly.ADD, MachTypes.gc1, Sparc_Assembly.IMM bytes, MachTypes.gc1),
                                   absent, "Attempt to allocate some heap") ::
                                  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                   (Sparc_Assembly.SUBCC, MachTypes.G0, Sparc_Assembly.REG MachTypes.gc2, MachTypes.gc1),
                                   absent, "Is a GC required?") ::
                                  (Sparc_Assembly.BRANCH_ANNUL
                                   (Sparc_Assembly.BL, 6),
                                   absent, "Skip call to GC if not") ::
                                  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                   (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM (primary - bytes), MachTypes.gc1),
                                   absent, "Tag result with primary") ::
                                  (Sparc_Assembly.LOAD_AND_STORE
                                   (Sparc_Assembly.LD, MachTypes.global, MachTypes.implicit, gc_entry),
                                   absent, "Fetch entry point of GC") ::
                                  (Sparc_Assembly.JUMP_AND_LINK
                                   (Sparc_Assembly.JMPL, link, Sparc_Assembly.IMM 0, MachTypes.global,
                                    Debugger_Types.null_backend_annotation),
                                   absent, "Call GC") ::
                                  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                   (Sparc_Assembly.OR, MachTypes.global, Sparc_Assembly.IMM bytes, MachTypes.G0),
                                   absent, "Size argument for GC") ::
                                  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                   (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM primary, MachTypes.global),
                                   absent, "Tag result with primary") ::
                                  (if aligned then
                                     header_code
                                   else
                                     (Sparc_Assembly.LOAD_AND_STORE
                                      (Sparc_Assembly.ST, MachTypes.G0, rd, Sparc_Assembly.IMM (bytes - primary - 4)),
                                      absent, "Zero unaligned extra word") :: header_code)
d3034 19
a3052 38
				  (load_large_number_into_register
				   (rd, MirTypes.GP_IMM_ANY bytes)) @@
                                  ((Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                   (Sparc_Assembly.ADD, MachTypes.gc1, Sparc_Assembly.REG rd, MachTypes.gc1),
                                   absent, "Attempt to allocate some heap") ::
                                  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                   (Sparc_Assembly.SUBCC, MachTypes.G0, Sparc_Assembly.REG MachTypes.gc2, MachTypes.gc1),
                                   absent, "Is a GC required?") ::
                                  (Sparc_Assembly.BRANCH_ANNUL
                                   (Sparc_Assembly.BL, 5),
                                   absent, "Skip call to GC if not") ::
                                  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                   (Sparc_Assembly.SUB, MachTypes.global, Sparc_Assembly.REG rd, MachTypes.gc1),
                                   absent, "Calculate address of new object") ::
                                  (Sparc_Assembly.LOAD_AND_STORE
                                   (Sparc_Assembly.LD, MachTypes.global, MachTypes.implicit, gc_entry),
                                   absent, "Fetch entry point of GC") ::
                                  (Sparc_Assembly.JUMP_AND_LINK
                                   (Sparc_Assembly.JMPL, link, Sparc_Assembly.IMM 0, MachTypes.global,
                                    Debugger_Types.null_backend_annotation),
                                   absent, "Call GC") ::
                                  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                   (Sparc_Assembly.OR, MachTypes.global, Sparc_Assembly.REG rd, MachTypes.G0),
                                   absent, "Size argument for GC") ::
                                  (if aligned then
                                     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                      (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM primary, MachTypes.global),
                                      absent, "Tag object with primary") :: header_code
                                   else
                                     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                      (Sparc_Assembly.ADD, rd, Sparc_Assembly.REG rd, MachTypes.global),
                                      absent, "Calculate end of object") ::
                                     (Sparc_Assembly.LOAD_AND_STORE
                                      (Sparc_Assembly.ST, MachTypes.G0, rd, Sparc_Assembly.IMM (~4)),
                                      absent, "Zero unaligned extra word") ::
                                     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                      (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM primary, MachTypes.global),
                                      absent, "Tag object with primary") :: header_code))
d3071 5
a3075 2
                                            (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM (12+7), rs),
                                            absent, "Calculate length of Array")])                                
d3079 1
a3079 1
                                            (Sparc_Assembly.SRL, rd, Sparc_Assembly.IMM 2, rs),
d3082 5
a3086 2
                                            (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM (4+7), rd),
                                            absent, "")])
d3089 7
a3095 28
                                  ((Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                     (Sparc_Assembly.ANDN, rd, Sparc_Assembly.IMM 7, rd),
                                     absent, "Calculate aligned size in bytes") ::
                                    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                     (Sparc_Assembly.ADD, MachTypes.gc1, Sparc_Assembly.REG rd, MachTypes.gc1),
                                     absent, "Attempt to allocate some heap") ::
                                    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                     (Sparc_Assembly.SUBCC, MachTypes.G0, Sparc_Assembly.REG MachTypes.gc2, MachTypes.gc1),
                                     absent, "Is a GC required?") ::
                                    (Sparc_Assembly.BRANCH_ANNUL
                                     (Sparc_Assembly.BL, 5),
                                     absent, "Skip call to GC if not") ::
                                    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                     (Sparc_Assembly.SUB, MachTypes.global, Sparc_Assembly.REG rd, MachTypes.gc1),
                                     absent, "Calculate address of new object") ::
                                    (Sparc_Assembly.LOAD_AND_STORE
                                     (Sparc_Assembly.LD, MachTypes.global, MachTypes.implicit, gc_entry),
                                     absent, "Fetch entry point of GC") ::
                                    (Sparc_Assembly.JUMP_AND_LINK
                                     (Sparc_Assembly.JMPL, link, Sparc_Assembly.IMM 0, MachTypes.global,
                                      Debugger_Types.null_backend_annotation),
                                     absent, "Call GC") ::
                                    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                     (Sparc_Assembly.OR, MachTypes.global, Sparc_Assembly.REG rd, MachTypes.G0),
                                     absent, "Size argument for GC") ::
                                    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                     (Sparc_Assembly.ADD, rd, Sparc_Assembly.REG rd, MachTypes.global),
                                     absent, "Calculate end of object") ::
d3097 2
a3098 5
                                     (Sparc_Assembly.ST, MachTypes.G0, rd, Sparc_Assembly.IMM (~4)),
                                     absent, "Zero last word in case it's unaligned") ::
                                    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                     (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM primary, MachTypes.global),
                                     absent, "Tag object with primary") ::
d3101 1
a3101 1
                                     absent, "") ::
d3104 1
a3104 1
                                     absent, "Calculate header tag") ::
d3107 1
a3107 1
                                     absent, "Initialise header tag") :: nil)
@


1.194
log
@Fix to avoid lr unspilling alloc
@
text
@d4 3
d4145 4
a4148 2
		(Lists.assoc(tag, loc_refs),
		 spills,
d4198 1
a4198 1
		 end))
d4207 4
a4210 2
			     (procedure_name_list, tagged_code',
			      leaf_list, nop_offsets)),
d4220 6
a4225 4
                   MLWorks.Integer.makestring(Lists.reducel( fn(x,Code_Module.WORDSET(Code_Module.WORD_SET{2=tagged_code', ...})) =>
                                            (Lists.reducel (fn (x,(_,_,y)) => (size y) + x) (x,tagged_code'))
                                            | _ => Crash.impossible "what the ?")
                   (0,proc_elements)) ^ "\n")
@


1.193
log
@Updates to use lr as unspill register
@
text
@d4 3
d2840 2
d2945 2
a2946 1

d2967 1
a2967 1
					 (((size+12) div 8) * 8,
d2980 1
a2980 1
					 (((size+12) div 8) * 8, Tags.REFPTR, true,
d3067 1
a3067 1
                            | MirTypes.GP_GC_REG reg =>
d3069 6
d3083 1
a3083 1
                                            (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM (12+7), lookup_reg(MirTypes.GC.unpack reg, gc_array)),
d3088 1
a3088 1
                                            (Sparc_Assembly.SRL, rd, Sparc_Assembly.IMM 2, lookup_reg(MirTypes.GC.unpack reg, gc_array)),
d3091 1
a3091 1
                                            (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM (4+7), lookup_reg(MirTypes.GC.unpack reg, gc_array)),
d3130 1
a3130 1
                                     (Sparc_Assembly.SLL, MachTypes.global, Sparc_Assembly.IMM 4, lookup_reg(MirTypes.GC.unpack reg, gc_array)),
d3144 25
a3168 20
		     ((case adr of
			MirTypes.LEA =>
			  [(Sparc_Assembly.Call
			    (Sparc_Assembly.CALL, 2),
			    absent, "Call self"),
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.ADD, lookup_reg_operand reg_operand,
			     Sparc_Assembly.IMM 4, MachTypes.lr),
			    Option.PRESENT tag, "Update gc pointer")]
		      (* Note that lr points to the call instruction *)
		      (* Thus lr + 4, as computed by the ADD *)
		      (* points to the ADD instruction, which is fixed *)
		      (* up during linearisation *)
		      | MirTypes.LEO =>
			  [(Sparc_Assembly.LOAD_OFFSET
			    (Sparc_Assembly.LEO, lookup_reg_operand reg_operand, 0),
			    Option.PRESENT tag,
			    "Get offset of tag from procedure start")]
			  ), opcode_list, block_list, final_result)

@


1.192
log
@Update debugger information production
@
text
@d4 3
d2835 30
a2864 26
		    (let
		       val reg = lookup_reg_operand reg_operand
		     in
		       (if Lists.length tag_list <= 2 then
			  let
			    val (numbered_tag_list, _) =
			      Lists.number_from(tag_list, 0, 4, fn x=> x)
			    fun do_tests(done, []) = rev done
			      | do_tests(done, (tag, imm) :: (rest as _ :: _)) =
				do_tests((Sparc_Assembly.BRANCH
					  (Sparc_Assembly.BE, 0),
					  Option.PRESENT tag, "Do the branch") ::
					 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					  (Sparc_Assembly.SUBCC, MachTypes.G0,
					   Sparc_Assembly.IMM imm, reg),
					  absent, "Do the test") :: done, rest)
			      | do_tests(done, (tag, imm) :: rest) =
				do_tests((Sparc_Assembly.BRANCH_ANNUL
					  (Sparc_Assembly.BA, 0),
					  Option.PRESENT tag, "Do the branch") ::
					 (Sparc_Assembly.nop_code, absent,
					  "No test required in final case") ::
					 done, rest)
			  in
			    do_tests([], numbered_tag_list)
			  end
d2866 7
a2872 2
			  if (not needs_preserve) andalso reg = MachTypes.global then
			    Crash.impossible"mach_cg: leaf switch on global"
d2901 8
a2908 7
			      if needs_preserve then
				instrs
			      else
				move_reg(MachTypes.lr, MachTypes.global) :: instrs
			    end)
		     end,
		   opcode_list, block_list, final_result)
d4153 2
a4154 1
                                        ((ty,leaf,(count,debug)::annotations),runtime_env, is_exn)))
@


1.191
log
@Added leaf case switches
@
text
@d4 3
d3727 1
a3727 1
                 NewMap.YES((a, b, c),_) =>
d3731 1
a3731 1
                                            else true,c),runtime_env))))
d3736 1
a3736 1
                                         runtime_env)))))
d4136 1
a4136 1
				 NewMap.YES((ty,leaf,annotations),runtime_env) =>
d4140 1
a4140 1
                                        ((ty,leaf,(count,debug)::annotations),runtime_env)))
@


1.190
log
@New runtime directory structure.
@
text
@d4 3
d2829 64
a2892 46
		    ((if Lists.length tag_list <= 2 then
			let
			  val reg = lookup_reg_operand reg_operand
			  val (numbered_tag_list, _) =
			    Lists.number_from(tag_list, 0, 4, fn x=> x)
			  fun do_tests(done, []) = rev done
			  | do_tests(done, (tag, imm) :: (rest as _ :: _)) =
			    do_tests((Sparc_Assembly.BRANCH
				      (Sparc_Assembly.BE, 0),
				      Option.PRESENT tag, "Do the branch") ::
				     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				      (Sparc_Assembly.SUBCC, MachTypes.G0,
				       Sparc_Assembly.IMM imm, reg),
				      absent, "Do the test") :: done, rest)
			  | do_tests(done, (tag, imm) :: rest) =
			    do_tests((Sparc_Assembly.BRANCH_ANNUL
				      (Sparc_Assembly.BA, 0),
				      Option.PRESENT tag, "Do the branch") ::
				     (Sparc_Assembly.nop_code, absent,
				      "No test required in final case") ::
				     done, rest)
			in
			  do_tests([], numbered_tag_list)
			end
		      else
			(Sparc_Assembly.Call
			 (Sparc_Assembly.CALL, 2),
			 absent, "Call self") ::
			(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			 (Sparc_Assembly.ADD, MachTypes.lr,
			  Sparc_Assembly.IMM(4*4),
			  MachTypes.lr), absent,
			 "Offset to start of table") ::
			(Sparc_Assembly.JUMP_AND_LINK
			 (Sparc_Assembly.JMPL, MachTypes.G0,
			  Sparc_Assembly.REG MachTypes.lr,
			  lookup_reg_operand reg_operand,
                          Debugger_Types.null_backend_annotation), absent,
			 "Branch into table") ::
			Sparc_Assembly.nop ::
			map
			(fn tag =>
			 (Sparc_Assembly.BRANCH_ANNUL
			  (Sparc_Assembly.BA, 0), Option.PRESENT tag, ""))
			tag_list),
			opcode_list, block_list, final_result)
d3592 1
d3594 1
@


1.189
log
@Restore floating point callee saves before tailing
@
text
@d4 3
d668 2
a669 2
require "../rts/implicit";
require "../rts/tags";
@


1.188
log
@Modify fp_save_start to be calculated from fp_save_offset, fp_save_size
and float_value_size, ensuring double alignment if necessary
@
text
@d4 4
d2804 3
d2808 2
a2809 1
		      ([(case bl_dest of
@


1.187
log
@Fix shift of constant by constant problems
@
text
@d4 3
d1804 1
a1804 1
	  val fp_save_start = gc_spill_offset
@


1.186
log
@Fix floating point spill alignment problem
@
text
@d4 3
d2076 12
a2087 1
		      else Crash.impossible"Mach_Cg(BINARY) first arg not reg"
@


1.185
log
@Add loop entry to MirTypes.PROC_PARAMS.
@
text
@d4 3
d1465 2
a1466 1
     allow_fp_spare_slot   : bool (* Do we need a slot for float to int conversion? *)
d1528 2
a1529 1
		      allow_fp_spare_slot
d1538 1
a1538 2
		val symbolic_value = 
		  fn i => 
d1557 1
a1557 2
		val symbolic_value = 
		  fn i => 
d1573 27
d1602 2
a1603 1
		    (fn value => (spill := Option.SOME2(value);value)) (symbolic_value i)
a1606 7
	    | symbolic_value(MirTypes.FP_SPILL_SLOT i) =
	      (case i of 
		 Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
		   (fn value => (spill := Option.SOME2(value);value)) 
		   (~4 * (1 + non_gc_spill_size + i))
		 | Option.SOME1(ref(Option.SOME2(i)),name) => i
		 | Option.SOME2(i) => ~(fp_spill_offset + 4 * (1 + i)))
d1671 2
a1672 1
		   allow_fp_spare_slot
d3725 1
a3725 1
	  val float_spill_size = case MachTypes.fp_used of
d3733 1
a3733 1
	    if total_fp_size <> 0 andalso float_spill_size <> 4 andalso
d3745 1
a3745 1
	    non_gc_spill_size * 4 + float_spill_size * total_fp_size
d3753 1
a3753 1
	  val fp_save_offset = fp_spill_offset + fp_spill_size * float_spill_size
d3773 2
a3774 1
	     allow_fp_spare_slot = needs_fp_spare
@


1.184
log
@Fixed stack initialisation to cope with starting on a non-aligned boundary
@
text
@d4 3
d3492 1
a3492 1
		    spill_sizes, stack_allocated},
@


1.183
log
@Work on avoiding initialisation of stack slots
@
text
@d4 3
d1595 2
a1596 1
	    do_store(reg, offset+8, n-2,
d1598 1
a1598 1
		      (Sparc_Assembly.STD, MachTypes.G0,
d1601 8
a1608 1
		      "Initialise two stack slots") :: done)
d3155 6
d3166 1
a3166 1
					4 * gc_stack_slots
d3748 15
a3828 39
(*
	  val analyse_instr =
	    fn (x as (_, b)) =>
	    ((case b of
		MirTypes.TBINARY _ => output(std_out, "Analysing " ^ "TBINARY\n")
	      | MirTypes.BINARY _ => output(std_out, "Analysing " ^ "BINARY\n")
	      | MirTypes.UNARY _ => output(std_out, "Analysing " ^ "UNARY\n")
	      | MirTypes.NULLARY _ => output(std_out, "Analysing " ^ "NULLARY\n")
	      | MirTypes.TBINARYFP _ => output(std_out, "Analysing " ^ "TBINARYFP\n")
	      | MirTypes.TUNARYFP _ => output(std_out, "Analysing " ^ "TUNARYFP\n")
	      | MirTypes.BINARYFP _ => output(std_out, "Analysing " ^ "BINARYFP\n")
	      | MirTypes.UNARYFP _ => output(std_out, "Analysing " ^ "UNARYFP\n")
	      | MirTypes.STACKOP _ => output(std_out, "Analysing " ^ "STACKOP\n")
	      | MirTypes.STOREOP _ => output(std_out, "Analysing " ^ "STOREOP\n")
	      | MirTypes.STOREFPOP _ => output(std_out, "Analysing " ^ "STOREFPOP\n")
	      | MirTypes.REAL _ => output(std_out, "Analysing " ^ "REAL\n")
	      | MirTypes.FLOOR _ => output(std_out, "Analysing " ^ "FLOOR\n")
	      | MirTypes.BRANCH _ => output(std_out, "Analysing " ^ "BRANCH\n")
	      | MirTypes.TEST _ => output(std_out, "Analysing " ^ "TEST\n")
	      | MirTypes.FTEST _ => output(std_out, "Analysing " ^ "FTEST\n")
	      | MirTypes.BRANCH_AND_LINK _ => output(std_out, "Analysing " ^ "BRANCH_AND_LINK\n")
	      | MirTypes.TAIL_CALL _ => output(std_out, "Analysing " ^ "TAIL_CALL\n")
	      | MirTypes.CALL_C => output(std_out, "Analysing " ^ "CALL_C\n")
	      | MirTypes.SWITCH _ => output(std_out, "Analysing " ^ "SWITCH\n")
	      | MirTypes.ALLOCATE _ => output(std_out, "Analysing " ^ "ALLOCATE\n")
	      | MirTypes.ALLOCATE_STACK _ => output(std_out, "Analysing " ^ "ALLOCATE_STACK\n")
	      | MirTypes.DEALLOCATE_STACK _ => output(std_out, "Analysing " ^ "DEALLOCATE_STACK\n")
	      | MirTypes.ADR _ => output(std_out, "Analysing " ^ "ADR\n")
	      | MirTypes.INTERCEPT => output(std_out, "Analysing " ^ "INTERCEPT\n")
	      | MirTypes.INTERRUPT => output(std_out, "Analysing " ^ "INTERRUPT\n")
	      | MirTypes.ENTER => output(std_out, "Analysing " ^ "ENTER\n")
	      | MirTypes.RTS => output(std_out, "Analysing " ^ "RTS\n")
	      | MirTypes.NEW_HANDLER _ => output(std_out, "Analysing " ^ "NEW_HANDLER\n")
	      | MirTypes.OLD_HANDLER => output(std_out, "Analysing " ^ "OLD_HANDLER\n")
	      | MirTypes.RAISE _ => output(std_out, "Analysing " ^ "RAISE\n")
	      | MirTypes.COMMENT _ => output(std_out, "Analysing " ^ "COMMENT\n"));
		analyse_instr x)
*)

a3840 19
(*
	  val _ = MLWorks.ExtendedArray.iterate_index
	    (fn (i, true) =>
	     output(std_out, "Spill slot " ^ MLWorks.Integer.makestring i ^
		    " still requires initialisation\n")
	     | (i, false) =>
	     output(std_out, "Spill slot " ^ MLWorks.Integer.makestring i ^
		    " no longer requires initialisation\n"))
	    spill_array
	  val _ = MLWorks.ExtendedArray.iterate_index
	    (fn (i, true) =>
	     output(std_out, "Stack slot " ^ MLWorks.Integer.makestring i ^
		    " still requires initialisation\n")
	     | (i, false) =>
	     output(std_out, "Stack slot " ^ MLWorks.Integer.makestring i ^
		    " no longer requires initialisation\n"))
	    stack_array
*)

a3847 19

(*
	  val _ =
	    if gc_spill_size <> 0 andalso not spills_need_init then
	      output(std_out, "All spills fully initialised\n")
	    else
	      ()
	  val _ =
	    if stack_extra <> 0 andalso not stack_need_init then
	      output(std_out, "All stack slots fully initialised\n")
	    else
	      ()
	  val _ =
	    if (gc_spill_size + stack_extra <> 0) andalso
	      not (spills_need_init orelse stack_need_init) then
	      output(std_out, "No stack initialisation required\n")
	    else
	      ()
*)
@


1.182
log
@Changed the other restore instruction.
@
text
@d4 3
d179 1
a179 1
Changed maps used on tags to that providfed by mirtypes for efficiency
d1505 15
a1519 19
      fun do_blocks(_, [], _, (*_, _, _, _, _, _,*) _) = []
      | do_blocks(needs_preserve, MirTypes.BLOCK(tag,opcodes) :: rest,
		  PROC_STACK
		  {non_gc_spill_size,
		   fp_spill_size,
		   fp_save_size,
		   gc_spill_size,
		   gc_stack_alloc_size,
		   register_save_size,
		   non_gc_spill_offset,
		   fp_spill_offset,
		   fp_save_offset,
		   gc_spill_offset,
		   gc_stack_alloc_offset,
		   register_save_offset,
		   allow_fp_spare_slot
		   },
		  fps_to_preserve
		  ) =
a1520 2
	  val frame_size = register_save_offset + register_save_size
	  val non_save_frame_size = register_save_offset
d1539 3
a1541 3
                case i of
                  Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
                    (fn value => (spill := Option.SOME2(value);value)) (symbolic_value i)
d1564 3
a1566 3
                case i of 
                  Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
                    (fn value => (spill := Option.SOME2(value);value)) (symbolic_value i)
d1577 67
d3105 9
d3116 17
a3132 33
			fun do_store(_, _, 0, done) = done
			  | do_store(reg, offset, 1, done) =
			    (Sparc_Assembly.LOAD_AND_STORE
			     (Sparc_Assembly.ST, MachTypes.G0,
			      reg,
			      Sparc_Assembly.IMM offset), absent,
			     "Initialise a stack slot") :: done
			  | do_store(reg, offset, n, done) =
			    if n < 0 then Crash.impossible"Do_store"
			    else
			      do_store(reg, offset+8, n-2,
				       (Sparc_Assembly.LOAD_AND_STORE
					(Sparc_Assembly.STD, MachTypes.G0,
					 reg,
					 Sparc_Assembly.IMM offset), absent,
					"Initialise two stack slots") :: done)
			(* revised version of n_stores running off sp *)
			fun n_stores no_of_stores =
			  (* Assumes area to be cleared immediately *)
			  (* above register save area *)
			  let
			    val end_limit = 64 + (no_of_stores-1)*4
			    val end_instrs =
			      [(Sparc_Assembly.BRANCH_ANNUL
				(Sparc_Assembly.BA, 0),
				Option.PRESENT end_tag,
				"Finish cleaning stack"),
			       Sparc_Assembly.nop]
			  in
			    if check_range(end_limit, true,
					   arith_imm_limit) then
			      do_store(MachTypes.sp, 64, no_of_stores,
				       end_instrs)
d3134 3
a3136 9
			      Crash.impossible
			      ("n_stores end_limit = " ^
			       MLWorks.Integer.makestring end_limit)
			  end
			val gc_stack_slots = (gc_spill_size + gc_stack_alloc_size)
			val (clean_stack, opcodes, block) =
			  if (*gc_stack_size*) gc_stack_slots (*div 4*) <= 10 then
			    (false,
			     n_stores gc_stack_slots, (top_tag, []))
d3149 1
a3149 1
					4 * (gc_spill_size + gc_stack_alloc_size)
d3170 1
a3170 1
				  Sparc_Assembly.IMM 64,
d3469 1
a3469 1
                   tag, MirTypes.PROC_PARAMS
d3649 1
a3649 1
	      if t = tag then (t, code) :: (L @@ rest)
d3731 163
d3898 2
d3917 1
a3917 1
	  ((tag, code), 
@


1.181
log
@Fix restore instruction to match that commonly generated.
@
text
@d4 3
d3281 1
a3281 1
			 MachTypes.sp), absent, "Restore in the delay slot")]
@


1.180
log
@Fix bug introduced in fp register saving by stack rationalisation
@
text
@d4 3
d1240 1
a1240 1
				  (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM disp, MachTypes.G0),
d2476 1
a2476 1
                         (Sparc_Assembly.ADD,MachTypes.global,
d2516 1
a2516 1
                         (Sparc_Assembly.ADD,MachTypes.global,
d2672 1
a2672 1
			    Sparc_Assembly.IMM 0, MachTypes.sp),
@


1.179
log
@Fix bug in float spill area alignment
Rationalise stack layout information
@
text
@d4 4
d1689 2
a1690 2
	  val save_fps =
	    do_save_instrs(~fp_save_offset, fps_to_preserve)
d1692 1
a1692 2
	  val restore_fps =
	    do_restore_instrs(~fp_save_offset, fps_to_preserve)
@


1.178
log
@Fix code generation of LEO for mutually recursive function case
@
text
@d4 3
a1063 7
(* Replaced during code vector reform
	(* CT added the following instead of next_offset+4 *)
	val next_offset' =
	  next_offset + 4 (* raw spill count *) + 4 (* Back-pointer *)
	  + 4 (* profiler information *) + 4 (* offset to dbug information *)
	  + (size current_proc_padded_name) (* debug information *)
*)
a1381 4
(* Replaced during code vector reform
		(* CT added this code for the double word alignment *)
                val offset'' = 8 + 8 + size padded_name + offset'
*)
d1429 17
d1492 1
a1492 1
      fun do_blocks(_, [], _, _, _, _, _, _, _, _) = []
d1494 15
a1508 7
		  gc_spill_size,
		  non_gc_spill_size,
		  needs_fp_spare,
		  non_gc_stack_size,
		  gc_stack_size,
		  gc_stack_area,
		  frame_size,
d1512 2
a1513 2
	  val non_save_frame_size = frame_size - 64
	  fun gc_area_start_offset _ = ~(non_gc_stack_size + 4)
d1516 17
a1532 17
	  | symbolic_value MirTypes.NON_GC_SPILL_SIZE =
	    non_gc_stack_size
	  | symbolic_value(MirTypes.GC_SPILL_SLOT i) =
            let 
              val symbolic_value = 
                fn i => 
                (if i >= gc_spill_size then
                   Crash.impossible
                   ("Spill slot " ^ MLWorks.Integer.makestring i ^
                    " requested, but only " ^ MLWorks.Integer.makestring gc_spill_size ^
                    " allocated\n")
                 else
                   ();
                   ~(non_gc_stack_size + 4 * (1 + i))
                   )
            in
                case i of 
d1535 22
a1556 22
                | Option.SOME1(ref(Option.SOME2(i)),name) => i
                | Option.SOME2(i) => symbolic_value i
            end
	  | symbolic_value(MirTypes.NON_GC_SPILL_SLOT i) =
            let 
              val symbolic_value = 
                fn i => 
                let
                  val offset = if needs_fp_spare then 1 else 0
                in
                  (if i >= non_gc_spill_size then
                     Crash.impossible
                     ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
                      " requested, but only " ^
                      MLWorks.Integer.makestring non_gc_spill_size ^
                      " allocated\n")
                   else
                     ();
                     ~4 * (1 + offset + i)
                     )
                end
            in
d1560 10
a1569 10
                | Option.SOME1(ref(Option.SOME2(i)),name) => i
                | Option.SOME2(i) => symbolic_value i
            end
	  | symbolic_value(MirTypes.FP_SPILL_SLOT i) =
               (case i of 
                  Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
                    (fn value => (spill := Option.SOME2(value);value)) 
                            (~4 * (1 + non_gc_spill_size + i))
                | Option.SOME1(ref(Option.SOME2(i)),name) => i
                | Option.SOME2(i) => ~4 * (1 + non_gc_spill_size + i))
a1684 14
	  val real_non_gc_stack_size =
	    if non_gc_stack_size mod 8 = 0 orelse
	      MachTypes.fp_used = MachTypes.single then
	      non_gc_stack_size
	    else
	      non_gc_stack_size - 4

(*
	  val _ = case fps_to_preserve of
	    [] => ()
	  | _ => Print.print("Preserving " ^
			     MLWorks.Integer.makestring(Lists.length fps_to_preserve) ^
			     " floating point registers\n")
*)
d1686 1
a1686 1
	    do_save_instrs(~real_non_gc_stack_size, fps_to_preserve)
d1689 1
a1689 1
	    do_restore_instrs(~real_non_gc_stack_size, fps_to_preserve)
a1993 36
(*
		      val (extra, reg_or_imm, is_null, rs1) =
			if is_reg gp_operand then
			  let
			    val rs1 = lookup_gp_operand gp_operand
			  in
			    ([], imm, rd = rs1, rs1)
			  end
			else
			  let
			    val (high, low) = split_int gp_operand
			  in
			    if gp_check_range(gp_operand, true,
					      arith_imm_limit) then
			      ([],
			       if low = 0 then
				 Sparc_Assembly.REG MachTypes.G0
			       else
				 make_imm_format3 gp_operand,
			       false,
			       MachTypes.G0)
			    else
			      ([(Sparc_Assembly.SetHI
				 (Sparc_Assembly.SETHI, rd, high),
				 absent, "Get high part")],
			       Sparc_Assembly.IMM low, false, rd)
			  end
		    in
		      (if is_null then
			 []
		       else
			 extra @@ [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				   (opcode, rd, reg_or_imm, rs1), absent, "")],
			 opcode_list, block_list, final_result)
		    end
*)
d2181 1
a2181 2
		    if 4 * (gc_spill_size + offset + 1) >
		      gc_stack_size then
d2185 1
a2185 2
				       MLWorks.Integer.makestring
				       (gc_stack_size div 4 - gc_spill_size) ^
d2193 1
a2193 1
				      (~(gc_stack_area + 4 * (offset + 1)))) ::
d2734 1
a2734 2
		  (if 4 * (gc_spill_size + alloc_size + fp_offset) >
		     gc_stack_size then
d2741 1
a2741 1
				      (gc_stack_size div 4 - gc_spill_size) ^
d2750 1
a2750 1
					(gc_stack_area +
a2807 21
(*
                                    let
                                      val (high, low) = split_int (MirTypes.GP_IMM_ANY header)
                                      val store =
                                        [(Sparc_Assembly.LOAD_AND_STORE
                                          (Sparc_Assembly.ST, MachTypes.global, rd, Sparc_Assembly.IMM (~primary)),
                                          absent, "Initialise header")]
                                    in
                                      if high = 0 then
                                        (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                         (Sparc_Assembly.OR, MachTypes.global, Sparc_Assembly.IMM header, MachTypes.G0),
                                         absent, "") :: store
                                      else
                                        (Sparc_Assembly.SetHI
                                         (Sparc_Assembly.SETHI, MachTypes.global, high),
                                         absent, "") ::
                                        (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                         (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.IMM low, MachTypes.global),
                                         absent, "") :: store
                                  end
*)
a2843 8
(*
                                  (Sparc_Assembly.SetHI
                                   (Sparc_Assembly.SETHI, rd, high),
                                   absent, "") ::
                                  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                   (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM low, rd),
                                   absent, "Load large immediate size")
*)
d3072 1
d3074 1
a3074 1
			  if gc_stack_size div 4 <= 10 then
d3076 1
a3076 3
			     n_stores((*gc_area_start_offset(),*)
				      gc_stack_size div 4),
			     (top_tag, []))
d3087 10
a3096 4
				    if gc_stack_size mod 8 = 0 then
				      gc_stack_size
				    else
				      gc_stack_size+4
a3105 19
(*
				    let
				      val (high, low) =
					split_int(MirTypes.GP_IMM_ANY
						  the_limit)
				    in
				      (Sparc_Assembly.SetHI
				       (Sparc_Assembly.SETHI,
					MachTypes.global, high),
				       absent, "Get high part") ::
				      (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				       (Sparc_Assembly.ADD,
					MachTypes.global,
					Sparc_Assembly.IMM low,
					MachTypes.global),
				       absent, "Add in low of limit") ::
				      branch_out
				    end
*)
a3313 11
(*
			  (Sparc_Assembly.SAVE_AND_RESTORE
			   (Sparc_Assembly.SAVE, MachTypes.sp,
			    Sparc_Assembly.IMM ~64, MachTypes.sp),
			   absent, "Create new frame for raise"),
			  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.OR, MachTypes.caller_closure,
			    Sparc_Assembly.REG MachTypes.G0,
			    MachTypes.G0),
			   absent, "Clear caller closure for gc"),
*)
a3323 4
(*
			  handle MachTypes.OutOfScope r =>
			    Crash.impossible ("Raise parameter was in " ^ MachSpec.print_register r ^ " in a leaf procedure")
*)
a3328 3
(*
 ([], opcode_list, block_list, final_result)
*)
a3560 8
(*
	    (ch (fn r =>
		 MachTypes.check_reg(MirTypes.GC.Map.apply'(gc_map, r))) gc)
	    orelse
	    (ch (fn r =>
		 MachTypes.check_reg(MirTypes.NonGC.Map.apply'(non_gc_map, r))) non_gc)
	    orelse
*)
d3625 2
d3628 1
a3628 1
	    if total_fp_size <> 0 andalso float_spill_size = 4 andalso
d3634 5
d3640 3
a3642 3
	    non_gc_spill_size * 4 + float_spill_size * fp_spill_size
	    + float_spill_size * fp_save_size
	  val gc_stack_size = gc_spill_size * 4 + stack_extra * 4
d3644 26
a3669 8
	    if (non_gc_stack_size + gc_stack_size) mod 8 = 0 then
	      non_gc_stack_size
	    else
	      non_gc_stack_size + 4
	  (* Ensure total stack requirement double aligned *)
	  val gc_stack_area = non_gc_stack_size + 4 * gc_spill_size
	  (* Base of stack allocation area for gc objects *)
	  val frame_size = gc_stack_size + non_gc_stack_size + 64
a3670 1
	  val needs_preserve = needs_preserve orelse needs_fp_spare
d3674 1
a3674 7
				     gc_spill_size,
				     non_gc_spill_size,
				     needs_fp_spare,
				     non_gc_stack_size,
				     gc_stack_size,
				     gc_stack_area,
				     frame_size,
@


1.177
log
@Added code generation of load_offset.
Added handling of case where load_offset can't be one instruction
similar to case where adr expands to more than one
@
text
@d4 5
d1153 21
a1173 21
	  fun linearise_proc(offset, [], done) = (offset, rev done)
	  | linearise_proc(start, blocks as (block :: block_list), done) =
	    let
	      (* Insert algorithm for optimal linearisation of blocks here *)
	      (* Present algorithm just uses the current order *)
	      (* Also assumes NOPs inserted after all control transfers *)
	      fun do_block(block_start, (block_tag, opcode_list), done) =
		let
		  fun do_opcode((Sparc_Assembly.BRANCH(branch, i),
				 Option.PRESENT tag, comment), offset) =
                    (case lookup_env tag of
                       Map.YES res => 
                         let
                           val disp =
                             fault_range(( res - offset) div 4,
                                         true, branch_disp_limit)
                         in
                           (Sparc_Assembly.BRANCH(branch, disp), comment)
                         end
                     | Map.NO =>
                         Crash.impossible"Assoc do_opcode branch")
d1175 1
a1175 1
		  | do_opcode((Sparc_Assembly.BRANCH_ANNUL(branch, i),
d1177 7
a1183 7
                    (case lookup_env tag of
                       Map.YES res => 
                         let
                           val disp =
                             fault_range((res - offset) div 4,
                                         true, branch_disp_limit)
                         in
d1185 4
a1188 4
                         end
                     | Map.NO =>
                         (Crash.impossible"Assoc do_opcode branch_annul"))
		  | do_opcode((Sparc_Assembly.FBRANCH(branch, i),
d1190 4
a1193 4
		    (case lookup_env tag of
                       Map.YES res => 
                         let
                           val disp =
d1196 6
a1201 6
                         in
                           (Sparc_Assembly.FBRANCH(branch, disp), comment)
                         end
                     | Map.NO =>
                         Crash.impossible"Assoc do_opcode fbranch")
		  | do_opcode((Sparc_Assembly.FBRANCH_ANNUL(branch, i),
d1203 67
a1269 51
		    (case lookup_env tag of
                       Map.YES res => 
                         let
                           val disp =
                             fault_range((res - offset) div 4,
                                         true, branch_disp_limit)
                         in
                           (Sparc_Assembly.FBRANCH_ANNUL(branch, disp), comment)
                         end
                     | Map.NO =>
                         Crash.impossible"Assoc do_opcode fbranch_annul")
		  | do_opcode((Sparc_Assembly.Call(Sparc_Assembly.CALL, i),
			       Option.PRESENT tag, comment), offset) =
                    (case lookup_env tag of
                       Map.YES res => 
                         let
                           val disp =
                             fault_range(( res + i - offset) div 4,
                                         true, call_disp_limit)
                         in
                           (Sparc_Assembly.Call(Sparc_Assembly.CALL, disp), comment)
                         end
                     | Map.NO => Crash.impossible "Assoc do_opcode Call")
		  | do_opcode((Sparc_Assembly.LOAD_OFFSET(Sparc_Assembly.LEO, rd, i),
			       Option.PRESENT tag, comment), offset) =
		    (* This will probably suffer the same problems as adr did *)
		    (case lookup_env tag of
                       Map.YES res =>
                         let
                           val disp = (res + i)
                         in
			   if check_range(disp, true, arith_imm_limit) then
			     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			      (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM disp, MachTypes.G0),
			      comment)
			   else
                             let
                               val _ =
                                 diagnostic_output 3
                                 (fn _ => ["Found bad LEO, substituting\n"])
                               val head_size = (offset - block_start) div 4
                               val tail = drop(1 + head_size, opcode_list)
                               (* get the opcodes after this one *)
                               val new_comment = comment ^ " (expanded adr)"
                               val new_tail =
                                 (Sparc_Assembly.SPECIAL_LOAD_OFFSET
                                  (Sparc_Assembly.LOAD_OFFSET_HIGH, rd, MachTypes.G0, i),
                                  Option.PRESENT tag, new_comment) ::
                                 (Sparc_Assembly.SPECIAL_LOAD_OFFSET
                                  (Sparc_Assembly.LOAD_OFFSET_AND_MASK, rd, rd, i),
                                  Option.PRESENT tag, new_comment) :: tail
d1271 35
a1305 3
                               raise bad_offset
				 (block_tag,
				  copy_n(head_size, opcode_list, [], new_tail))
d1307 16
a1322 80
                         end
                     | Map.NO => Crash.impossible "Assoc do_opcode LEO")
		  | do_opcode((Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			       (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM i,
				rs1),
			       Option.PRESENT tag, comment), offset) =
                    (case lookup_env tag of
                       Map.YES res =>
                         let
                           val disp = res + i - offset
                         in
                           if check_range(disp, true, arith_imm_limit) then
                             (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                              (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM disp,
                               rs1),
                              comment)
                           else
                             let
                               val _ =
                                 diagnostic_output 3
                                 (fn _ => ["Found bad LEA, substituting\n"])
                               val head_size = (offset - block_start) div 4
                               val tail = drop(1 + head_size, opcode_list)
                               (* get the opcodes after this one *)
                               val _ =
                                 if rs1 = rd then
                                   Crash.impossible"ADR has dest in lr"
                                 else ()
                               val new_comment = comment ^ " (expanded adr)"
                               val new_tail =
                                 (Sparc_Assembly.SetHI
                                  (Sparc_Assembly.SETHI, rd, i),
                                  Option.PRESENT tag, new_comment) ::
                                 (Sparc_Assembly.SPECIAL_ARITHMETIC
                                  (Sparc_Assembly.ADD_AND_MASK, rd,
                                   Sparc_Assembly.IMM(i + 4), rd),
                                  Option.PRESENT tag, new_comment) ::
                                 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                  (Sparc_Assembly.ADD, rd,
                                   Sparc_Assembly.REG rd, rs1),
                                  Option.ABSENT, new_comment) :: tail
                             in
                               raise bad_offset
				 (block_tag,
				  copy_n(head_size, opcode_list, [], new_tail))
                             end
                         end
                     | Map.NO =>
                         Crash.impossible"Assoc do_opcode arith")

		  | do_opcode((Sparc_Assembly.SPECIAL_ARITHMETIC
			       (_, rd, Sparc_Assembly.IMM i,
				rs1),
			       Option.PRESENT tag, comment), offset) =
                    (case lookup_env tag of
                       Map.YES res =>
                         let
                           val disp =
                             make_imm_fault
                             ((res + i - offset) mod 1024,
                              true, arith_imm_limit)
                         in
                           (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                            (Sparc_Assembly.ADD, rd, disp, rs1),
                            comment)
                         end
                     | Map.NO =>
                         Crash.impossible"Assoc do_opcode arith")
		  | do_opcode((Sparc_Assembly.SPECIAL_LOAD_OFFSET(load, rd, rn, i),
			       Option.PRESENT tag, comment), _) =
                    (case lookup_env tag of
                       Map.YES res =>
                         let
                           val disp = res + i
			 in
			   case load of
			     Sparc_Assembly.LOAD_OFFSET_HIGH =>
			       (Sparc_Assembly.SetHI
				(Sparc_Assembly.SETHI, rd,
				 (disp div 1024) mod (1024 * 1024 * 4)),
d1324 37
a1360 5
			   | Sparc_Assembly.LOAD_OFFSET_AND_MASK =>
			       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, rd,
				 make_imm_fault(disp mod 1024, true, arith_imm_limit),
				 rn),
d1362 3
a1364 25
                         end
                     | Map.NO =>
                         Crash.impossible"Assoc do_opcode SPECIAL_LOAD_OFFSET")
		    
		  | do_opcode((Sparc_Assembly.SetHI(_, rd, i),
			       Option.PRESENT tag, comment), offset) =
                    (case lookup_env tag of
                       Map.YES res => 
                         let
                           val disp = res + i - offset
                           val disp = (disp div 1024) mod (1024 * 1024 * 4)
                         (* Ensure positive *)
                         in
                           (Sparc_Assembly.SetHI(Sparc_Assembly.SETHI, rd, disp),
                            comment)
                         end
                     | Map.NO =>
                         Crash.impossible"Assoc do_opcode arith")

                    | do_opcode((opcode, Option.ABSENT, comment), offset) =
                      (opcode, comment)
                    | do_opcode _ = Crash.impossible"Bad tagged instruction"
                      
		  val (opcodes_and_offsets, next) =
		    Lists.number_from(opcode_list, block_start, 4, fn x => x)
d1366 14
a1379 7
		in
		  (rev_map do_opcode (opcodes_and_offsets, done), next)
		end
	      val (so_far, next) = do_block(start, block, done)
	    in
	      linearise_proc(next, block_list, so_far)
	    end
d1385 1
a1385 1
		  linearise_proc(offset, proc, [])
d1413 1
a1413 1
	  do_linearise_sub(0, proc_list(*Lists.zip(proc_list,padded_name_list)*))
@


1.176
log
@Remove module type to separate file
@
text
@d4 3
d1073 1
a1073 1
  exception bad_adr of
d1123 25
d1220 36
a1255 1
                     | Map.NO => Crash.impossible "Problem in _mach_cg.sml")
d1274 1
a1274 10
                                 (fn _ => ["Found bad ADR, substituting\n"])
                               fun drop(n, the_list) =
                                 if n < 0 then
                                   Crash.impossible"drop negative arg"
                                 else
                                   if n = 0 then the_list
                                   else
                                     case the_list of
                                       [] => Crash.impossible"drop bad list"
                                     | _ :: rest => drop(n-1, rest)
a1294 14
			       fun rev_app([], y) = y
				 | rev_app(x :: xs, y) = rev_app(xs, x :: y)

                               fun copy_n(n, from, acc) =
                                 if n < 0 then
                                   Crash.impossible"copy_n negative arg"
                                 else
                                   if n = 0 then
                                     rev_app(acc, new_tail)
                                   else
                                     case from of
                                       (x :: xs) =>
					 copy_n(n-1, xs, x :: acc)
                                     | _ => Crash.impossible"copy_n short list"
d1296 3
a1298 2
                               raise bad_adr(block_tag,
                                             copy_n(head_size, opcode_list, []))
d1322 23
a1344 1

d1394 1
a1394 1
	  fun subst_bad_adr_block(proc_list, block as (tag, opcode_list)) =
d1408 2
a1409 2
	  handle bad_adr bad_adr_block =>
	    do_linearise (subst_bad_adr_block(proc_list, bad_adr_block))
d3014 19
a3032 12
		     ([(Sparc_Assembly.Call
			(Sparc_Assembly.CALL, 2),
			absent, "Call self"),
		       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			(Sparc_Assembly.ADD, lookup_reg_operand reg_operand,
			 Sparc_Assembly.IMM 4, MachTypes.lr),
			Option.PRESENT tag, "Update gc pointer")],
		     opcode_list, block_list, final_result)
		 (* Note that lr points to the call instruction *)
		 (* Thus lr + 4, as computed by the ADD *)
		 (* points to the ADD instruction, which is fixed *)
		 (* up during linearisation *)
d3037 1
a3037 1

@


1.175
log
@Moved machspec into main
@
text
@d4 3
d619 1
d643 1
d677 1
a677 1
  type Module = MachTypes.Module
d838 1
a838 1
  fun value_cg(i, MirTypes.SCON (Ident.STRING x),_) = MachTypes.STRING(i, x)
d848 1
a848 1
	 MachTypes.REAL(i, encoding_function(sign, mantissa, exponent))
d856 1
a856 1
      MachTypes.MLVALUE (i,value)
d3918 1
a3918 1
	  (MachTypes.WORDSET(MachTypes.WORD_SET
d3930 1
a3930 1
                   MLWorks.Integer.makestring(Lists.reducel( fn(x,MachTypes.WORDSET(MachTypes.WORD_SET{2=tagged_code', ...})) =>
d3939 5
a3943 5
      val ext_elements = make_external_refs(MachTypes.EXTERNAL, ext_refs)
      val ext_vars = make_external_refs(MachTypes.VAR, vars)
      val ext_exns = make_external_refs(MachTypes.EXN, exns)
      val ext_strs = make_external_refs(MachTypes.STRUCT, strs)
      val ext_funs = make_external_refs(MachTypes.FUNCT, funs)
d3946 1
a3946 1
	MachTypes.MODULE(value_elements @@
@


1.174
log
@Debugger_info for some more debugger options.
@
text
@d4 3
d621 1
a621 1
require "machspec";
@


1.173
log
@Preventing generation of unnecessary debug information.
@
text
@d4 3
d1363 1
a1363 1
                      Options.COMPILEROPTIONS {debug, debug_polyvariables, opt_leaf_fns, ...},
d1440 2
a1441 5
                    ((*output(std_out,"\n name = "^name^"\n");*)
                     (fn value => (spill := Option.SOME2(value);value)) (symbolic_value i))
                | Option.SOME1(ref(Option.SOME2(i)),name) => 
                    ((*output(std_out,"\n name = "^name^"\n");*)
                     i)
d1465 2
a1466 4
                    ((*output(std_out,"\n name = "^name^"\n");*)
                     (fn value => (spill := Option.SOME2(value);value)) (symbolic_value i))
                | Option.SOME1(ref(Option.SOME2(i)),name) => ((*output(std_out,"\n name = "^name^"\n");*)
                     i)
d1472 3
a1474 5
                    ((*output(std_out,"\n name = "^name^"\n");*)
                     (fn value => (spill := Option.SOME2(value);value)) 
                            (~4 * (1 + non_gc_spill_size + i)))
                | Option.SOME1(ref(Option.SOME2(i)),name) => ((*output(std_out,"\n name = "^name^"\n");*)
                     i)
a2158 1
                    (*val _ = output(std_out,"\n MirTypes.STOREOP ... \n")*)
d2250 2
a2251 5
			    ([(((*output(std_out,"\n rd = "^MachTypes.reg_to_string rd^"  rs1 = "^MachTypes.reg_to_string rs1^(case reg_or_imm of
                                       Sparc_Assembly.IMM(n) => "imm = "^MLWorks.Integer.makestring n
| _ => "")^"\n");*)
                               Sparc_Assembly.LOAD_AND_STORE(store, rd, rs1,
							     reg_or_imm)), absent, "")],
a3427 1
          (*val _ = output(std_out,"\n proc_cg : "^procedure_name^"\n")*)
d3584 17
a3600 21
	    if debug orelse debug_polyvariables then
              let
                val Debugger_Types.INFO (i,_) = !debug_map
              in
                (case NewMap.tryApply' (i, procedure_name) of
                   NewMap.YES((a, b, c),_) =>
                     debug_map := 
                     ((*output(std_out,"\n map defined at "^procedure_name^"\n");*)
                     Debugger_Types.INFO (NewMap.define(i, 
                           procedure_name,((a,if needs_preserve then b
                                              else true,c),runtime_env)),debug_polyvariables))
                 | _ => 
                     debug_map := 
                     ((*output(std_out,"\n map defined at "^procedure_name^"\n");*)
                     Debugger_Types.INFO (NewMap.define(i, 
                           procedure_name,((Debugger_Types.null_type,false,nil),
                                           runtime_env)),debug_polyvariables)))
              end
	    else
	      ()

d3873 1
a3873 1
                              val Debugger_Types.INFO (i,b) = !debug_map
d3880 1
a3880 1
                                        ((ty,leaf,(count,debug)::annotations),runtime_env)),b)
@


1.172
log
@Dummy entry to keep in synch with Hope, after I accidentally checked in
an unchanged version to Hope.
@
text
@d4 4
d3593 21
a3613 17
            let
              val Debugger_Types.INFO (i,_) = !debug_map
            in
              (case NewMap.tryApply' (i, procedure_name) of
                 NewMap.YES((a, b, c),_) =>
                   debug_map := 
                   ((*output(std_out,"\n map defined at "^procedure_name^"\n");*)
                   Debugger_Types.INFO (NewMap.define(i, 
                         procedure_name,((a,if needs_preserve then b
                                            else true,c),runtime_env)),debug_polyvariables))
               | _ => 
                   debug_map := 
                   ((*output(std_out,"\n map defined at "^procedure_name^"\n");*)
                   Debugger_Types.INFO (NewMap.define(i, 
                         procedure_name,((Debugger_Types.null_type,false,nil),
                                         runtime_env)),debug_polyvariables)))
            end
@


1.171
log
@Added comment to FLOOR case.
@
text
@d4 3
@


1.170
log
@moved mach_cg to main/
@
text
@d4 6
d2425 3
a2427 1
                        (* Test for a possible overflow if the number is too big in magnitude *)
@


1.169
log
@Put in Simon's suggestions to use a common large number splitting
mechanism throughout, and spot the previously non-optimal case
@
text
@d4 4
d604 1
a604 1
require "mach_cg";
@


1.168
log
@Replaced TADDCC instruction with TADDCCTV, and removed explicit exception
handling from built-in arithmetic operators.
@
text
@d4 4
d1486 3
a1488 6
	  fun load_large_number_into_register (reg, num) =
	    let
	      val (high, low) =
		split_int(MirTypes.GP_IMM_ANY(num))
	    in
              if high = 0 then
d1491 1
a1491 1
                   Sparc_Assembly.IMM low, MachTypes.G0),
d1493 6
a1498 1
              else
d1500 5
a1504 1
                  (Sparc_Assembly.SETHI, reg, high),
d1508 1
a1508 1
                   Sparc_Assembly.IMM low, reg),
a1509 1
	    end
d1875 27
d1936 1
d2750 7
d2776 1
d2813 1
d2819 5
a2823 2
                                   absent, "Load large immediate size") ::
                                  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
d2858 1
a2858 1
                                      absent, "Tag object with primary") :: header_code)
d3068 4
d3089 1
d3175 2
a3176 1
			    load_large_number_into_register(MachTypes.O3,frame_size) @@
d3187 2
a3188 1
			    load_large_number_into_register(MachTypes.O3, frame_size) @@
@


1.167
log
@Added proper compilation of INTERRUPT instruction
@
text
@d4 3
d1637 1
a1637 1
			Sparc_Assembly.TADDCC
d1639 1
a1639 1
			Sparc_Assembly.TSUBCC
a1685 6
			      val new_tag = MirTypes.new_tag()
			      (* We're going to reverse the sense *)
			      (* of the overflow test, and rely on the *)
			      (* scheduler to fill delay slot. *)
			      (* This should shorten the normal *)
			      (* (non-overflow) path by one instruction *)
d1693 4
a1696 12
				 (opcode, rd, reg_or_imm, rs1), absent, ""),
				(Sparc_Assembly.BRANCH_ANNUL
				 (Sparc_Assembly.BVC, 0),
				 Option.PRESENT new_tag, "Do the branch on ok"),
				Sparc_Assembly.nop,
				(Sparc_Assembly.BRANCH_ANNUL
				 (Sparc_Assembly.BA, 0),
				 Option.PRESENT tag, "Else go to exception"),
				Sparc_Assembly.nop],
			      [],
			      MirTypes.BLOCK(new_tag, opcode_list) :: block_list,
			      final_result)
d1698 3
a1700 1
			  else
d1715 1
a1715 1
		      else
d2005 1
a2005 1
		    val (operation, test) =
d2007 24
a2030 12
                        of (MachTypes.single,   MirTypes.FADDV) => (Sparc_Assembly.FADDS, Sparc_Assembly.FCMPS)
                         | (MachTypes.single,   MirTypes.FSUBV) => (Sparc_Assembly.FSUBS, Sparc_Assembly.FCMPS)
                         | (MachTypes.single,   MirTypes.FMULV) => (Sparc_Assembly.FMULS, Sparc_Assembly.FCMPS)
                         | (MachTypes.single,   MirTypes.FDIVV) => (Sparc_Assembly.FDIVS, Sparc_Assembly.FCMPS)
                         | (MachTypes.double,   MirTypes.FADDV) => (Sparc_Assembly.FADDD, Sparc_Assembly.FCMPD)
                         | (MachTypes.double,   MirTypes.FSUBV) => (Sparc_Assembly.FSUBD, Sparc_Assembly.FCMPD)
                         | (MachTypes.double,   MirTypes.FMULV) => (Sparc_Assembly.FMULD, Sparc_Assembly.FCMPD)
                         | (MachTypes.double,   MirTypes.FDIVV) => (Sparc_Assembly.FDIVD, Sparc_Assembly.FCMPD)
                         | (MachTypes.extended, MirTypes.FADDV) => (Sparc_Assembly.FADDX, Sparc_Assembly.FCMPX)
                         | (MachTypes.extended, MirTypes.FSUBV) => (Sparc_Assembly.FSUBX, Sparc_Assembly.FCMPX)
                         | (MachTypes.extended, MirTypes.FMULV) => (Sparc_Assembly.FMULX, Sparc_Assembly.FCMPX)
                         | (MachTypes.extended, MirTypes.FDIVV) => (Sparc_Assembly.FDIVX, Sparc_Assembly.FCMPX)
d2032 3
a2034 5
		    ([(Sparc_Assembly.FBINARY(operation, rd, rs1, rs2), absent, ""),
                      (Sparc_Assembly.FUNARY(test, rd, rs1), absent, "Test validity of result"),
                      Sparc_Assembly.nop,
                      (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBU, 0), Option.PRESENT tag, "")],
                     opcode_list, block_list, final_result)
d2038 2
d2043 22
a2064 12
		      val (operation, test, extra_moves) =
			case (MachTypes.fp_used, tagged_unary_fp_op)
                          of (MachTypes.single,   MirTypes.FABSV)  => (Sparc_Assembly.FABS,   Sparc_Assembly.FCMPS, 0)
                           | (MachTypes.single,   MirTypes.FNEGV)  => (Sparc_Assembly.FNEG,   Sparc_Assembly.FCMPS, 0)
                           | (MachTypes.single,   MirTypes.FSQRTV) => (Sparc_Assembly.FSQRTS, Sparc_Assembly.FCMPS, 0)
                           | (MachTypes.double,   MirTypes.FABSV)  => (Sparc_Assembly.FABS,   Sparc_Assembly.FCMPD, 1)
                           | (MachTypes.double,   MirTypes.FNEGV)  => (Sparc_Assembly.FNEG,   Sparc_Assembly.FCMPD, 1)
                           | (MachTypes.double,   MirTypes.FSQRTV) => (Sparc_Assembly.FSQRTD, Sparc_Assembly.FCMPD, 0)
                           | (MachTypes.extended, MirTypes.FABSV)  => (Sparc_Assembly.FABS,   Sparc_Assembly.FCMPX, 3)
                           | (MachTypes.extended, MirTypes.FNEGV)  => (Sparc_Assembly.FNEG,   Sparc_Assembly.FCMPX, 3)
                           | (MachTypes.extended, MirTypes.FSQRTV) => (Sparc_Assembly.FSQRTX, Sparc_Assembly.FCMPX, 0)
                           | _ => Crash.impossible "Bad tagged unary FP generated"
d2066 8
a2073 8
                        | add_moves(rd, rs2, moves) =
                          let
                            val rd = MachTypes.next_reg rd
                            val rs2 = MachTypes.next_reg rs2
                          in
                            (Sparc_Assembly.FUNARY(Sparc_Assembly.FMOV, rd, rs2),
                             absent, "") :: add_moves(rd, rs2, moves - 1)
                          end
d2076 3
a2078 5
		      ((Sparc_Assembly.FUNARY(operation, rd, rs2), absent, "") ::
                       (Sparc_Assembly.FUNARY(test, rd, rs2), absent, "Test validity of result") ::
                       Sparc_Assembly.nop ::
                       (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBU, 0), Option.PRESENT tag, "") ::
                       extra_code, opcode_list, block_list, final_result)
@


1.166
log
@Added (currently trivial) code generation of INTERRUPT instruction
@
text
@d4 3
d648 3
a650 3
    [(Sparc_Assembly.other_nop_code,MirTypes.Option.ABSENT,"Dummy instructions for tracing"),
     (Sparc_Assembly.other_nop_code,MirTypes.Option.ABSENT,"Dummy instructions for tracing"),
     (Sparc_Assembly.other_nop_code,MirTypes.Option.ABSENT,"Dummy instructions for tracing")]
d823 1
a823 1
  type half_op = Sparc_Assembly.opcode * MirTypes.tag MirTypes.Option.opt
d827 1
a827 1
  val absent = MirTypes.Option.ABSENT
d854 1
a854 1
	  ((_, MirTypes.Option.PRESENT tag, _), true) => (tag, true)
d1036 1
a1036 1
  MirTypes.tag * (Sparc_Assembly.opcode * MirTypes.tag MirTypes.Option.opt * string) list
d1041 1
a1041 1
       (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BA, i), MirTypes.Option.PRESENT tag', comm),
d1044 1
a1044 1
       [(Sparc_Assembly.BRANCH(Sparc_Assembly.BA, i), MirTypes.Option.PRESENT tag', comm),
d1094 1
a1094 1
				 MirTypes.Option.PRESENT tag, comment), offset) =
d1108 1
a1108 1
			       MirTypes.Option.PRESENT tag, comment), offset) =
d1121 1
a1121 1
			       MirTypes.Option.PRESENT tag, comment), offset) =
d1134 1
a1134 1
			       MirTypes.Option.PRESENT tag, comment), offset) =
d1147 1
a1147 1
			       MirTypes.Option.PRESENT tag, comment), offset) =
d1161 1
a1161 1
			       MirTypes.Option.PRESENT tag, comment), offset) =
d1197 1
a1197 1
                                  MirTypes.Option.PRESENT tag, new_comment) ::
d1201 1
a1201 1
                                  MirTypes.Option.PRESENT tag, new_comment) ::
d1205 1
a1205 1
                                  MirTypes.Option.ABSENT, new_comment) :: tail
d1231 1
a1231 1
			       MirTypes.Option.PRESENT tag, comment), offset) =
d1248 1
a1248 1
			       MirTypes.Option.PRESENT tag, comment), offset) =
d1262 1
a1262 1
                    | do_opcode((opcode, MirTypes.Option.ABSENT, comment), offset) =
d1520 1
a1520 1
		    Sparc_Assembly.IMM offset), MirTypes.Option.ABSENT,
d1525 1
a1525 1
		    Sparc_Assembly.IMM offset), MirTypes.Option.ABSENT,
d1530 1
a1530 1
		    Sparc_Assembly.IMM offset), MirTypes.Option.ABSENT,
d1535 1
a1535 1
		    MachTypes.fp, Sparc_Assembly.IMM (offset+8)), MirTypes.Option.ABSENT,
d1545 1
a1545 1
		    Sparc_Assembly.IMM offset), MirTypes.Option.ABSENT,
d1551 1
a1551 1
		    Sparc_Assembly.IMM offset), MirTypes.Option.ABSENT,
d1557 1
a1557 1
		    Sparc_Assembly.IMM offset), MirTypes.Option.ABSENT,
d1562 1
a1562 1
		    MachTypes.fp, Sparc_Assembly.IMM (offset+8)), MirTypes.Option.ABSENT,
d1699 1
a1699 1
				 MirTypes.Option.PRESENT new_tag, "Do the branch on ok"),
d1703 1
a1703 1
				 MirTypes.Option.PRESENT tag, "Else go to exception"),
d2032 1
a2032 1
                      (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBU, 0), MirTypes.Option.PRESENT tag, "")],
d2066 1
a2066 1
                       (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBU, 0), MirTypes.Option.PRESENT tag, "") ::
d2070 1
a2070 1
				   MirTypes.Option.PRESENT offset) =>
d2392 1
a2392 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBG, 0), MirTypes.Option.PRESENT tag, ""),
d2398 1
a2398 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBL, 0), MirTypes.Option.PRESENT tag, ""),
d2405 1
a2405 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBGE, 6), MirTypes.Option.ABSENT, ""),
d2457 1
a2457 1
			  MirTypes.Option.PRESENT tag, "Branch relative"),
d2508 1
a2508 1
			   MirTypes.Option.PRESENT tag, "Do the branch"),
d2541 1
a2541 1
		       MirTypes.Option.PRESENT tag, "Do the branch"),
d2556 1
a2556 1
		      MirTypes.Option.PRESENT tag, "Call"),
d2580 1
a2580 1
			      MirTypes.Option.PRESENT tag, "Branch relative (tail call)")
d2594 1
a2594 1
				      MirTypes.Option.PRESENT tag, "Do the branch") ::
d2602 1
a2602 1
				      MirTypes.Option.PRESENT tag, "Do the branch") ::
d2628 1
a2628 1
			  (Sparc_Assembly.BA, 0), MirTypes.Option.PRESENT tag, ""))
d2632 1
a2632 1
					  MirTypes.Option.PRESENT fp_offset) =>
d2878 1
a2878 1
			MirTypes.Option.PRESENT tag, "Update gc pointer")],
d2893 46
a2938 2
		    ([], opcode_list, block_list, final_result)
		(* Not yet implemented fully *)
d2969 1
a2969 1
				MirTypes.Option.PRESENT end_tag,
d2993 1
a2993 1
				  MirTypes.Option.PRESENT top_tag,
d3041 1
a3041 1
				  MirTypes.Option.PRESENT top_tag,
d3051 1
a3051 1
				  MirTypes.Option.PRESENT end_tag, ""),
d3075 1
a3075 1
			    MirTypes.Option.PRESENT non_ov_tag,
d3080 1
a3080 1
			    MirTypes.Option.PRESENT ov_tag, ""),
d3115 1
a3115 1
			    MirTypes.Option.PRESENT non_ov_tag, ""),
d3169 1
a3169 1
				   MirTypes.Option.PRESENT join_tag, ""),
d3288 1
a3288 1
      fun exit_block [] = MirTypes.Option.ABSENT
d3293 1
a3293 1
	  then MirTypes.Option.PRESENT block
d3345 1
a3345 1
		   {leaf, registers_used = MirTypes.Option.PRESENT
d3355 2
a3356 2
	      MirTypes.Option.ABSENT => block_list
	    | MirTypes.Option.PRESENT exit_block =>
d3391 1
a3391 1
	    MirTypes.Option.PRESENT stack_extra => stack_extra
d3556 1
a3556 1
	      MirTypes.Option.PRESENT{gc = gc_spill_size,
d3660 1
a3660 1
			    MirTypes.Option.PRESENT tag =>
d3662 1
a3662 1
			  | MirTypes.Option.ABSENT => " no tag") ^
d3732 1
a3732 1
				 MirTypes.Option.PRESENT tag =>
d3734 1
a3734 1
			       | MirTypes.Option.ABSENT => " no tag") ^
@


1.165
log
@Merged in bug fixes
@
text
@d4 3
d2889 3
d3424 1
@


1.164
log
@Record compiler option debug_polyvariables in Debugger_Types.INFO
for recompilation purposes.
@
text
@d4 11
d799 14
a812 10
      let
        val the_real = Reals.evaluate_real x
        val (sign, mantissa, exponent) = Reals.find_real_components the_real
        val encoding_function = case MachTypes.fp_used of
          MachTypes.single => to_single_string (error_info,x,location)
        | MachTypes.double => to_double_string (error_info,x,location)
        | MachTypes.extended => to_extended_string (error_info,x,location)
      in
        MachTypes.REAL(i, encoding_function(sign, mantissa, exponent))
      end
@


1.163
log
@Modified leaf test to look at the actual registers used by a function
rather than believing the output from the mir optimiser
@
text
@d4 4
d1314 2
a1315 1
    (Options.OPTIONS {compiler_options = Options.COMPILEROPTIONS {debug, opt_leaf_fns, ...},
d3439 1
a3439 1
              val Debugger_Types.INFO i = !debug_map
d3447 1
a3447 1
                                            else true,c),runtime_env))))
d3452 2
a3453 1
                         procedure_name,((Debugger_Types.null_type,false,nil),runtime_env)))))
d3727 1
a3727 1
                              val Debugger_Types.INFO i = !debug_map
d3734 1
a3734 1
                                        ((ty,leaf,(count,debug)::annotations),runtime_env)))
@


1.163.1.1
log
@Fork for bug fixing
@
text
@a3 4
Revision 1.163  1993/08/26  13:19:57  jont
Modified leaf test to look at the actual registers used by a function
rather than believing the output from the mir optimiser

@


1.163.1.2
log
@Put a handler around the part of value_cg dealing with reals to turn
conversion errors into compilation errors
@
text
@a3 3
Revision 1.163.1.1  1993/08/26  13:19:57  jont
Fork for bug fixing

d788 10
a797 14
      (let
	 val the_real = Reals.evaluate_real x
	 val (sign, mantissa, exponent) = Reals.find_real_components the_real
	 val encoding_function = case MachTypes.fp_used of
	   MachTypes.single => to_single_string (error_info,x,location)
	 | MachTypes.double => to_double_string (error_info,x,location)
	 | MachTypes.extended => to_extended_string (error_info,x,location)
       in
	 MachTypes.REAL(i, encoding_function(sign, mantissa, exponent))
       end handle MLWorks.Internal.StringToReal =>
	 Info.error' 
	 error_info
	 (Info.FATAL, location, "Real number too big : " ^ x)
      )
@


1.162
log
@Fixed extended-float save and restore.
@
text
@d4 3
d3310 1
d3316 95
d3412 1
d3414 3
d3418 6
d3430 1
a3430 1
            Lists.exists check_instr_block block_list
d3432 1
a3432 1
          val _ = 
a3478 1
	  val stack_opt = stack_allocated
a3488 3
	  val stack_extra = case stack_opt of
	    MirTypes.Option.PRESENT stack_extra => stack_extra
	  | _ =>  Crash.impossible"Stack size missing to mach_cg"
@


1.161
log
@Made NEW_HANDLER instruction force non-leaf.
@
text
@d4 3
d1506 1
a1506 1
		    MachTypes.fp, Sparc_Assembly.IMM offset), MirTypes.Option.ABSENT,
d1533 1
a1533 1
		    MachTypes.fp, Sparc_Assembly.IMM offset), MirTypes.Option.ABSENT,
@


1.160
log
@Debugger Environments and extra stack spills for local and closure
variable inspection in the debugger;
structure Option.
@
text
@d4 5
d3296 1
@


1.159
log
@Fixed code generation of large integers to avoid stamping on other operands
by using G4 only when safe and using the result register otherwise.
@
text
@d4 4
d584 1
d587 5
a591 1
  sharing type Sparc_Schedule.Sparc_Assembly.Sparc_Opcodes.MachTypes.Sparc_Reg = MachSpec.register
d605 2
d616 3
a618 3
    [(Sparc_Assembly.other_nop_code,MirTypes.ABSENT,"Dummy instructions for tracing"),
     (Sparc_Assembly.other_nop_code,MirTypes.ABSENT,"Dummy instructions for tracing"),
     (Sparc_Assembly.other_nop_code,MirTypes.ABSENT,"Dummy instructions for tracing")]
d787 1
a787 1
  type half_op = Sparc_Assembly.opcode * MirTypes.tag MirTypes.Opt
d791 1
a791 1
  val absent = MirTypes.ABSENT
d818 1
a818 1
	  ((_, MirTypes.PRESENT tag, _), true) => (tag, true)
d1000 1
a1000 1
  MirTypes.tag * (Sparc_Assembly.opcode * MirTypes.tag MirTypes.Opt * string) list
d1005 1
a1005 1
       (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BA, i), MirTypes.PRESENT tag', comm),
d1008 1
a1008 1
       [(Sparc_Assembly.BRANCH(Sparc_Assembly.BA, i), MirTypes.PRESENT tag', comm),
d1058 1
a1058 1
				 MirTypes.PRESENT tag, comment), offset) =
d1072 1
a1072 1
			       MirTypes.PRESENT tag, comment), offset) =
d1085 1
a1085 1
			       MirTypes.PRESENT tag, comment), offset) =
d1098 1
a1098 1
			       MirTypes.PRESENT tag, comment), offset) =
d1111 1
a1111 1
			       MirTypes.PRESENT tag, comment), offset) =
d1125 1
a1125 1
			       MirTypes.PRESENT tag, comment), offset) =
d1161 1
a1161 1
                                  MirTypes.PRESENT tag, new_comment) ::
d1165 1
a1165 1
                                  MirTypes.PRESENT tag, new_comment) ::
d1169 1
a1169 1
                                  MirTypes.ABSENT, new_comment) :: tail
d1195 1
a1195 1
			       MirTypes.PRESENT tag, comment), offset) =
d1212 1
a1212 1
			       MirTypes.PRESENT tag, comment), offset) =
d1226 1
a1226 1
                    | do_opcode((opcode, MirTypes.ABSENT, comment), offset) =
d1358 61
a1418 29
	    | symbolic_value MirTypes.NON_GC_SPILL_SIZE =
	      non_gc_stack_size
	    | symbolic_value(MirTypes.GC_SPILL_SLOT i) =
	      (if i >= gc_spill_size then
		 Crash.impossible
		 ("Spill slot " ^ MLWorks.Integer.makestring i ^
		  " requested, but only " ^ MLWorks.Integer.makestring gc_spill_size ^
		  " allocated\n")
	       else
		 ();
		 ~(non_gc_stack_size + 4 * (1 + i))
		 )
	    | symbolic_value(MirTypes.NON_GC_SPILL_SLOT i) =
	      let
		val offset = if needs_fp_spare then 1 else 0
	      in
		(if i >= non_gc_spill_size then
		   Crash.impossible
		   ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
		    " requested, but only " ^
		    MLWorks.Integer.makestring non_gc_spill_size ^
		    " allocated\n")
		 else
		   ();
		   ~4 * (1 + offset + i)
		   )
	      end
	    | symbolic_value(MirTypes.FP_SPILL_SLOT i) =
	      ~4 * (1 + non_gc_spill_size + i)
d1483 1
a1483 1
		    Sparc_Assembly.IMM offset), MirTypes.ABSENT,
d1488 1
a1488 1
		    Sparc_Assembly.IMM offset), MirTypes.ABSENT,
d1493 1
a1493 1
		    Sparc_Assembly.IMM offset), MirTypes.ABSENT,
d1498 1
a1498 1
		    MachTypes.fp, Sparc_Assembly.IMM offset), MirTypes.ABSENT,
d1508 1
a1508 1
		    Sparc_Assembly.IMM offset), MirTypes.ABSENT,
d1514 1
a1514 1
		    Sparc_Assembly.IMM offset), MirTypes.ABSENT,
d1520 1
a1520 1
		    Sparc_Assembly.IMM offset), MirTypes.ABSENT,
d1525 1
a1525 1
		    MachTypes.fp, Sparc_Assembly.IMM offset), MirTypes.ABSENT,
d1662 1
a1662 1
				 MirTypes.PRESENT new_tag, "Do the branch on ok"),
d1666 1
a1666 1
				 MirTypes.PRESENT tag, "Else go to exception"),
d1995 1
a1995 1
                      (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBU, 0), MirTypes.PRESENT tag, "")],
d2029 1
a2029 1
                       (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBU, 0), MirTypes.PRESENT tag, "") ::
d2033 1
a2033 1
				   MirTypes.PRESENT offset) =>
d2061 1
d2153 5
a2157 3
			    ([(Sparc_Assembly.LOAD_AND_STORE(store, rd, rs1,
							     reg_or_imm),
			       absent, "")],
d2355 1
a2355 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBG, 0), MirTypes.PRESENT tag, ""),
d2361 1
a2361 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBL, 0), MirTypes.PRESENT tag, ""),
d2368 1
a2368 1
                        (Sparc_Assembly.FBRANCH(Sparc_Assembly.FBGE, 6), MirTypes.ABSENT, ""),
d2420 1
a2420 1
			  MirTypes.PRESENT tag, "Branch relative"),
d2471 1
a2471 1
			   MirTypes.PRESENT tag, "Do the branch"),
d2504 1
a2504 1
		       MirTypes.PRESENT tag, "Do the branch"),
d2519 1
a2519 1
		      MirTypes.PRESENT tag, "Call"),
d2543 1
a2543 1
			      MirTypes.PRESENT tag, "Branch relative (tail call)")
d2557 1
a2557 1
				      MirTypes.PRESENT tag, "Do the branch") ::
d2565 1
a2565 1
				      MirTypes.PRESENT tag, "Do the branch") ::
d2591 1
a2591 1
			  (Sparc_Assembly.BA, 0), MirTypes.PRESENT tag, ""))
d2595 1
a2595 1
					  MirTypes.PRESENT fp_offset) =>
d2841 1
a2841 1
			MirTypes.PRESENT tag, "Update gc pointer")],
d2885 1
a2885 1
				MirTypes.PRESENT end_tag,
d2909 1
a2909 1
				  MirTypes.PRESENT top_tag,
d2957 1
a2957 1
				  MirTypes.PRESENT top_tag,
d2967 1
a2967 1
				  MirTypes.PRESENT end_tag, ""),
d2991 1
a2991 1
			    MirTypes.PRESENT non_ov_tag,
d2996 1
a2996 1
			    MirTypes.PRESENT ov_tag, ""),
d3031 1
a3031 1
			    MirTypes.PRESENT non_ov_tag, ""),
d3085 1
a3085 1
				   MirTypes.PRESENT join_tag, ""),
d3204 1
a3204 1
      fun exit_block [] = MirTypes.ABSENT
d3209 1
a3209 1
	  then MirTypes.PRESENT block
d3261 1
a3261 1
		   {leaf, registers_used = MirTypes.PRESENT
d3264 1
a3264 1
		   block_list)) =
d3266 1
d3271 2
a3272 2
	      MirTypes.ABSENT => block_list
	    | MirTypes.PRESENT exit_block =>
d3314 17
a3330 10
          val _ = if needs_preserve then ()
                  else
                    let
                      val Debugger_Types.INFO i = !debug_map
                    in
                      (case NewMap.tryApply' (i, procedure_name) of
                         NewMap.YES(a, _, c) =>
                           debug_map := Debugger_Types.INFO (NewMap.define(i, procedure_name,(a,true,c)))
                       | _ => ())
                    end
d3364 1
a3364 1
	      MirTypes.PRESENT{gc = gc_spill_size,
d3373 1
a3373 1
	    MirTypes.PRESENT stack_extra => stack_extra
d3471 1
a3471 1
			    MirTypes.PRESENT tag =>
d3473 1
a3473 1
			  | MirTypes.ABSENT => " no tag") ^
d3490 3
a3492 3
	  val code_list = map #1 temp_code_list
	  val code_list = map remove_redundant_loads_from_proc code_list
	  val spill_size_list = map #2 temp_code_list
a3493 1
          val padded_name_list = map #4 temp_code_list
d3543 1
a3543 1
				 MirTypes.PRESENT tag =>
d3545 1
a3545 1
			       | MirTypes.ABSENT => " no tag") ^
d3585 54
a3638 53
	     (fn (((tag, code),spills),padded_name) =>
	      (Lists.assoc(tag, loc_refs),
	       spills,
	       let
		 fun annotation_points ([],_,res) = rev res
		   | annotation_points ((inst,_)::t,count,res) =
		     (case inst of 
			Sparc_Assembly.JUMP_AND_LINK (_,_,_,_,Debugger_Types.Nop) => ()        
		      | Sparc_Assembly.JUMP_AND_LINK (_,_,_,_,debug) =>        
			  let
			    val unpadded_name =
			      let
				val s = size padded_name
				fun check_index to =
				  if String.ordof(padded_name,to) = 0 
				    then check_index(to-1)
				  else String.substring(padded_name,0,to+1)
			      in
				check_index (s-1) 
				handle String.Substring => ""
				     | Ord => ""
			      end
			    val Debugger_Types.INFO i = !debug_map
			  in
			    case NewMap.tryApply'(i, unpadded_name) of
			      NewMap.YES(ty,leaf,annotations) =>
				debug_map :=
				Debugger_Types.INFO
				(NewMap.define(i, unpadded_name, (ty,leaf,(count,debug)::annotations)))
			    | _ => ()
			  end
		      | _ => ();
			  annotation_points(t,count+4,
					    Sparc_Opcodes.output_opcode(Sparc_Assembly.assemble inst)::res))
                          
		 val code =
		   if debug then
		     implode (annotation_points (code,0,[]))
		   else 
		     implode
		     (map
		      (fn (x, _) =>
		       Sparc_Opcodes.output_opcode(Sparc_Assembly.assemble x))
		      code)

		 val padded_code =
		   if size code mod 8 = 4
		     then code ^ nop_instruction
		   else code
	       in
		 padded_code
	       end))
	     (Lists.zip(Lists.zip(linear_code,spill_size_list),padded_name_list)))
@


1.158
log
@Modified the TBINARY operations to shorten the normal (non-exceptional) path
@
text
@d4 3
d1631 2
d1711 28
a1738 8
		      ([],
		       MirTypes.UNARY(MirTypes.MOVE,
				      MirTypes.GC_REG MirRegisters.global,
				      gp_operand) ::
		       MirTypes.BINARY(binary_op, reg_operand,
				       MirTypes.GP_GC_REG MirRegisters.global,
				       gp_operand') ::
		       opcode_list, block_list, final_result)
d1759 28
a1786 10
			    ([],
			     MirTypes.UNARY(MirTypes.MOVE,
					    MirTypes.GC_REG
					    MirRegisters.global,
					    gp_operand') ::
			     MirTypes.BINARY(binary_op, reg_operand,
					     gp_operand,
					     MirTypes.GP_GC_REG
					     MirRegisters.global) ::
			     opcode_list, block_list, final_result)
@


1.157
log
@Removed integer parameter
@
text
@d4 3
d1598 1
d1600 6
d1615 6
a1620 2
				 (Sparc_Assembly.BVS, 0),
				 MirTypes.PRESENT tag, "Do the branch"),
d1622 3
a1624 1
			      opcode_list, block_list, final_result)
@


1.156
log
@Improved coding of MirTypes.ENTRY so that simple stack requiring procedures
have a one instruction shorter entry sequence
@
text
@d4 4
a539 1
require "../utils/integer";
a560 1
  structure Integer : INTEGER
d644 1
a644 1
		 Integer.makestring i,
d646 1
a646 1
		 Integer.makestring pos_limit]);
d670 1
a670 1
		     Integer.makestring l)
d1018 1
a1018 1
	     (fn (x, y) => Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ Integer.makestring y ^ "\n"))
d1346 2
a1347 2
		 ("Spill slot " ^ Integer.makestring i ^
		  " requested, but only " ^ Integer.makestring gc_spill_size ^
d1359 1
a1359 1
		   ("non gc spill slot " ^ Integer.makestring i ^
d1361 1
a1361 1
		    Integer.makestring non_gc_spill_size ^
d1491 1
a1491 1
			     Integer.makestring(Lists.length fps_to_preserve) ^
d1940 1
a1940 1
				       Integer.makestring offset ^
d1942 1
a1942 1
				       Integer.makestring
d2494 1
a2494 1
				      Integer.makestring alloc_size ^
d2496 1
a2496 1
				      Integer.makestring fp_offset ^
d2498 1
a2498 1
				      Integer.makestring
d2791 1
a2791 1
			       Integer.makestring end_limit)
d3543 1
a3543 1
                   Integer.makestring(Lists.reducel( fn(x,MachTypes.WORDSET(MachTypes.WORD_SET{2=tagged_code', ...})) =>
@


1.155
log
@Changed PROFILE instruction to INTERCEPT.
@
text
@d4 3
d1335 2
a1336 2
	  fun gc_area_start_offset _ =
	    ~(non_gc_stack_size + 4)
d2879 36
a2914 7

			val offset_from_bottom_of_stack_buffer = 2048
			(* yeh advised number *)

			val immediate_size = check_range(frame_size + offset_from_bottom_of_stack_buffer, 
							 true, arith_imm_limit)

d2916 22
a2937 41
			  (if immediate_size
			     then []
			   else
			     load_large_number_into_register (MachTypes.O2,frame_size) @@
			     [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			       (Sparc_Assembly.ADD, MachTypes.O3,
				Sparc_Assembly.IMM (offset_from_bottom_of_stack_buffer) , MachTypes.O2),
			       absent, "Add in extra buffering amount at stack base")]) @@
			     [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			       (Sparc_Assembly.SUB, MachTypes.global, 
				if immediate_size 
				  then Sparc_Assembly.IMM(frame_size + offset_from_bottom_of_stack_buffer) 
				else Sparc_Assembly.REG MachTypes.O3, 
				  MachTypes.sp), 
			       absent, "Check the stack for underflow"),
			     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			      (Sparc_Assembly.SUBCC, MachTypes.G0, 
			       Sparc_Assembly.REG(MachTypes.global), MachTypes.stack_limit), 
			      absent, "Compare the required stack size with the calculated"),
			     (Sparc_Assembly.BRANCH_ANNUL
			      (Sparc_Assembly.BCS, 0),
			      MirTypes.PRESENT non_ov_tag,
			      "Unsigned stack overflow test"),
			     Sparc_Assembly.nop,
			     (Sparc_Assembly.BRANCH_ANNUL
			      (Sparc_Assembly.BA, 0),
			      MirTypes.PRESENT ov_tag, ""),
			     Sparc_Assembly.nop]

			val ov_tag_code =
			  (if immediate_size
			     then [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				    (Sparc_Assembly.OR, MachTypes.O3, 
				     Sparc_Assembly.IMM(frame_size + offset_from_bottom_of_stack_buffer),
				     MachTypes.G0), 
				    absent, "Set the required size in O3")]			       
			   else []) @@
			     [(Sparc_Assembly.LOAD_AND_STORE
			       (Sparc_Assembly.LD, MachTypes.global,
				MachTypes.implicit, Sparc_Assembly.IMM (4 * Implicit_Vector.extend)),
			       absent, "Get address of stack_overflow"),
d2942 11
a2952 9
			      absent, "Do stack_overflow"),
			     Sparc_Assembly.nop] @@
			     (if immediate_size
				then []
			      else load_large_number_into_register (MachTypes.O2,frame_size)) @@
				[(Sparc_Assembly.BRANCH_ANNUL
				  (Sparc_Assembly.BA, 0),
				  MirTypes.PRESENT non_ov_tag, ""),
				 Sparc_Assembly.nop]
d2966 2
a2967 2
				  (Sparc_Assembly.SUB, MachTypes.O2, 
				   Sparc_Assembly.REG(MachTypes.O2), MachTypes.G0), 
d2973 1
a2973 1
				   else Sparc_Assembly.REG MachTypes.O2,
@


1.154
log
@Added leaf raise code
@
text
@d4 3
d1277 1
a1277 1
    (Options.OPTIONS {compiler_options = Options.COMPILEROPTIONS {trace, debug, opt_leaf_fns, ...},
d2742 1
a2742 1
                | MirTypes.PROFILER reg =>
@


1.153
log
@Added some important comments about adr
@
text
@d4 3
d3020 1
a3020 1
			     Sparc_Assembly.IMM (4 * Implicit_Vector.raise_code)),
d3022 1
d3032 1
d3034 1
a3034 1
			   (Sparc_Assembly.JMPL, MachTypes.lr,
d3041 1
a3041 1
			    MachTypes.after_preserve (lookup_reg_operand reg)),
d3043 1
d3046 1
@


1.152
log
@OLD_HANDLER now generates handler chain pop
@
text
@d4 3
d2732 4
d3159 3
@


1.151
log
@Changed bytearray implementation to use ref tags. Tidied up some
explicit integers into references to TAGS
@
text
@d4 4
d2982 5
a2986 1
		    ([], opcode_list, block_list, final_result)
@


1.150
log
@Produced leaf and code vector intercept offset for each procedure
and added this into WORDSET
@
text
@d4 4
d2491 1
a2491 1
					 4 * (fp_offset + alloc_size) - 1)) ::
d2519 1
a2519 1
                                         (8, 1, true, 0)
d2521 5
a2525 2
                                         (8 * ((size+2) div 2), 5, size mod 2 <> 0, 64*size+2)
                                     | MirTypes.ALLOC_STRING => (((size+12) div 8) * 8, 5, true, 64*size+10)
d2530 9
a2538 3
                                           | MachTypes.double   => (16, 5, true, 64*(16 - 4) +26))
                                     | MirTypes.ALLOC_REF  => (8 + 8*((size+2) div 2), 3, size mod 2 <> 0, 64*size+18)
                                     | MirTypes.ALLOC_BYTEARRAY => (((size+12) div 8) * 8, 5, true, 64*size+26)
d2649 1
a2649 1
                                         (3, 18,
d2654 1
a2654 1
                                         (5, 26,
@


1.149
log
@Signature revisions
@
text
@d4 3
d34 1
a34 1
Changed the type of nop used for tracing to store it being moved by the scheduler
d593 5
a597 5
  | contract_sexpr(Sexpr.NIL, x :: xs, acc) = contract_sexpr(x, xs, acc)
  | contract_sexpr(Sexpr.ATOM x, to_do, acc) =
    contract_sexpr(Sexpr.NIL, to_do, x :: acc)
  | contract_sexpr(Sexpr.CONS(x, y), to_do, acc) =
    contract_sexpr(x, y :: to_do, acc)
d602 9
d1319 29
a1347 29
	  | symbolic_value MirTypes.NON_GC_SPILL_SIZE =
	    non_gc_stack_size
	  | symbolic_value(MirTypes.GC_SPILL_SLOT i) =
	    (if i >= gc_spill_size then
	       Crash.impossible
	       ("Spill slot " ^ Integer.makestring i ^
		" requested, but only " ^ Integer.makestring gc_spill_size ^
		" allocated\n")
	     else
	       ();
	    ~(non_gc_stack_size + 4 * (1 + i))
	       )
	  | symbolic_value(MirTypes.NON_GC_SPILL_SLOT i) =
	    let
	      val offset = if needs_fp_spare then 1 else 0
	    in
	    (if i >= non_gc_spill_size then
	       Crash.impossible
	       ("non gc spill slot " ^ Integer.makestring i ^
		" requested, but only " ^
		Integer.makestring non_gc_spill_size ^
		" allocated\n")
	     else
	       ();
	      ~4 * (1 + offset + i)
	       )
	    end
	  | symbolic_value(MirTypes.FP_SPILL_SLOT i) =
	    ~4 * (1 + non_gc_spill_size + i)
d1351 6
a1356 6
	  | gp_check_range(MirTypes.GP_IMM_ANY i, signed, pos_limit) =
	    check_range(i, signed, pos_limit)
	  | gp_check_range(MirTypes.GP_IMM_SYMB symb, signed, pos_limit) =
	    check_range(symbolic_value symb, signed, pos_limit)
	  | gp_check_range _ =
	    Crash.impossible"gp_check_range of non-immediate" 
d1361 1
a1361 6
	  | split_int(MirTypes.GP_IMM_ANY i) =
	    (((i div 4096) mod (256 * 256 * 16))*4, i mod 4096)
	  | split_int(MirTypes.GP_IMM_SYMB symb) =
	    let
	      val i = symbolic_value symb
	    in
d1363 7
a1369 2
	    end
	  | split_int _ = Crash.impossible"split_int of non-immediate" 
d1393 5
a1397 5
	  | make_imm_format3(MirTypes.GP_IMM_ANY i) =
	    make_imm_fault(i, true, arith_imm_limit)
	  | make_imm_format3(MirTypes.GP_IMM_SYMB symb) =
	    make_imm_fault(symbolic_value symb, true, arith_imm_limit)
	  | make_imm_format3 _ = Crash.impossible"make_imm of non-immediate"
d1401 4
a1404 4
	  | make_imm_for_store(MirTypes.GP_IMM_SYMB symb) =
	    make_imm_fault(symbolic_value symb, true, arith_imm_limit)
	  | make_imm_for_store _ =
	    Crash.impossible"make_imm_for_store(bad value)"
d2711 1
d2713 1
a2713 137
		    ([], opcode_list, block_list, final_result)
(*
                    let
                      val temp = lookup_reg_operand reg
                      val after_profiling = MirTypes.new_tag()
                      val register_tag = MirTypes.new_tag()
                      val increment_tag = MirTypes.new_tag()
		      val call_profiler =
			if needs_preserve then
			  [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.OR, MachTypes.global,
			     Sparc_Assembly.REG MachTypes.G0,
			     MachTypes.callee_closure),
			    absent,"Save closure register"),
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.OR, temp,
			     Sparc_Assembly.REG MachTypes.G0,
			     MachTypes.caller_arg),
			    absent,"Save present caller_arg"),
			   (Sparc_Assembly.SAVE_AND_RESTORE
			    (Sparc_Assembly.SAVE, MachTypes.sp,
			     Sparc_Assembly.IMM ~64, MachTypes.sp),
			    absent, "Create new frame in non-leaf case"),
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.OR, MachTypes.caller_arg,
			     Sparc_Assembly.REG MachTypes.G0,
			     MachTypes.global),
			    absent,"Procedure argument"),
			   (Sparc_Assembly.LOAD_AND_STORE
			    (Sparc_Assembly.LD, MachTypes.global,
			     MachTypes.implicit,
			     Sparc_Assembly.IMM (4 * Implicit_Vector.profiler)),
			    absent, "Get address of profiler"),
			   (Sparc_Assembly.JUMP_AND_LINK
			    (Sparc_Assembly.JMPL, MachTypes.lr,
			     Sparc_Assembly.IMM 0, MachTypes.global,
                             Debugger_Types.null_backend_annotation),
			    absent, "Do profiling"),
			   Sparc_Assembly.nop,
			   (Sparc_Assembly.SAVE_AND_RESTORE
			    (Sparc_Assembly.RESTORE, MachTypes.G0,
			     Sparc_Assembly.IMM 0, MachTypes.sp),
			    absent, ""),
			   (Sparc_Assembly.BRANCH
			    (Sparc_Assembly.BA, 0),
			    MirTypes.PRESENT after_profiling,
			    "Jump to rest of block after profiling"),
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.OR, MachTypes.caller_arg,
			     Sparc_Assembly.REG MachTypes.G0,
			     temp),
			    absent,"Preserve present caller_arg")]
			else
			  [(Sparc_Assembly.LOAD_AND_STORE
			    (Sparc_Assembly.LD, MachTypes.global,
			     MachTypes.implicit,
			     Sparc_Assembly.IMM (4 * Implicit_Vector.profiler)),
			    absent, "Get address of profiler"),
			  (Sparc_Assembly.SAVE_AND_RESTORE
			   (Sparc_Assembly.SAVE, MachTypes.sp,
			    Sparc_Assembly.IMM ~64, MachTypes.sp),
			    absent, "Create new frame in leaf case"),
			   (Sparc_Assembly.JUMP_AND_LINK
			    (Sparc_Assembly.JMPL, MachTypes.lr,
			     Sparc_Assembly.IMM 0, MachTypes.global,
                             Debugger_Types.null_backend_annotation),
			    absent, "Do profiling"),
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.OR,MachTypes.caller_arg,
			     Sparc_Assembly.REG MachTypes.G0,
			     MachTypes.callee_closure),
			    absent,""),
			   (Sparc_Assembly.BRANCH
			    (Sparc_Assembly.BA, 0),
			    MirTypes.PRESENT after_profiling,
			    "Jump to rest of block after profiling"),
			   (Sparc_Assembly.SAVE_AND_RESTORE
			    (Sparc_Assembly.RESTORE, MachTypes.G0,
			     Sparc_Assembly.IMM 0, MachTypes.sp),
			    absent, "restore in delay slot")]
                    in
		      ((Sparc_Assembly.LOAD_AND_STORE
			(Sparc_Assembly.LD,temp,
			 if needs_preserve then
			   MachTypes.callee_closure
			 else
			   MachTypes.caller_closure,
			   Sparc_Assembly.IMM ~1),
			absent,"Get code vector pointer") ::
		       (Sparc_Assembly.LOAD_AND_STORE
			(Sparc_Assembly.LD,temp,temp,Sparc_Assembly.IMM 3),
			absent,"Get the existing call count field") ::
		       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			(Sparc_Assembly.ANDCC, MachTypes.G0,
			 Sparc_Assembly.IMM 3, temp),
			absent, "Is the field raw ?") ::
		       (Sparc_Assembly.BRANCH_ANNUL
			(Sparc_Assembly.BNE, 0),
			MirTypes.PRESENT after_profiling,
			"continue if not counting") ::
		       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			(Sparc_Assembly.OR, temp,
			 Sparc_Assembly.REG MachTypes.G0,
			 MachTypes.G0),
			absent, "Clear the raw value (delay slot)") ::
		       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			(Sparc_Assembly.SUBCC, MachTypes.G0,
			 Sparc_Assembly.IMM 0, temp),
			absent, "Is the address unset (call c if so) ?") ::
		       (Sparc_Assembly.BRANCH_ANNUL
			(Sparc_Assembly.BNE, 0),
			MirTypes.PRESENT increment_tag,
			"") ::
		       (Sparc_Assembly.LOAD_AND_STORE
			(Sparc_Assembly.LD, MachSpec.global, temp,
			 Sparc_Assembly.IMM 0),
			absent,"present value") ::
		       call_profiler,
		     [],
                     MirTypes.BLOCK(after_profiling, opcode_list) ::
		     block_list, 
                     (increment_tag,
                      [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                        (Sparc_Assembly.ADD, MachSpec.global,
			 Sparc_Assembly.IMM 1,MachSpec.global),
                        absent,""),
		      (Sparc_Assembly.LOAD_AND_STORE
		       (Sparc_Assembly.ST, MachSpec.global, temp,
			Sparc_Assembly.IMM 0),
		       absent,""),
		      (Sparc_Assembly.BRANCH_ANNUL
		       (Sparc_Assembly.BA, 0),
		       MirTypes.PRESENT after_profiling,
		       "Jump to rest of block after profiling"),
		      Sparc_Assembly.nop]) :: final_result)
                    end
*)
d2715 124
a2838 125
		 | MirTypes.ENTER =>
		     if needs_preserve then
		       let
			 val top_tag = MirTypes.new_tag()
			 val end_tag = MirTypes.new_tag()
			 fun do_store(_, _, 0, done) = done
			   | do_store(reg, offset, 1, done) =
			     (Sparc_Assembly.LOAD_AND_STORE
					 (Sparc_Assembly.ST, MachTypes.G0,
					  reg,
					  Sparc_Assembly.IMM offset), absent,
					 "Initialise a stack slot") :: done
			   | do_store(reg, offset, n, done) =
			     if n < 0 then Crash.impossible"Do_store"
			     else
				do_store(reg, offset+8, n-2,
					(Sparc_Assembly.LOAD_AND_STORE
					 (Sparc_Assembly.STD, MachTypes.G0,
					  reg,
					  Sparc_Assembly.IMM offset), absent,
					 "Initialise two stack slots") :: done)
			 (* revised version of n_stores running off sp *)
			 fun n_stores no_of_stores =
			   (* Assumes area to be cleared immediately *)
			   (* above register save area *)
			   let
			     val
			       end_limit = 64 + (no_of_stores-1)*4
			     val end_instrs =
			       [(Sparc_Assembly.BRANCH_ANNUL
				 (Sparc_Assembly.BA, 0),
				 MirTypes.PRESENT end_tag,
				 "Finish cleaning stack"),
				Sparc_Assembly.nop]
			   in
			     if check_range(end_limit, true,
					    arith_imm_limit) then
			       do_store(MachTypes.sp, 64, no_of_stores,
					end_instrs)
			     else
			       Crash.impossible
			       ("n_stores end_limit = " ^
				Integer.makestring end_limit)
			   end
			 val (clean_stack, opcodes, block) =
			   if gc_stack_size div 4 <= 10 then
			     (false,
			      n_stores((*gc_area_start_offset(),*)
				       gc_stack_size div 4),
			      (top_tag, []))
			   else
			     let
			       val branch_out =
				 [(Sparc_Assembly.BRANCH_ANNUL
				   (Sparc_Assembly.BA, 0),
				   MirTypes.PRESENT top_tag,
				   "")]
			       val load_limit =
				 let
				   val the_limit =
				     if gc_stack_size mod 8 = 0 then
				       gc_stack_size
				     else
				       gc_stack_size+4
				 in
				   if check_range(the_limit, true,
						  arith_imm_limit) then
				     move_imm(MachTypes.global,
					      the_limit) :: branch_out
				   else
				     let
				       val (high, low) =
					 split_int(MirTypes.GP_IMM_ANY
						   the_limit)
				     in
				       (Sparc_Assembly.SetHI
					(Sparc_Assembly.SETHI,
					 MachTypes.global, high),
					absent, "Get high part") ::
				       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					(Sparc_Assembly.ADD,
					 MachTypes.global,
					 Sparc_Assembly.IMM low,
					 MachTypes.global),
					absent, "Add in low of limit") ::
				       branch_out
				     end
				 end
			       val load_start =
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, MachTypes.I2,
				   Sparc_Assembly.IMM 64,
				   MachTypes.sp), absent,
				  "") ::
				 load_limit
			       val store_loop =
				 [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				   (Sparc_Assembly.SUBCC, MachTypes.global,
				    Sparc_Assembly.IMM 8,
				    MachTypes.global),
				   absent, "Update counter"),
				  (Sparc_Assembly.BRANCH_ANNUL
				   (Sparc_Assembly.BGE, 0),
				   MirTypes.PRESENT top_tag,
				   "Branch if not finished"),
				  (Sparc_Assembly.LOAD_AND_STORE
				   (Sparc_Assembly.STD, MachTypes.G0,
				    MachTypes.global,
				    Sparc_Assembly.REG MachTypes.I2),
				   absent,
				   "Initialise a stack slot (delay slot)"),
				  (Sparc_Assembly.BRANCH_ANNUL
				   (Sparc_Assembly.BA, 0),
				   MirTypes.PRESENT end_tag, ""),
				  Sparc_Assembly.nop]
			     in
			       (true, load_start, (top_tag, store_loop))
			     end
			 val (opcode_list, block_list, final_result) =
			   if clean_stack then
			     ([],
			      (MirTypes.BLOCK(end_tag, opcode_list)) ::
			      block_list,
			      block :: final_result)
			   else (opcode_list, block_list, final_result)
d2840 3
a2842 3
			 val ov_tag = MirTypes.new_tag()  (* Overflow case *)
			 val non_ov_tag = MirTypes.new_tag()
			 (* Non overflow case *)
d2844 2
a2845 2
			 val join_tag = MirTypes.new_tag()
			 val final_result = (join_tag, opcodes) :: final_result
d2847 2
a2848 2
			 val offset_from_bottom_of_stack_buffer = 2048
			 (* yeh advised number *)
d2850 2
a2851 2
			 val immediate_size = check_range(frame_size + offset_from_bottom_of_stack_buffer, 
							  true, arith_imm_limit)
d2853 11
a2863 11
			 val check_for_stack_overflow_wrap =
			   (if immediate_size
			      then []
			    else
			      load_large_number_into_register (MachTypes.O2,frame_size) @@
			      [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, MachTypes.O3,
				 Sparc_Assembly.IMM (offset_from_bottom_of_stack_buffer) , MachTypes.O2),
				absent, "Add in extra buffering amount at stack base")]) @@
			      [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.SUB, MachTypes.global, 
d2883 2
a2884 2
			 val ov_tag_code =
			   (if immediate_size
d2890 41
a2930 14
			    else []) @@
			      [(Sparc_Assembly.LOAD_AND_STORE
				(Sparc_Assembly.LD, MachTypes.global,
				 MachTypes.implicit, Sparc_Assembly.IMM (4 * Implicit_Vector.extend)),
				absent, "Get address of stack_overflow"),
			      (Sparc_Assembly.JUMP_AND_LINK
			       (Sparc_Assembly.JMPL, MachTypes.O4,
				Sparc_Assembly.IMM 0, MachTypes.global,
                                Debugger_Types.null_backend_annotation),
			       absent, "Do stack_overflow"),
			      Sparc_Assembly.nop] @@
			      (if immediate_size
				 then []
			       else load_large_number_into_register (MachTypes.O2,frame_size)) @@
d2933 79
a3011 111
				   MirTypes.PRESENT non_ov_tag, ""),
				  Sparc_Assembly.nop]
		       in
 			 ((if trace
                             then trace_dummy_instructions
                           else []) 
                             @@ check_for_stack_overflow_wrap,
                             [],
                             (case opcode_list of
                                [] => block_list
                              | _ => 
                                  MirTypes.BLOCK(end_tag,opcode_list) ::
			       block_list),
			     (non_ov_tag,
			      (if immediate_size
				 then []
			       else 
				 [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				   (Sparc_Assembly.SUB, MachTypes.O2, 
				    Sparc_Assembly.REG(MachTypes.O2), MachTypes.G0), 
				   absent, "Negate the frame size")]) @@
				 ((Sparc_Assembly.SAVE_AND_RESTORE
				   (Sparc_Assembly.SAVE, MachTypes.sp,
				    if immediate_size
				      then Sparc_Assembly.IMM(~frame_size)
				    else Sparc_Assembly.REG MachTypes.O2,
				      MachTypes.sp), absent, "New frame") ::
				 (save_fps @@
				  [(Sparc_Assembly.BRANCH_ANNUL
				  (Sparc_Assembly.BA, 0),
				  MirTypes.PRESENT join_tag, ""),
				 Sparc_Assembly.nop]))) ::
			     (ov_tag,ov_tag_code)  ::
			     final_result)
		       end
		     else
 		       (if trace
                          then trace_dummy_instructions
                        else [], opcode_list, block_list, final_result)

		 | MirTypes.RTS =>
		     (if needs_preserve then
			restore_fps @@
			[(Sparc_Assembly.JUMP_AND_LINK
			  (Sparc_Assembly.JMPL, MachTypes.G0,
			   Sparc_Assembly.IMM 8,
			   MachTypes.after_preserve MachTypes.lr,
                           Debugger_Types.null_backend_annotation),
			  absent, "Scheduled return"),
			 (Sparc_Assembly.SAVE_AND_RESTORE
			  (Sparc_Assembly.RESTORE, MachTypes.G0,
			   Sparc_Assembly.IMM 0,
			   MachTypes.sp), absent, "Restore in the delay slot")]
		      else
			[(Sparc_Assembly.JUMP_AND_LINK
			  (Sparc_Assembly.JMPL, MachTypes.G0,
			   Sparc_Assembly.IMM 8, MachTypes.lr,
                           Debugger_Types.null_backend_annotation),
			  absent, "Ordinary return"),
			 Sparc_Assembly.nop],
			opcode_list, block_list, final_result)
		 | MirTypes.NEW_HANDLER tag =>
		     ([], opcode_list, block_list, final_result)
		 | MirTypes.OLD_HANDLER =>
		  ([], opcode_list, block_list, final_result)
		 | MirTypes.RAISE reg =>
		     let
		       val code =
			 if needs_preserve then
			   [(Sparc_Assembly.LOAD_AND_STORE
			     (Sparc_Assembly.LD, MachTypes.global,
			      MachTypes.implicit,
			      Sparc_Assembly.IMM (4 * Implicit_Vector.raise_code)),
			     absent, "Do all the work of getting to the handler"),
			   (Sparc_Assembly.JUMP_AND_LINK
			    (Sparc_Assembly.JMPL, MachTypes.lr,
			     Sparc_Assembly.REG MachTypes.global, MachTypes.G0,
                             Debugger_Types.null_backend_annotation),
			    absent, "Raise"),
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.OR, MachTypes.caller_arg,
			     Sparc_Assembly.REG MachTypes.G0,
			     lookup_reg_operand reg),
                            absent, "Move arg to raise into arg reg")]
			 else
			   [(Sparc_Assembly.LOAD_AND_STORE
			     (Sparc_Assembly.LD, MachTypes.global,
			      MachTypes.implicit,
			      Sparc_Assembly.IMM (4 * Implicit_Vector.raise_code)),
			     absent, "Do all the work of getting to the handler"),
			   (Sparc_Assembly.SAVE_AND_RESTORE
			    (Sparc_Assembly.SAVE, MachTypes.sp,
			     Sparc_Assembly.IMM ~64, MachTypes.sp),
			    absent, "Create new frame for raise"),
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.OR, MachTypes.caller_closure,
			     Sparc_Assembly.REG MachTypes.G0,
			     MachTypes.G0),
			    absent, "Clear caller closure for gc"),
			   (Sparc_Assembly.JUMP_AND_LINK
			    (Sparc_Assembly.JMPL, MachTypes.lr,
			     Sparc_Assembly.REG MachTypes.global, MachTypes.G0,
                             Debugger_Types.null_backend_annotation),
			    absent, "Raise"),
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.OR, MachTypes.caller_arg,
			     Sparc_Assembly.REG MachTypes.G0,
			     MachTypes.after_preserve (lookup_reg_operand reg)),
			    absent,"Move arg to raise into arg reg")]
                           handle MachTypes.OutOfScope r =>
                             Crash.impossible ("Raise parameter was in " ^ MachSpec.print_register r ^ " in a leaf procedure")
d3014 3
a3016 3
		     end
		 | MirTypes.COMMENT string =>
		     Crash.impossible"MirTypes.COMMENT not filtered out"
d3018 1
a3018 1
		     ([], opcode_list, block_list, final_result)
d3020 10
a3029 10
		 | MirTypes.CALL_C =>
		     ([(Sparc_Assembly.LOAD_AND_STORE
			(Sparc_Assembly.LD, MachTypes.global,
			 MachTypes.implicit, Sparc_Assembly.IMM (4 * Implicit_Vector.external)),
			absent, "Get address of callc"),
		       (Sparc_Assembly.JUMP_AND_LINK
			(Sparc_Assembly.JMPL, MachTypes.lr,
			 Sparc_Assembly.IMM 0, MachTypes.global,Debugger_Types.null_backend_annotation),
			absent, "Do call_c"), Sparc_Assembly.nop],
		     opcode_list, block_list, final_result)
d3230 1
d3232 1
a3232 1
	    move_first([], do_blocks(needs_preserve orelse needs_fp_spare,
d3261 2
a3262 1
           padded_name)
d3264 1
a3264 1
      | proc_cg _ = Crash.impossible "mach_cg.proc_cg"
d3324 1
d3406 1
d3415 34
a3448 34
	       (fn (((tag, code),spills),padded_name) =>
		(Lists.assoc(tag, loc_refs),
		 spills,
		 let
                   fun annotation_points ([],_,res) = rev res
                     | annotation_points ((inst,_)::t,count,res) =
                       (case inst of 
                          Sparc_Assembly.JUMP_AND_LINK (_,_,_,_,Debugger_Types.Nop) => ()        
                        | Sparc_Assembly.JUMP_AND_LINK (_,_,_,_,debug) =>        
                            let
                              val unpadded_name =
                                let
                                  val s = size padded_name
                                  fun check_index to =
                                    if String.ordof(padded_name,to) = 0 
                                      then check_index(to-1)
                                    else String.substring(padded_name,0,to+1)
                                in
                                  check_index (s-1) 
                                  handle String.Substring => ""
                                       | Ord => ""
                                end
                              val Debugger_Types.INFO i = !debug_map
			     in
			       case NewMap.tryApply'(i, unpadded_name) of
				 NewMap.YES(ty,leaf,annotations) =>
				   debug_map :=
                                     Debugger_Types.INFO
                                     (NewMap.define(i, unpadded_name, (ty,leaf,(count,debug)::annotations)))
			       | _ => ()
                            end
                        | _ => ();
                            annotation_points(t,count+4,
                                              Sparc_Opcodes.output_opcode(Sparc_Assembly.assemble inst)::res))
d3450 19
a3468 9
                   val code = 
                     if debug
                       then implode (annotation_points (code,0,[]))
                     else 
                       implode
                       (map
                        (fn (x, _) =>
                         Sparc_Opcodes.output_opcode(Sparc_Assembly.assemble x))
                        code)
a3469 10
                   val padded_code =
                     if size code mod 8 = 4
                       then code ^ nop_instruction
                     else code
		 in
                   padded_code
		 end))
	       (Lists.zip(Lists.zip(linear_code,spill_size_list),padded_name_list)))
	      handle Lists.Assoc => Crash.impossible"Assoc tagged_code"

d3471 1
a3471 1

d3473 3
a3475 1
	  (MachTypes.WORDSET(MachTypes.WORD_SET(procedure_name_list, tagged_code')),
d3485 1
a3485 1
                   Integer.makestring(Lists.reducel( fn(x,MachTypes.WORDSET(MachTypes.WORD_SET(_, tagged_code'))) =>
@


1.148
log
@Options & Info changes
@
text
@d4 3
d516 1
d538 1
d546 1
a546 1
  sharing Info.Location = MirTables.MirTypes.Debugger_Types.Datatypes.Ident.Location
d549 2
a560 1
  structure Datatypes = Debugger_Types.Datatypes
d562 1
a562 1
  structure Ident = Datatypes.Ident
d566 1
d568 2
a1245 2
  structure NewMap = Datatypes.NewMap
 
d1248 2
a1249 1
    (Options.COMPILEROPTIONS {trace, debug, opt_leaf_fns, ...},
@


1.147
log
@Changed value datatype
Added MLVALUEs
@
text
@d4 4
a515 1
require "../mir/__mirprint";
d530 1
a539 1
  structure Info : INFO
a541 1
  sharing Info = MirTables.MirTypes.Debugger_Types.Info
d543 1
a543 3
  sharing MirTables.MirTypes =
    MirRegisters.MirTypes =
    Sparc_Schedule.Sparc_Assembly.MirTypes
a544 1
  sharing type MirPrint_.MirTypes.opcode = MirRegisters.MirTypes.opcode
d559 2
d654 1
a654 1
  fun adjust (info,x,location) (mantissa, exponent, max_exponent, bits) =
d664 1
a664 1
          info
d712 1
a712 1
    | value_cg(i, MirTypes.SCON (Ident.REAL(x,location)),info) =
d717 3
a719 3
          MachTypes.single => to_single_string (info,x,location)
        | MachTypes.double => to_double_string (info,x,location)
        | MachTypes.extended => to_extended_string (info,x,location)
d1239 15
a1253 15
  fun mach_cg info_opts
	      (MirTypes.OPTIONS {trace, debug, opt_leaf_fns, ...},
               MirTypes.CODE(MirTypes.REFS(loc_refs,
                                           {requires = ext_refs,
                                            vars = vars,
                                            exns = exns,
                                            strs = strs,
                                            funs = funs}),
               value_list,
	       proc_list_list
	      ),
	      (gc_map,
	       non_gc_map,
	       fp_map),
              debugging_map) =
d1280 1
a1280 1
	 value_cg(Lists.assoc(tag, loc_refs), x,info_opts))
@


1.146
log
@Changes for code vector reform.
@
text
@d4 3
d710 15
a724 13
  fun value_cg(i, Ident.STRING x,_) = MachTypes.STRING(i, x)
  | value_cg(i, Ident.REAL(x,location),info) =
    let
      val the_real = Reals.evaluate_real x
      val (sign, mantissa, exponent) = Reals.find_real_components the_real
      val encoding_function = case MachTypes.fp_used of
	MachTypes.single => to_single_string (info,x,location)
      | MachTypes.double => to_double_string (info,x,location)
      | MachTypes.extended => to_extended_string (info,x,location)
    in
      MachTypes.REAL(i, encoding_function(sign, mantissa, exponent))
    end
  | value_cg(_, Ident.INT _,_) = Crash.impossible"VALUE(INT)"
@


1.145
log
@Improved code generation of switches. Improved code generation of
sequences near calls and tails to allow better scheduling
@
text
@d4 4
d511 1
d519 15
a533 14
   structure Print : PRINT
   structure Timer : TIMER
   structure Lists : LISTS
   structure Crash : CRASH
   structure Integer : INTEGER
   structure Sexpr : SEXPR
   structure Reals : REALS
   structure MirTables : MIRTABLES
   structure MirRegisters : MIRREGISTERS
   structure MachSpec : MACHSPEC
   structure Sparc_Schedule : SPARC_SCHEDULE
   structure Implicit_Vector : IMPLICIT_VECTOR
   structure Diagnostic : DIAGNOSTIC
   structure Info : INFO
d535 8
a542 8
   sharing Info.Location = MirTables.MirTypes.Debugger_Types.Datatypes.Ident.Location
   sharing Info = MirTables.MirTypes.Debugger_Types.Info
   sharing MirTables.MirTypes.Set = MachSpec.Set
   sharing MirTables.MirTypes =
     MirRegisters.MirTypes =
     Sparc_Schedule.Sparc_Assembly.MirTypes
   sharing type Sparc_Schedule.Sparc_Assembly.Sparc_Opcodes.MachTypes.Sparc_Reg = MachSpec.register
   sharing type MirPrint_.MirTypes.opcode = MirRegisters.MirTypes.opcode
d912 2
a913 6
  fun tag_offsets_for_list(_, [], [], env) = env
    | tag_offsets_for_list(_, _::_, [], env) =
      Crash.impossible "Not as many names as procedures in the set"
    | tag_offsets_for_list(_, [], _::_, env) =
      Crash.impossible "Not as many procedures as names in the set"
    | tag_offsets_for_list(offset, (_, proc) :: rest, current_proc_padded_name::other_procs, env) =
d916 1
d922 3
d930 1
a930 1
	tag_offsets_for_list(next_offset'', rest, other_procs, env)
d949 1
a949 1
  fun linearise_list proc_list padded_name_list =
d960 1
a960 1
      fun do_linearise proc_list padded_name_list =
d963 1
a963 2
	  val tag_env = tag_offsets_for_list(0, proc_list, padded_name_list,
					     Map.empty (*(MirTypes.order_tag,MirTypes.equal_tag)*))
d1176 5
a1180 4
	  | do_linearise_sub(offset, ((tag, proc),padded_name) :: rest) =
	    let
	      val (offset', done') =
		linearise_proc(offset, proc, [])
d1183 3
d1190 3
a1192 3
	    in
	      (tag, done') :: do_linearise_sub(offset''', rest)
	    end
d1207 1
a1207 1
	  do_linearise_sub(0, Lists.zip(proc_list,padded_name_list))
d1209 1
a1209 1
	    do_linearise (subst_bad_adr_block(proc_list, bad_adr_block)) padded_name_list
d1212 1
a1212 1
      do_linearise new_proc_list padded_name_list
d2358 1
a2358 1
		       Sparc_Assembly.IMM 11, lookup_reg_operand reg_operand,
d2385 1
a2385 1
			       Sparc_Assembly.IMM 11, lookup_reg_operand reg,
d2389 2
a2390 3
			     (Sparc_Assembly.BRANCH(Sparc_Assembly.BA,
							  0),
			      MirTypes.PRESENT tag, "Branch relative")
d2686 2
d2822 1
d3516 1
a3516 1
	     fn () => linearise_list new_code_list' padded_name_list)
a3570 2
                   fun generate_nulls 0 = ""
                     | generate_nulls n = chr(0) ^ generate_nulls (n-1)
d3572 1
a3572 1
                     if (size code + size padded_name ) mod 8 = 4
a3574 3
                   fun generate_offset (x,0) = ""
                     | generate_offset (x,n) =
                       generate_offset(x div 256,n-1) ^ chr(x mod 256)
d3576 1
a3576 4
		   generate_nulls 4 ^ (* call count *)
                   generate_offset (11 + size padded_code,4) ^ (* offset to debug information *)
                   padded_code ^
                   padded_name
d3584 2
a3585 2
	  (MachTypes.WORDSET(MachTypes.WORD_SET tagged_code'),
	   Lists.zip(linear_code',procedure_name_list))
a3589 17
(*
      fun has_delay(Sparc_Assembly.BRANCH _) = true
	| has_delay(Sparc_Assembly.BRANCH_ANNUL _) = true
	| has_delay(Sparc_Assembly.FBRANCH _) = true
	| has_delay(Sparc_Assembly.FBRANCH_ANNUL _) = true
	| has_delay(Sparc_Assembly.Call _) = true
	| has_delay(Sparc_Assembly.JUMP_AND_LINK _) = true
	| has_delay _ = false

      fun count_delays(n, []) = n
	| count_delays(n, [_]) = n
	| count_delays(n, (x, _) :: (ys as ((y, _) :: xs))) =
	  if has_delay x andalso y = Sparc_Assembly.nop_code then
	    count_delays(n+1, xs)
	  else
	    count_delays(n, ys)

a3590 19
	Lists.iterate
	(fn code_list =>
	 Lists.iterate
	 (fn ((tag, code), name) =>
	  let
	    val nops = count_delays(0, code)
	  in
	    if nops <> 0 then
	      output(std_out, "Found " ^ Integer.makestring nops ^
		     (case nops of 1 => " nop" | _ => " nops") ^
			" in final code for " ^ name ^ "\n")
	    else
	      ()
	  end)
	 code_list)
	code_list
*)

      val _ =
d3594 1
a3594 1
                   Integer.makestring(Lists.reducel( fn(x,MachTypes.WORDSET(MachTypes.WORD_SET tagged_code')) =>
@


1.144
log
@Modified to return final machine code in an easily printed form
@
text
@d4 3
d505 1
d536 1
d723 1
a723 1
    | last_opcode [elem as (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
d727 1
a727 1
    | last_opcode([(Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
d729 1
a729 1
                   elem as (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
d735 1
a735 1
  | last_opcode([elem as (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
d762 4
a765 4
      val new_opc = case rev_opc of
	(Sparc_Assembly.BRANCH_ANNUL _, _, _) :: rest => rest
	| (operation, opt, comment) ::
	  (Sparc_Assembly.BRANCH _, _, _) :: rest =>
d767 3
a769 4
	  | _ :: (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
		  _, _) :: rest => rest
	  | _ =>
	      Crash.impossible"Remove trailing branch fails"
d820 1
a820 1
	make_proc_info((Map.empty (*(MirTypes.order_tag,MirTypes.equal_tag)*), Map.empty (*(MirTypes.order_tag,MirTypes.equal_tag)*)), block_list)
a829 5
(*
	    case proc_info_map block_tag of
	      Map.YES res => res
	    | _ => (block_tag, false)
*)
d900 4
a903 2
  fun linearise_list proc_list padded_name_list =
    let
a904 4
      fun tag_offsets([], offset, tag_env) = (offset, tag_env)
      | tag_offsets((tag, ho_list) :: rest, disp, tag_env) =
	tag_offsets(rest, disp + 4 * (Lists.length ho_list),
		    Map.define (tag_env, tag, disp))
d906 20
a925 17
      fun tag_offsets_for_list(_, [], [], env) = env
        | tag_offsets_for_list(_, _::_, [], env) = Crash.impossible "Not as many names as procedures in the set"
        | tag_offsets_for_list(_, [], _::_, env) = Crash.impossible "Not as many procedures as names in the set"
        | tag_offsets_for_list(offset, (_, proc) :: rest, current_proc_padded_name::other_procs, env) =
	let
	  val (next_offset, env) = tag_offsets(proc, offset, env)
	    (* CT added the following instead of next_offset+4 *)
          val next_offset' = next_offset + 4 (* raw spill count *) + 4 (* Back-pointer *)
                                         + 4 (* profiler information *) + 4 (* offset to dbug information *)
                                         + (size current_proc_padded_name) (* debug information *)
	  val next_offset'' =
	    if next_offset' mod 8 = 4
	      then next_offset'+4
	    else next_offset'
	in
	  tag_offsets_for_list(next_offset'', rest, other_procs, env)
	end
d927 18
d950 4
a953 2
      exception bad_adr of MirTypes.tag * (Sparc_Assembly.opcode * MirTypes.tag MirTypes.Opt * string) list
	
d1099 4
a1102 1
                               fun copy_n(n, from) =
d1107 1
a1107 1
                                     new_tail
d1110 2
a1111 1
                                       (x :: xs) => x :: copy_n(n-1, xs)
d1115 1
a1115 1
                                             copy_n(head_size, opcode_list))
d1443 3
d1454 1
a1454 1
	    (needs_preserve, tag', opcodes, Sexpr.NIL, blocks,
d1548 1
a1548 1
				 (Sparc_Assembly.BVSA, 0),
d1899 2
a1900 2
		| MirTypes.STOREOP(store_op, reg_operand, reg_operand',
				   gp_operand) =>
d1902 68
a1969 9
		    val rd = lookup_reg_operand reg_operand
		    val rs1 = lookup_reg_operand reg_operand'
		    val store = case store_op of
		      MirTypes.LD => Sparc_Assembly.LD
		    | MirTypes.ST => Sparc_Assembly.ST
		    | MirTypes.LDB => Sparc_Assembly.LDUB
		    | MirTypes.STB => Sparc_Assembly.STB
		    | MirTypes.LDREF => Sparc_Assembly.LD
		    | MirTypes.STREF => Sparc_Assembly.ST
d1971 3
a1973 2
		    if is_reg gp_operand orelse
		      gp_check_range(gp_operand, true, arith_imm_limit) then
d1975 9
a1983 4
			val reg_or_imm =
			  if is_reg gp_operand then
			    Sparc_Assembly.REG(lookup_gp_operand gp_operand)
			  else make_imm_for_store gp_operand
d1985 23
a2007 4
			([(Sparc_Assembly.LOAD_AND_STORE(store, rd, rs1,
							 reg_or_imm),
			   absent, "")],
			 opcode_list, block_list, final_result)
a2008 10
		    else
		      ([],
		       MirTypes.UNARY(MirTypes.MOVE,
				      MirTypes.GC_REG MirRegisters.global,
				      gp_operand) ::
		       MirTypes.STOREOP(store_op, reg_operand,
					reg_operand',
					MirTypes.GP_GC_REG
					MirRegisters.global) ::
		       opcode_list, block_list, final_result)
d2257 1
a2257 1
			[(Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, 0),
d2265 12
a2276 12
		      MirTypes.BNT => Sparc_Assembly.BEA
		    | MirTypes.BTA => Sparc_Assembly.BNEA
		    | MirTypes.BEQ => Sparc_Assembly.BEA
		    | MirTypes.BNE => Sparc_Assembly.BNEA
		    | MirTypes.BHI => Sparc_Assembly.BGUA
		    | MirTypes.BLS => Sparc_Assembly.BLEUA
		    | MirTypes.BHS => Sparc_Assembly.BCCA
		    | MirTypes.BLO => Sparc_Assembly.BCSA
		    | MirTypes.BGT => Sparc_Assembly.BGA
		    | MirTypes.BLE => Sparc_Assembly.BLEA
		    | MirTypes.BGE => Sparc_Assembly.BGEA
		    | MirTypes.BLT => Sparc_Assembly.BLA
d2283 1
a2283 1
		      | _ => (Sparc_Assembly.reverse_branch_annul branch,
d2327 4
a2330 4
		      MirTypes.FBEQ => Sparc_Assembly.FBEA
		    | MirTypes.FBNE => Sparc_Assembly.FBNEA
		    | MirTypes.FBLE => Sparc_Assembly.FBLEA
		    | MirTypes.FBLT => Sparc_Assembly.FBLA
d2403 1
a2403 1
				      (Sparc_Assembly.BAA, 0),
a2414 1
			Sparc_Assembly.nop ::
d2417 1
a2417 1
			  Sparc_Assembly.IMM(5*4),
d2430 1
a2430 1
			  (Sparc_Assembly.BAA, 0), MirTypes.PRESENT tag, ""))
d2525 1
a2525 1
                                   (Sparc_Assembly.BLA, 6),
d2563 1
a2563 1
                                   (Sparc_Assembly.BLA, 5),
d2626 1
a2626 1
                                     (Sparc_Assembly.BLA, 5),
d2773 1
a2773 1
			(Sparc_Assembly.BNEA, 0),
d2786 1
a2786 1
			(Sparc_Assembly.BNEA, 0),
d2807 1
a2807 1
		       (Sparc_Assembly.BAA, 0),
d2843 1
a2843 1
				 (Sparc_Assembly.BAA, 0),
d2867 1
a2867 1
				   (Sparc_Assembly.BAA, 0),
d2915 1
a2915 1
				   (Sparc_Assembly.BGEA, 0),
d2925 1
a2925 1
				   (Sparc_Assembly.BAA, 0),
d2973 1
a2973 1
			      (Sparc_Assembly.BCSA, 0),
d2978 1
a2978 1
			      (Sparc_Assembly.BAA, 0),
d3004 1
a3004 1
				   (Sparc_Assembly.BAA, 0),
d3034 1
a3034 1
				  (Sparc_Assembly.BAA, 0),
d3120 2
d3123 1
d3142 2
a3143 1
	  do_everything(needs_preserve, tag, opcodes, Sexpr.NIL, rest, [])
d3368 5
a3372 5
      fun remove_redundant_loads [] = []
	| remove_redundant_loads(arg as [x]) = arg
	| remove_redundant_loads((ins1 as (Sparc_Assembly.LOAD_AND_STORE
					   (Sparc_Assembly.ST, rd1, rs11, rs12),
					   tag1, comment1)) ::
d3379 1
a3379 1
	     remove_redundant_loads(ins1 :: rest))
d3381 2
a3382 2
	    ins1 :: ins2 :: remove_redundant_loads rest
	| remove_redundant_loads(x :: rest) = x :: remove_redundant_loads rest
d3384 2
a3508 18
(*
	  fun print_code((tag, code),name) =
	      (Print.print ("[Sparc_Assembly Code]" ^ " for " ^ name ^ "\n");
	       map
	       (fn (x,y) => Print.print
		(Sparc_Assembly.print x ^
		 (if size y = 0 then "" else " ; " ^ y) ^ "\n"))
	       code)

	  val _ =
	    diagnostic_output 3
	    (fn _ => 
	     ((Print.print"Alternative code\n";
	       map print_code 
               (Lists.zip(linear_code',procedure_name_list)));
	      []))
*)

d3587 37
a3623 1
      val _ = 
@


1.143
log
@Fixed small bugs in arithmetic of two immediates
@
text
@d4 3
a501 1
require "../mir/mirprint";
a518 1
   structure MirPrint : MIRPRINT
d528 1
a528 1
   sharing MirTables.MirTypes = MirPrint.MirTypes =
a1216 8
(*
      val _ =
	Print.print("#gc registers used = " ^ Integer.makestring gc ^ "\n")
      val _ =
	Print.print("#non_gc registers used = " ^ Integer.makestring non_gc ^ "\n")
      val _ =
	Print.print("#fp registers used = " ^ Integer.makestring fp ^ "\n")
*)
a3320 8
	  val _ = diagnostic_output 3
	    (fn _ => ["Unscheduled code without save alteration\n"])

	  val _ = diagnostic_output 3
	    (fn _ => (map print_unscheduled_code 
                      (Lists.zip(code_list,procedure_name_list));
		      []))

d3324 1
a3324 1
	    (fn _ => ["Unscheduled code with save alteration\n"])
d3384 1
a3384 1
	  val _ = diagnostic_output 3 (fn _ => (["Rescheduling save/restore shuffled code\n"]))
d3391 1
a3391 1
	  val _ = diagnostic_output 3 (fn _ => ["Rescheduled code with save/restore shuffling\n"])
d3403 1
d3415 1
a3415 1
	     ((Print.print"Alternative code with save/restore shuffling\n";
d3419 1
d3493 2
a3494 1
	  MachTypes.WORDSET(MachTypes.WORD_SET tagged_code')
d3497 1
a3497 1
      val proc_elements = map list_proc_cg proc_list_list
d3527 1
a3527 1
     (module, !debug_map)
@


1.142
log
@Changed int and real scons to carry a location around
@
text
@d4 3
d1481 5
a1485 4
		    fun needs_reverse MirTypes.SUBV = true
		    | needs_reverse MirTypes.DIVV = true
		    | needs_reverse MirTypes.MODV = true
		    | needs_reverse _ = false
d1490 10
a1499 4
			if needs_reverse tagged_binary_op andalso
			  is_reg gp_operand' then
			  (gp_operand, gp_operand', true)
			else (gp_operand', gp_operand, false)
d1588 1
d1597 1
d1602 9
a1610 3
			if needs_reverse opcode then
			  (gp_operand, gp_operand', true)
			else (gp_operand', gp_operand, false)
@


1.141
log
@Raised Info.errors for overflow of constants during code generation
@
text
@d4 3
d521 1
d635 1
a635 1
  fun adjust (info,x) (mantissa, exponent, max_exponent, bits) =
d646 1
a646 1
          (Info.FATAL,Info.Location.UNKNOWN,
d693 1
a693 1
  | value_cg(i, Ident.REAL x,info) =
d698 3
a700 3
	MachTypes.single => to_single_string (info,x)
      | MachTypes.double => to_double_string (info,x)
      | MachTypes.extended => to_extended_string (info,x)
@


1.140
log
@Changed the type of nop used for tracing to store it being moved by the scheduler
@
text
@d4 3
d518 1
d631 1
a631 1
  fun adjust(mantissa, exponent, max_exponent, bits) =
d640 4
a643 1
	  raise(Reals.too_big)
d649 1
a649 1
  fun to_single_string(sign, mantissa, exponent) =
d652 1
a652 1
      val (mantissa, real_exponent) = adjust(mantissa, real_exponent, 255, 23)
d661 1
a661 1
  fun to_double_string(sign, mantissa, exponent) =
d664 1
a664 1
      val (mantissa, real_exponent) = adjust(mantissa, real_exponent, 2047, 52)
d673 1
a673 1
  fun to_extended_string(sign, mantissa, exponent) =
d677 1
a677 1
	adjust(mantissa, real_exponent, 32767, 63)
d688 2
a689 2
  fun value_cg(i, Ident.STRING x) = MachTypes.STRING(i, x)
  | value_cg(i, Ident.REAL x) =
d694 3
a696 3
	MachTypes.single => to_single_string
      | MachTypes.double => to_double_string
      | MachTypes.extended => to_extended_string
d700 1
a700 1
  | value_cg(_, Ident.INT _) = Crash.impossible"VALUE(INT)"
d1241 1
a1241 1
	 value_cg(Lists.assoc(tag, loc_refs), x))
@


1.139
log
@Changed the sense of the branch in the stack-overflow checking code
@
text
@d4 3
d538 3
a540 3
    [(Sparc_Assembly.nop_code,MirTypes.ABSENT,"Dummy instructions for tracing"),
     (Sparc_Assembly.nop_code,MirTypes.ABSENT,"Dummy instructions for tracing"),
     (Sparc_Assembly.nop_code,MirTypes.ABSENT,"Dummy instructions for tracing")]
@


1.138
log
@Changes to propagate compiler options as parameters instead of references.
@
text
@d4 3
d569 1
a569 1
      (diagnostic_output 1
d1395 2
d1402 1
d1524 1
a1524 1
			(diagnostic_output 1
d2848 2
a2849 2
			      (Sparc_Assembly.BCCA, 0),
			      MirTypes.PRESENT ov_tag,
d2854 1
a2854 1
			      MirTypes.PRESENT non_ov_tag, ""),
d3138 1
a3138 1
	      diagnostic_output 1
d3296 1
a3296 1
	  val _ = diagnostic_output 1 
d3306 1
a3306 1
	  val _ = diagnostic_output 1 
d3327 1
a3327 1
	      val _ = diagnostic_output 1 (fn _ => ["Rescheduled at block level, now doing proc level\n"])
d3367 1
a3367 1
	  val _ = diagnostic_output 1 (fn _ => (["Rescheduling save/restore shuffled code\n"]))
d3377 1
a3377 1
	  val _ = diagnostic_output 1 (fn _ => ["Linearising\n"])
d3384 1
a3384 1
	  val _ = diagnostic_output 1 (fn _ => ["Linearised\n"])
d3395 1
a3395 1
	    diagnostic_output 2
@


1.137
log
@Replaced a call to Print.print with one to Diagnostic.output.
@
text
@d4 3
a529 2
  val force_non_leaf = ref false
  val generate_tracing = ref false
a537 2
  val do_fall_through = ref true
  val show_mach = ref true
d1180 2
a1181 1
              (MirTypes.CODE(MirTypes.REFS(loc_refs,
d1187 3
a1189 1
              value_list, proc_list_list),
a1192 1
              generate_debugging_info,
d2877 1
a2877 1
 			 ((if !generate_tracing
d2910 1
a2910 1
 		       (if !generate_tracing
d3109 1
a3109 1
            ! force_non_leaf orelse
d3438 1
a3438 1
                     if generate_debugging_info
@


1.136
log
@Changed Error structure to Info
@
text
@d4 3
d1517 2
a1518 1
			(Print.print"Mach_Cg(TBINARY) first arg not reg\n";
@


1.135
log
@Added the generation of 3 NOP instructions for the purposes of tracing
(if the correct flag is set to true )
@
text
@d4 4
d480 1
d501 1
d521 1
d1177 8
a1184 7
  fun mach_cg(MirTypes.CODE(MirTypes.REFS(loc_refs,
					  {requires = ext_refs,
					   vars = vars,
					   exns = exns,
					   strs = strs,
					   funs = funs}),
			    value_list, proc_list_list),
@


1.134
log
@Reworked in terms of mononewmap
@
text
@d4 3
d518 1
d520 5
d2864 9
a2872 6
			 (check_for_stack_overflow_wrap,
			  [],
			  (case opcode_list of
			     [] => block_list
			   | _ => 
			       MirTypes.BLOCK(end_tag,opcode_list) ::
d2897 4
a2900 1
		       ([], opcode_list, block_list, final_result)
@


1.133
log
@Changed maps used on tags to that providfed by mirtypes for efficiency
@
text
@d4 3
d1159 1
a1159 1
  structure Map = Datatypes.NewMap
d1185 1
a1185 1
	Map.iterate
d1191 1
a1191 1
	Map.iterate
d1197 1
a1197 1
	Map.iterate
d3057 1
a3057 1
	  val fps = Set.map (fn r => Map.apply'(fp_map, r)) fp
d3083 2
a3084 1
	    (ch (fn r => MachTypes.check_reg(Map.apply'(gc_map, r))) gc)
d3087 1
a3087 1
		 MachTypes.check_reg(Map.apply'(non_gc_map, r))) non_gc)
d3096 3
a3098 3
                      (case Map.tryApply' (i, procedure_name) of
                         Map.YES(a, _, c) =>
                           debug_map := Debugger_Types.INFO (Map.define(i, procedure_name,(a,true,c)))
d3398 2
a3399 2
			       case Map.tryApply'(i, unpadded_name) of
				 Map.YES(ty,leaf,annotations) =>
d3402 1
a3402 1
                                     (Map.define(i, unpadded_name, (ty,leaf,(count,debug)::annotations)))
@


1.132
log
@Fixed bug in the size put in the header of a double
@
text
@d4 3
d506 1
a506 1
  structure Map = Datatypes.NewMap
d774 1
a774 1
	make_proc_info((Map.empty (MirTypes.order_tag,MirTypes.equal_tag), Map.empty (MirTypes.order_tag,MirTypes.equal_tag)), block_list)
d896 1
a896 1
					     Map.empty (MirTypes.order_tag,MirTypes.equal_tag))
d1156 2
@


1.131
log
@check_range did an abs which failed on most negative integer
@
text
@d4 3
d2328 1
a2328 1
                                           | MachTypes.double   => (16, 5, true, 64*16+26))
@


1.130
log
@Change to NewMap.empty which now takes < and = functions instead of the single-function
@
text
@d4 3
a531 3
      let
	val pos_i = abs i
      in
d533 1
a533 2
	(i < 0 andalso pos_i <= pos_limit)
      end
@


1.129
log
@Got floor working
@
text
@d4 3
a703 4
  fun tag_order arg =
    if MirTypes.equal_tag arg then Map.EQUAL
    else if MirTypes.order_tag arg then Map.LESS else Map.GREATER

d769 1
a769 1
	make_proc_info((Map.empty tag_order, Map.empty tag_order), block_list)
d891 1
a891 1
					     Map.empty tag_order)
@


1.128
log
@When ordof used, the exception in Ord needed to be caught instead of substring
@
text
@d4 3
d1995 1
a1995 1
		      val (operation,operation',test) = 
d1997 3
a1999 3
                          MachTypes.single => (Sparc_Assembly.FSTOI,Sparc_Assembly.FITOS,Sparc_Assembly.FCMPS)
                        | MachTypes.double => (Sparc_Assembly.FDTOI,Sparc_Assembly.FITOD,Sparc_Assembly.FCMPD)
                        | MachTypes.extended => (Sparc_Assembly.FXTOI,Sparc_Assembly.FITOX,Sparc_Assembly.FCMPX)
d2005 1
d2038 28
@


1.127
log
@Removed some handles of hashtable lookup exceptions
@
text
@d4 3
d3346 2
a3347 1
                                    if String.ordof(padded_name,to) = 0 then check_index(to-1)
d3350 3
a3352 1
                                  check_index (s-1) handle String.Substring => ""
@


1.126
log
@Added argument value checking to floor
@
text
@d4 3
d896 1
a896 6
	  val applied_map = Map.tryApply tag_env

	  fun lookup_env tag =
	    case applied_map tag of
	      Map.YES res => res
	    | _ => raise Lists.Assoc
d916 12
a927 9
		    let
		      val disp =
			fault_range((lookup_env tag - offset) div 4,
				    true, branch_disp_limit)
			handle Lists.Assoc =>
			  Crash.impossible"Assoc do_opcode branch"
		    in
		      (Sparc_Assembly.BRANCH(branch, disp), comment)
		    end
d930 11
a940 9
		    let
		      val disp =
			fault_range((lookup_env tag - offset) div 4,
				    true, branch_disp_limit)
			handle Lists.Assoc =>
			  (Crash.impossible"Assoc do_opcode branch_annul")
		    in
		      (Sparc_Assembly.BRANCH_ANNUL(branch, disp), comment)
		    end
d943 11
a953 9
		    let
		      val disp =
			fault_range((lookup_env tag - offset) div 4,
				    true, branch_disp_limit)
			handle Lists.Assoc =>
			  Crash.impossible"Assoc do_opcode fbranch"
		    in
		      (Sparc_Assembly.FBRANCH(branch, disp), comment)
		    end
d956 11
a966 9
		    let
		      val disp =
			fault_range((lookup_env tag - offset) div 4,
				    true, branch_disp_limit)
			handle Lists.Assoc =>
			  Crash.impossible"Assoc do_opcode fbranch_annul"
		    in
		      (Sparc_Assembly.FBRANCH_ANNUL(branch, disp), comment)
		    end
d969 10
a978 7
		    let
		      val disp =
			fault_range((lookup_env tag + i - offset) div 4,
				    true, call_disp_limit)
		    in
		      (Sparc_Assembly.Call(Sparc_Assembly.CALL, disp), comment)
		    end
d983 62
a1044 59
		    let
		      val disp = lookup_env tag + i - offset
			handle Lists.Assoc =>
			  Crash.impossible"Assoc do_opcode arith"
		    in
		      if check_range(disp, true, arith_imm_limit) then
			(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			 (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM disp,
			  rs1),
			 comment)
		      else
			let
			  val _ =
			    diagnostic_output 3
			    (fn _ => ["Found bad ADR, substituting\n"])
			  fun drop(n, the_list) =
			    if n < 0 then
			      Crash.impossible"drop negative arg"
			      else
				if n = 0 then the_list
				else
				  case the_list of
				    [] => Crash.impossible"drop bad list"
				  | _ :: rest => drop(n-1, rest)
			  val head_size = (offset - block_start) div 4
			  val tail = drop(1 + head_size, opcode_list)
			  (* get the opcodes after this one *)
			  val _ =
			    if rs1 = rd then
			      Crash.impossible"ADR has dest in lr"
			    else ()
			  val new_comment = comment ^ " (expanded adr)"
			  val new_tail =
			    (Sparc_Assembly.SetHI
			     (Sparc_Assembly.SETHI, rd, i),
			     MirTypes.PRESENT tag, new_comment) ::
			    (Sparc_Assembly.SPECIAL_ARITHMETIC
			     (Sparc_Assembly.ADD_AND_MASK, rd,
			      Sparc_Assembly.IMM(i + 4), rd),
			     MirTypes.PRESENT tag, new_comment) ::
			    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (Sparc_Assembly.ADD, rd,
			      Sparc_Assembly.REG rd, rs1),
			     MirTypes.ABSENT, new_comment) :: tail
			  fun copy_n(n, from) =
			    if n < 0 then
			      Crash.impossible"copy_n negative arg"
			    else
			      if n = 0 then
				new_tail
			      else
				case from of
				  (x :: xs) => x :: copy_n(n-1, xs)
				| _ => Crash.impossible"copy_n short list"
			in
			  raise bad_adr(block_tag,
					copy_n(head_size, opcode_list))
			end
		    end
d1049 15
a1063 12
		    let
		      val disp =
			make_imm_fault
			((lookup_env tag + i - offset) mod 1024,
			 true, arith_imm_limit)
			handle Lists.Assoc =>
			  Crash.impossible"Assoc do_opcode arith"
		    in
		      (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		       (Sparc_Assembly.ADD, rd, disp, rs1),
		       comment)
		    end
d1066 17
a1082 14
		    let
		      val disp = lookup_env tag + i - offset
			handle Lists.Assoc =>
			  Crash.impossible"Assoc do_opcode arith"
		      val disp = (disp div 1024) mod (1024 * 1024 * 4)
		    (* Ensure positive *)
		    in
		      (Sparc_Assembly.SetHI(Sparc_Assembly.SETHI, rd, disp),
		       comment)
		    end
		  | do_opcode((opcode, MirTypes.ABSENT, comment), offset) =
		    (opcode, comment)
		  | do_opcode _ = Crash.impossible"Bad tagged instruction"

@


1.125
log
@Created a type `information' which wraps up the debugger information
needed in so many parts of the compiler.
@
text
@d4 4
d1969 6
a1974 7
		      val _ =
			diagnostic_output 1
			(fn _ => ["****** Exception tag case not yet handled for FLOOR\n"])
		      val operation = case MachTypes.fp_used of
			MachTypes.single => Sparc_Assembly.FSTOI
		      | MachTypes.double => Sparc_Assembly.FDTOI
		      | MachTypes.extended => Sparc_Assembly.FXTOI
d1977 1
d1979 34
a2012 1
		      ([(Sparc_Assembly.CONV_OP(operation, MachTypes.fp_global,
d2015 10
a2024 10
			  (Sparc_Assembly.LOAD_AND_STORE_FLOAT
			   (Sparc_Assembly.STF, MachTypes.fp_global,
			    MachTypes.fp,
			    Sparc_Assembly.IMM ~4), absent,
			   "Save converted value"),
			  (Sparc_Assembly.LOAD_AND_STORE(Sparc_Assembly.LD,
							 rd, MachTypes.fp,
							 Sparc_Assembly.IMM
							 ~4), absent,
			   "And reload into destination"),
d3009 3
@


1.124
log
@Made all moves use OR instead of ADD
@
text
@d4 3
d2987 1
a2987 2
          val _ = if needs_preserve 
                    then ()
d2989 8
a2996 4
		    (case Map.tryApply'(!debug_map, procedure_name) of
		       Map.YES(a, _, c) =>
			 debug_map := Map.define(! debug_map,procedure_name,(a,true,c))
		     | _ => ())
d3289 1
d3291 1
a3291 1
			       case Map.tryApply'(! debug_map, unpadded_name) of
d3294 2
a3295 3
				   Map.define(!debug_map,
					      unpadded_name,
					      (ty,leaf,(count,debug)::annotations))
d3366 1
a3366 1
      (module,! debug_map)
@


1.123
log
@Changed mir register to mach register translation to array lookup
@
text
@d4 3
d1110 1
a1110 1
     (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM 0, rs), absent, "")
d1114 1
a1114 1
     (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM imm, MachTypes.G0),
d1244 1
a1244 1
                  (Sparc_Assembly.ADD, reg,
d1556 1
a1556 1
		      val opcode = Sparc_Assembly.ADD
d1613 1
a1613 1
                       (Sparc_Assembly.ADD, lookup_reg_operand reg_operand,
d2248 1
a2248 1
                                         (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.IMM header, MachTypes.G0),
d2282 1
a2282 1
                                   (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.IMM bytes, MachTypes.G0),
d2320 1
a2320 1
                                   (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.REG rd, MachTypes.G0),
d2383 1
a2383 1
                                     (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.REG rd, MachTypes.G0),
d2430 1
a2430 1
			    (Sparc_Assembly.ADD, MachTypes.global,
d2435 1
a2435 1
			    (Sparc_Assembly.ADD, temp,
d2444 1
a2444 1
			    (Sparc_Assembly.ADD, MachTypes.caller_arg,
d2468 1
a2468 1
			    (Sparc_Assembly.ADD, MachTypes.caller_arg,
d2488 1
a2488 1
			    (Sparc_Assembly.ADD,MachTypes.caller_arg,
d2521 1
a2521 1
			(Sparc_Assembly.ADD, temp,
d2729 1
a2729 1
				    (Sparc_Assembly.ADD, MachTypes.O3, 
d2823 1
a2823 1
			    (Sparc_Assembly.ADD, MachTypes.caller_arg,
d2838 1
a2838 1
			    (Sparc_Assembly.ADD, MachTypes.caller_closure,
d2848 1
a2848 1
			    (Sparc_Assembly.ADD, MachTypes.caller_arg,
@


1.122
log
@Removed some redundant structures and sharing
@
text
@d4 3
d669 1
a669 1
		     (block as (block_tag, opcode_list)) :: rest) =
d676 1
a676 1
	((Map.define (main_tree, block_tag, (block, last_tag_exists)),
d760 2
d763 1
a763 1
	      Map.YES(_, res) => res
a764 3
(*
	    #2 (proc_info_map block_tag)
            handle Map.Undefined => (block_tag, false)
d820 1
a820 1
	      Map.YES(_, (_, t)) => t
a821 5
(*
            (case proc_info_map tag
               of (_, (_, t)) => t)
            handle Map.Undefined => false
*)
d1130 27
a1165 29
      (* Note to jont: MirTypes.GC.Set.T is a far more efficient set of GC *)
      (* registers than the polymorphic Set type. *)

      val gc_map_fn = Map.apply gc_map
      fun gc_trans set =
        Set.list_to_set (map gc_map_fn (MirTypes.GC.Set.to_list set))

      fun get_refs MirTypes.ENTER = Set.empty_set
        | get_refs MirTypes.RTS   = Set.empty_set
        | get_refs (opcode as MirTypes.ADR _) =
          Set.add_member 
          (MachTypes.lr,
           gc_trans (MirTypes.GC.Set.union (#gc (MirTables.defined_by opcode),
                                            #gc (MirTables.referenced_by opcode))))
        | get_refs opcode =
          gc_trans (MirTypes.GC.Set.union (#gc (MirTables.defined_by opcode),
                                           #gc (MirTables.referenced_by opcode)))

      fun get_refs_for_proc(MirTypes.PROC(_, _, _, block_list)) =
	Lists.reducel
	Set.union
	(Set.empty_set,
	 map (fn (MirTypes.BLOCK(_, opcode_list)) =>
	      Lists.reducel
	      Set.union
	      (Set.empty_set,
	       map get_refs opcode_list))
	 block_list)

d1354 1
a1354 1
		  val reg = Map.apply'(table, reg)
d1361 1
a1361 1
	        lookup_reg(reg, gc_map)
d1363 1
a1363 1
		lookup_reg(reg, non_gc_map)
d1366 1
a1366 1
	        lookup_reg(reg, gc_map)
d1368 1
a1368 1
		lookup_reg(reg, non_gc_map)
d1373 1
a1373 1
		Map.apply'(fp_map, reg)
d2345 1
a2345 1
                                            (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM (12+7), lookup_reg (reg, gc_map)),
d2350 1
a2350 1
                                            (Sparc_Assembly.SRL, rd, Sparc_Assembly.IMM 2, lookup_reg (reg, gc_map)),
d2353 1
a2353 1
                                            (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM (4+7), lookup_reg (reg, gc_map)),
d2392 1
a2392 1
                                     (Sparc_Assembly.SLL, MachTypes.global, Sparc_Assembly.IMM 4, lookup_reg (reg, gc_map)),
@


1.121
log
@Samm bug fix - debug info was incremented but not stored back
@
text
@d4 3
a426 1
require "../utils/set";
a430 1
require "../basics/ident";
a431 1
require "../mir/mirtypes";
a435 3
require "../debugger/debugger_types";
require "../typechecker/datatypes";
require "machtypes";
a436 2
require "sparc_opcodes";
require "sparc_assembly";
a444 1
   structure Set : SET
a447 1
   structure Ident : IDENT
a448 1
   structure MirTypes : MIRTYPES
a451 1
   structure MachTypes : MACHTYPES
a452 2
   structure Sparc_Opcodes : SPARC_OPCODES
   structure Sparc_Assembly : SPARC_ASSEMBLY
a455 2
   structure Debugger_Types : DEBUGGER_TYPES
   structure Datatypes : DATATYPES
d457 5
a461 11
   sharing MirTypes.Debugger_Types = Sparc_Assembly.Debugger_Types
   sharing MirTypes.Ident = Ident
   sharing MachTypes = Sparc_Opcodes.MachTypes = Sparc_Assembly.MachTypes
   sharing Sparc_Opcodes = Sparc_Assembly.Sparc_Opcodes
   sharing Set = MirTypes.Set = MirTables.Set = MirRegisters.Set = MachSpec.Set
   sharing MirTypes = MirTables.MirTypes = MirPrint.MirTypes =
     Sparc_Schedule.MirTypes = MirRegisters.MirTypes =
     Sparc_Assembly.MirTypes
   sharing Sparc_Assembly = Sparc_Schedule.Sparc_Assembly
   sharing type MachTypes.Sparc_Reg = MachSpec.register
   sharing Debugger_Types.Map = MirRegisters.Map
d464 4
a467 3
  structure Map = Debugger_Types.Map
  structure MirTypes = MirTypes
  structure MachTypes = MachTypes
d471 4
a474 1
  structure Datatypes = Datatypes
d750 2
a751 2
      val proc_info_map = Map.apply proc_info
      val tag_tree_map = Map.apply tag_tree
d757 4
d763 1
d780 3
a782 2
                          (tag_tree_map x; false)
                          handle Map.Undefined => true)
d817 4
d824 1
a825 1

d886 1
a886 1
	  val applied_map = Map.apply tag_env
d888 4
a891 2
	  fun lookup_env tag = applied_map tag
            handle Map.Undefined => raise Lists.Assoc
d2988 5
a2992 8
                  else 
                    let
                      val (a,_,c) = Debugger_Types.Map.apply(! debug_map) procedure_name
                    in
                      (debug_map := Debugger_Types.Map.define(! debug_map,procedure_name,(a,true,c));
                       ())
                    end
                  handle Debugger_Types.Map.Undefined => ()
d3275 1
a3275 1
                            (let
d3285 8
a3292 5
                              val (ty,leaf,annotations) = Debugger_Types.Map.apply(! debug_map) unpadded_name
                            in
                              debug_map := Debugger_Types.Map.define(!debug_map,
                                                                     unpadded_name,
                                                                     (ty,leaf,(count,debug)::annotations))
a3293 1
                          handle Debugger_Types.Map.Undefined => ())
@


1.120
log
@Implemented ALLOC_BYTEARRAY, and the NULLARY operation CLEAN.
@
text
@d4 3
d2995 1
a2995 1
                      (Debugger_Types.Map.define(! debug_map,procedure_name,(a,true,c));
@


1.119
log
@Added details about leafness to the debug information
@
text
@d4 3
d1613 6
d2211 1
d2217 1
d2223 1
a2223 1
                                val (bytes, primary, aligned, secondary) =
d2235 1
a2235 1
                                           | MachTypes.double   => (16, 5, true, 64*16+10))
d2237 1
d2239 2
a2240 2
                                val header =
                                  if secondary = 0 then [] else
d2242 1
a2242 1
                                      val (high, low) = split_int (MirTypes.GP_IMM_ANY secondary)
d2246 1
a2246 1
                                          absent, "Initialise secondary tag")]
d2250 1
a2250 1
                                         (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.IMM secondary, MachTypes.G0),
d2290 1
a2290 1
                                     header
d2294 1
a2294 1
                                      absent, "Zero unaligned extra word") :: header)
d2327 1
a2327 1
                                      absent, "Tag object with primary") :: header
d2337 1
a2337 1
                                      absent, "Tag object with primary") :: header)
d2341 22
a2362 9
                              (case allocate
                                 of MirTypes.ALLOC        => Crash.unimplemented "ALLOC variable size"
                                  | MirTypes.ALLOC_STRING => Crash.unimplemented "ALLOC_STRING variable size"
                                  | MirTypes.ALLOC_REAL   => Crash.unimplemented "ALLOC_REAL variable size"
                                  | MirTypes.ALLOC_REF =>
                                    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                     (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM (12+7), lookup_reg (reg, gc_map)),
                                     absent, "") ::
                                    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
d2364 1
a2364 1
                                     absent, "Calculate aligned size of array, in bytes") ::
d2394 1
a2394 1
                                     (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM 3, MachTypes.global),
d2400 2
a2401 2
                                     (Sparc_Assembly.ADD, MachTypes.global, Sparc_Assembly.IMM 18, MachTypes.global),
                                     absent, "Calculate secondary tag") ::
d2403 3
a2405 3
                                     (Sparc_Assembly.ST, MachTypes.global, rd, Sparc_Assembly.IMM (~3)),
                                     absent, "Initialise secondary tag") :: nil)

@


1.118
log
@Changed ord(substring ...) to ordof.
@
text
@d4 3
d486 1
d2952 1
d2961 10
d3263 1
a3263 1
                              val (ty,annotations) = Debugger_Types.Map.apply(! debug_map) unpadded_name
d3267 1
a3267 1
                                                                     (ty,(count,debug)::annotations))
@


1.117
log
@String structure is now pervasive.
@
text
@d4 3
d3243 1
a3243 2
                                    if ord(String.substring(padded_name,to,1)) = 0
                                      then check_index(to-1)
@


1.116
log
@Removed references to save
@
text
@d4 3
a414 1
require "../utils/string";
a440 1
   structure String : STRING
@


1.115
log
@Added floating point save and restore code
@
text
@d4 3
a428 2
require "save";

a451 1
   structure Save : SAVE
d463 1
a463 1
     Sparc_Schedule.MirTypes = MirRegisters.MirTypes = Save.MirTypes =
d465 1
a465 1
   sharing Sparc_Assembly = Sparc_Schedule.Sparc_Assembly = Save.Sparc_Assembly
@


1.114
log
@Removed some messages
@
text
@d4 3
d461 1
a461 1
   sharing Set = MirTypes.Set = MirTables.Set = MirRegisters.Set
a593 5
(*
      val _ = print("New mantissa = " ^ mantissa ^ " new exponent = " ^ Integer.makestring real_exponent)
      val _ =
	print(implode("Digits to binary_list " :: binary_list))
*)
a747 6
(*
      val _ =
	Print.print
	("reordering " ^ Integer.makestring(Lists.length block_list) ^
	 " blocks\n")
*)
a771 5
(*
		  val _ = Print.print
		    (Integer.makestring(Lists.length continuers) ^
		     " continuers\n")
*)
a784 3
(*
		  val _ = Print.print"Now do_fall_throughs\n"
*)
a831 9
(*
      val _ =
	Print.print
	("Number of blocks in procedure set = " ^
	 Integer.makestring
	 (Lists.reducel
	  (fn (x, (_, proc)) => x + Lists.length proc)
	  (0, proc_list)) ^ "\n")
*)
a944 8
(*
		      val _ =
			case i of
			  0 => ()
			| _ => Print.print
			    ("Handling call with non-zero offset = " ^
			     Integer.makestring i ^ "\n")
*)
a955 8
(*
		      val _ =
			case i of
			  0 => ()
			| _ => Print.print
			    ("Handling add with non-zero offset = " ^
			     Integer.makestring i ^ "\n")
*)
d1160 11
a1170 10
      fun do_block (_, [], _, _, _ ,_,_,_,_) = []
      | do_block(needs_preserve, MirTypes.BLOCK(tag,opcodes) :: rest,
		 gc_spill_size,
		 non_gc_spill_size,
		 needs_fp_spare,
		 non_gc_stack_size,
		 gc_stack_size,
		 gc_stack_area,
		 frame_size
		 ) =
d1263 69
a1601 44
(*
		| MirTypes.UNARY(unary_op, reg_operand, gp_operand) =>
		    let
		      val rd = lookup_reg_operand reg_operand
		      val opcode = case unary_op of
			MirTypes.MOVE => Sparc_Assembly.ADD
		      | MirTypes.NOT => Sparc_Assembly.ANDN
		      val (extra, reg_or_imm, is_null, rs1) =
			if is_reg gp_operand then
			  let
			    val rs2 = lookup_gp_operand gp_operand
			  in
			    ([], Sparc_Assembly.REG rs2,
			     rd = rs2 andalso opcode = Sparc_Assembly.ADD,
			     MachTypes.G0)
			  end
			else
			  let
			    val (high, low) = split_int gp_operand
			  in
			    if gp_check_range(gp_operand, true,
					      arith_imm_limit) then
			      ([],
			       if low = 0 then
				 Sparc_Assembly.REG MachTypes.G0
			       else
				 make_imm_format3 gp_operand,
			       false,
			       MachTypes.G0)
			    else
			      ([(Sparc_Assembly.SetHI
				 (Sparc_Assembly.SETHI, rd, high),
				 absent, "Get high part")],
			       Sparc_Assembly.IMM low, false, rd)
			  end
		    in
		      (if is_null then
			 []
		       else
			 extra @@ [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				   (opcode, rd, reg_or_imm, rs1), absent, "")],
			 opcode_list, block_list, final_result)
		    end
*)
d1711 1
a1711 1
                           | (MachTypes.single,   MirTypes.FNEGV)  => (Sparc_Assembly.FMOV,   Sparc_Assembly.FCMPS, 0)
d1714 1
a1714 1
                           | (MachTypes.double,   MirTypes.FNEGV)  => (Sparc_Assembly.FMOV,   Sparc_Assembly.FCMPD, 1)
d1717 1
a1717 1
                           | (MachTypes.extended, MirTypes.FNEGV)  => (Sparc_Assembly.FMOV,   Sparc_Assembly.FCMPX, 3)
d1927 1
a1927 1
			   "Store the value to be converted"),
a2569 64
(*
			 fun n_stores(from, no_of_stores) =
			   let
			     val (use_global, code) =
			       if check_range(from - 4 *(no_of_stores - 1),
					      true, arith_imm_limit) then
				 (false, [])
			       else
				 (true,
				  if check_range(from, true,
						 arith_imm_limit) then
				    [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				      (Sparc_Assembly.ADD, MachTypes.global,
				       Sparc_Assembly.IMM from, MachTypes.fp),
				      absent, "Point to start of gc area")]
				  else
				    let
				      val (high, low) =
					split_int(MirTypes.GP_IMM_ANY from)
				    in
				      [(Sparc_Assembly.SetHI
					(Sparc_Assembly.SETHI,
					 MachTypes.global, high),
					absent, "Get high part"),
				       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					(Sparc_Assembly.ADD,
					 MachTypes.global,
					 Sparc_Assembly.IMM low,
					 MachTypes.global),
					absent, "Add in low of limit"),
				       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					(Sparc_Assembly.ADD,
					 MachTypes.global,
					 Sparc_Assembly.IMM low,
					 MachTypes.fp),
					absent, "Add in low of limit")]
				    end)
			     fun do_store(_, _, 0, done) = done
			     | do_store(reg, offset, n, done) =
			       if n < 0 then Crash.impossible"Do_store"
			       else
				 do_store(reg, offset-4, n-1,
					  (Sparc_Assembly.LOAD_AND_STORE
					   (Sparc_Assembly.ST, MachTypes.G0,
					    reg,
					    Sparc_Assembly.IMM offset), absent,
					   "Initialise a stack slot") :: done)
			     val (the_reg, the_offset) =
			       if use_global then
				 (MachTypes.global, 0)
			       else
				 (MachTypes.fp, from)
			     val end_instrs =
			       [(Sparc_Assembly.BRANCH_ANNUL
				 (Sparc_Assembly.BAA, 0),
				 MirTypes.PRESENT end_tag,
				 "Finish cleaning stack"),
				Sparc_Assembly.nop]
			   in
			     code @@
			     do_store(the_reg, the_offset, no_of_stores,
				      end_instrs)
			   end
*)
a2620 36
(*
				 let
				   val the_start = gc_area_start_offset()
				 in
				   if check_range(the_start, true,
						  arith_imm_limit) then
				     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				      (Sparc_Assembly.ADD, MachTypes.I2,
				       Sparc_Assembly.IMM the_start,
				       MachTypes.fp), absent,
				      "") ::
				     load_limit
				   else
				     let
				       val (high, low) =
					 split_int(MirTypes.GP_IMM_ANY
						   the_start)
				     in
				       (Sparc_Assembly.SetHI
					(Sparc_Assembly.SETHI,
					 MachTypes.I2, high),
					absent, "Get high part") ::
				       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					(Sparc_Assembly.ADD, MachTypes.I2,
					 Sparc_Assembly.IMM low,
					 MachTypes.I2),
					absent, "Add in low of start") ::
				       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					(Sparc_Assembly.ADD, MachTypes.I2,
					 Sparc_Assembly.REG MachTypes.fp,
					 MachTypes.I2),
					absent, "Add in low of start") ::
				       load_limit
				     end
				 end
*)
a2640 21
(*
				 [(Sparc_Assembly.LOAD_AND_STORE
				   (Sparc_Assembly.ST, MachTypes.G0,
				    MachTypes.global,
				    Sparc_Assembly.REG MachTypes.I2),
				   absent, "Initialise a stack slot"),
				  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				   (Sparc_Assembly.ADDCC, MachTypes.global,
				    Sparc_Assembly.IMM 4,
				    MachTypes.global),
				   absent, "Update counter"),
				  (Sparc_Assembly.BRANCH_ANNUL
				   (Sparc_Assembly.BLEA, 0),
				   MirTypes.PRESENT top_tag,
				   "Branch if not finished"),
				  Sparc_Assembly.nop,
				  (Sparc_Assembly.BRANCH_ANNUL
				   (Sparc_Assembly.BAA, 0),
				   MirTypes.PRESENT end_tag, ""),
				  Sparc_Assembly.nop]
*)
d2736 1
a2736 1
				 [(Sparc_Assembly.SAVE_AND_RESTORE
d2741 3
a2743 2
				      MachTypes.sp), absent, "New frame"),
				 (Sparc_Assembly.BRANCH_ANNUL
d2746 1
a2746 1
				 Sparc_Assembly.nop]) ::
d2754 1
d2923 8
a2934 3
(*
	    | check_instr(MirTypes.TAIL_CALL _) = true
*)
a2939 7
	  fun check_instr'(MirTypes.BRANCH_AND_LINK _) = true
	    | check_instr'(MirTypes.TAIL_CALL _) = true
	    | check_instr' MirTypes.CALL_C = true
	    | check_instr'(MirTypes.SWITCH _) = true
	    | check_instr'(MirTypes.ADR _) = true
	    | check_instr' _ = false

a2942 13
	  fun check_instr_block'(MirTypes.BLOCK(_, instr_list)) =
	    Lists.exists check_instr' instr_list

(*
	  val _ =
	    Print.print(if leaf then "Leaf\n" else "Non-leaf\n")
	  val _ =
	    Print.print("gc = " ^
			Set.set_print(Set.map
				      (fn x => Map.apply'(gc_map, x)) gc,
				      MachTypes.reg_to_string) ^
			"\n")
*)
d2944 2
a2945 5
(*
	     not leaf orelse
*)
	    ((*Print.print"Checking fps\n";*)
	     ch (fn r => MachTypes.check_reg(Map.apply'(fp_map, r))) fp)
d2947 1
a2947 5
	    ((*Print.print"Checking gcs\n";*)
	     ch (fn r => MachTypes.check_reg(Map.apply'(gc_map, r))) gc)
	    orelse
	    ((*Print.print"Checking non_gcs\n";*)
	     ch (fn r =>
d2961 1
a2961 1
	      if t = tag then (t, code) :: (rev L @@ rest)
d2980 1
a2980 1
	    (* Moved this code from do_block as it is independent of the block number *)
d3000 8
d3010 1
d3023 10
a3032 9
	    move_first([], do_block(needs_preserve orelse needs_fp_spare,
				    block_list, 
				    gc_spill_size,
				    non_gc_spill_size,
				    needs_fp_spare,
				    non_gc_stack_size,
				    gc_stack_size,
				    gc_stack_area,
				    frame_size))
@


1.113
log
@Corrected an uncaught String.Substring
@
text
@d4 3
a2555 1
			       (Print.print"Generating double store\n";
d2561 1
a2561 2
					 "Initialise two stack slots") :: done))

a2656 2
			       val _ =
				 Print.print"generating looping stack clear\n"
@


1.112
log
@Removed obsolete memory profiling code.
@
text
@d4 3
d3390 1
a3390 1
                                  check_index (s-1)
@


1.111
log
@Added call point information recording
@
text
@d4 3
a469 1
  val generate_memory_profiling = ref false
a2853 16

                         val memory_profile_wrap =
                           if !generate_memory_profiling
                             then
                               [(Sparc_Assembly.LOAD_AND_STORE
                                 (Sparc_Assembly.LD, MachTypes.global,
                                  MachTypes.implicit, Sparc_Assembly.IMM (4 * Implicit_Vector.memory_profiler)),
                                 absent, "Get address of memory profiler"),
                               (Sparc_Assembly.JUMP_AND_LINK
                                (Sparc_Assembly.JMPL, MachTypes.global,
                                 Sparc_Assembly.IMM 0, MachTypes.global,
                                 Debugger_Types.null_backend_annotation),
                                absent, "Do memory profiling"),
                               Sparc_Assembly.nop]
                           else
                             []
d2855 1
a2855 1
			 (memory_profile_wrap @@ check_for_stack_overflow_wrap,
@


1.110
log
@Modified stack clearing code to use double wort stores where possible
@
text
@d4 3
a395 1
require "../utils/newmap";
d407 2
a424 1
   structure Map : NEWMAP
d442 2
d455 1
a455 1
   sharing Map = MirRegisters.Map
d458 1
a458 1
  structure Map = Map
d464 1
d473 1
a473 1
  val print_code_size = ref true
d1151 3
a1153 1
	       fp_map)) =
d1155 3
d3279 2
a3280 9
	  val code_list' =
(*
	    Timer.xtime
	    ("removing redundant saves", !do_timings,
	     fn () => map Save.remove_redundant_saves code_list)
*)
(**)
	    code_list
(**)
d3387 2
a3388 2
                   fun annotation_points ([],_) = ()
                     | annotation_points ((inst,_)::t,count) =
d3390 20
a3409 2
                          Sparc_Assembly.JUMP_AND_LINK (_,_,_,_,debug) =>        
                            output(std_out,Integer.makestring(count) ^ "  " ^ Debugger_Types.print_backend_annotation debug ^ "\n")
d3411 12
a3422 1
                            annotation_points(t,count+1))
a3423 12
                   (* Annotation information capture

                   val _ = output(std_out,"Annotation point information for " ^ padded_name ^ "\n")
                   val _ = annotation_points(code,0)

                     *)

		   val code = (implode
			       (map
				(fn (x, _) =>
				 Sparc_Opcodes.output_opcode(Sparc_Assembly.assemble x))
				code))
d3478 1
a3478 1
      module
@


1.109
log
@Allowed translation of tagged binary operations where both arguments
are constant
@
text
@d4 4
d2527 42
d2631 1
d2633 1
a2633 1
			   if gc_stack_size div 4 <= 7 then
d2635 1
a2635 1
			      n_stores(gc_area_start_offset(),
d2640 2
d2649 5
a2653 1
				   val the_limit = 4 - gc_stack_size
d2679 7
d2720 1
d2722 20
d2761 1
@


1.108
log
@Fixed leaf case profiling so it refers to the correct closure register
@
text
@d4 3
d1116 16
a1148 13
      fun is_reg(MirTypes.GP_GC_REG reg) = true
      | is_reg(MirTypes.GP_NON_GC_REG reg) = true
      | is_reg _ = false

      fun move_reg(rd, rs) =
	(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
	(Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM 0, rs), absent, "")

      fun move_imm(rd, imm) =
	(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
	 (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM imm, MachTypes.G0),
	 absent, "")

d1343 2
a1344 1
			if needs_reverse tagged_binary_op then
d1393 12
a1404 2
		      else Crash.impossible"Mach_Cg(TBINARY) first arg not reg"
		  end	
@


1.107
log
@Made TAIL_CALL allowable in leaf procedures
@
text
@d4 3
d2447 5
a2451 1
			 MachTypes.callee_closure,Sparc_Assembly.IMM ~1),
@


1.106
log
@Changed to build sexpressions in order to avoid quadratic behaviour
of appends
@
text
@d4 4
d985 2
a986 1
			    Print.print"Found bad ADR, substituting\n";
d1920 2
a1921 1
			Print.print"****** Exception tag case not yet handled for FLOOR\n"
d2063 8
a2070 5
			(Sparc_Assembly.SAVE_AND_RESTORE
			 (Sparc_Assembly.RESTORE, MachTypes.G0,
			  Sparc_Assembly.IMM 0, MachTypes.sp),
			 absent,
			 "Restore in delay slot")
d2957 1
a2957 1
	    | check_instr(MirTypes.ALLOCATE _) = true
a2958 4
(*
	    | check_instr(MirTypes.PROFILER _) = true
*)
	    | check_instr(MirTypes.TAIL_CALL _) = true
a2961 3
(*
	    | check_instr MirTypes.RAISE = true
*)
d2964 7
d2974 3
d3004 1
a3004 2
	    if not needs_preserve then
	      Print.print(procedure_name ^ " is leaf\n")
d3006 2
a3007 1
	      ()
d3106 2
a3107 1
	    (Print.print"Removing redundant load after store\n";
d3163 1
d3167 4
a3170 1

@


1.105
log
@Added type annotation information at application points
@
text
@d4 3
d383 1
d410 1
d461 11
d1268 1
a1268 1
	    (tag, done) :: final_result
d1274 2
a1275 2
	    (needs_preserve, tag', opcodes, [], blocks,
	     (tag, done) :: final_result)
d2861 1
a2861 1
	       done @@ result_list, new_blocks,
d2866 1
a2866 1
	  do_everything(needs_preserve, tag, opcodes, [], rest, [])
@


1.104
log
@Corrected code to generate unary not. Split out of code for move
@
text
@d4 3
d421 1
d439 1
d1930 2
a1931 1
			   Sparc_Assembly.IMM 0, lookup_reg_operand reg),
d2024 1
a2024 1
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.REG reg_operand) =>
d2027 2
a2028 1
		       Sparc_Assembly.IMM 11, lookup_reg_operand reg_operand),
d2032 1
a2032 1
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.TAG tag) =>
d2051 2
a2052 1
			       Sparc_Assembly.IMM 11, lookup_reg_operand reg),
d2099 2
a2100 1
			  lookup_reg_operand reg_operand), absent,
d2207 2
a2208 1
                                   (Sparc_Assembly.JMPL, link, Sparc_Assembly.IMM 0, MachTypes.global),
d2245 2
a2246 1
                                   (Sparc_Assembly.JMPL, link, Sparc_Assembly.IMM 0, MachTypes.global),
d2295 2
a2296 1
                                     (Sparc_Assembly.JMPL, link, Sparc_Assembly.IMM 0, MachTypes.global),
d2371 2
a2372 1
			     Sparc_Assembly.IMM 0, MachTypes.global),
d2400 2
a2401 1
			     Sparc_Assembly.IMM 0, MachTypes.global),
d2699 2
a2700 1
				Sparc_Assembly.IMM 0, MachTypes.global),
d2720 2
a2721 1
                                 Sparc_Assembly.IMM 0, MachTypes.global),
d2762 2
a2763 1
			   MachTypes.after_preserve MachTypes.lr),
d2772 2
a2773 1
			   Sparc_Assembly.IMM 8, MachTypes.lr),
d2792 2
a2793 1
			     Sparc_Assembly.REG MachTypes.global, MachTypes.G0),
d2817 2
a2818 1
			     Sparc_Assembly.REG MachTypes.global, MachTypes.G0),
d2839 1
a2839 1
			 Sparc_Assembly.IMM 0, MachTypes.global),
d3244 15
@


1.103
log
@Reimplemented the allocation code to deal with large
constant-sized objects.  Also corrected some problems with
variable-sized objects.  The code should now be smaller and
faster.
@
text
@d4 6
d1446 59
d1547 1
@


1.102
log
@Implemented tagged floating point instructions.  At the moment
they do not catch infinity.
@
text
@d4 4
d1204 1
a1204 1
	  fun load_large_number_into_register(reg,num) =
d1209 13
a1221 7
	      [(Sparc_Assembly.SetHI
		(Sparc_Assembly.SETHI, reg, high),
		absent, "Get high part"),
	       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		(Sparc_Assembly.ADD, reg,
		 Sparc_Assembly.IMM low, reg),
		absent, "Add in low part")]
d2063 1
a2063 1
		 | MirTypes.ALLOCATE(allocate, reg_operand, size) =>
d2065 8
a2072 29
		       val (link, impl) =
			 if needs_preserve then
			   (MachTypes.lr, Implicit_Vector.gc)
			 else
			   (MachTypes.gc2, Implicit_Vector.gc_leaf)
		       val (immediatep,i) =
			 (case (size,allocate) of 
			    (MirTypes.GP_IMM_INT x,_) => (true,x)
			  | (MirTypes.GP_GC_REG _,MirTypes.ALLOC_REF) => (false,0)
			  | _ => Crash.impossible
			      "Allocate has non-constant or non-garbage collectable reg")
		       val rd = lookup_reg_operand reg_operand
		       val (size_in_bytes, ptr_tag, needs_to_zero_a_word,offset_of_word_to_zero) =
			 case allocate of
			   MirTypes.ALLOC =>
			     if i = 2 
                               then (8, 1,false,0) 
                             else (8 * ((i + 2) div 2), 5, (i mod 2) = 0,4*i -1)
			 | MirTypes.ALLOC_STRING =>
			     (((i + 12) div 8) * 8, 5,false,0)
			 | MirTypes.ALLOC_REAL =>
			     (case MachTypes.fp_used of
				MachTypes.single =>
				  Crash.unimplemented"ALLOC_REAL single"
			      | MachTypes.double => (16, 5,false,0)
			      | MachTypes.extended =>
				  Crash.unimplemented"ALLOC_REAL extended")
			 | MirTypes.ALLOC_REF => 
                             (12 + 4*i +  4 * (1 - (i mod 2)), 3,i mod 2 = 0,(i*4) + 9)
d2074 16
a2089 9
                       val clear_extra_alignment_words =
                         (if immediatep andalso needs_to_zero_a_word
                            then
                              [(Sparc_Assembly.LOAD_AND_STORE
                                (Sparc_Assembly.ST, MachTypes.G0,
                                 rd, Sparc_Assembly.IMM offset_of_word_to_zero),
                                absent, "Zero the alignment word")]
                          else 
                            [])
d2091 21
a2111 37
		       fun do_allocate_immediate goto_tag =
                         ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                            (Sparc_Assembly.ADD, MachTypes.gc1,
                             Sparc_Assembly.IMM size_in_bytes,
                             MachTypes.gc1),
                            absent, "Calculate new heap start"),
                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                          (Sparc_Assembly.SUBCC, MachTypes.G0,
                           Sparc_Assembly.REG(MachTypes.gc2), MachTypes.gc1),
                          absent, "Check if collection needed"),
                         (Sparc_Assembly.BRANCH_ANNUL
                          (Sparc_Assembly.BLA, 0), MirTypes.PRESENT goto_tag,
                          "Don't do next instruction if gc is required"),
                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                          (Sparc_Assembly.ADD, rd,
                           Sparc_Assembly.IMM(ptr_tag - size_in_bytes),
                           MachTypes.gc1),
                          absent, "Generate tagged result"),
                         (Sparc_Assembly.LOAD_AND_STORE
                          (Sparc_Assembly.LD, MachTypes.global,
                           MachTypes.implicit, Sparc_Assembly.IMM (4 * impl)),
                          absent, "Get address of callgc"),
                         (Sparc_Assembly.JUMP_AND_LINK
                          (Sparc_Assembly.JMPL, link,
                           Sparc_Assembly.IMM 0, MachTypes.global),
                          absent, "Do callgc"),
                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                          (Sparc_Assembly.ADD, MachTypes.global,
                           Sparc_Assembly.IMM size_in_bytes, MachTypes.G0),
                          absent, "Setup callgc argument"),
                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                          (Sparc_Assembly.ADD, rd,
                           Sparc_Assembly.IMM ptr_tag, MachTypes.global),
                          absent, "Tag result of garbage collection"),
                         (Sparc_Assembly.BRANCH_ANNUL
                          (Sparc_Assembly.BAA, 0), MirTypes.PRESENT goto_tag,
                          "Jump to rest of block after gc")])
d2113 76
a2188 82
		       fun do_allocate_for_variable_size_reference normal_finish_tag finish_tag =
                         [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                           (Sparc_Assembly.ADD, MachTypes.global,
                            Sparc_Assembly.IMM 12,
                            MachTypes.gc1),
                           absent, "Calculate new heap start"),
                          (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                           (Sparc_Assembly.ADD, MachTypes.gc1,
                            Sparc_Assembly.REG(lookup_gp_operand size),
                            MachTypes.global),
                           absent, "Calculate new heap start"),
                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                          (Sparc_Assembly.SUBCC, MachTypes.G0,
                           Sparc_Assembly.REG(MachTypes.gc2), MachTypes.gc1),
                          absent, "Check if collection needed"),
                         (Sparc_Assembly.BRANCH_ANNUL
                          (Sparc_Assembly.BLA, 0), MirTypes.PRESENT normal_finish_tag,
                          ""),
                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                          (Sparc_Assembly.ADD, rd,
                           Sparc_Assembly.IMM(ptr_tag - 12),
                           MachTypes.global),
                          absent, "Generate tagged result"),
                         (Sparc_Assembly.LOAD_AND_STORE
                          (Sparc_Assembly.LD, MachTypes.global,
                           MachTypes.implicit, Sparc_Assembly.IMM (4 * impl)),
                          absent, "Get address of callgc"),
                         (Sparc_Assembly.JUMP_AND_LINK
                          (Sparc_Assembly.JMPL, link,
                           Sparc_Assembly.IMM 0, MachTypes.global),
                          absent, "Do callgc"),
                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                          (Sparc_Assembly.ADD, MachTypes.global,
                           Sparc_Assembly.IMM 12, lookup_gp_operand size),
                          absent, "Setup callgc arguments"),
                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                          (Sparc_Assembly.ADD, rd,
                           Sparc_Assembly.IMM ptr_tag, MachTypes.global),
                          absent, "Tag result of garbage collection"),
                         (Sparc_Assembly.LOAD_AND_STORE
                          (Sparc_Assembly.ST, MachTypes.G0,
                           MachTypes.gc1, Sparc_Assembly.IMM (~4)),
                          absent, "Zero the extra word"),
                         (Sparc_Assembly.BRANCH_ANNUL
                          (Sparc_Assembly.BAA, 0), MirTypes.PRESENT finish_tag,
                          "Jump to rest of block after gc")]
                         
		       fun do_header(header,goto_tag) =
                         clear_extra_alignment_words @@
			 (if check_range(header,true,arith_imm_limit)
			    then
			      [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, MachTypes.global,
				 Sparc_Assembly.IMM header, MachTypes.G0),
				absent, "Generate header word value")]
			  else				    
			    load_large_number_into_register(MachTypes.global,header))
                            @@
			    [(Sparc_Assembly.LOAD_AND_STORE
                              (Sparc_Assembly.ST, MachTypes.global,
                               rd, Sparc_Assembly.IMM (~ptr_tag)),
                              absent, "Store the header word"),
                            (Sparc_Assembly.BRANCH_ANNUL
                             (Sparc_Assembly.BAA, 0), MirTypes.PRESENT goto_tag,
                             "Jump to rest of block after doing header")]
                            
		       fun do_header_for_variable_size_reference (reg,tag,goto_tag) =
                         [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                           (Sparc_Assembly.SLL, MachTypes.global,
                            Sparc_Assembly.IMM 4, reg),
                           absent, "Generate header word value"),
                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                           (Sparc_Assembly.ADD, MachTypes.global,
                            Sparc_Assembly.IMM tag, MachTypes.global),
                           absent, "Generate header word value"),
                         (Sparc_Assembly.LOAD_AND_STORE
                          (Sparc_Assembly.ST, MachTypes.global,
                           rd, Sparc_Assembly.IMM (~ptr_tag)),
                          absent, "Store the header word"),
                         (Sparc_Assembly.BRANCH_ANNUL
                          (Sparc_Assembly.BAA, 0), MirTypes.PRESENT goto_tag,
                          "Jump to rest of block after doing header")]
d2190 56
a2245 74
		       val (split_tag, after_gc_tag,realign_gc_tag) =
			 (MirTypes.new_tag(), MirTypes.new_tag(),MirTypes.new_tag())
		     in
		       case allocate of
			 MirTypes.ALLOC =>
			   if i = 2 then
			     (do_allocate_immediate split_tag, [],
			      MirTypes.BLOCK(split_tag, opcode_list) ::
			      block_list,
			      final_result)
			   else
			     (do_allocate_immediate after_gc_tag, [],
			      MirTypes.BLOCK(split_tag, opcode_list) ::
			      block_list,
			      (after_gc_tag,
			       do_header (2 + 64 * i, split_tag)) ::
			      final_result)
		       | MirTypes.ALLOC_STRING =>
			   (do_allocate_immediate after_gc_tag, [],
			    MirTypes.BLOCK(split_tag, opcode_list) ::
			    block_list,
			    (after_gc_tag,
			     do_header (10 + 64 * i, split_tag)) ::
			    final_result)
		       | MirTypes.ALLOC_REF =>
			   if immediatep
                             then
                               (do_allocate_immediate after_gc_tag , [],
                                MirTypes.BLOCK(split_tag, opcode_list) :: block_list,
                                (after_gc_tag,do_header (i * 64 + 18, split_tag)) :: final_result)
                           else
                             (do_allocate_for_variable_size_reference realign_gc_tag after_gc_tag, [],
                              MirTypes.BLOCK(split_tag, opcode_list) :: block_list,
                              [(realign_gc_tag,
                                [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                  (Sparc_Assembly.ANDCC, MachTypes.G0,
                                   Sparc_Assembly.IMM 4, MachTypes.gc1),
                                  absent, "Is the gc address aligned ?"),
                                (Sparc_Assembly.BRANCH_ANNUL
                                 (Sparc_Assembly.BEA, 0),
                                 MirTypes.PRESENT after_gc_tag, ""),
                                Sparc_Assembly.nop,
                                (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                 (Sparc_Assembly.ADD, MachTypes.gc1,
                                  Sparc_Assembly.IMM 4, MachTypes.gc1),
                                 absent, ""),
                                (Sparc_Assembly.LOAD_AND_STORE
                                 (Sparc_Assembly.ST, MachTypes.G0,
                                  MachTypes.gc1, Sparc_Assembly.IMM (~4)),
                                 absent, "Zero the extra word"),
                                (Sparc_Assembly.BRANCH_ANNUL
                                 (Sparc_Assembly.BAA, 0), MirTypes.PRESENT after_gc_tag,
                                 "Jump to rest of block after gc")]),
                              (after_gc_tag, 
                               do_header_for_variable_size_reference(lookup_gp_operand size,
                                                                     18,
                                                                     split_tag))] @@
                                  final_result)
		       | MirTypes.ALLOC_REAL =>
			   let
			     val real_size =
			       (case MachTypes.fp_used of
				  MachTypes.single => 4
				| MachTypes.double => 12
				| MachTypes.extended => 20)
			   in
			     (do_allocate_immediate after_gc_tag, [],
			      MirTypes.BLOCK(split_tag, opcode_list) ::
			      block_list,
			      (after_gc_tag,
			       do_header (10 + 64 * 12, split_tag)) ::
			      final_result)
			   end
		     end
@


1.101
log
@Added parameter to RAISE once again, and changed leaf-case raise
to fetch from that parameter.
@
text
@d4 4
d1548 25
a1572 2
                  (output(std_out,"****** mach_cg TBINARYFP - not defined so ignoring \n");
                   ([], opcode_list, block_list, final_result))
d1575 32
a1606 3
                  (output(std_out,"****** mach_cg TUNARYFP - not defined so ignoring \n");
                   ([], opcode_list, block_list, final_result))

@


1.100
log
@Added stuff to pass through interpretive externals,
and split raise code into leaf and non-leaf cases
@
text
@d4 4
d2685 1
a2685 1
		 | MirTypes.RAISE =>
d2698 5
a2702 1
			   Sparc_Assembly.nop]
d2725 1
a2725 1
			     MachTypes.callee_arg),
d2727 2
@


1.99
log
@Allowed leaf case raise. Doesn't work yet because of mirtables
@
text
@d4 3
d2682 40
a2721 19
		     ([(Sparc_Assembly.LOAD_AND_STORE
			(Sparc_Assembly.LD, MachTypes.global,
			 MachTypes.implicit,
			 Sparc_Assembly.IMM (4 * Implicit_Vector.raise_code)),
			absent, "Do all the work of getting to the handler"),
		     (Sparc_Assembly.SAVE_AND_RESTORE
		      (Sparc_Assembly.SAVE, MachTypes.sp,
		       Sparc_Assembly.IMM ~64, MachTypes.sp),
		      absent, "Create new frame for raise"),
		       (Sparc_Assembly.JUMP_AND_LINK
			(Sparc_Assembly.JMPL, MachTypes.lr,
			 Sparc_Assembly.REG MachTypes.global, MachTypes.G0),
			absent, "Raise"),
		       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			(Sparc_Assembly.ADD, MachTypes.caller_arg,
			 Sparc_Assembly.REG MachTypes.G0,
			 MachTypes.callee_arg),
			absent,"Move arg to raise into arg reg")],
		     opcode_list, block_list, final_result)
d3177 9
a3185 5
      val ext_elements =
	Timer.xtime
	("generating external elements", !do_timings,
	 fn () => 
	 map (fn (x, y) => MachTypes.EXTERNAL(y, x)) ext_refs)
d3189 5
a3193 1
			 ext_elements)
@


1.98
log
@Enabled leaf case allocation.
@
text
@d4 3
d2684 4
d2692 6
a2697 2
		       Sparc_Assembly.nop],
		      opcode_list, block_list, final_result)
d2809 1
d2811 1
@


1.97
log
@Changed stack overflow check to be unsigned.
Added (temporary) handling for externals defined by interpreter
@
text
@d4 4
d1993 1
a1993 2
			   (MachTypes.lr, Implicit_Vector.gc)
		       (* Temporarily changed back *)
a2800 12
	  fun check_instr'(MirTypes.BRANCH_AND_LINK _) = true
	    | check_instr'(MirTypes.ALLOCATE _) = true
(*
	    | check_instr'(MirTypes.PROFILER _) = true
*)
	    | check_instr'(MirTypes.TAIL_CALL _) = true
	    | check_instr' MirTypes.CALL_C = true
	    | check_instr'(MirTypes.SWITCH _) = true
	    | check_instr'(MirTypes.ADR _) = true
	    | check_instr' MirTypes.RAISE = true
	    | check_instr' _ = false

a2803 3
	  fun check_instr_block'(MirTypes.BLOCK(_, instr_list)) =
	    Lists.exists check_instr' instr_list

d2828 1
a2828 15
	    (let
(*
	       val _ = Print.print"Checking instructions\n"
*)
	       val frame = Lists.exists check_instr_block block_list
	       val had_frame = Lists.exists check_instr_block' block_list
	     in
	       ((if had_frame andalso not frame then
		   Print.print
		   ("Converting non-leaf procedure " ^
		    procedure_name ^ " to leaf\n")
		 else
		   ());
		   had_frame)
	     end)
@


1.96
log
@Improved profiling so as not to affect leafness
Removed various redundant loads (should be expression analyser)
@
text
@d4 4
d1056 6
a1061 1
  fun mach_cg(MirTypes.CODE(MirTypes.REFS(loc_refs, ext_refs),
d1064 2
a1065 2
	      non_gc_map,
	      fp_map)) =
d2571 3
a2573 2
			      (Sparc_Assembly.BGEA, 0),
			      MirTypes.PRESENT ov_tag, ""),
@


1.95
log
@Changed gc_trans to deal with new types returned by MirTables.
@
text
@d4 3
a1973 1
(*
d1976 6
a1981 243
		       val (immediatep,i) =
			 (case (size,allocate) of 
			    (MirTypes.GP_IMM_INT x,_) => (true,x)
			  | (MirTypes.GP_GC_REG _,MirTypes.ALLOC_REF) => (false,0)
			  | _ => Crash.impossible
			      "Allocate has non-constant or non-garbage collectable reg")
		       val rd = lookup_reg_operand reg_operand
		       val (size_in_bytes, ptr_tag, needs_to_zero_a_word,offset_of_word_to_zero) =
			 case allocate of
			   MirTypes.ALLOC =>
			     if i = 2 
                               then (8, 1,false,0) 
                             else (8 * ((i + 2) div 2), 5, (i mod 2) = 0,4*i -1)
			 | MirTypes.ALLOC_STRING =>
			     (((i + 12) div 8) * 8, 5,false,0)
			 | MirTypes.ALLOC_REAL =>
			     (case MachTypes.fp_used of
				MachTypes.single =>
				  Crash.unimplemented"ALLOC_REAL single"
			      | MachTypes.double => (16, 5,false,0)
			      | MachTypes.extended =>
				  Crash.unimplemented"ALLOC_REAL extended")
			 | MirTypes.ALLOC_REF => 
                             (12 + 4*i +  4 * (1 - (i mod 2)), 3,i mod 2 = 0,(i*4) + 9)

                       val clear_extra_alignment_words =
                         (if immediatep andalso needs_to_zero_a_word
                            then
                              [(Sparc_Assembly.LOAD_AND_STORE
                                (Sparc_Assembly.ST, MachTypes.G0,
                                 rd, Sparc_Assembly.IMM offset_of_word_to_zero),
                                absent, "Zero the alignment word")]
                          else 
                            [])

		       fun do_allocate goto_tag goto_tag' =
			 ((if immediatep
			     then
			       [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				 (Sparc_Assembly.ADD, MachTypes.gc1,
				  Sparc_Assembly.IMM size_in_bytes,
				  MachTypes.gc1),
				 absent, "Calculate new heap start")]
			       else
			       [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				 (Sparc_Assembly.ADD, MachTypes.gc1,
				  Sparc_Assembly.REG(lookup_gp_operand size),
				  MachTypes.gc1),
				 absent, "Calculate new heap start"),
                                (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				 (Sparc_Assembly.ADD, MachTypes.gc1,
				  Sparc_Assembly.IMM( 12),
				  MachTypes.gc1),
				 absent, "")]) @@
			 [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.SUBCC, MachTypes.G0,
			    Sparc_Assembly.REG(MachTypes.gc2), MachTypes.gc1),
			   absent, "Check if collection needed"),
			  (Sparc_Assembly.BRANCH_ANNUL
			   (Sparc_Assembly.BLA, 0), MirTypes.PRESENT goto_tag,
			   "Don't do next instruction if gc is required")] @@
			 (if immediatep
			    then [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				   (Sparc_Assembly.ADD, rd,
				    Sparc_Assembly.IMM(ptr_tag - size_in_bytes),
				    MachTypes.gc1),
				   absent, "Generate tagged result")]
			      else
				[(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, rd,
				   Sparc_Assembly.IMM(ptr_tag),
				   MachTypes.gc1),
				  absent, "Generate tagged result")]) @@
			  [(Sparc_Assembly.LOAD_AND_STORE
			   (Sparc_Assembly.LD, MachTypes.global,
			    MachTypes.implicit, Sparc_Assembly.IMM (4 * Implicit_Vector.gc)),
			   absent, "Get address of callgc")] @@
                          (if immediatep
                             then []
                           else [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, MachTypes.global,
				   Sparc_Assembly.REG(lookup_gp_operand size), MachTypes.G0),
				   absent, "Setup callgc argument")]) @@
			  [(Sparc_Assembly.JUMP_AND_LINK
			   (Sparc_Assembly.JMPL, MachTypes.lr,
			    Sparc_Assembly.IMM 0, MachTypes.global),
			   absent, "Do callgc")] @@
			  [if immediatep
			     then (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				   (Sparc_Assembly.ADD, MachTypes.global,
				    Sparc_Assembly.IMM size_in_bytes, MachTypes.G0),
				   absent, "Setup callgc argument")
			   else  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, MachTypes.global,
				   Sparc_Assembly.IMM 12, MachTypes.global),
				   absent, "Add in the extra bytes")] @@
			  [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.ADD, rd,
			    Sparc_Assembly.IMM ptr_tag, MachTypes.global),
			   absent, "Tag result of garbage collection")]
                          @@
                          (if immediatep
                            then
                              [(Sparc_Assembly.BRANCH_ANNUL
                                (Sparc_Assembly.BAA, 0), MirTypes.PRESENT goto_tag',
                                "Jump to rest of block after gc"),
                               Sparc_Assembly.nop]
                          else
                            (* Check for the extra word to be zeroed *)
                            [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                              (Sparc_Assembly.ANDCC, MachTypes.G0,
                               Sparc_Assembly.IMM 4, MachTypes.gc1),
                              absent, "Is the gc address aligned ?"),
                            (Sparc_Assembly.BRANCH_ANNUL
                             (Sparc_Assembly.BEA, 0),
                             MirTypes.PRESENT goto_tag', ""),
                            Sparc_Assembly.nop,
                            (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                             (Sparc_Assembly.ADD, MachTypes.gc1,
                              Sparc_Assembly.IMM 4, MachTypes.gc1),
                             absent, ""),
                            (Sparc_Assembly.BRANCH_ANNUL
                             (Sparc_Assembly.BAA, 0), MirTypes.PRESENT goto_tag',
                             "Jump to rest of block after gc"),
                            (Sparc_Assembly.LOAD_AND_STORE
                             (Sparc_Assembly.ST, MachTypes.G0,
                              MachTypes.gc1, Sparc_Assembly.IMM (~4)),
                             absent, "Zero the extra word")]))

		       fun do_header(header,goto_tag) =
                         clear_extra_alignment_words @@
			 (if check_range(header,true,arith_imm_limit)
			    then
			      [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, MachTypes.global,
				 Sparc_Assembly.IMM header, MachTypes.G0),
				absent, "Generate header word value")]
			  else				    
			    load_large_number_into_register(MachTypes.global,header))
			      @@
			    [(Sparc_Assembly.LOAD_AND_STORE
                              (Sparc_Assembly.ST, MachTypes.global,
			    rd, Sparc_Assembly.IMM (~ptr_tag)),
			   absent, "Store the header word"),
			  (Sparc_Assembly.BRANCH_ANNUL
			   (Sparc_Assembly.BAA, 0), MirTypes.PRESENT goto_tag,
			   "Jump to rest of block after doing header")
			  ]

		       fun do_header_from_reg (reg,tag,goto_tag) =
                         clear_extra_alignment_words @@
                         [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                           (Sparc_Assembly.SLL, MachTypes.global,
                            Sparc_Assembly.IMM 4, reg),
                           absent, "Generate header word value"),
                         (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                           (Sparc_Assembly.ADD, MachTypes.global,
                            Sparc_Assembly.IMM tag, MachTypes.global),
                           absent, "Generate header word value"),
                         (Sparc_Assembly.LOAD_AND_STORE
                          (Sparc_Assembly.ST, MachTypes.global,
                           rd, Sparc_Assembly.IMM (~ptr_tag)),
                          absent, "Store the header word"),
                         (Sparc_Assembly.BRANCH_ANNUL
                          (Sparc_Assembly.BAA, 0), MirTypes.PRESENT goto_tag,
                          "Jump to rest of block after doing header")
                         ]

		       val (split_tag, after_gc_tag,extra_addition_tag) =
			 (MirTypes.new_tag(), MirTypes.new_tag(),MirTypes.new_tag())
		     in
		       case allocate of
			 MirTypes.ALLOC =>
			   if i = 2 then
			     (do_allocate split_tag split_tag, [],
			      MirTypes.BLOCK(split_tag, opcode_list) ::
			      block_list,
			      final_result)
			   else
			     (do_allocate after_gc_tag after_gc_tag, [],
			      MirTypes.BLOCK(split_tag, opcode_list) ::
			      block_list,
			      (after_gc_tag,
			       do_header (2 + 64 * i, split_tag)) ::
			      final_result)
		       | MirTypes.ALLOC_STRING =>
			   (do_allocate after_gc_tag after_gc_tag, [],
			    MirTypes.BLOCK(split_tag, opcode_list) ::
			    block_list,
			    (after_gc_tag,
			     do_header (10 + 64 * i, split_tag)) ::
			    final_result)
		       | MirTypes.ALLOC_REF =>
			   ((if immediatep 
			       then 
                                 (do_allocate after_gc_tag after_gc_tag)
			     else 
			       (do_allocate extra_addition_tag after_gc_tag)) , [],
                               [MirTypes.BLOCK(split_tag, opcode_list)] @@ block_list,
                               (if immediatep
                                  then []
                                else [(extra_addition_tag,
                                       [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                         (Sparc_Assembly.SUB, rd,
                                          Sparc_Assembly.REG(lookup_gp_operand size),
                                          rd),
                                         absent, ""),
                                       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                                         (Sparc_Assembly.SUB, rd,
                                          Sparc_Assembly.IMM( 12 ),
                                          rd),
                                         absent, ""),
                                       (Sparc_Assembly.BRANCH_ANNUL
                                        (Sparc_Assembly.BAA, 0),
                                        MirTypes.PRESENT after_gc_tag, ""),
                                       Sparc_Assembly.nop])]) @@
                                  [(after_gc_tag, 
                                    if immediatep
                                      then do_header (i * 64 + 18, split_tag)
                                    else
                                      do_header_from_reg(lookup_gp_operand size,
                                                         18,
                                                         split_tag))] @@
                                  final_result)
		       | MirTypes.ALLOC_REAL =>
			   let
			     val real_size =
			       (case MachTypes.fp_used of
				  MachTypes.single => 4
				| MachTypes.double => 12
				| MachTypes.extended => 20)
			   in
			     (do_allocate after_gc_tag after_gc_tag, [],
			      MirTypes.BLOCK(split_tag, opcode_list) ::
			      block_list,
			      (after_gc_tag,
			       do_header (10 + 64 * 12, split_tag)) ::
			      final_result)
			   end
		     end
*)
		 | MirTypes.ALLOCATE(allocate, reg_operand, size) =>
		     let
d2037 1
a2037 1
                           MachTypes.implicit, Sparc_Assembly.IMM (4 * Implicit_Vector.gc)),
d2040 1
a2040 1
                          (Sparc_Assembly.JMPL, MachTypes.lr,
d2080 1
a2080 1
                           MachTypes.implicit, Sparc_Assembly.IMM (4 * Implicit_Vector.gc)),
d2083 1
a2083 1
                          (Sparc_Assembly.JMPL, MachTypes.lr,
d2231 71
d2303 36
a2338 38
		     ([(Sparc_Assembly.LOAD_AND_STORE
                        (Sparc_Assembly.LD,temp,
                         MachTypes.callee_closure,Sparc_Assembly.IMM ~1),
                        absent,"Get the existing call count field"),
                     (Sparc_Assembly.LOAD_AND_STORE
                      (Sparc_Assembly.LD,temp,temp,Sparc_Assembly.IMM 3),
                      absent,""),
                     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                      (Sparc_Assembly.SUBCC, MachTypes.G0,
                       Sparc_Assembly.REG(MachTypes.G0), temp),
                      absent, "Is the field set ?"),
                     (Sparc_Assembly.BRANCH_ANNUL
			      (Sparc_Assembly.BEA, 0),
			      MirTypes.PRESENT register_tag, ""),
                     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                      (Sparc_Assembly.ADD,MachTypes.caller_arg,
                       Sparc_Assembly.REG MachTypes.G0,
                       MachTypes.callee_closure),
                      absent,""),
                     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                      (Sparc_Assembly.ANDCC, MachTypes.G0,
                      Sparc_Assembly.IMM 3, temp),
                     absent, "Is the address aligned ?"),
                     (Sparc_Assembly.BRANCH_ANNUL
                      (Sparc_Assembly.BEA, 0),
                      MirTypes.PRESENT increment_tag, ""),
                     (Sparc_Assembly.LOAD_AND_STORE
                      (Sparc_Assembly.LD,MachSpec.global,temp,Sparc_Assembly.IMM 0),
                      absent,""),
                     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
                      (Sparc_Assembly.ADD,temp,Sparc_Assembly.IMM 0,MachTypes.G0),
                      absent,""),
                     (Sparc_Assembly.BRANCH_ANNUL
                      (Sparc_Assembly.BAA, 0), MirTypes.PRESENT after_profiling,
                      "Jump to rest of block after profiling"),
                     Sparc_Assembly.nop],
                     [] , 
                     MirTypes.BLOCK(after_profiling,opcode_list) :: block_list, 
d2341 2
a2342 1
                        (Sparc_Assembly.ADD,MachSpec.global,Sparc_Assembly.IMM 1,MachSpec.global),
d2344 9
a2352 21
                       (Sparc_Assembly.LOAD_AND_STORE
                      (Sparc_Assembly.ST,MachSpec.global,temp,Sparc_Assembly.IMM 0),
                        absent,""),
                       (Sparc_Assembly.BRANCH_ANNUL
                        (Sparc_Assembly.BAA, 0), MirTypes.PRESENT after_profiling,
                        "Jump to rest of block after profiling"),
                       Sparc_Assembly.nop]) ::
                      (register_tag,
                       [(Sparc_Assembly.LOAD_AND_STORE
                         (Sparc_Assembly.LD, MachTypes.global,
                          MachTypes.implicit, Sparc_Assembly.IMM (4 * Implicit_Vector.profiler)),
                         absent, "Get address of profiler"),
                       (Sparc_Assembly.JUMP_AND_LINK
                        (Sparc_Assembly.JMPL, MachTypes.lr,
                         Sparc_Assembly.IMM 0, MachTypes.global),
                       absent, "Do profiling"),
                      Sparc_Assembly.nop,
                      (Sparc_Assembly.BRANCH_ANNUL
                      (Sparc_Assembly.BAA, 0), MirTypes.PRESENT after_profiling,
                      "Jump to rest of block after profiling"),
                      Sparc_Assembly.nop]) :: final_result)
d2774 42
d2817 1
d2819 8
a2826 4
	     ch (fn r => MachTypes.check_reg(Map.apply'(fp_map, r))) fp
	     orelse
	     ch (fn r => MachTypes.check_reg(Map.apply'(gc_map, r))) gc
	     orelse
d2828 17
a2844 1
		 MachTypes.check_reg(Map.apply'(non_gc_map, r))) non_gc
d2846 6
d2940 21
d2991 1
@


1.94
log
@Fixed problem in enter coding to ensure stack slots cleared.
@
text
@d4 3
d1074 6
a1079 12
      fun gcs_only x =
	map
	(fn (MirTypes.GC x) => x | _ => Crash.impossible"Non-gc in gcs_only")
	(Lists.filterp
	 (fn (MirTypes.GC _) => true | _ => false)
	 x)

      val applied_gc_map = Map.apply gc_map
      fun gc_trans x =
	Set.list_to_set
	(map (fn x => applied_gc_map x)
	 (gcs_only(Set.set_to_list x)))
d1082 9
a1090 8
      | get_refs MirTypes.RTS = Set.empty_set
      | get_refs(opcode as (MirTypes.ADR _)) =
	Set.union(Set.singleton MachTypes.lr,
		  gc_trans(Set.union(MirTables.referenced_by opcode,
				     MirTables.defined_by opcode)))
      | get_refs opcode =
	gc_trans(Set.union(MirTables.referenced_by opcode,
			   MirTables.defined_by opcode))
@


1.93
log
@Added memory profiling
@
text
@d4 3
d409 3
a411 1
  val call_disp_limit = 32 * 256 * 256 * 256 (* 2 ** 29 *)
d672 2
d679 1
a679 1
	    #2 (Map.apply proc_info block_tag)
d702 1
a702 1
                          (Map.apply tag_tree x; false)
d741 1
a741 1
            (case Map.apply proc_info tag
d815 3
a817 1
	  fun lookup_env tag = Map.apply tag_env tag
d883 8
d892 1
a892 1
			fault_range((lookup_env tag - offset) div 4,
d902 9
a910 1
		      val disp = lookup_env tag - offset - i
d946 1
a946 1
			      Sparc_Assembly.IMM(i - 4), rd),
d974 1
a974 1
			((lookup_env tag - offset - i) mod 1024,
d986 1
a986 1
		      val disp = lookup_env tag - offset - i
d1078 1
d1081 1
a1081 1
	(map (fn x => Map.apply gc_map x)
d1217 1
a1217 1
		  val reg = Map.apply table reg
d1236 1
a1236 1
	      Map.apply fp_map reg
d1340 2
d2455 1
a2455 1
			 Sparc_Assembly.IMM ~4, MachTypes.lr),
d2458 4
a2461 1

d2590 6
d2598 2
a2599 1
			     do_store(the_reg, the_offset, no_of_stores, [])
d2708 2
a2709 4
			 val non_ov_tag = MirTypes.new_tag() (* None overflow case *)
			 val join_tag = case opcode_list of
			   [] => end_tag
			 | _ => MirTypes.new_tag()
d2711 2
a2712 1
			 val offset_from_bottom_of_stack_buffer = 2048 (* yeh advised number *)
d2714 3
d2794 2
a2795 1
			       MirTypes.BLOCK(join_tag,opcode_list) :: block_list),
d2955 1
a2955 1
	     ch (fn r => MachTypes.check_reg(Map.apply fp_map r)) fp
d2957 1
a2957 1
	     ch (fn r => MachTypes.check_reg(Map.apply gc_map r)) gc
d2960 1
a2960 1
		 MachTypes.check_reg(Map.apply non_gc_map r)) non_gc
@


1.92
log
@Fixed up discrepancy between split_int and gp_check_range
@
text
@d4 3
d396 1
d2733 15
d2749 1
a2749 1
			 (check_for_stack_overflow_wrap,
@


1.91
log
@Added bool ref do_timings to control printing of timings for various stages
@
text
@d4 3
d1130 2
a1131 1
	    ((i div (1024 div 4)) mod (256 * 256 * 64), (i mod (1024 div 4))*4)
d1133 1
a1133 1
	    ((i div 1024) mod (256 * 256 * 64), i mod 1024)
d1138 1
a1138 1
	      ((i div 1024) mod (256 * 256 * 64), i mod 1024)
@


1.90
log
@Changed BalancedTree to generic Map
@
text
@d4 3
d389 1
a389 1
  val do_timings = false
d782 1
a782 1
	("reordering blocks", do_timings,
d3013 1
a3013 1
	    ("main proc_cg stage", do_timings,
d3030 1
a3030 1
	    ("removing redundant saves", do_timings,
d3045 1
a3045 1
		("rescheduling blocks", do_timings,
d3062 1
a3062 1
		("rescheduling procs", do_timings,
d3098 1
a3098 1
	    ("rescheduling", do_timings,
d3108 1
a3108 1
	    ("linearising", do_timings,
d3182 1
a3182 1
	("generating external elements", do_timings,
@


1.89
log
@With the addition of the extra slots in the code and the addition of diagnostic information,
the tag offset calculations needed to be changed
@
text
@d4 4
a326 1
require "../utils/balancedtree";
a352 1
   structure BalancedTree : BALANCEDTREE
d574 1
a574 1
	((BalancedTree.insert(main_tree, block_tag, (block, last_tag_exists)),
d576 1
a576 1
	    BalancedTree.insert(tag_tree, tag, 0)
d581 2
a582 7
    if MirTypes.equal_tag arg then
      BalancedTree.EQ
    else
      if MirTypes.order_tag arg then
	BalancedTree.LT
      else
	BalancedTree.GT
d655 1
a655 2
	make_proc_info((BalancedTree.empty tag_order,
			BalancedTree.empty tag_order), block_list)
d662 2
a663 3
	    case BalancedTree.lookup(proc_info, block_tag) of
	      BalancedTree.YES(_, last_tag_exists) => last_tag_exists
	    | _ => (block_tag, false)
d685 2
a686 3
			  case BalancedTree.lookup(tag_tree, x) of
			    BalancedTree.YES _ => false
			  | _ => true)
d724 4
a727 3
	    case BalancedTree.lookup(proc_info, tag) of
	      BalancedTree.YES(_, (_, true)) => true
	    | _ => false
d757 1
a757 1
		    BalancedTree.insert(tag_env, tag, disp))
d788 1
a788 1
					     BalancedTree.empty tag_order)
d795 1
a795 1
		      (BalancedTree.to_alist tag_env) ;
d798 2
a799 4
	  fun lookup_env tag =
	    case BalancedTree.lookup(tag_env, tag) of
	      BalancedTree.YES i => i
	    | _ => raise Lists.Assoc
@


1.88
log
@Redid the reorderer for the lineariser efficiently
@
text
@d4 3
d747 1
a747 1
  fun linearise_list proc_list =
d764 4
a767 2
      fun tag_offsets_for_list(_, [], env) = env
      | tag_offsets_for_list(offset, (_, proc) :: rest, env) =
d771 7
a777 4
	  val next_offset' =
	    if next_offset mod 8 = 4
	      then next_offset + 12
	    else next_offset+8
d779 1
a779 1
	  tag_offsets_for_list(next_offset', rest, env)
d789 1
a789 1
      fun do_linearise proc_list =
d792 1
a792 1
	  val tag_env = tag_offsets_for_list(0, proc_list,
d983 1
a983 1
	  | do_linearise_sub(offset, (tag, proc) :: rest) =
d988 5
a992 4
		val offset'' =
		  if offset' mod 8 = 4
		    then offset' + 4
		  else offset'
d994 1
a994 2
	      (* CT The difference is now offset'' + 8 was offset' + 4 *)
	      (tag, done') :: do_linearise_sub(offset'' + 8, rest)
d1010 1
a1010 1
	  do_linearise_sub(0, proc_list)
d1012 1
a1012 1
	    do_linearise(subst_bad_adr_block(proc_list, bad_adr_block))
d1015 1
a1015 1
      do_linearise new_proc_list
d2971 11
d2985 2
a2986 1
           procedure_name)
d3022 1
d3113 1
a3113 1
	     fn () => linearise_list new_code_list')
d3138 2
a3139 7
	    let
	      fun splice ([],[]) = []
		| splice (h::t,a::b) = (h,a):: splice(t,b)
		| splice (_,_) = Crash.impossible "splice problem in _Mach_Cg_"
	    in
	      (map
	       (fn (((tag, code),spills),name) =>
a3149 4
                   fun normalise_to_four_bytes (x) = 
                     x ^ generate_nulls((4 - ((size x) mod 4)) mod 4)
                   val padded_name = 
                     normalise_to_four_bytes(name ^ chr(0))
d3163 1
a3163 1
	       (splice(splice(linear_code,spill_size_list),procedure_name_list)))
a3164 1
	    end
@


1.87
log
@Fixed bug in array allocation: if a gc occurred inside the allocation, 2 words too few were allocated
Also added function name printing to the sparc code output
@
text
@d4 4
d312 1
d320 1
d340 1
d347 1
d381 2
d560 83
d648 9
a656 11
      val null_block = (proc_tag, [])
      (* CT this now works on the continuer and non-continuer lists in turn *)
      fun find_dest_block(_, [], [], x,y) = (null_block, false, x,y)
        | find_dest_block(dest_tag,
                          (block as (block_tag, opcode_list)) ::
                          rest,
                          other,
                          x , [] ) =
          if dest_tag = block_tag then
            (block, true, x @@ rest, other)
          else find_dest_block(dest_tag, rest, other, block :: x,[])
a657 33
        | find_dest_block(dest_tag,
                          [],
                          (block as (block_tag, opcode_list)) ::
                          rest,
                          x , y ) =
          if dest_tag = block_tag then
            (block, true, x , y @@ rest)
          else find_dest_block(dest_tag, [], rest, x, block :: y)
            
        | find_dest_block _ = Crash.impossible "This should never happen in _mach_cg "

      fun do_fall_throughs(done, block, []) = rev(block :: done)
      | do_fall_throughs(done, block,rest) =
	let
	  fun continues(_, x) =
	    let
	      fun sub_cont [] = false
                | sub_cont [(Sparc_Assembly.BRANCH_ANNUL _, _, _)] = true
                | sub_cont [_] = false
                | sub_cont[(Sparc_Assembly.BRANCH _, _, _), _] = true
                | sub_cont[(Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
                            _, _), _] = true
                | sub_cont(_ :: rest) = sub_cont rest
	    in
	      sub_cont x
	    end
          
	   val (continuers,non_continuers) =
             Lists.partition continues rest 
        in
          do_fall_throughs_with_continuers_calculated(done,block,continuers,non_continuers)
        end
      
d659 1
a659 1
      and do_fall_throughs_with_continuers_calculated(done, (block as (block_tag, opcode_list)),
d662 4
a665 20
	  fun continue_tags(acc,(_, x)) =
	    let
	      fun sub_cont (acc,[]) = acc
                | sub_cont (acc,[(Sparc_Assembly.BRANCH_ANNUL _, MirTypes.PRESENT tag,
                             _)]) = tag::acc
                | sub_cont (acc,[_]) = acc
                | sub_cont(acc,[(Sparc_Assembly.BRANCH _, MirTypes.PRESENT tag, _),
                            _]) = tag::acc
                (* Treat computed GOTO specially *)
                | sub_cont(acc,[(Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
                             MirTypes.PRESENT _, _),
                            (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
                             MirTypes.PRESENT tag, _)]) = tag::acc
                | sub_cont(acc,[(Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
                             MirTypes.PRESENT tag, _),
                            _]) = tag::acc
                | sub_cont(acc,_ :: rest) = sub_cont (acc,rest)
	    in
	      sub_cont (acc,x)
	    end
a666 16
	  fun last_tag opcode_list =
	    let
	      val (last_opcode, is_ok) = last_opcode opcode_list
	    in
	      case (last_opcode, is_ok) of
		((Sparc_Assembly.BRANCH _, MirTypes.PRESENT dest_tag, _),
		 true) =>
		  (dest_tag, true)
		| ((Sparc_Assembly.BRANCH_ANNUL _, MirTypes.PRESENT dest_tag,
		    _),
		   true) =>
		  (dest_tag, true)
		| _ => (block_tag, false)
	    end
	  val (dest_tag, found_block) = last_tag opcode_list

d674 2
a675 2
	      [] => 
                (rev done) @@ (block :: non_continuers)
d678 22
a699 14
		  val exit_tags =
		    Lists.reducel( fn (x,y) => continue_tags(x,y))  ([],continuers)
		  val heads =
		    Lists.filterp (fn (x) => not(Lists.member(x,exit_tags))) 
                    (map #1 continuers)
		  val (next_block, continuers', non_continuers') = case heads of
		    [] => (Lists.hd continuers, (Lists.tl continuers),
			   non_continuers)
		  | tag :: _ =>
                      let
                        val (others,value) = Lists.assoc_returning_others(tag,continuers)
                      in
                        ((tag, value),others , non_continuers)
                      end
d701 4
a704 2
		  do_fall_throughs_with_continuers_calculated(block :: done, next_block, 
                                                              continuers', non_continuers')
a710 15
	      fun remove_trailing_branch(block_tag, opcode_list) =
		let
		  val rev_opc = rev opcode_list
		  val new_opc = case rev_opc of
		    (Sparc_Assembly.BRANCH_ANNUL _, _, _) :: rest => rest
		  | (operation, opt, comment) ::
		    (Sparc_Assembly.BRANCH _, _, _) :: rest =>
		    (operation, opt, comment ^ " preceding BA removed") :: rest
		  | _ :: (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
			  _, _) :: rest => rest
		  | _ =>
		      Crash.impossible"Remove trailing branch fails"
		in
		  (block_tag, rev new_opc)
		end
d713 3
a715 2
		do_fall_throughs_with_continuers_calculated(remove_trailing_branch block :: done,
				 dest_block, continuers', non_continuers')
d717 1
a717 1
		do_next()
d720 1
a720 1
	    do_next()
d722 15
d746 10
d758 5
a762 3
	tag_offsets(rest, disp + 4 * (Lists.length ho_list), (tag, disp) :: tag_env)
      fun tag_offsets_for_list(_, []) = []
      | tag_offsets_for_list(offset, (_, proc) :: rest) =
d764 1
a764 1
	  val (next_offset, env_so_far) = tag_offsets(proc, offset, [])
d766 4
a769 4
	    val next_offset' =
	      if next_offset mod 8 = 4
		then next_offset + 12
	      else next_offset+8
d771 1
a771 1
	  env_so_far @@ tag_offsets_for_list(next_offset', rest)
d774 4
a777 1
      val new_proc_list = map reorder_blocks proc_list
d784 2
a785 1
	  val tag_env = tag_offsets_for_list(0, proc_list)
d792 1
a792 1
		      tag_env ;
d795 14
a808 1
	  fun linearise_proc(offset, [], done) = (offset, done)
d814 1
a814 1
	      fun do_block(block_start, (block_tag, opcode_list)) =
d820 1
a820 1
			fault_range((Lists.assoc(tag, tag_env) - offset) div 4,
d831 1
a831 1
			fault_range((Lists.assoc(tag, tag_env) - offset) div 4,
d842 1
a842 1
			fault_range((Lists.assoc(tag, tag_env) - offset) div 4,
d853 1
a853 1
			fault_range((Lists.assoc(tag, tag_env) - offset) div 4,
d864 1
a864 1
			fault_range((Lists.assoc(tag, tag_env) - offset) div 4,
d874 1
a874 1
		      val disp = Lists.assoc(tag, tag_env) - offset - i
d938 1
a938 1
			((Lists.assoc(tag, tag_env) - offset - i) mod 1024,
d950 1
a950 1
		      val disp = Lists.assoc(tag, tag_env) - offset - i
d967 1
a967 1
		  (map do_opcode opcodes_and_offsets, next)
d969 1
a969 1
	      val (this_block, next) = do_block(start, block)
d971 1
a971 1
	      linearise_proc(next, block_list, done @@ this_block)
d1933 1
d2176 233
d2996 3
a2998 1
	    map proc_cg proc_list
d3011 4
a3014 1
	  val code_list' = map Save.remove_redundant_saves code_list
d3027 9
a3035 6
		map
		(fn (proc_tag, proc) =>
		 (proc_tag, map
		  (fn (tag, x) => (tag, Sparc_Schedule.reschedule_block x))
		  proc))
		code_list
d3043 4
a3046 1
	      val code_list'' = map Sparc_Schedule.reschedule_proc code_list'
d3079 4
a3082 1
	  val new_code_list' = do_reschedule code_list'
d3089 4
a3092 1
	  val linear_code' = linearise_list new_code_list'
d3174 4
a3177 1
	map (fn (x, y) => MachTypes.EXTERNAL(y, x)) ext_refs
@


1.86
log
@First version of the profiler
@
text
@d4 3
d396 5
a400 1
      (diagnostic_output 1 (fn _ => ["fault_range called with value " ^ Integer.makestring i]) ;
a1699 5
		    val reg_or_imm =
		      if is_reg gp_op' then
			Sparc_Assembly.REG(lookup_gp_operand gp_op')
		      else
			make_imm_format3 gp_op'
d1705 27
a1731 8
		    ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		       (test_instr, MachTypes.G0,
			reg_or_imm, rs1),
		       absent, "Do the test"),
		      (Sparc_Assembly.BRANCH_ANNUL(branch, 0),
		       MirTypes.PRESENT tag, "Do the branch"),
		      Sparc_Assembly.nop],
		    opcode_list, block_list, final_result)
a1866 4
                 (* NOTE: that if you call this with a register argument, the requested size must
                  be a multiple of 8 when twelve has been added to it for double-word alignment.
                  Size is expected to be integer for all apart from a ALLOC_REF which is taken to 
                  be an array allocation *)
d1945 8
a1952 2
			   absent, "Get address of callgc"),
			  (Sparc_Assembly.JUMP_AND_LINK
d1963 2
a1964 2
				   Sparc_Assembly.REG(lookup_gp_operand size), MachTypes.G0),
				   absent, "Setup callgc argument")] @@
d1968 29
a1996 5
			   absent, "Tag result of garbage collection"),
			  (Sparc_Assembly.BRANCH_ANNUL
			   (Sparc_Assembly.BAA, 0), MirTypes.PRESENT goto_tag',
			   "Jump to rest of block after gc")
			  ])
d2010 1
a2010 1
			   (Sparc_Assembly.ST, MachTypes.global,
d2672 1
a2672 1
	  fun print_unscheduled_code(tag, block_list) =
d2690 1
d2705 2
a2706 1
	    (fn _ => (map print_unscheduled_code code_list;
d2715 2
a2716 1
	    (fn _ => (map print_unscheduled_code code_list' ;
d2731 2
a2732 1
	      val _ = diagnostic_output 3 (fn _ => (map print_unscheduled_code code_list' ;
d2740 1
a2740 1
	  fun print_scheduled_code code_list =
d2742 1
a2742 1
	      fun print_proc(proc_tag, proc) =
d2755 1
a2755 1
		      (Print.print("Block tag " ^ MirTypes.print_tag tag ^ "\n");
d2771 1
a2771 1
	  val _ = diagnostic_output 3 (fn _ => (print_scheduled_code new_code_list' ;
d2779 2
a2780 2
	  fun print_code(tag, code) =
	      (Print.print "[Sparc_Assembly Code]\n";
d2791 2
a2792 1
	       map print_code linear_code');
@


1.85
log
@Removed some pervasive references to hd, length etc. Added a type
specifier to an overloaded use of +. Added error detection for
incorrect stack allocations
@
text
@d4 5
d984 1
a984 1
      fun get_refs_for_proc(MirTypes.PROC(_, _, block_list)) =
d1625 1
a1625 1
			Print.print"Exception tag case not yet handled for FLOOR\n"
d1737 2
a1738 2
		      (Sparc_Assembly.JMPL, MachTypes.lr,  (* CT 3 from ~1 *)
		       Sparc_Assembly.IMM 3, lookup_reg_operand reg_operand),
d1761 1
a1761 2
			       (* CT changed to 3 was 4 and 0 before this *)
			       Sparc_Assembly.IMM 3, lookup_reg_operand reg),
d2071 73
d2518 2
a2519 1
		  (tag, MirTypes.PROC_PARAMS
d2618 2
a2619 1
	   non_gc_stack_size)
d2651 1
d2754 1
a2754 1
	       (fn ((tag, code),spills) =>
d2763 13
d2777 4
a2780 3
		   if (size code) mod 8 = 4
		     then code ^ nop_instruction
		   else code 
d2782 1
a2782 1
	       (splice(linear_code,spill_size_list)))
@


1.84
log
@Forced relinearisation to fix up out of range ADRs to recalculate
the tag table
@
text
@d4 4
d375 1
a375 1
  fun check_range(i, signed, pos_limit) =
d646 2
a647 1
		    [] => (hd continuers, (tl continuers) , non_continuers)
d699 1
a699 1
	tag_offsets(rest, disp + 4 * (length ho_list), (tag, disp) :: tag_env)
d1415 10
d1767 1
a1767 1
		    ((if length tag_list <= 2 then
d1815 12
a1826 1
		  (case allocate of
d2521 1
d2537 1
a2537 1
	    (0, map (fn (_, opcodes) => length opcodes) code)
d2704 1
a2704 1
                   makestring(Lists.reducel( fn(x,MachTypes.WORDSET(MachTypes.WORD_SET tagged_code')) =>
@


1.83
log
@Fixed up problem with out of range ADR instructions by recursing the
lineariser
@
text
@d4 4
a917 8
	  fun do_all proc_list =
	    let
	      val x = do_linearise_sub(0, proc_list)
		handle bad_adr bad_adr_block =>
		  do_all(subst_bad_adr_block(proc_list, bad_adr_block))
	    in
	      x
	    end
d919 3
a921 1
	  do_all proc_list
@


1.82
log
@If there is a word added for double alignment, then this needs to be zeroed out
before it confuses the garbage collector
@
text
@d4 4
d386 1
a386 1
      val res =       Sparc_Assembly.IMM i
d679 3
d683 1
a683 1
      (proc_tag, do_fall_throughs([], hd block_list, tl block_list))
a702 79
      fun linearise_proc(offset, [], done, _) = (offset, done)
      | linearise_proc(start, blocks as (block :: block_list), done, tag_env) =
	let
	  (* Insert algorithm for optimal linearisation of blocks here *)
	  (* Present algorithm just uses the current order *)
	  (* Also assumes NOPs inserted after all control transfers *)
	  fun do_block(offset, (_, opcode_list)) =
	    let
	      fun do_opcode((Sparc_Assembly.BRANCH(branch, i),
			     MirTypes.PRESENT tag, comment), offset) =
		let
		  val disp =
		    fault_range((Lists.assoc(tag, tag_env) - offset) div 4,
				   true, branch_disp_limit)
		    handle Lists.Assoc =>
		      Crash.impossible"Assoc do_opcode branch"
		in
		  (Sparc_Assembly.BRANCH(branch, disp), comment)
		end
	      | do_opcode((Sparc_Assembly.BRANCH_ANNUL(branch, i),
			   MirTypes.PRESENT tag, comment), offset) =
		let
		  val disp =
		    fault_range((Lists.assoc(tag, tag_env) - offset) div 4,
				true, branch_disp_limit)
		    handle Lists.Assoc =>
		      (
		       Crash.impossible"Assoc do_opcode branch_annul")
		in
		  (Sparc_Assembly.BRANCH_ANNUL(branch, disp), comment)
		end
	      | do_opcode((Sparc_Assembly.FBRANCH(branch, i),
			   MirTypes.PRESENT tag, comment), offset) =
		let
		  val disp =
		    fault_range((Lists.assoc(tag, tag_env) - offset) div 4,
				true, branch_disp_limit)
		    handle Lists.Assoc =>
		      Crash.impossible"Assoc do_opcode fbranch"
		in
		  (Sparc_Assembly.FBRANCH(branch, disp), comment)
		end
	      | do_opcode((Sparc_Assembly.FBRANCH_ANNUL(branch, i),
			   MirTypes.PRESENT tag, comment), offset) =
		let
		  val disp =
		    fault_range((Lists.assoc(tag, tag_env) - offset) div 4,
				true, branch_disp_limit)
		    handle Lists.Assoc =>
		      Crash.impossible"Assoc do_opcode fbranch_annul"
		in
		  (Sparc_Assembly.FBRANCH_ANNUL(branch, disp), comment)
		end
	      | do_opcode((Sparc_Assembly.Call(Sparc_Assembly.CALL, i),
			   MirTypes.PRESENT tag, comment), offset) =
		let
		  val disp =
		    fault_range((Lists.assoc(tag, tag_env) - offset) div 4,
				   true, call_disp_limit)
		in
		  (Sparc_Assembly.Call(Sparc_Assembly.CALL, disp), comment)
		end
	      | do_opcode((Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM i, rs1),
			   MirTypes.PRESENT tag, comment), offset) =
		let
		  val disp =
		    make_imm_fault(Lists.assoc(tag, tag_env) - offset - i,
				   true, arith_imm_limit)
		    handle Lists.Assoc =>
		      Crash.impossible"Assoc do_opcode arith"
		in
		  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		   (Sparc_Assembly.ADD, rd, disp, rs1),
		   comment)
		end
	      | do_opcode((opcode, MirTypes.ABSENT, comment), offset) =
		(opcode, comment)
	      | do_opcode _ = Crash.impossible"Bad tagged instruction"
d704 1
a704 2
	      val (opcodes_and_offsets, next) =
		Lists.number_from(opcode_list, offset, 4, fn x => x)
d706 2
a707 7
	    in
	      (map do_opcode opcodes_and_offsets, next)
	    end
	  val (this_block, next) = do_block(start, block)
	in
	  linearise_proc(next, block_list, done @@ this_block, tag_env)
	end
a709 2
	  val new_proc_list =
	      map reorder_blocks proc_list
d711 1
a711 1
	  val tag_env = tag_offsets_for_list(0, new_proc_list)
d721 166
d891 1
a891 1
		linearise_proc(offset, proc, [], tag_env)
d901 21
d923 1
a923 1
	  do_linearise_sub(0, new_proc_list) 
d926 1
a926 1
      do_linearise proc_list
d2614 2
a2615 2
	  val _ = diagnostic_output 1 (fn _ => ["Rescheduled code with save/restore shuffling\n"])
	  val _ =  diagnostic_output 3 (fn _ => (print_scheduled_code new_code_list' ;
d2617 1
d2620 2
@


1.81
log
@Added checking on the use use spill slots. Also avoided using
spill slot 0 as the address of the gc stack area.
@
text
@d4 4
d1724 1
a1724 1
		       val (size_in_bytes, ptr_tag) =
d1727 3
a1729 1
			     if i = 2 then (8, 1) else (8 * ((i + 2) div 2), 5)
d1731 1
a1731 1
			     (((i + 12) div 8) * 8, 5)
d1736 1
a1736 1
			      | MachTypes.double => (16, 5)
d1739 2
a1740 1
			 | MirTypes.ALLOC_REF => (12 + 4*i +  4 * (1 - (i mod 2)), 3)
d1742 10
d1817 1
d1837 1
@


1.80
log
@New pervasive library code
@
text
@d4 3
d887 2
d894 7
d902 1
d907 8
d916 1
d1980 3
a1982 3
			      n_stores(symbolic_value(MirTypes.GC_SPILL_SLOT
						      0),
				       gc_stack_size div 4), (top_tag, []))
d2019 1
a2019 2
				   val the_start =
				     symbolic_value(MirTypes.GC_SPILL_SLOT 0)
@


1.79
log
@Changed register lookup to use Map instead of Table.  See changes in
MirRegisters.  See mirregisters.sml revision 1.13.
@
text
@d4 4
d1266 2
a1267 1
		  Crash.unimplemented"mach_cg TBINARYFP"
d1270 3
a1272 1
		  Crash.unimplemented"mach_cg TUNARYFP"
@


1.78
log
@Tail call to a tag had a baa followed by a restore instead of ba followed by restore
@
text
@d4 3
d280 1
a280 1
require "../utils/table";
d306 1
a306 1
   structure Table : TABLE
d333 1
d336 1
a336 1
  structure Table = Table
d813 3
a815 3
	      (gc_table,
	      non_gc_table,
	      fp_table)) =
d845 1
a845 1
	(map (fn x => Table.lookup(x, gc_table))
d961 1
a961 1
		  val reg = Table.lookup(reg, table)
d968 1
a968 1
	        lookup_reg(reg, gc_table)
d970 1
a970 1
		lookup_reg(reg, non_gc_table)
d973 1
a973 1
	        lookup_reg(reg, gc_table)
d975 1
a975 1
		lookup_reg(reg, non_gc_table)
d980 1
a980 1
	      Table.lookup(reg, fp_table)
d2284 1
a2284 1
	     ch (fn r => MachTypes.check_reg(Table.lookup(r, fp_table))) fp
d2286 1
a2286 1
	     ch (fn r => MachTypes.check_reg(Table.lookup(r, gc_table))) gc
d2289 1
a2289 1
		 MachTypes.check_reg(Table.lookup(r, non_gc_table))) non_gc
@


1.77
log
@Removed obsolete PRESERVE_ALL_REGS and PREVIOUS_ENVIRONMENT
MIR instructions.
@
text
@d4 4
d1603 1
a1603 1
			     (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA,
@


1.76
log
@Tried to speed the file up (factor of 2-3) - removed invariant code
from function calls
@
text
@d4 4
a2140 19

		 | MirTypes.PRESERVE_ALL_REGS =>
		     ([(Sparc_Assembly.LOAD_AND_STORE
                        (Sparc_Assembly.LD, MachTypes.global,
                         MachTypes.implicit, Sparc_Assembly.IMM (4 * Implicit_Vector.preserve)),
                        absent, "Get address of ml_preserve"),
                       (Sparc_Assembly.JUMP_AND_LINK
                        (Sparc_Assembly.JMPL, MachTypes.lr,
                         Sparc_Assembly.IMM 0, MachTypes.global),
                        absent, "Preserve registers"),
                       Sparc_Assembly.nop],
                     opcode_list, block_list, final_result)                     
		 | MirTypes.PREVIOUS_ENVIRONMENT =>
		     ([(Sparc_Assembly.SAVE_AND_RESTORE
			(Sparc_Assembly.RESTORE, MachTypes.G0,
			 Sparc_Assembly.IMM 0,
			 MachTypes.sp), absent,
			"Restore previous environment")],
		      opcode_list, block_list, final_result)
@


1.75
log
@Removed some redundant code
@
text
@d4 3
d334 1
a481 6
(*
  val nop_code =
    Sparc_Assembly.ARITHMETIC_AND_LOGICAL
    (Sparc_Assembly.AND, MachTypes.G0, Sparc_Assembly.IMM 0, MachTypes.G0)
  val nop = (nop_code, absent, "Delay slot")
*)
d509 10
a518 8
      fun find_dest_block(_, [], _) = (null_block, false, [])
      | find_dest_block(dest_tag,
			(block as (block_tag, opcode_list)) ::
			rest,
			done) =
	if dest_tag = block_tag then
	  (block, true, done @@ rest)
	else find_dest_block(dest_tag, rest, block :: done)
d520 10
a529 3
      fun dest_block_exists(_, []) = false
      | dest_block_exists(dest_tag, (block_tag, _) :: rest) =
	dest_tag = block_tag orelse dest_block_exists(dest_tag, rest)
d532 1
a532 2
      | do_fall_throughs(done, (block as (block_tag, opcode_list)),
			 rest as (next :: remainder)) =
a533 16
	  fun last_tag opcode_list =
	    let
	      val (last_opcode, is_ok) = last_opcode opcode_list
	    in
	      case (last_opcode, is_ok) of
		((Sparc_Assembly.BRANCH _, MirTypes.PRESENT dest_tag, _),
		 true) =>
		  (dest_tag, true)
		| ((Sparc_Assembly.BRANCH_ANNUL _, MirTypes.PRESENT dest_tag,
		    _),
		   true) =>
		  (dest_tag, true)
		| _ => (block_tag, false)
	    end
	  val (dest_tag, found_block) = last_tag opcode_list

d546 12
a557 2

	  fun continue_tags(_, x) =
d559 6
a564 6
	      fun sub_cont [] = Set.empty_set
	      | sub_cont [(Sparc_Assembly.BRANCH_ANNUL _, MirTypes.PRESENT tag,
			   _)] = Set.singleton tag
                | sub_cont [_] = Set.empty_set
                | sub_cont([(Sparc_Assembly.BRANCH _, MirTypes.PRESENT tag, _),
                            _]) = Set.singleton tag
d566 1
a566 1
                | sub_cont([(Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
d569 2
a570 2
                             MirTypes.PRESENT tag, _)]) = Set.singleton tag
                | sub_cont([(Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
d572 2
a573 2
                            _]) = Set.singleton tag
                | sub_cont(_ :: rest) = sub_cont rest
d575 1
a575 1
	      sub_cont x
d578 15
a592 4
	  val continuers =
	    Lists.filterp continues rest
	  val non_continuers =
	    Lists.filterp (fn x => not (continues x)) rest
d596 7
a602 1
	      [] => rev(rev rest @@ (block :: done))
a604 1
		  val entry_tags = map #1 continuers
d606 1
a606 4
		    Lists.reducel
		    Set.union
		    (Set.empty_set, map continue_tags continuers)
		  fun isnt_head tag = Set.is_member(tag, exit_tags)
d608 4
a611 3
		    Lists.filterp (fn x => not(isnt_head x)) entry_tags
		  val (next_block, remainder) = case heads of
		    [] => (hd continuers, (tl continuers) @@ non_continuers)
d613 5
a617 4
		      ((tag, Lists.assoc(tag, continuers)),
		       (Lists.filterp
			(fn (t, _) => tag <> t)
			continuers) @@ non_continuers)
d619 2
a620 1
		  do_fall_throughs(block :: done, next_block, remainder)
d625 2
a626 2
	      val (dest_block, found_dest, others) =
		find_dest_block(dest_tag, rest, [])
d644 2
a645 2
		do_fall_throughs(remove_trailing_branch block :: done,
				 dest_block, others)
d2223 11
a2233 9
      fun small_exit_block(MirTypes.BLOCK(tag, opcode_list)) =
	let
	  val list_without_comments =
	    Lists.filterp
	    (fn (MirTypes.COMMENT _) => false | _ => true)
	    opcode_list
	in
	  length list_without_comments <= 2
	end
d2367 1
a2367 1
	  ((tag, code), (* CT removed the padding *)
a2487 2
	  exception splice_error

d2496 1
a2496 1
		| splice (_,_) = raise splice_error
d2518 1
d2524 10
@


1.74
log
@Fixed computed gotos
@
text
@d4 3
d582 1
a2444 4
	  val _ = diagnostic_output 1 (fn _ => ["Rescheduling ordinary code\n"])

	  val new_code_list = do_reschedule code_list

a2448 4
	  val _ = diagnostic_output 1 (fn _ => ["Rescheduled code\n"])
	  val _ = diagnostic_output 3 (fn _ => (print_scheduled_code new_code_list ;
						[]))

a2452 1
	  val linear_code = linearise_list new_code_list
a2500 1
	  val tagged_code = make_tagged_code linear_code
@


1.73
log
@Removed the dummy instruction that is pushed onto blocks of the wrong size
to double-word align them - this is done elsewhere, and the blocks were
being thrown away anyway
@
text
@d4 5
d484 8
a491 8
  | last_opcode [elem as (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
			  _, _)] =
    (elem, true)
  | last_opcode([elem as (Sparc_Assembly.BRANCH(Sparc_Assembly.BA, _), _, _),
		 _]) =
(*
    (print"Found last opcode as BA";
*)
d493 3
a498 3
(*
    (print"Found penultimate opcode as BAA";
*)
d544 6
a549 6
	      | sub_cont [(Sparc_Assembly.BRANCH_ANNUL _, _, _)] = true
	      | sub_cont [_] = false
	      | sub_cont[(Sparc_Assembly.BRANCH _, _, _), _] = true
	      | sub_cont[(Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
			  _, _), _] = true
	      | sub_cont(_ :: rest) = sub_cont rest
d559 12
a570 7
	      | sub_cont [_] = Set.empty_set
	      | sub_cont([(Sparc_Assembly.BRANCH _, MirTypes.PRESENT tag, _),
			 _]) = Set.singleton tag
	      | sub_cont([(Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _),
			   MirTypes.PRESENT tag, _),
			 _]) = Set.singleton tag
	      | sub_cont(_ :: rest) = sub_cont rest
@


1.72
log
@Allocation wasn't working correctly
@
text
@d4 3
d2335 1
a2335 8
	  ((tag, 
	    if code_len mod 2 = 0 then  
	      (* This nop will be thrown away in the rescheduling, but we need 
	       to add its size to get the procedure offsets correct *)
	     code @@ [(MirTypes.new_tag(),
		      [(Sparc_Assembly.nop_code, absent, "Padding")])]
	   else
	     code),
@


1.71
log
@Added alignment check for alloc of an array
@
text
@d4 3
d1634 3
a1636 1
                  be a multiple of 8 when twelve has been added to it for double-word alignment *)
d1640 3
a1642 3
			 (case size of 
			    MirTypes.GP_IMM_INT x => (true,x)
			  | MirTypes.GP_GC_REG _ => (false,0)
d1661 1
a1661 1
		       fun do_allocate goto_tag =
d1674 6
a1679 1
				 absent, "Calculate new heap start")]) @@
d1698 1
a1698 6
				  absent, "Generate tagged result"),
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.SUB, rd,
				   Sparc_Assembly.REG(lookup_gp_operand size),
				   rd),
				  absent, "")]) @@
d1721 1
a1721 1
			   (Sparc_Assembly.BAA, 0), MirTypes.PRESENT goto_tag,
d1744 20
a1763 2
		       val (split_tag, after_gc_tag) =
			 (MirTypes.new_tag(), MirTypes.new_tag())
d1768 1
a1768 1
			     (do_allocate split_tag, [],
d1773 1
a1773 1
			     (do_allocate after_gc_tag, [],
d1780 1
a1780 1
			   (do_allocate after_gc_tag, [],
d1788 2
a1789 1
			       then []
d1791 27
a1817 13
			       (* If size came from a register, allow space for 
				the header and link fields *)
			       [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, 
				 (lookup_gp_operand size),
				 Sparc_Assembly.IMM(12),
				 (lookup_gp_operand size)),
				absent, "Setup callgc argument")]) @@ 
			       do_allocate after_gc_tag, [],
			    MirTypes.BLOCK(split_tag, opcode_list) ::
			    block_list,
			    (after_gc_tag, do_header (i * 64 + 18, split_tag)) ::
			    final_result)
d1826 1
a1826 1
			     (do_allocate after_gc_tag, [],
@


1.70
log
@Added things needed to support arrays - rearranged link fields in references,
changed so that ALLOC(REF) can take a register value argument
@
text
@d4 4
d1629 3
d1654 1
a1654 1
			 | MirTypes.ALLOC_REF => (12 + 4*i, 3)
@


1.69
log
@TAIL_CALL of register had an offset of 4 instead of an offset of 3 (typo)
@
text
@d4 3
d730 1
a730 1
	  val _ = diagnostic_output 1 (fn _ => ["Tag_env ="])
d732 1
a732 1
	    diagnostic_output 1
d1625 1
a1625 1
		 | MirTypes.ALLOCATE(allocate, reg_operand, i) =>
d1627 6
d1647 1
a1647 1
			 | MirTypes.ALLOC_REF => (16, 3)
d1650 14
a1663 7
			 [
			  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.ADD, MachTypes.gc1,
			    Sparc_Assembly.IMM size_in_bytes,
			    MachTypes.gc1),
			   absent, "Calculate new heap start"),
			  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
d1669 19
a1687 7
			   "Don't do next instruction if gc is required"),
			  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.ADD, rd,
			    Sparc_Assembly.IMM(ptr_tag - size_in_bytes),
			    MachTypes.gc1),
			   absent, "Generate tagged result"),
			  (Sparc_Assembly.LOAD_AND_STORE
d1694 11
a1704 6
			   absent, "Do callgc"),
			  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.ADD, MachTypes.global,
			    Sparc_Assembly.IMM size_in_bytes, MachTypes.G0),
			   absent, "Setup callgc argument"),
			  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
d1711 1
a1711 1
			  ]
d1757 12
a1768 1
			   (do_allocate after_gc_tag, [],
d1771 1
a1771 1
			    (after_gc_tag, do_header (82, split_tag)) ::
a1991 1
			     (* SUBCC is dest op2 op1 - dest := op1 - op2 *)
d2331 1
a2331 1
	  val _ = diagnostic_output 2
d2340 1
a2340 1
	  val _ = diagnostic_output 2
d2355 2
a2356 2
	      val _ = diagnostic_output 1 (fn _ => ["Result so far\n"])
	      val _ = diagnostic_output 2 (fn _ => (map print_unscheduled_code code_list' ;
d2399 1
a2399 1
	  val _ = diagnostic_output 2 (fn _ => (print_scheduled_code new_code_list ;
d2403 1
a2403 1
	  val _ =  diagnostic_output 2 (fn _ => (print_scheduled_code new_code_list' ;
a2409 1
	    if !show_mach then
a2415 2
	    else
	      []
a2416 1
	  (* val _ = map print_code linear_code *)
@


1.68
log
@Added a missing factor of four when jumping to the raise code.
@
text
@d4 3
d1548 2
a1549 2
			       (* CT 4 from 0 as past size word *)
			       Sparc_Assembly.IMM 4, lookup_reg_operand reg),
@


1.67
log
@Code bodies tagged incorrectly with non_gc_spill_size instead of non_gc_stack_size
@
text
@d4 3
d2058 1
a2058 1
			 Sparc_Assembly.IMM Implicit_Vector.raise_code),
@


1.66
log
@Added a non_gc number in front of each code object in a closure,
Got mutually recursive functions working as there were problems with
alignment in the existing implementation
@
text
@d4 5
d2246 1
a2246 1
	   non_gc_spill_size)
@


1.65
log
@A working version of the stack checking code, calling code on the implicit vector
@
text
@d4 3
a321 8
      val _ = diagnostic_output 5 
	(fn _ => ["Calling fault_range within make_imm_fault on value" ,
		  Integer.makestring i ,
		  (if signed 
		     then " on signed " 
		   else " on unsigned ") ,
		     "with maxpos " ,
		     Integer.makestring max_pos])
a323 1
      val _ = diagnostic_output 5 (fn _ => [" OK "])
d611 5
d617 1
a617 1
	  env_so_far @@ tag_offsets_for_list(next_offset + 4, rest)
a629 11
		  val debug_dummy = (* Delete this eventually *)
		    (Lists.assoc(tag, tag_env) - offset)
		  val _ =
		    diagnostic_output 5
		    (fn _ => 
		    ["Calling fault_range from within do_opcode on tag ",
		     MirTypes.print_tag tag,
		     " on the following div 4 ",
		     Integer.makestring debug_dummy,
		     " with value of offset ",
		     Integer.makestring offset])
a634 1
		    val _ = diagnostic_output 5 (fn _ => [" OK "])
a640 11
		  val debug_dummy = (* Delete this eventually *)
		    (Lists.assoc(tag, tag_env) - offset)
		  val _ =
		    diagnostic_output 5
		    (fn _ => 
		    ["branch annul Calling fault_range from within do_opcode on tag ",
		     MirTypes.print_tag tag,
		     " on the following div 4 ",
		     Integer.makestring debug_dummy,
		     " with value of offset ",
		     Integer.makestring offset])
a645 7
(*
		       Print.print("Tag " ^ MirTypes.print_tag tag);
		       Print.print"\nTag_env =\n";
		       map
		       (fn (x, y) => Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ Integer.makestring y ^ "\n"))
		       tag_env;
*)
a646 1
		    val _ = diagnostic_output 5 (fn _ => [" OK "])
a652 11
		  val debug_dummy = (* Delete this eventually *)
		    (Lists.assoc(tag, tag_env) - offset)
		  val _ =
		    diagnostic_output 5
		    (fn _ => 
		    ["fbranch Calling fault_range from within do_opcode on tag ",
		     MirTypes.print_tag tag,
		     " on the following div 4 ",
		     Integer.makestring debug_dummy,
		     " with value of offset ",
		     Integer.makestring offset])
a657 1
		    val _ = diagnostic_output 5 (fn _ => [" OK "])
a663 11
		  val debug_dummy = (* Delete this eventually *)
		    (Lists.assoc(tag, tag_env) - offset)
		  val _ =
		    diagnostic_output 5
		    (fn _ => 
		    ["Fbranch_annul Calling fault_range from within do_opcode on tag ",
		     MirTypes.print_tag tag,
		     " on the following div 4 ",
		     Integer.makestring debug_dummy,
		     " with value of offset ",
		     Integer.makestring offset])
a668 1
		    val _ = diagnostic_output 5 (fn _ => [" OK "])
a674 11
		  val debug_dummy = (* Delete this eventually *)
		    (Lists.assoc(tag, tag_env) - offset)
		  val _ =
		    diagnostic_output 5
		    (fn _ => 
		    ["On call Calling fault_range from within do_opcode on tag ",
		     MirTypes.print_tag tag,
		     " on the following div 4 ",
		     Integer.makestring debug_dummy,
		     " with value of offset ",
		     Integer.makestring offset])
a677 1
		    val _ = diagnostic_output 5 (fn _ => [" OK "])
d698 1
d701 1
a711 3
(*
	    if !do_fall_through then
*)
d713 1
a713 4
(*
	    else
	      proc_list
*)
d716 1
a716 2
(*
	  val _ = Print.print"Tag_env =\n"
d718 6
a723 4
	    map
	    (fn (x, y) => Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ Integer.makestring y ^ "\n"))
	    tag_env
*)
d729 5
d735 2
a736 1
	      (tag, done') :: do_linearise_sub(offset' + 4, rest)
d739 1
a739 1
	  do_linearise_sub(0, new_proc_list)
d803 1
a803 1
      fun do_block (_, [], _, _, _) = []
d805 8
a812 1
		 spills_opt, stack_opt, needs_fp_spare) =
a813 28
	  val (gc_spill_size, non_gc_spill_size, fp_spill_size) =
	    case spills_opt of
	      MirTypes.PRESENT{gc = gc_spill_size,
			       non_gc = non_gc_spill_size,
			       fp = fp_spill_size} =>
	      (gc_spill_size, non_gc_spill_size, fp_spill_size)
	     | _ => Crash.impossible"Spill sizes missing to mach_cg"
	  val non_gc_spill_size =
	    if needs_fp_spare then non_gc_spill_size + 1
	    else non_gc_spill_size
	  val stack_extra = case stack_opt of
	    MirTypes.PRESENT stack_extra => stack_extra
	  | _ =>  Crash.impossible"Stack size missing to mach_cg"
	  val float_spill_size = case MachTypes.fp_used of
	    MachTypes.single => 4
	  | MachTypes.double => 8
	  | MachTypes.extended => 16
	  val non_gc_stack_size =
	    non_gc_spill_size * 4 + float_spill_size * fp_spill_size
	  val gc_stack_size = gc_spill_size * 4 + stack_extra * 4
	  val non_gc_stack_size =
	    if (non_gc_stack_size + gc_stack_size) mod 8 = 0 then
	      non_gc_stack_size
	    else
	      non_gc_stack_size + 4
	  (* Ensure total stack requirement double aligned *)
	  val gc_stack_area = non_gc_stack_size + 4 * gc_spill_size
	  val frame_size = gc_stack_size + non_gc_stack_size + 64
d1513 2
a1514 2
		      (Sparc_Assembly.JMPL, MachTypes.lr,
		       Sparc_Assembly.IMM ~1, lookup_reg_operand reg_operand),
d1537 2
a1538 1
			       Sparc_Assembly.IMM 0, lookup_reg_operand reg),
d1916 1
a1916 1
			 val offset_from_bottom_of_stack_buffer = 128
d2046 12
a2057 12
		 | MirTypes.RAISE reg_operand =>
		     let
		       val reg_or_imm =
			 Sparc_Assembly.REG(lookup_reg_operand reg_operand)
		     in
		       ([(Sparc_Assembly.JUMP_AND_LINK
			  (Sparc_Assembly.JMPL, MachTypes.lr,
			   reg_or_imm, MachTypes.G0),
			  absent, "Raise"),
			 Sparc_Assembly.nop],
			opcode_list, block_list, final_result)
		     end
d2143 1
a2143 7
(* 
	  val _ =
	    Print.print(if small_exit_block exit_block then
		    "Small exit block\n"
		  else
		    "Big exit block\n")
*)
d2185 33
d2220 8
a2227 2
				    block_list, spill_sizes, stack_allocated,
				    needs_fp_spare))
d2233 4
a2236 2
	  (tag, 
	   if code_len mod 2 = 0 then
d2240 2
a2241 1
	     code)
d2269 4
a2272 1
	  val code_list = map proc_cg proc_list
d2366 7
a2372 1
	  val _ = map print_code linear_code
d2374 6
a2379 4
	  val _ =
	    (Print.print"Alternative code with save/restore shuffling\n";
	     map print_code linear_code')
	     
d2381 23
a2403 11
	    (map
	     (fn (tag, code) =>
	      (Lists.assoc(tag, loc_refs),
	       implode
	       (map
		(fn (x, _) =>
		 Sparc_Opcodes.output_opcode(Sparc_Assembly.assemble x))
		code))
	      )
	     linear_code)
	    handle Lists.Assoc => Crash.impossible"Assoc tagged_code"
@


1.64
log
@More code for the stack limit checking added
@
text
@d4 3
a752 11
		  val debug_dummy = (* Delete this eventually *)
		    Lists.assoc(tag, tag_env) - offset - i
		  val _ = diagnostic_output 5
		    (fn _ => 
		    ["On add instruction Calling make_imm_fault from within do_opcode on tag ",
		     MirTypes.print_tag tag,
		     " on the following  ",
		     Integer.makestring debug_dummy,
		     " with value of offset and i ",
		     Integer.makestring offset,
		     Integer.makestring i]) 
a757 1
		    val _ = diagnostic_output 5 (fn _ => [" OK "])
a2005 1

d2010 1
a2010 9
			      (* If not of immediate size, then use O2 for the negative frame size, and O3 for the 
			       negative frame size plus the offset_from_bottom_of_stack_buffer that is required *)
			      load_large_number_into_register (MachTypes.O2,frame_size)
			      @@ [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, MachTypes.O3,
				   Sparc_Assembly.IMM (offset_from_bottom_of_stack_buffer) , MachTypes.O2),
				  absent, "Add in low part")
				 ] )
				@@
d2012 4
d2034 1
a2034 2
			     Sparc_Assembly.nop
			     ]
a2035 23
			 (* Stack overflow code temporarily put here *)

			 (* Dummy tag for doing enough returns for returning from stack overflow *)
			 val dummy_code =
			    [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			      (Sparc_Assembly.ADD, MachTypes.callee_arg, 
			       Sparc_Assembly.IMM(0),
			       MachTypes.caller_arg), 
			      absent, "Set up the arguments yet again"),
			     (Sparc_Assembly.LOAD_AND_STORE
			      (Sparc_Assembly.LD, MachTypes.stack_limit,
			       MachTypes.stack_limit, Sparc_Assembly.IMM (0)),
			      absent, "Reset stack limit to its correct value"), 
			     (Sparc_Assembly.JUMP_AND_LINK
			      (Sparc_Assembly.JMPL, MachTypes.G0,
			       Sparc_Assembly.IMM 8, MachTypes.I7),
			      absent, "Return from stack overflow checking"),
			    (Sparc_Assembly.SAVE_AND_RESTORE
			      (Sparc_Assembly.RESTORE, MachTypes.G0,
			       Sparc_Assembly.IMM 0, MachTypes.sp),
			      absent,
			      "Restore ")]
			   
a2036 1
			   (* Set the size into O3 in the frame case - other case already does this *)
d2038 50
a2087 104
			     then
			       [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, MachTypes.O3, 
				 Sparc_Assembly.IMM(frame_size + offset_from_bottom_of_stack_buffer),
				 MachTypes.G0), 
				absent, "Set the required size in O3")]			       
			    else [])
			      @@
			   [(Sparc_Assembly.SAVE_AND_RESTORE
			     (Sparc_Assembly.SAVE, MachTypes.sp,
			      Sparc_Assembly.IMM(~64),
			      MachTypes.sp), absent, "Save around C call"),
			   (* Set up the args for the explicit vector call *)
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.ADD, MachTypes.caller_arg, 
			     Sparc_Assembly.IMM(0),
			     MachTypes.stack_limit), 
			    absent, "Pass the current stack limit to the garbage collector"),
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.ADD, MachTypes.caller_closure, 
			     Sparc_Assembly.IMM(0),
			     MachTypes.I3), 
			    absent, "Pass the required size to the garbage collector"),			   
			   (Sparc_Assembly.LOAD_AND_STORE
			    (Sparc_Assembly.LD, MachTypes.global,
			     MachTypes.implicit, 
			     Sparc_Assembly.IMM (4 * Implicit_Vector.extend )),
			    absent, "Get address of GC routine to call"),
			   (Sparc_Assembly.JUMP_AND_LINK
			    (Sparc_Assembly.JMPL, MachTypes.lr,
			     Sparc_Assembly.IMM 0, MachTypes.global),
			    absent, "Call the C stack overflow handler"),
			   Sparc_Assembly.nop,
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.ADD, MachTypes.stack_limit, 
			     Sparc_Assembly.IMM(0),
			     MachTypes.caller_arg), 
			    absent, "Set the new stack limit"),
			   (Sparc_Assembly.LOAD_AND_STORE
			    (Sparc_Assembly.LD, MachTypes.global, 
			     MachTypes.stack_limit,Sparc_Assembly.IMM( 4 )), 
			    absent, "Calculate the new stack start"),
			   (Sparc_Assembly.SAVE_AND_RESTORE
			    (Sparc_Assembly.RESTORE, MachTypes.G0,
			     Sparc_Assembly.IMM 0, MachTypes.sp),
			    absent,
			    "Back to initial call arguments"),
			   (Sparc_Assembly.SAVE_AND_RESTORE
			    (Sparc_Assembly.SAVE, MachTypes.sp,
			     (* Need the code here for the bigger than immediate case *)
			     Sparc_Assembly.IMM(~64),
			     MachTypes.global), absent, "Offset returned by the GC for new stack"),
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.ADD, MachTypes.caller_arg, 
			     Sparc_Assembly.IMM(0),
			     MachTypes.callee_arg), 
			    absent, "Set up the arguments yet again"),
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.ADD, MachTypes.caller_closure, 
			     Sparc_Assembly.IMM(0),
			     MachTypes.callee_closure), 
			    absent, "Set up the arguments yet again")]
			   @@
			   (if immediate_size
			      then
				[]
			    else
			      load_large_number_into_register (MachTypes.O2,frame_size))
			      @@
			      [(Sparc_Assembly.Call
				(Sparc_Assembly.CALL, 2),
				MirTypes.PRESENT non_ov_tag, "Set up the link register"),
			       Sparc_Assembly.nop]
			      @@
			      dummy_code
			     in
				   (check_for_stack_overflow_wrap,
				    [],
				    (case opcode_list of
				       [] => block_list
				     | _ => 
					 MirTypes.BLOCK(join_tag,opcode_list) :: block_list),
				    (non_ov_tag,
				     (if immediate_size
				       then []
				      else 
					[(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
					 (Sparc_Assembly.SUB, MachTypes.O2, 
					  Sparc_Assembly.REG(MachTypes.O2), MachTypes.G0), 
					 absent, "Negate the frame size")])
				    @@
				    [(Sparc_Assembly.SAVE_AND_RESTORE
				       (Sparc_Assembly.SAVE, MachTypes.sp,
					if immediate_size
					  then Sparc_Assembly.IMM(~frame_size)
					else Sparc_Assembly.REG MachTypes.O2,
					  MachTypes.sp), absent, "New frame"),
					(Sparc_Assembly.BRANCH_ANNUL
					 (Sparc_Assembly.BAA, 0),
					 MirTypes.PRESENT join_tag, ""),
					Sparc_Assembly.nop]) ::
				    (ov_tag,ov_tag_code)  ::
				    final_result)
			     end
@


1.63
log
@Added check for header actually fitting immediate in do_header, and work on stack_limit
checking code
@
text
@d4 4
d289 2
d310 3
a312 1
    else Crash.impossible"Immediate constant out of range"
d316 8
d325 2
d328 1
a328 1
      Sparc_Assembly.IMM i
d628 11
d644 1
d651 11
d675 1
d682 11
d698 1
d705 11
d721 1
d728 11
d742 1
d750 11
d766 1
d934 1
a934 1
	    ((i div 1024) mod (256 * 256 * 64), (i mod 1024) * 4)
d936 1
a936 1
	    ((i div 4096) mod (256 * 256 * 64), i mod 4096)
d941 1
a941 1
	      ((i div 4096) mod (256 * 256 * 64), i mod 4096)
d1747 1
a1747 1
			   (Sparc_Assembly.JMPL, MachTypes.O7,
d2054 11
a2064 5
			 val return_tag = MirTypes.new_tag() 

			 val return_tag_code =
			   (return_tag,
			    [(Sparc_Assembly.JUMP_AND_LINK
d2066 1
a2066 1
			       Sparc_Assembly.IMM 8, MachTypes.O7),
d2068 1
a2068 1
			     (Sparc_Assembly.SAVE_AND_RESTORE
d2072 1
a2072 1
			      "Restore in delay slot")]) 
d2088 1
a2088 1
			      MachTypes.sp), absent, "Frame for the  link pointer"),
d2091 1
a2091 1
			    (Sparc_Assembly.ADD, MachTypes.O0, 
d2093 1
a2093 1
			     MachTypes.G6), 
d2096 1
a2096 1
			    (Sparc_Assembly.ADD, MachTypes.O1, 
d2106 1
a2106 1
			    (Sparc_Assembly.JMPL, MachTypes.O7,
d2111 1
a2111 1
			    (Sparc_Assembly.ADD, MachTypes.G6, 
d2113 1
a2113 1
			     MachTypes.O0), 
d2116 2
a2117 2
			    (Sparc_Assembly.LD, MachTypes.G4, 
			     MachTypes.G6,Sparc_Assembly.IMM( 4 )), 
d2128 1
a2128 1
			     MachTypes.G4), absent, "Offset returned by the GC for new stack"),
d2130 1
a2130 1
			    (Sparc_Assembly.ADD, MachTypes.O0, 
d2132 1
a2132 1
			     MachTypes.I0), 
d2135 1
a2135 1
			    (Sparc_Assembly.ADD, MachTypes.O1, 
d2137 2
a2138 10
			     MachTypes.I1), 
			    absent, "Set up the arguments yet again"),
			   (Sparc_Assembly.Call
			    (Sparc_Assembly.CALL, 2),
			    absent, "Set up the link register"),
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.ADD, MachTypes.lr,
			     Sparc_Assembly.IMM ~4, MachTypes.lr),
			    MirTypes.PRESENT tag, 
			    "Put the return address of the dummy frame into the link register")]
d2146 6
a2151 4
			   [(Sparc_Assembly.BRANCH_ANNUL
			    (Sparc_Assembly.BAA, 0),
			    MirTypes.PRESENT non_ov_tag, "")]

a2158 1
				    return_tag_code ::
d2190 1
a2190 1
                        (Sparc_Assembly.JMPL, MachTypes.O7,
d2244 1
a2244 1
			(Sparc_Assembly.JMPL, MachTypes.O7,
d2413 2
a2414 5
(*
	  val _ =
	    (Print.print"Unscheduled code without save alteration\n";
	     map print_unscheduled_code code_list)
*)
d2416 4
a2420 5
(*
	  val _ =
	    (Print.print"Unscheduled code with save alteration\n";
	     map print_unscheduled_code code_list')
*)
d2422 7
d2438 6
a2443 5
(*
	      val _ = Print.print"Rescheduled at block level, now doing proc level\n"
	      val _ = Print.print"Result so far\n"
	      val _ = map print_unscheduled_code code_list'
*)
d2475 2
a2476 3
(* 
	  val _ = (Print.print"Rescheduling ordinary code\n")
*)
d2478 3
a2480 3
(* 
	  val _ = (Print.print"Rescheduling save/restore shuffled code\n")
*)
d2483 3
a2485 3
(* 
	  val _ = Print.print ( "Rescheduled code\n")
	  val _ = (print_scheduled_code new_code_list)
d2487 3
a2489 3
	  val _ = Print.print "Rescheduled code with save/restore shuffling\n"
	  val _ =  (print_scheduled_code new_code_list')
*)
@


1.62
log
@Added require for implicit
@
text
@d4 3
d227 1
d241 1
a241 1
require "../rts/implicit" ;
d266 1
d283 1
d855 14
d1674 10
a1683 6
			 [
			  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.ADD, MachTypes.global,
			    Sparc_Assembly.IMM header, MachTypes.G0),
			   absent, "Generate header word value"),
			  (Sparc_Assembly.LOAD_AND_STORE
d1925 1
d1932 2
a1933 12
			      let
				val (high, low) =
				  split_int(MirTypes.GP_IMM_ANY(~frame_size))
			      in
				[(Sparc_Assembly.SetHI
				  (Sparc_Assembly.SETHI, MachTypes.O2, high),
				  absent, "Get high part"),
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, MachTypes.O2,
				   Sparc_Assembly.IMM low, MachTypes.O2),
				  absent, "Add in low part"),
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
d1935 1
a1935 1
				   Sparc_Assembly.IMM (~offset_from_bottom_of_stack_buffer) , MachTypes.O2),
d1937 1
a1937 2
				 ] 
			      end)
d1940 1
a1940 1
			       (Sparc_Assembly.ADD, MachTypes.global, 
d1942 1
a1942 1
				  then Sparc_Assembly.IMM(~frame_size + ~offset_from_bottom_of_stack_buffer) 
d1979 10
d2001 2
a2002 2
			     Sparc_Assembly.IMM(1),
			     MachTypes.G0), 
d2027 6
a2032 1
			    "Restore in delay slot"),
d2037 1
a2037 1
			    absent, "Set up the arguments again"),
d2042 1
a2042 6
			    absent, "Set up the arguments again"),      
			   (Sparc_Assembly.SAVE_AND_RESTORE
			    (Sparc_Assembly.SAVE, MachTypes.sp,
			     (* Need the code here for the bigger than immediate case *)
			     Sparc_Assembly.IMM(~64),
			     MachTypes.G4), absent, "Offset returned by the GC for new stack"),
d2050 9
a2058 2
			    "Put the return address of the dummy frame into the link register"),
			   (Sparc_Assembly.BRANCH_ANNUL
d2060 1
a2060 2
			    MirTypes.PRESENT non_ov_tag, ""),
			   Sparc_Assembly.nop ]
d2071 9
a2079 1
				     [(Sparc_Assembly.SAVE_AND_RESTORE
d2323 1
d2329 1
d2383 1
a2383 1
	  val _ = Print.print"Rescheduling ordinary code\n"
d2387 1
a2387 1
	  val _ = Print.print"Rescheduling save/restore shuffled code\n"
d2392 2
a2393 2
	  val _ = Print.print"Rescheduled code\n"
	  val _ = print_scheduled_code new_code_list
d2395 2
a2396 2
	  val _ = Print.print"Rescheduled code with save/restore shuffling\n"
	  val _ = print_scheduled_code new_code_list'
@


1.61
log
@Started work on runtime stack limit checking, now gets offsets in implicit vector
from the structure defined in rts, adr took no notice of the tag argument
@
text
@d4 4
d230 1
@


1.60
log
@Started adding stack limit code on procedure entry
@
text
@d4 3
d232 1
d235 1
d256 1
d1629 2
a1630 2
			    MachTypes.implicit, Sparc_Assembly.IMM 0),
			   absent, "Get address of callc"),
d1716 1
a1716 1
			absent, "Update gc pointer")],
d1887 3
a1889 1
			 val join_tag = MirTypes.new_tag() (* Join them back up again *)
d1920 1
a1920 1
			     [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
d1942 85
d2030 5
a2034 1
				    MirTypes.BLOCK(join_tag,opcode_list) :: block_list, 
d2046 1
a2046 5
				    (ov_tag,
				     [(Sparc_Assembly.BRANCH_ANNUL
				       (Sparc_Assembly.BAA, 0),
				       MirTypes.PRESENT non_ov_tag, ""),
				      Sparc_Assembly.nop]) ::
d2051 1
d2055 1
a2055 1
                         MachTypes.implicit, Sparc_Assembly.IMM 8),
d2109 1
a2109 1
			 MachTypes.implicit, Sparc_Assembly.IMM 4),
d2189 1
a2189 1
(*
d2337 1
a2337 1
(*
d2341 1
a2341 1
(*
d2346 1
a2346 1
(*
@


1.59
log
@Changed all prints to Print.print
@
text
@d4 3
d1878 78
a1955 28
		       in
			 if check_range(frame_size, true, arith_imm_limit)
			   then
			     ((Sparc_Assembly.SAVE_AND_RESTORE
			       (Sparc_Assembly.SAVE, MachTypes.sp,
				Sparc_Assembly.IMM(~frame_size),
				MachTypes.sp), absent, "New frame") ::
			      opcodes,
			      opcode_list, block_list, final_result)
			 else
			   let
			     val (high, low) =
			       split_int(MirTypes.GP_IMM_ANY(~frame_size))
			   in
			     ((Sparc_Assembly.SetHI
			       (Sparc_Assembly.SETHI, MachTypes.global, high),
			       absent, "Get high part") ::
			      (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			       (Sparc_Assembly.ADD, MachTypes.global,
				Sparc_Assembly.IMM low, MachTypes.global),
			       absent, "Add in low part") ::
			      (Sparc_Assembly.SAVE_AND_RESTORE
			       (Sparc_Assembly.SAVE, MachTypes.sp,
				Sparc_Assembly.REG MachTypes.global,
				MachTypes.sp), absent, "New frame") :: opcodes,
			     opcode_list, block_list, final_result)
			   end
		       end
@


1.58
log
@Added code to call ml_preserve for the PRESERVE opcode.
@
text
@d4 3
a271 12
(*
  fun unchecked_imm(MirTypes.GP_IMM_INT i) = 4 * i
  | unchecked_imm(MirTypes.GP_IMM_ANY i) = i
  | unchecked_imm(MirTypes.GP_IMM_SYMB _) =
    let
      val _ = Print.print"Warning, symbolic value not translated"
    in
      0
    end
  | unchecked_imm _ = Crash.impossible"unchecked_imm of non-immediate"
*)

d605 1
d607 2
a608 2
		      (print("Tag " ^ MirTypes.print_tag tag);
		       print"Tag_env =";
d610 1
a610 1
		       (fn (x, y) => print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ Integer.makestring y))
d613 1
a613 1
		       Crash.impossible"Assoc do_opcode branch_annul"
d688 1
a688 1
	  val _ = print"Tag_env ="
d691 1
a691 1
	    (fn (x, y) => print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ Integer.makestring y))
d1372 1
a1372 1
			print"Exception tag case not yet handled for FLOOR"
d2044 2
a2045 2
	    print(if small_exit_block exit_block then
		    "Small exit block"
d2047 1
a2047 1
		    "Big exit block")
d2115 1
a2115 1
		    print(
d2121 1
a2121 1
			     " ; " ^ comment)
d2123 1
a2123 1
		  (print("Block tag " ^ MirTypes.print_tag tag);
d2127 2
a2128 1
	      (print("Procedure entry tag " ^ MirTypes.print_tag tag);
d2135 1
a2135 1
	    (print"Unscheduled code without save alteration";
d2141 1
a2141 1
	    (print"Unscheduled code with save alteration";
d2155 2
a2156 2
	      val _ = print"Rescheduled at block level, now doing proc level"
	      val _ = print"Result so far"
d2171 1
a2171 1
			print(
d2177 1
a2177 1
				 " ; " ^ comment)
d2179 1
a2179 1
		      (print("Block tag " ^ MirTypes.print_tag tag);
d2183 1
a2183 1
		  (print("Procedure tag " ^ MirTypes.print_tag proc_tag);
d2191 1
a2191 1
	  val _ = print"Rescheduling ordinary code"
d2195 1
a2195 1
	  val _ = print"Rescheduling save/restore shuffled code"
d2200 1
a2200 1
	  val _ = print"Rescheduled code"
d2203 1
a2203 1
	  val _ = print"Rescheduled code with save/restore shuffling"
d2224 1
a2224 1
	    (print"Alternative code with save/restore shuffling";
@


1.57
log
@Removed the SAVE instruction generated by the PRESERVE instruction.
This will need to be replaced with something useful at some point.
@
text
@d4 4
d1914 10
a1923 2
		     ([],
		      opcode_list, block_list, final_result)
@


1.56
log
@Changed offsets in CALL instructions to point
to the right place.
@
text
@d3 5
a7 1
$Log:	_mach_cg.sml,v $
d1910 1
a1910 4
		     ([(Sparc_Assembly.SAVE_AND_RESTORE
			(Sparc_Assembly.SAVE, MachTypes.sp,
			 Sparc_Assembly.IMM ~64,
			 MachTypes.sp), absent, "New frame")],
@


1.55
log
@Added a missing NOP after the in-line CALL_C code.
@
text
@d4 3
d1544 1
a1544 1
			 (Sparc_Assembly.CALL, 0),
d1702 1
a1702 1
			(Sparc_Assembly.CALL, 0),
@


1.54
log
@Removed some superfluous debugging output
@
text
@d4 3
d1959 1
a1959 1
			absent, "Do call_c")],
@


1.53
log
@Fixed code to do stack initialisation, and added more optimal versions
where the size is small.
@
text
@d4 4
d2127 1
a2127 1
(**)
d2131 1
a2131 1
(**)
@


1.52
log
@Improved coding for tail calls by putting restore in delay slot
@
text
@d4 3
a777 3
	  val gc_stack_area =
	    4 * non_gc_spill_size + 4 * gc_spill_size +
	    float_spill_size * fp_spill_size
d787 1
d1704 55
d1760 17
a1776 11
			   case gc_stack_size of
			     0 => (false, [], (top_tag, []))
			   | _ =>
			       let
				 val branch_out =
				   [(Sparc_Assembly.BRANCH_ANNUL
				     (Sparc_Assembly.BAA, 0),
				     MirTypes.PRESENT top_tag,
				     "")]
				 val load_limit =
				   if check_range(~gc_stack_size, true,
d1779 1
a1779 1
					      ~gc_stack_size) :: branch_out
d1784 1
a1784 1
						   (~gc_stack_size))
d1791 2
a1792 1
					(Sparc_Assembly.ADD, MachTypes.global,
d1795 1
a1795 1
					absent, "Update gc pointer") ::
d1798 60
a1857 28
				 val store_loop =
				   [(Sparc_Assembly.LOAD_AND_STORE
				     (Sparc_Assembly.ST, MachTypes.G0,
				      MachTypes.fp,
				      Sparc_Assembly.REG MachTypes.I2),
				     absent, "Initialise a stack slot"),
				   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				    (Sparc_Assembly.SUB, MachTypes.I2,
				     Sparc_Assembly.IMM 4,
				     MachTypes.I2),
				    absent, "Update gc pointer"),
				   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				    (Sparc_Assembly.SUBCC, MachTypes.G0,
				     Sparc_Assembly.REG MachTypes.global,
				     MachTypes.I2),
				    absent, "Have we finished?"),
				   (Sparc_Assembly.BRANCH_ANNUL
				    (Sparc_Assembly.BGA, 0),
				    MirTypes.PRESENT top_tag, "Do the branch"),
				   Sparc_Assembly.nop,
				   (Sparc_Assembly.BRANCH_ANNUL
				    (Sparc_Assembly.BAA, 0),
				    MirTypes.PRESENT end_tag, "")]
			       in
				 (true,
				  move_imm(MachTypes.I2, 4) :: load_limit,
				  (top_tag, store_loop))
			       end
d2123 1
a2123 1
(*
d2127 1
a2127 1
*)
@


1.51
log
@Improved lineariser slightly
@
text
@d4 3
d531 3
a533 2
		  | first :: (Sparc_Assembly.BRANCH _, _, _) :: rest =>
		      first :: rest
d1059 6
a1064 1
			      ([], make_imm_format3 gp_operand, false,
d1397 2
a1398 1
			  MirTypes.PRESENT tag, "Branch relative")]),
d1485 21
a1505 4
		    ([],
		     MirTypes.PREVIOUS_ENVIRONMENT ::
		     MirTypes.BRANCH(MirTypes.BRA, bl_dest) ::
		     opcode_list, block_list, final_result)
d2048 1
d2050 1
a2050 1
	      map Sparc_Schedule.reschedule_proc code_list'
@


1.50
log
@Added implementation of tail call
@
text
@d4 3
d414 7
d467 3
a469 1
	      | sub_cont((Sparc_Assembly.BRANCH _, _, _) :: rest) = true
d483 3
d530 2
@


1.49
log
@Fixed minor bug in continuation block spotting
@
text
@d4 3
d572 8
a579 1
		      Crash.impossible"Assoc do_opcode branch_annul"
d653 7
d1444 18
a1461 27
		| MirTypes.BRANCH_AND_LINK(branch_and_link, bl_dest) =>
		    ((case branch_and_link of
			MirTypes.BLR =>
			  let
			    val reg = case bl_dest of
			      MirTypes.REG reg_operand =>
				lookup_reg_operand reg_operand
			    | _ => Crash.impossible"BLR to tag"
			  in
			    [(Sparc_Assembly.JUMP_AND_LINK
			      (Sparc_Assembly.JMPL, MachTypes.lr,
			       Sparc_Assembly.IMM ~1, reg),
			      absent, "Call to tagged value"),
			     Sparc_Assembly.nop]
			  end
		      | MirTypes.BSR =>
			  let
			    val tag =
			      case bl_dest of
				MirTypes.TAG tag => tag
			      | _ => Crash.impossible"BSR to reg"
			  in
			    [(Sparc_Assembly.Call
			      (Sparc_Assembly.CALL, 0),
			      MirTypes.PRESENT tag, "Call"),
			     Sparc_Assembly.nop]
			  end), opcode_list, block_list, final_result)
d1999 5
d2008 29
d2038 3
d2042 9
@


1.48
log
@Added stack initialisation of gc areas.
@
text
@d4 3
d466 2
a467 2
	      | sub_cont((Sparc_Assembly.BRANCH _, MirTypes.PRESENT tag, _) ::
			 rest) = Set.singleton tag
@


1.47
log
@Fixed problem of procedures without exits (eg fun f x = raise Match)
@
text
@d4 3
d677 2
a678 1
	(Sparc_Assembly.ADD, rd, imm, MachTypes.G0), absent, "")
d739 8
d1644 101
a1744 33
		     (if needs_preserve then
			let
			  val frame_size =
			    ~(((4 * gc_spill_size + 4 * non_gc_spill_size +
				8 * fp_spill_size + stack_extra * 4 + 68)
			       div 8) * 8)
			in
			  if
			    check_range(frame_size, true, arith_imm_limit) then
			    [(Sparc_Assembly.SAVE_AND_RESTORE
			      (Sparc_Assembly.SAVE, MachTypes.sp,
			       Sparc_Assembly.IMM frame_size,
			       MachTypes.sp), absent, "New frame")]
			  else
			    let
			      val (high, low) =
				split_int(MirTypes.GP_IMM_ANY frame_size)
			    in
			      [(Sparc_Assembly.SetHI
				(Sparc_Assembly.SETHI, MachTypes.global, high),
				absent, "Get high part"),
			       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, MachTypes.global,
				 Sparc_Assembly.IMM low, MachTypes.global),
				absent, "Add in low part"),
			       (Sparc_Assembly.SAVE_AND_RESTORE
				(Sparc_Assembly.SAVE, MachTypes.sp,
				 Sparc_Assembly.REG MachTypes.global,
				 MachTypes.sp), absent, "New frame")]
			    end
			end
		      else
			[], opcode_list, block_list, final_result)
@


1.46
log
@Improved lineariser by spotting blocks terminating with branches with
delay slots
@
text
@d4 4
d1737 1
a1737 1
      fun exit_block [] = Crash.impossible"Can't find procedure exit"
d1742 1
a1742 1
	  then block
d1805 7
a1811 4
	    if small_exit_block exit_block then
	      append_small_exit(exit_block, block_list)
	    else
	      block_list
a1864 17
	  fun do_reschedule code_list =
	    let
	      val code_list' =
		map
		(fn (proc_tag, proc) =>
		 (proc_tag, map
		  (fn (tag, x) => (tag, Sparc_Schedule.reschedule_block x))
		  proc))
		code_list
	    in
	      map Sparc_Schedule.reschedule_proc code_list'
	    end
	  val code_list = map proc_cg proc_list
	  val code_list' = map Save.remove_redundant_saves code_list
	  val new_code_list = do_reschedule code_list
	  val new_code_list' = do_reschedule code_list'

d1885 2
d1891 3
d1898 16
a1913 10
(*
	    map
	    (fn (proc_tag, proc) =>
	     (proc_tag, map
	      (fn (tag, x) => (tag, Sparc_Schedule.reschedule_block x))
	      proc))
	    code_list
	  val new_code_list' =
	    map Sparc_Schedule.reschedule_proc new_code_list
*)
a1914 1
(**)
a1915 1
(**)
a1929 1
(**)
a1932 1
(**)
@


1.45
log
@*** empty log message ***
@
text
@d4 3
d387 1
d389 9
a397 4
  | last_opcode [elem as (opcode, _, _)] =
    (case opcode of
      Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, _) => (elem, true)
    | _ => (Sparc_Assembly.nop, false))
d444 1
d456 2
d496 11
a506 1
		(block_tag, rev(tl(rev opcode_list)))
d1731 54
d1792 13
d1931 1
a1931 1
(*
d1935 1
a1935 1
*)
d1937 1
a1937 1
	  val tagged_code =
d1939 13
a1951 8
	    (fn (tag, code) =>
	     (Lists.assoc(tag, loc_refs),
	      implode
	      (map
	       (Sparc_Opcodes.output_opcode o Sparc_Assembly.assemble o #1)
	       code))
	     )
	    linear_code) handle Lists.Assoc => Crash.impossible"Assoc tagged_code"
d1953 1
a1953 1
	  MachTypes.WORDSET(MachTypes.WORD_SET tagged_code)
@


1.44
log
@Minor changes. Experimenting with save/restore optimisation
@
text
@d4 3
d1785 21
d1807 8
d1825 1
d1827 1
d1844 2
a1845 5
	    let
	      val _ = print"Alternative code with save/restore shuffling";
	    in
	      map print_code linear_code'
	    end
@


1.43
log
@Added reference to save for optimising save/restore use (perhaps)
@
text
@d4 3
d205 2
a206 1
     Sparc_Schedule.MirTypes = MirRegisters.MirTypes = Save.MirTypes
d374 1
d379 1
d381 1
a381 1
  fun last_opcode [] = (nop, false)
d385 1
a385 1
    | _ => (nop, false))
d680 1
a680 1
      fun do_block (_, [], _, _) = []
d682 1
a682 1
		 spills_opt, stack_opt) =
d691 3
d711 1
a711 1
	    1 - (non_gc_stack_size + 4 * (1 + i))
d713 5
a717 1
	    1 - 4 * (1 + i)
d719 1
a719 1
	    1 - 4 * (1 + non_gc_spill_size + i)
d853 2
a854 1
				nop], opcode_list, block_list, final_result)
d1248 11
a1258 2
			  (Sparc_Assembly.CONV_OP(operation, rd,
						  MachTypes.global),
d1267 2
a1268 2
					 MirTypes.GP_GC_REG
					 MirRegisters.global) ::
a1280 4
		      val tag_result =
			[(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			  (Sparc_Assembly.SLL, rd, Sparc_Assembly.IMM 2, rd),
			  absent, "Tag the result")]
d1282 2
a1283 1
		      ([(Sparc_Assembly.CONV_OP(operation, rd, rs2),
d1285 10
d1307 1
a1307 1
			 nop]
d1357 2
a1358 1
		      nop], opcode_list, block_list, final_result)
d1377 1
a1377 1
		      nop,
d1380 2
a1381 1
		      nop], opcode_list, block_list, final_result)
d1396 1
a1396 1
			     nop]
d1408 1
a1408 1
			     nop]
d1429 1
a1429 1
				     (nop_code, absent,
d1439 1
a1439 1
			nop ::
d1450 1
a1450 1
			nop ::
d1665 2
a1666 1
			 nop], opcode_list, block_list, final_result)
d1680 2
a1681 1
			 nop], opcode_list, block_list, final_result)
a1712 26
(*
	  exception NeedsPreserve

	  fun check_reg reg =
	    (case reg of
	       MachTypes.L0 => raise NeedsPreserve
	     | MachTypes.L1 => raise NeedsPreserve
	     | MachTypes.L2 => raise NeedsPreserve
	     | MachTypes.L3 => raise NeedsPreserve
	     | MachTypes.L4 => raise NeedsPreserve
	     | MachTypes.L5 => raise NeedsPreserve
	     | MachTypes.L6 => raise NeedsPreserve
	     | MachTypes.L7 => raise NeedsPreserve
	     | MachTypes.O0 => raise NeedsPreserve
	     | MachTypes.O1 => raise NeedsPreserve
	     | MachTypes.O2 => raise NeedsPreserve
	     | MachTypes.O3 => raise NeedsPreserve
	     | MachTypes.O4 => raise NeedsPreserve
	     | MachTypes.O5 => raise NeedsPreserve
	     (* We don't count this as an output
	     | MachTypes.O6 => raise NeedsPreserve
	     *)
	     | MachTypes.O7 => raise NeedsPreserve
	     | _ => ())
	       
*)
d1731 9
a1739 2
	  val code = move_first([], do_block(needs_preserve, block_list,
					     spill_sizes, stack_allocated))
d1741 10
d1757 2
a1758 1
	     code @@ [(MirTypes.new_tag(), [(nop_code, absent, "Padding")])]
d1766 12
d1779 4
a1782 2
	  val _ = map Save.remove_redundant_saves code_list
	  val new_code_list =
d1791 3
a1793 1
	  val linear_code = linearise_list new_code_list'
d1808 9
@


1.42
log
@Moved some functions out into MachTypes
@
text
@d4 3
d173 1
d195 1
d202 2
a203 2
     Sparc_Schedule.MirTypes = MirRegisters.MirTypes
   sharing Sparc_Assembly = Sparc_Schedule.Sparc_Assembly
d1741 1
@


1.41
log
@Changed coding of conversion operations
Added (unimplemented) exception generating fp opcodes
@
text
@d4 4
d1674 1
d1699 1
d1701 1
a1701 1
	    (Set.map f s; false) handle NeedsPreserve => true
d1705 1
a1705 1
	     ch (fn r => check_reg(Table.lookup(r, fp_table))) fp
d1707 1
a1707 1
	     ch (fn r => check_reg(Table.lookup(r, gc_table))) gc
d1709 2
a1710 1
	     ch (fn r => check_reg(Table.lookup(r, non_gc_table))) non_gc
@


1.40
log
@Implemented FTEST. Added it to the lineariser
@
text
@d4 3
d1044 6
d1207 1
a1207 1
		| MirTypes.CONVOP(int_to_float, fp_operand, gp_operand) =>
d1209 6
a1214 16
		      val (operation, to_fp) =
			case (MachTypes.fp_used, int_to_float) of
			  (MachTypes.single, MirTypes.ITOF) =>
			    (Sparc_Assembly.FITOS, true)
			| (MachTypes.double, MirTypes.ITOF) =>
			    (Sparc_Assembly.FITOD, true)
			| (MachTypes.extended, MirTypes.ITOF) =>
			    (Sparc_Assembly.FITOX, true)
			| (MachTypes.single, MirTypes.FTOI) =>
			    (Sparc_Assembly.FSTOI, false)
			| (MachTypes.double, MirTypes.FTOI) =>
			    (Sparc_Assembly.FDTOI, false)
			| (MachTypes.extended, MirTypes.FTOI) =>
			    (Sparc_Assembly.FXTOI, false)
		      val fr = lookup_fp_operand fp_operand
		      val ir =
a1218 27
		      val rd =
			if to_fp then
			  fr
			else
			  if is_reg gp_operand then
			    ir
			  else Crash.impossible"Conversion to integer constant"
		      val rs2 =
			if to_fp then
			  ir
			else
			  fr
		      val tag_result =
			if to_fp then []
			else
			  [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.SLL, rd, Sparc_Assembly.IMM 2, rd),
			    absent, "Tag the result")]
		      val (untag_operand, rs2) =
			if to_fp then
			  ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (Sparc_Assembly.SRA, MachTypes.global, 
			      Sparc_Assembly.IMM 2, rs2), absent,
			     "Untag operand")],
			   MachTypes.global)
			else
			  ([], rs2)
d1221 7
a1227 3
			(untag_operand @@
			 (Sparc_Assembly.CONV_OP(operation, rd, rs2),
			  absent, "") :: tag_result,
d1234 1
a1234 1
			 MirTypes.CONVOP(int_to_float, fp_operand,
d1238 22
@


1.39
log
@Added more real stuff, plus translation of new CALL_C
@
text
@d4 3
d504 2
d507 1
a507 3
		  ((Sparc_Assembly.BRANCH(branch, disp), comment)
		   handle Lists.Assoc =>
		     Crash.impossible"Assoc do_opcode branch")
d515 2
d518 1
a518 3
		  ((Sparc_Assembly.BRANCH_ANNUL(branch, disp), comment)
		   handle Lists.Assoc =>
		     Crash.impossible"Assoc do_opcode branch_annul")
d520 22
d549 1
a549 3
		  ((Sparc_Assembly.Call(Sparc_Assembly.CALL, disp), comment)
		   handle Lists.Assoc =>
		     Crash.impossible"Assoc do_opcode call")
d558 2
d561 3
a563 5
		  ((Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		    (Sparc_Assembly.ADD, rd, disp, rs1),
		    comment)
		   handle Lists.Assoc =>
		     Crash.impossible"Assoc do_opcode arith")
d1229 1
a1229 4
			  if is_reg gp_operand then
			    ir
			  else
			    MachTypes.global
d1240 5
a1244 1
			  ([move_reg(MachTypes.global, rs2)], MachTypes.global)
d1249 2
a1250 1
			((Sparc_Assembly.CONV_OP(operation, rd, rs2),
d1324 20
a1343 1
		  Crash.unimplemented"do_opcodes(FTEST)"
@


1.38
log
@Removed references to fp_double registers.
@
text
@d4 3
d274 13
a286 8
  fun to_double_string(sign, mantissa, exponent) =
    let
      val real_exponent = exponent + 1023
      fun n_zeroes(done, 0) = implode done
      | n_zeroes(done, n) = n_zeroes("0" :: done, n-1)
      fun adjust(mantissa, exponent) =
	if mantissa_is_zero mantissa then
	  (mantissa, 0)
d288 1
a288 2
	  if exponent > 0 andalso exponent < 2047 then
	    (mantissa, exponent)
d290 6
a295 8
	    (* Need to handle subnormal numbers *)
	    if exponent > 2047 then
	      raise(Reals.too_big)
	    else
	      if exponent < ~52 then (n_zeroes([], 64), 0)
	      else
		(n_zeroes([], abs exponent) ^ mantissa, 0)
      val (mantissa, real_exponent) = adjust(mantissa, real_exponent)
d298 2
a299 2
	   to_binary(11, real_exponent) @@
	   explode(String.substring(mantissa, 1, 52))
d309 27
d342 1
a342 1
	MachTypes.single => Crash.unimplemented"VALUE Single precision fp"
d344 1
a344 1
      | MachTypes.extended => Crash.unimplemented"VALUE Extended precision fp"
d1130 5
a1134 2
			  val imm as Sparc_Assembly.IMM arg =
			    make_imm_for_store gp_operand
d1400 7
a1406 1
			 | MirTypes.ALLOC_REAL => (16, 5)
d1495 14
a1508 6
			   (do_allocate after_gc_tag, [],
			    MirTypes.BLOCK(split_tag, opcode_list) ::
			    block_list,
			    (after_gc_tag,
			     do_header (10 + 64 * 12, split_tag)) ::
			    final_result)
d1600 10
@


1.37
log
@Added more floating point, unary, binary, more stores. Also added
support for symbolic values
@
text
@d4 4
d554 1
a554 2
	      fp_table,
	      fp_double_table)) =
d611 1
a611 2
	  val (gc_spill_size, non_gc_spill_size, fp_spill_size,
	       fp_double_spill_size) =
d615 2
a616 4
			       fp = fp_spill_size,
			       fp_double = fp_double_spill_size} =>
	      (gc_spill_size, non_gc_spill_size, fp_spill_size,
	       fp_double_spill_size)
a639 2
	  | symbolic_value(MirTypes.FP_DOUBLE_SPILL_SLOT i) =
	    Crash.impossible"FP_DOUBLE_SPILL_SLOT"
d1475 1
a1475 2
				8 * fp_spill_size + 16 * fp_double_spill_size +
				stack_extra * 4 + 68)
d1565 1
a1565 1
		    {fp, fp_double, gc, non_gc},
a1598 2
	     orelse
	     ch (fn r => check_reg(Table.lookup(r, fp_double_table))) fp_double
@


1.36
log
@Added real loads, stores and conversion operations
@
text
@d4 3
d155 2
a156 2
functor Mach_Cg
  (structure Print : PRINT
d197 1
d207 1
a218 15
  fun gp_check_range(MirTypes.GP_IMM_INT i, signed, pos_limit) =
    check_range(i, signed, pos_limit div 4)
  | gp_check_range(MirTypes.GP_IMM_ANY i, signed, pos_limit) =
    check_range(i, signed, pos_limit)
  | gp_check_range(MirTypes.GP_IMM_SYMB _, signed, pos_limit) =
    check_range(0, signed, pos_limit)
  | gp_check_range _ = Crash.impossible"gp_check_range of non-immediate" 

  fun split_int(MirTypes.GP_IMM_INT i) =
    ((i div 1024) mod (256 * 256 * 64), (i mod 1024) * 4)
  | split_int(MirTypes.GP_IMM_ANY i) =
    ((i div 4096) mod (256 * 256 * 64), i mod 4096)
  | split_int(MirTypes.GP_IMM_SYMB _) = (0, 0)
  | split_int _ = Crash.impossible"split_int of non-immediate" 

a229 12
  fun make_imm_format3(MirTypes.GP_IMM_INT i) =
    make_imm_fault(4 * i, true, arith_imm_limit)
  | make_imm_format3(MirTypes.GP_IMM_ANY i) =
    make_imm_fault(i, true, arith_imm_limit)
  | make_imm_format3(MirTypes.GP_IMM_SYMB _) =
    let
      val _ = Print.print"Warning, symbolic value not translated"
    in
      Sparc_Assembly.IMM 0
    end
  | make_imm_format3 _ = Crash.impossible"make_imm of non-immediate"

d306 1
a306 1
	MachTypes.single => Crash.unimplemented"Single precision fp"
d308 1
a308 1
      | MachTypes.extended => Crash.unimplemented"Extended precision fp"
a562 10
      fun make_imm_for_store(MirTypes.GP_IMM_ANY i) =
	make_imm_fault(i, true, arith_imm_limit)
      | make_imm_for_store(MirTypes.GP_IMM_SYMB _) =
	let
	  val _ = Print.print"Warning, symbolic value not translated"
	in
	  Sparc_Assembly.IMM 0
	end
      | make_imm_for_store _ = Crash.impossible"make_imm_for_store(bad value)"

d621 4
d626 76
a701 25
	    4 * non_gc_spill_size + 4 * gc_spill_size + 8 * fp_spill_size +
	    16 * fp_double_spill_size
      fun do_everything
	  (_, tag, [], done, [], final_result) =
	  (tag, done) :: final_result
	| do_everything
	  (needs_preserve, tag, [], done,
	   MirTypes.BLOCK(tag',opcodes) :: blocks,
	   final_result) =
	  do_everything
	  (needs_preserve, tag', opcodes, [], blocks,
	   (tag, done) :: final_result)
	| do_everything
	  (needs_preserve, tag, opcode :: opcode_list, done,
	   block_list, final_result) =
	  let
	    fun lookup_reg(reg, table) =
	      let
		val reg = Table.lookup(reg, table)
	      in
		if needs_preserve then reg
		else MachTypes.after_restore reg
	      end
	    
	    fun lookup_reg_operand(MirTypes.GC_REG reg) =
d706 1
a706 1
	    fun lookup_gp_operand(MirTypes.GP_GC_REG reg) =
d713 1
a713 1
	    fun lookup_fp_operand(MirTypes.FP_REG reg) =
d716 17
a732 17
	    val (result_list, opcode_list, new_blocks, new_final_result) =
	      case opcode of
		MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
				 gp_operand, gp_operand') =>
		let
		  val rd = lookup_reg_operand reg_operand
		  val opcode = case tagged_binary_op of
		    MirTypes.ADDV =>
		      Sparc_Assembly.TADDCC
		  | MirTypes.SUBV =>
		      Sparc_Assembly.TSUBCC
		  | MirTypes.MULV =>
		      Crash.impossible"do_opcodes(TBINARY(MULV))"
		  | MirTypes.DIVV =>
		      Crash.impossible"do_opcodes(TBINARY(DIVV))"
		  | MirTypes.MODV =>
		      Crash.impossible"do_opcodes(TBINARY(MODV))"
d734 21
a754 6
		  fun needs_reverse MirTypes.SUBV = true
		  | needs_reverse MirTypes.DIVV = true
		  | needs_reverse MirTypes.MODV = true
		  | needs_reverse _ = false
		  val (gp_operand, gp_operand', redo) =
		    if is_reg gp_operand then (gp_operand, gp_operand', false)
d756 32
a787 116
		      if needs_reverse tagged_binary_op then
			(gp_operand, gp_operand', true)
		      else (gp_operand', gp_operand, false)
		in
		  if redo then
		    ([],
		     MirTypes.UNARY(MirTypes.MOVE,
				    MirTypes.GC_REG MirRegisters.global,
				    gp_operand) ::
		     MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
				     MirTypes.GP_GC_REG MirRegisters.global,
				     gp_operand') ::
		     opcode_list, block_list, final_result)
		  else
		    if is_reg gp_operand then
		      let
			val rs1 = lookup_gp_operand gp_operand
		      in
			if is_reg gp_operand' orelse
			  gp_check_range(gp_operand', true,
					 arith_imm_limit) then
			  let
			    val reg_or_imm =
			      if is_reg gp_operand' then
				Sparc_Assembly.REG(lookup_gp_operand
						   gp_operand')
			      else make_imm_format3 gp_operand'
			  in
			    ([(Sparc_Assembly.TAGGED_ARITHMETIC
			       (opcode, rd, reg_or_imm, rs1), absent, ""),
			      (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BVSA,
							   0),
			       MirTypes.PRESENT tag, "Do the branch"),
			      nop], opcode_list, block_list, final_result)
			  end
			else
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  MirTypes.GC_REG MirRegisters.global,
					  gp_operand') ::
			   MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
					    gp_operand,
					    MirTypes.GP_GC_REG
					    MirRegisters.global) ::
			   opcode_list, block_list, final_result)
		      end
		    else Crash.impossible"Mach_Cg(TBINARY) first arg not reg"
		end	
	      | MirTypes.BINARY(binary_op, reg_operand, gp_operand,
				gp_operand') =>
		let
		  val rd = lookup_reg_operand reg_operand
		  val opcode =
		    case binary_op of
		      MirTypes.ADD => Sparc_Assembly.ADD
		    | MirTypes.SUB => Sparc_Assembly.SUB
		    | MirTypes.MULU =>
			Crash.unimplemented"MirTypes.MULU"
		    | MirTypes.MULS =>
			Crash.unimplemented"MirTypes.MULS"
		    | MirTypes.DIVU =>
			Crash.unimplemented"MirTypes.DIVU"
		    | MirTypes.DIVS =>
			Crash.unimplemented"MirTypes.DIVS"
		    | MirTypes.MODU =>
			Crash.unimplemented"MirTypes.MODU"
		    | MirTypes.MODS =>
			Crash.unimplemented"MirTypes.MODS"
		    | MirTypes.AND => Sparc_Assembly.AND
		    | MirTypes.OR => Sparc_Assembly.OR
		    | MirTypes.BIC => Sparc_Assembly.ANDN
		    | MirTypes.EOR => Sparc_Assembly.XOR
		    | MirTypes.LSR => Sparc_Assembly.SRL
		    | MirTypes.ASL => Sparc_Assembly.SLL
		    | MirTypes.ASR => Sparc_Assembly.SRA
		  fun needs_reverse Sparc_Assembly.SUB = true
		  | needs_reverse Sparc_Assembly.SUBCC = true
		  | needs_reverse Sparc_Assembly.SUBX = true
		  | needs_reverse Sparc_Assembly.SUBXCC = true
		  | needs_reverse Sparc_Assembly.SRL = true
		  | needs_reverse Sparc_Assembly.SLL = true
		  | needs_reverse Sparc_Assembly.SRA = true
		  | needs_reverse _ = false
		  val (gp_operand, gp_operand', redo) =
		    if is_reg gp_operand then (gp_operand, gp_operand', false)
		    else
		      if needs_reverse opcode then
			(gp_operand, gp_operand', true)
		      else (gp_operand', gp_operand, false)
		in
		  if redo then
		    ([],
		     MirTypes.UNARY(MirTypes.MOVE,
				    MirTypes.GC_REG MirRegisters.global,
				    gp_operand) ::
		     MirTypes.BINARY(binary_op, reg_operand,
				     MirTypes.GP_GC_REG MirRegisters.global,
				     gp_operand') ::
		     opcode_list, block_list, final_result)
		  else
		    if is_reg gp_operand then
		      let
			val rs1 = lookup_gp_operand gp_operand
		      in
			if is_reg gp_operand' orelse
			  gp_check_range(gp_operand', true,
					 arith_imm_limit) then
			  let
			    val reg_or_imm =
			      if is_reg gp_operand' then
				Sparc_Assembly.REG(lookup_gp_operand
						   gp_operand')
			      else make_imm_format3 gp_operand'
			  in
			    ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			       (opcode, rd, reg_or_imm, rs1), absent, "")],
d789 5
a793 15
			  end
			else
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  MirTypes.GC_REG MirRegisters.global,
					  gp_operand') ::
			   MirTypes.BINARY(binary_op, reg_operand,
					   gp_operand,
					   MirTypes.GP_GC_REG
					   MirRegisters.global) ::
			   opcode_list, block_list, final_result)
		      end
		    else Crash.impossible"Mach_Cg(BINARY) first arg not reg"
		end
              | MirTypes.UNARY(unary_op, reg_operand, gp_operand) =>
d796 32
a827 4
		    val opcode = case unary_op of
		      MirTypes.MOVE => Sparc_Assembly.ADD
		    | MirTypes.NOT => Sparc_Assembly.ANDN
		    val (extra, reg_or_imm, is_null, rs1) =
d829 1
a829 7
			let
			  val rs2 = lookup_gp_operand gp_operand
			in
			  ([], Sparc_Assembly.REG rs2,
			   rd = rs2 andalso opcode = Sparc_Assembly.ADD,
			   MachTypes.G0)
			end
d831 15
d847 1
a847 1
			  val (high, low) = split_int gp_operand
d849 14
a862 4
			  if gp_check_range(gp_operand, true,
					    arith_imm_limit) then
			    ([], make_imm_format3 gp_operand, false,
			     MachTypes.G0)
d864 10
a873 4
			    ([(Sparc_Assembly.SetHI
			       (Sparc_Assembly.SETHI, rd, high),
			       absent, "Get high part")],
			     Sparc_Assembly.IMM low, false, rd)
d875 1
a875 7
		  in
		    (if is_null then
		       []
		     else
		       extra @@ [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				 (opcode, rd, reg_or_imm, rs1), absent, "")],
		       opcode_list, block_list, final_result)
d877 1
a877 37
	      | MirTypes.BINARYFP(binary_fp_op, fp_operand, fp_operand',
				  fp_operand'') =>
		Crash.unimplemented"do_opcodes(BINARYFP)"
	      | MirTypes.UNARYFP(unary_fp_op, fp_operand,
				 fp_operand') =>
		Crash.unimplemented"do_opcodes(UNARYFP)"
              | MirTypes.STACKOP(stack_op, reg_operand,
				 MirTypes.PRESENT offset) =>
		let
		  val opcode = case stack_op of
		    MirTypes.PUSH => MirTypes.STREF
		  | MirTypes.POP => MirTypes.LDREF
		in
		  ([],
		   MirTypes.STOREOP(opcode, reg_operand,
				    MirTypes.GC_REG MirRegisters.fp,
				    MirTypes.GP_IMM_ANY
				    (~(gc_stack_area + 4 * (offset + 1)))) ::
		   opcode_list, block_list, final_result)
		end
              | MirTypes.STACKOP _ =>
		  Crash.impossible"Offset missing on STACK_OP"
	      | MirTypes.STOREOP(store_op, reg_operand, reg_operand',
				 gp_operand) =>
		let
		  val rd = lookup_reg_operand reg_operand
		  val rs1 = lookup_reg_operand reg_operand'
		  val store = case store_op of
		    MirTypes.LD => Sparc_Assembly.LD
		  | MirTypes.ST => Sparc_Assembly.ST
		  | MirTypes.LDB => Sparc_Assembly.LDUB
		  | MirTypes.STB => Sparc_Assembly.STB
		  | MirTypes.LDREF => Sparc_Assembly.LD
		  | MirTypes.STREF => Sparc_Assembly.ST
		in
		  if is_reg gp_operand orelse
		    gp_check_range(gp_operand, true, arith_imm_limit) then
d879 5
a883 1
		      val reg_or_imm =
d885 21
a905 2
			  Sparc_Assembly.REG(lookup_gp_operand gp_operand)
			else make_imm_for_store gp_operand
d907 6
a912 4
		      ([(Sparc_Assembly.LOAD_AND_STORE(store, rd, rs1,
						       reg_or_imm),
			 absent, "")],
		       opcode_list, block_list, final_result)
d914 28
a941 31
		  else
		    ([],
		     MirTypes.UNARY(MirTypes.MOVE,
				    MirTypes.GC_REG MirRegisters.global,
				    gp_operand) ::
		     MirTypes.STOREOP(store_op, reg_operand,
					     reg_operand',
					     MirTypes.GP_GC_REG
					     MirRegisters.global) ::
		     opcode_list, block_list, final_result)
		end
	      | MirTypes.STOREFPOP(store_fp_op, fp_operand, reg_operand,
				   gp_operand) =>

		let
		  val frd = lookup_fp_operand fp_operand
		  val rs1 = lookup_reg_operand reg_operand
		  val store = case (MachTypes.fp_used, store_fp_op) of
		    (MachTypes.single, MirTypes.FLD) => Sparc_Assembly.LDF
		  | (MachTypes.single, MirTypes.FST) => Sparc_Assembly.STF
		  | (MachTypes.single, MirTypes.FLDREF) => Sparc_Assembly.LDF
		  | (MachTypes.single, MirTypes.FSTREF) => Sparc_Assembly.STF
		  | (MachTypes.double, MirTypes.FLD) => Sparc_Assembly.LDDF
		  | (MachTypes.double, MirTypes.FST) => Sparc_Assembly.STDF
		  | (MachTypes.double, MirTypes.FLDREF) => Sparc_Assembly.LDDF
		  | (MachTypes.double, MirTypes.FSTREF) => Sparc_Assembly.STDF
		  | (MachTypes.extended, _) =>
		      Crash.unimplemented"STOREFPOP extended"
		in
		  if is_reg gp_operand orelse
		    gp_check_range(gp_operand, true, arith_imm_limit) then
d943 40
a982 4
		      val reg_or_imm =
			if is_reg gp_operand then
			  Sparc_Assembly.REG(lookup_gp_operand gp_operand)
			else make_imm_for_store gp_operand
d984 3
a986 4
		      ([(Sparc_Assembly.LOAD_AND_STORE_FLOAT(store, frd, rs1,
							     reg_or_imm),
			 absent, "")],
		       opcode_list, block_list, final_result)
d988 7
a994 1
		  else
d996 4
a999 7
		     MirTypes.UNARY(MirTypes.MOVE,
				    MirTypes.GC_REG MirRegisters.global,
				    gp_operand) ::
		     MirTypes.STOREFPOP(store_fp_op, fp_operand,
					reg_operand,
					MirTypes.GP_GC_REG
					MirRegisters.global) ::
d1001 5
a1005 2
		end
              | MirTypes.CONVOP(int_to_float, fp_operand, gp_operand) =>
d1007 9
a1015 46
		    val (operation, to_fp) =
		      case (MachTypes.fp_used, int_to_float) of
			(MachTypes.single, MirTypes.ITOF) =>
			  (Sparc_Assembly.FITOS, true)
		      | (MachTypes.double, MirTypes.ITOF) =>
			  (Sparc_Assembly.FITOD, true)
		      | (MachTypes.extended, MirTypes.ITOF) =>
			  (Sparc_Assembly.FITOX, true)
		      | (MachTypes.single, MirTypes.FTOI) =>
			  (Sparc_Assembly.FSTOI, false)
		      | (MachTypes.double, MirTypes.FTOI) =>
			  (Sparc_Assembly.FDTOI, false)
		      | (MachTypes.extended, MirTypes.FTOI) =>
			  (Sparc_Assembly.FXTOI, false)
		    val fr = lookup_fp_operand fp_operand
		    val ir =
		      if is_reg gp_operand then
			lookup_gp_operand gp_operand
		      else
			MachTypes.global
		    val rd =
		      if to_fp then
			fr
		      else
			if is_reg gp_operand then
			  ir
			else Crash.impossible"Conversion to integer constant"
		    val rs2 =
		      if to_fp then
			if is_reg gp_operand then
			  ir
			else
			  MachTypes.global
		      else
			fr
		    val tag_result =
		      if to_fp then []
		      else
			[(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			  (Sparc_Assembly.SLL, rd, Sparc_Assembly.IMM 2, rd),
			  absent, "Tag the result")]
		    val (untag_operand, rs2) =
		      if to_fp then
			([move_reg(MachTypes.global, rs2)], MachTypes.global)
		      else
			([], rs2)
d1017 13
a1029 4
		    if is_reg gp_operand then
		      ((Sparc_Assembly.CONV_OP(operation, rd, rs2),
			absent, "") :: tag_result,
		       opcode_list, block_list, final_result)
d1035 4
a1038 3
		       MirTypes.CONVOP(int_to_float, fp_operand,
				       MirTypes.GP_GC_REG
				       MirRegisters.global) ::
d1041 166
a1206 2
	      | MirTypes.BRANCH(branch, bl_dest) =>
		  ((case bl_dest of
d1216 80
a1295 54
		      opcode_list, block_list, final_result)
	      | MirTypes.TEST(cond_branch, tag, gp_operand,
			      gp_operand') =>
		let
		  val branch = case cond_branch of
		    MirTypes.BNT => Sparc_Assembly.BEA
		  | MirTypes.BTA => Sparc_Assembly.BNEA
		  | MirTypes.BEQ => Sparc_Assembly.BEA
		  | MirTypes.BNE => Sparc_Assembly.BNEA
		  | MirTypes.BHI => Sparc_Assembly.BGUA
		  | MirTypes.BLS => Sparc_Assembly.BLEUA
		  | MirTypes.BHS => Sparc_Assembly.BCCA
		  | MirTypes.BLO => Sparc_Assembly.BCSA
		  | MirTypes.BGT => Sparc_Assembly.BGA
		  | MirTypes.BLE => Sparc_Assembly.BLEA
		  | MirTypes.BGE => Sparc_Assembly.BGEA
		  | MirTypes.BLT => Sparc_Assembly.BLA
		  val (branch, gp_op, gp_op') =
		    case gp_operand of
		      MirTypes.GP_GC_REG _ =>
			(branch, gp_operand, gp_operand')
		    | MirTypes.GP_NON_GC_REG _ =>
			(branch, gp_operand, gp_operand')
		    | _ => (Sparc_Assembly.reverse_branch_annul branch,
			    gp_operand', gp_operand)
		  val _ = case gp_op of
		    MirTypes.GP_GC_REG _ => ()
		  | MirTypes.GP_NON_GC_REG _ => ()
		  | _ => Crash.impossible"Two constant operands to test"
		  val rs1 = lookup_gp_operand gp_op
		  val reg_or_imm =
		    if is_reg gp_op' then
		      Sparc_Assembly.REG(lookup_gp_operand gp_op')
		    else
		      make_imm_format3 gp_op'
		  val test_instr = case cond_branch of
		    MirTypes.BTA => Sparc_Assembly.ANDCC
		  | MirTypes.BNT => Sparc_Assembly.ANDCC
		  | _ => Sparc_Assembly.SUBCC
		in
		  ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		     (test_instr, MachTypes.G0,
		      reg_or_imm, rs1),
		     absent, "Do the test"),
		    (Sparc_Assembly.BRANCH_ANNUL(branch, 0),
		     MirTypes.PRESENT tag, "Do the branch"),
		    nop], opcode_list, block_list, final_result)
		end
	      | MirTypes.FTEST(fcond_branch, tag, fp_operand,
			       fp_operand') =>
		Crash.unimplemented"do_opcodes(FTEST)"
              | MirTypes.BRANCH_AND_LINK(branch_and_link, bl_dest) =>
		  ((case branch_and_link of
		      MirTypes.BLR =>
d1297 4
a1300 30
			  val reg = case bl_dest of
			    MirTypes.REG reg_operand =>
			      lookup_reg_operand reg_operand
			  | _ => Crash.impossible"BLR to tag"
			in
			  [(Sparc_Assembly.JUMP_AND_LINK
			    (Sparc_Assembly.JMPL, MachTypes.lr,
			     Sparc_Assembly.IMM ~1, reg),
			    absent, "Call to tagged value"),
			   nop]
			end
		    | MirTypes.BSR =>
			let
			  val tag =
			    case bl_dest of
			      MirTypes.TAG tag => tag
			    | _ => Crash.impossible"BSR to reg"
			in
			  [(Sparc_Assembly.Call
			    (Sparc_Assembly.CALL, 0),
			    MirTypes.PRESENT tag, "Call"),
			   nop]
			end), opcode_list, block_list, final_result)
	      | MirTypes.SWITCH(computed_goto, reg_operand, tag_list) =>
		  ((if length tag_list <= 2 then
		      let
			val reg = lookup_reg_operand reg_operand
			val (numbered_tag_list, _) =
			  Lists.number_from(tag_list, 0, 4, fn x=> x)
			fun do_tests(done, []) = rev done
d1316 53
a1368 25
		      in
			do_tests([], numbered_tag_list)
		      end
		    else
		      (Sparc_Assembly.Call
		       (Sparc_Assembly.CALL, 0),
		       absent, "Call self") ::
		      nop ::
		      (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		       (Sparc_Assembly.ADD, MachTypes.lr,
			Sparc_Assembly.IMM(5*4),
			MachTypes.lr), absent,
		       "Offset to start of table") ::
		      (Sparc_Assembly.JUMP_AND_LINK
		       (Sparc_Assembly.JMPL, MachTypes.G0,
			Sparc_Assembly.REG MachTypes.lr,
			lookup_reg_operand reg_operand), absent,
		       "Branch into table") ::
		      nop ::
		      map
		      (fn tag =>
		       (Sparc_Assembly.BRANCH_ANNUL
			(Sparc_Assembly.BAA, 0), MirTypes.PRESENT tag, ""))
		      tag_list),
		      opcode_list, block_list, final_result)
d1370 39
a1408 21
	      | MirTypes.ALLOCATE_STACK(allocate, reg_operand, alloc_size,
					MirTypes.PRESENT fp_offset) =>
		(case allocate of
		  MirTypes.ALLOC =>
		    ([],
		     MirTypes.BINARY(MirTypes.SUB, reg_operand,
				     MirTypes.GP_GC_REG MirRegisters.fp,
				     MirTypes.GP_IMM_ANY
				     (gc_stack_area +
				      4 * (fp_offset + alloc_size) - 1)) ::
		     (* Note tagging on pointer *)
		     opcode_list, block_list, final_result)
		 | _ => Crash.impossible"ALLOCATE_STACK strange allocate")
	      | MirTypes.ALLOCATE_STACK _ =>
		  Crash.impossible"ALLOCATE_STACK with no offset from fp"
	      | MirTypes.DEALLOCATE_STACK _ =>
		  ([], opcode_list, block_list, final_result)
	      | MirTypes.ALLOCATE(allocate, reg_operand, i) =>
		let
		  val rd =
		    lookup_reg_operand reg_operand
d1410 14
a1423 8
		  val (size_in_bytes, ptr_tag) =
		    case allocate of
		      MirTypes.ALLOC =>
			if i = 2 then (8, 1) else (8 * ((i + 2) div 2), 5)
		    | MirTypes.ALLOC_STRING =>
			(((i + 12) div 8) * 8, 5)
		    | MirTypes.ALLOC_REAL => (16, 5)
		    | MirTypes.ALLOC_REF => (16, 3)
d1425 80
a1504 64
		  fun do_allocate goto_tag =
		    [
		     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		      (Sparc_Assembly.ADD, MachTypes.gc1,
		       Sparc_Assembly.IMM size_in_bytes,
		       MachTypes.gc1),
		      absent, "Calculate new heap start"),
		     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		      (Sparc_Assembly.SUBCC, MachTypes.G0,
		       Sparc_Assembly.REG(MachTypes.gc2), MachTypes.gc1),
		      absent, "Check if collection needed"),
		     (Sparc_Assembly.BRANCH_ANNUL
		      (Sparc_Assembly.BLA, 0), MirTypes.PRESENT goto_tag,
		      "Don't do next instruction if gc is required"),
		     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		      (Sparc_Assembly.ADD, rd,
		       Sparc_Assembly.IMM(ptr_tag - size_in_bytes),
		       MachTypes.gc1),
		      absent, "Generate tagged result"),
		     (Sparc_Assembly.LOAD_AND_STORE
		      (Sparc_Assembly.LD, MachTypes.global,
		       MachTypes.implicit, Sparc_Assembly.IMM 0),
		      absent, "Get address of callc"),
		     (Sparc_Assembly.JUMP_AND_LINK
		      (Sparc_Assembly.JMPL, MachTypes.O7,
		       Sparc_Assembly.IMM 0, MachTypes.global),
		      absent, "Do callgc"),
		     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		      (Sparc_Assembly.ADD, MachTypes.global,
		       Sparc_Assembly.IMM size_in_bytes, MachTypes.G0),
		      absent, "Setup callgc argument"),
		     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		      (Sparc_Assembly.ADD, rd,
		       Sparc_Assembly.IMM ptr_tag, MachTypes.global),
		      absent, "Tag result of garbage collection"),
		     (Sparc_Assembly.BRANCH_ANNUL
		      (Sparc_Assembly.BAA, 0), MirTypes.PRESENT goto_tag,
		      "Jump to rest of block after gc")
		     ]

		  fun do_header(header,goto_tag) =
		    [
		     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		      (Sparc_Assembly.ADD, MachTypes.global,
		       Sparc_Assembly.IMM header, MachTypes.G0),
		      absent, "Generate header word value"),
		     (Sparc_Assembly.LOAD_AND_STORE
		      (Sparc_Assembly.ST, MachTypes.global,
		       rd, Sparc_Assembly.IMM (~ptr_tag)),
		      absent, "Store the header word"),
		     (Sparc_Assembly.BRANCH_ANNUL
		      (Sparc_Assembly.BAA, 0), MirTypes.PRESENT goto_tag,
		      "Jump to rest of block after doing header")
		     ]

		  val (split_tag, after_gc_tag) =
		    (MirTypes.new_tag(), MirTypes.new_tag())
		in
		  case allocate of
		    MirTypes.ALLOC =>
		      if i = 2 then
			(do_allocate split_tag, [],
			 MirTypes.BLOCK(split_tag, opcode_list) :: block_list,
			 final_result)
d1506 36
a1541 32
			(do_allocate after_gc_tag, [],
			 MirTypes.BLOCK(split_tag, opcode_list) :: block_list,
			 (after_gc_tag, do_header (2 + 64 * i, split_tag)) ::
			 final_result)
		  | MirTypes.ALLOC_STRING =>
		      (do_allocate after_gc_tag, [],
		       MirTypes.BLOCK(split_tag, opcode_list) :: block_list,
		       (after_gc_tag, do_header (10 + 64 * i, split_tag)) ::
		       final_result)
		  | MirTypes.ALLOC_REF =>
		      (do_allocate after_gc_tag, [],
		       MirTypes.BLOCK(split_tag, opcode_list) :: block_list,
		       (after_gc_tag, do_header (82, split_tag)) ::
		       final_result)
		  | MirTypes.ALLOC_REAL =>
		      (do_allocate after_gc_tag, [],
		       MirTypes.BLOCK(split_tag, opcode_list) :: block_list,
		       (after_gc_tag, do_header (10 + 64 * 8, split_tag)) ::
		       final_result)
		end

	      | MirTypes.ADR(adr, reg_operand, tag) =>
		  ([(Sparc_Assembly.Call
		     (Sparc_Assembly.CALL, 0),
		     absent, "Call self"),
		    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		     (Sparc_Assembly.ADD, lookup_reg_operand reg_operand,
		      Sparc_Assembly.IMM ~4, MachTypes.lr),
		     absent, "Update gc pointer")],
		  opcode_list, block_list, final_result)
	      | MirTypes.ENTER =>
		  (if needs_preserve then
d1543 2
a1544 5
		       val frame_size =
			 ~(((4 * gc_spill_size + 4 * non_gc_spill_size +
			     8 * fp_spill_size + 16 * fp_double_spill_size +
			     stack_extra * 4 + 68)
			   div 8) * 8)
d1546 5
a1550 22
		       if check_range(frame_size, true, arith_imm_limit) then
			 [(Sparc_Assembly.SAVE_AND_RESTORE
			   (Sparc_Assembly.SAVE, MachTypes.sp,
			    Sparc_Assembly.IMM frame_size,
			    MachTypes.sp), absent, "New frame")]
		       else
			 let
			   val (high, low) =
			     split_int(MirTypes.GP_IMM_ANY frame_size)
			 in
			   [(Sparc_Assembly.SetHI
			     (Sparc_Assembly.SETHI, MachTypes.global, high),
			     absent, "Get high part"),
			    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.ADD, MachTypes.global,
			     Sparc_Assembly.IMM low, MachTypes.global),
			     absent, "Add in low part"),
			    (Sparc_Assembly.SAVE_AND_RESTORE
			     (Sparc_Assembly.SAVE, MachTypes.sp,
			      Sparc_Assembly.REG MachTypes.global,
			      MachTypes.sp), absent, "New frame")]
			 end
d1552 8
a1559 54
		   else
		     [], opcode_list, block_list, final_result)
	      | MirTypes.PRESERVE_ALL_REGS =>
		  ([(Sparc_Assembly.SAVE_AND_RESTORE
		     (Sparc_Assembly.SAVE, MachTypes.sp,
		      Sparc_Assembly.IMM ~64,
		      MachTypes.sp), absent, "New frame")],
		   opcode_list, block_list, final_result)
	      | MirTypes.PREVIOUS_ENVIRONMENT =>
		  ([(Sparc_Assembly.SAVE_AND_RESTORE
		    (Sparc_Assembly.RESTORE, MachTypes.G0,
		     Sparc_Assembly.IMM 0,
		     MachTypes.sp), absent, "Restore previous environment")],
		  opcode_list, block_list, final_result)
	      | MirTypes.RTS =>
		  (if needs_preserve then
		     [(Sparc_Assembly.JUMP_AND_LINK
		       (Sparc_Assembly.JMPL, MachTypes.G0,
			Sparc_Assembly.IMM 8,
			MachTypes.after_preserve MachTypes.lr),
		       absent, "Scheduled return"),
		      (Sparc_Assembly.SAVE_AND_RESTORE
		       (Sparc_Assembly.RESTORE, MachTypes.G0,
			Sparc_Assembly.IMM 0,
			MachTypes.sp), absent, "Restore in the delay slot")]
		   else
		     [(Sparc_Assembly.JUMP_AND_LINK
		       (Sparc_Assembly.JMPL, MachTypes.G0,
			Sparc_Assembly.IMM 8, MachTypes.lr),
		       absent, "Ordinary return"),
		      nop], opcode_list, block_list, final_result)
	      | MirTypes.NEW_HANDLER tag =>
		  ([], opcode_list, block_list, final_result)
	      | MirTypes.OLD_HANDLER =>
		  ([], opcode_list, block_list, final_result)
	      | MirTypes.RAISE reg_operand =>
		  let
		    val reg_or_imm =
		      Sparc_Assembly.REG(lookup_reg_operand reg_operand)
		  in
		    ([(Sparc_Assembly.JUMP_AND_LINK
		       (Sparc_Assembly.JMPL, MachTypes.lr,
			reg_or_imm, MachTypes.G0),
		       absent, "Raise"),
		      nop], opcode_list, block_list, final_result)
		  end
	      | MirTypes.COMMENT string =>
		  ([], opcode_list, block_list, final_result)
	  in
	    do_everything
	    (needs_preserve, tag, opcode_list,
	     done @@ result_list, new_blocks,
	     new_final_result)
	  end
@


1.35
log
@Added encoding and output of reals
@
text
@d4 3
d278 1
a278 1
      fun to_sub(0, value, done) = done
d291 6
a296 4
      val real_exponent = exponent + 127
      val _ =
	if real_exponent < 0 then
	  raise(Reals.too_small)
d298 2
a299 2
	  if real_exponent > 2047 then
	    raise(Reals.too_big)
d301 17
a317 1
	    ()
d319 1
a319 6
      binary_list_to_string
      ([],
       (if sign then "1" else "0") ::
	  to_binary(11, real_exponent) @@
	  explode(String.substring(mantissa, 0, 52)),
	  0, 128)
d327 4
d332 1
a332 1
      MachTypes.REAL(i, to_double_string(sign, mantissa, exponent))
d690 3
d947 40
a986 1
		Crash.unimplemented"do_opcodes(STOREFPOP)"
d988 62
a1049 1
		  Crash.unimplemented"do_opcodes(CONVOP)"
@


1.34
log
@Added code for STACK_OPs. Added show_mach for controlling opcode lsiting
@
text
@d4 3
d135 1
d137 1
d156 1
d158 1
d249 57
d307 7
a313 1
  | value_cg(i, Ident.REAL x) = Crash.unimplemented"VALUE(REAL)"
@


1.33
log
@Added extra argument to STACKOP, as yet unimplemented.
@
text
@d4 3
d178 1
d453 1
d455 1
d457 1
d460 1
d799 16
a814 2
              | MirTypes.STACKOP(stack_op, reg_operand, offset) =>
		  Crash.unimplemented"do_opcodes(STACKOP)"
d1161 5
a1165 1
		  Crash.unimplemented"do_opcodes(PREVIOUS_ENVIRONMENT)"
d1291 9
a1299 5
	    (Print.print "[Sparc_Assembly Code]\n";
	     map
	     (fn (x,y) => Print.print
	      (Sparc_Assembly.print x ^ " ; " ^ y ^ "\n"))
	     code)
@


1.32
log
@Corrected pointers produced by ALLOCATE_STACK to be correctly tagged
@
text
@d4 3
d791 1
a791 1
              | MirTypes.STACKOP(stack_op, reg_operand) =>
@


1.31
log
@Added ALLOC_REAL
@
text
@d4 3
d975 5
a979 4
				       MirTypes.GP_GC_REG MirRegisters.fp,
				       MirTypes.GP_IMM_ANY
				       (gc_stack_area +
					4 * (fp_offset + alloc_size))) ::
@


1.30
log
@Added ALLOCATE_STACK coding, plus use of various stack sizes provided
by previous stage.
@
text
@d4 4
d993 2
a994 4
		    | MirTypes.ALLOC_REAL =>
			Crash.unimplemented "ALLOC_REAL"
		    | MirTypes.ALLOC_REF =>
			Crash.unimplemented "ALLOC_REF"
d1070 10
a1079 2
		  | _ =>
		      Crash.impossible "ALLOC should already have died"
@


1.29
log
@Fixed printing of sparc assembly code.
@
text
@d4 3
d528 20
d962 12
d975 1
a975 2
		  Crash.unimplemented "ALLOCATE_STACK"

d977 1
a977 2
		  Crash.unimplemented "DEALLOCATE_STACK"
		      
d1083 30
a1112 5
		     [(Sparc_Assembly.SAVE_AND_RESTORE
		       (Sparc_Assembly.SAVE, MachTypes.sp,
			Sparc_Assembly.IMM ~64,
			(* This should change in the light of real info *)
			MachTypes.sp), absent, "New frame")]
d1164 1
a1164 2
      fun do_block (_, []) = []
	| do_block (needs_preserve, MirTypes.BLOCK(tag,opcodes) :: rest) =
d1166 1
d1218 2
a1219 1
	  val code = move_first([], do_block(needs_preserve, block_list))
d1231 1
a1231 1
      | proc_cg _ = Crash.impossible "macg_cg.proc_cg"
@


1.28
log
@Does proper check to see whether a preserve is required. Changed
various prints to Print.prints.
@
text
@d4 4
d1145 8
a1152 8
	    not leaf orelse
	    ch (fn r => check_reg(Table.lookup(r, fp_table))) fp
	    orelse
	    ch (fn r => check_reg(Table.lookup(r, fp_double_table))) fp_double
	    orelse
	    ch (fn r => check_reg(Table.lookup(r, gc_table))) gc
	    orelse
	    ch (fn r => check_reg(Table.lookup(r, non_gc_table))) non_gc
d1187 1
d1189 5
a1193 6
	    let
	      val _ = Print.print"Sparc_Assembly Code"
	    in
	      map (Print.print o (fn (x, y) => Sparc_Assembly.print x ^
			    " ; " ^ y)) code
	    end
d1196 1
@


1.27
log
@Added improved linearisation top block choice.
@
text
@d4 3
d106 6
a111 5
require "../utils/lists.sml";
require "../utils/set.sml";
require "../utils/crash.sml";
require "../utils/table.sml";
require "../utils/integer.sml";
d124 17
a140 16
functor Mach_Cg(
  structure Lists : LISTS
  structure Set : SET
  structure Crash : CRASH
  structure Table : TABLE
  structure Integer : INTEGER
  structure Ident : IDENT
  structure MirTypes : MIRTYPES
  structure MirTables : MIRTABLES
  structure MirRegisters : MIRREGISTERS
  structure MirPrint : MIRPRINT
  structure MachTypes : MACHTYPES
  structure MachSpec : MACHSPEC
  structure Sparc_Opcodes : SPARC_OPCODES
  structure Sparc_Assembly : SPARC_ASSEMBLY
  structure Sparc_Schedule : SPARC_SCHEDULE
d142 9
a150 9
  sharing MirTypes.Ident = Ident
  sharing MachTypes = Sparc_Opcodes.MachTypes = Sparc_Assembly.MachTypes
  sharing Sparc_Opcodes = Sparc_Assembly.Sparc_Opcodes
  sharing Set = MirTypes.Set = MirTables.Set = MirRegisters.Set
  sharing MirTypes = MirTables.MirTypes = MirPrint.MirTypes =
    Sparc_Schedule.MirTypes = MirRegisters.MirTypes
  sharing Sparc_Assembly = Sparc_Schedule.Sparc_Assembly
  sharing type MachTypes.Sparc_Reg = MachSpec.register
) : MACH_CG =
d167 1
a167 1
      val _ = print"Warning, symbolic value not translated"
d215 1
a215 1
      val _ = print"Warning, symbolic value not translated"
a246 3
(*
      val _ = print"Reordering to eliminiate fall throughs"
*)
a252 5
(*
	let
	  val _ = print"Find_dest_block"
	in
*)
a255 3
(*
	end
*)
a305 16
(*
	  fun find_next_block([], _) = (null_block, [], false)
	  | find_next_block(_, []) = (null_block, [], false)
	  | find_next_block((block as (_, to_look_at)) :: rest, to_look_in) =
	    let
(*
	      val _ = print("Find next block in list size" ^ Integer.makestring(length to_look_in))
*)
	      val (dest_tag, found) = last_tag to_look_at
	    in
	      if found andalso dest_block_exists(dest_tag, to_look_in) then
		(block, to_look_in, true)
	      else
		find_next_block(rest, tl to_look_in @@ [block])
	    end
*)
a325 5
(*
		  val (next_block, remainder, found_next) =
		    find_next_block(continuers,
				    (tl continuers) @@ non_continuers)
*)
d327 1
a327 8
(*
		  if found_next then
*)
		    do_fall_throughs(block :: done, next_block, remainder)
(*
		  else
		    rev(rev rest @@ (block :: done))
*)
d474 1
a474 1
	  val _ = print"Warning, symbolic value not translated"
a499 5
(*
      fun get_refs opcode =
	let
	  val _ = print("Get ref of " ^ MirPrint.opcode opcode)
*)
a508 5
(*
	in
	  get_refs opcode
	end
*)
a554 3
(*
	    val _ = print("Translating " ^ MirPrint.opcode opcode)
*)
d627 1
a627 39
		end
(*
		  val (rs1, reg_or_imm, extra) =
		    if is_reg gp_operand then
		      (lookup_gp_operand gp_operand,
		       if is_reg gp_operand' then
			 Sparc_Assembly.REG(lookup_gp_operand
					    gp_operand')
		       else
			 make_imm_format3 gp_operand', [])
		    else
		      let
			fun make_reverse_sub opcode =
			  (rd,
			   (if is_reg gp_operand' then
			      Sparc_Assembly.REG(lookup_gp_operand
						 gp_operand')
			    else
			      make_imm_format3 gp_operand'),
			      [move_imm(rd, make_imm_format3 gp_operand)])
		      in
			case opcode of
			  Sparc_Assembly.TSUBCC => make_reverse_sub opcode
			| _ =>
			    ((if is_reg gp_operand' then
				lookup_gp_operand gp_operand'
			      else
				Crash.impossible"TBINARY of IMM, IMM"),
				make_imm_format3 gp_operand, [])
		      end
		in
		  (extra @@
		   [(Sparc_Assembly.TAGGED_ARITHMETIC
		     (opcode, rd, reg_or_imm, rs1), absent, ""),
		    (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BVSA, 0),
		     MirTypes.PRESENT tag, "Do the branch"),
		    nop], opcode_list, block_list, final_result)
		end
*)
a710 70
(*
		  val (rs1, reg_or_imm, extra) =
		    if is_reg gp_operand then
		      let
			val rs1 = lookup_gp_operand gp_operand
		      in
			(if is_reg gp_operand' then
			   (rs1, Sparc_Assembly.REG(lookup_gp_operand
						    gp_operand'), [])
			 else
			   let
			     val (high, low) = split_int gp_operand'
			   in
			     if gp_check_range(gp_operand', true,
					       arith_imm_limit) then
			       (rs1, make_imm_format3 gp_operand', [])
			     else
			       let
				 val temp_reg =
				   if rd <> rs1 then rd
				   else MachTypes.global
			       in
				 (temp_reg, Sparc_Assembly.IMM low,
				  [(Sparc_Assembly.SetHI
				    (Sparc_Assembly.SETHI, temp_reg, high),
				    absent, "Get high part"),
				   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				    (opcode, temp_reg,
				     Sparc_Assembly.REG rs1,
				     temp_reg), absent,
				    "First part of add")])
			       end
			   end)
		      end
		    else
		      let
			fun make_reverse_sub opcode =
			  (rd,
			   (if is_reg gp_operand' then
			      Sparc_Assembly.REG(lookup_gp_operand
						 gp_operand')
			    else
			      make_imm_format3 gp_operand'),
			      [move_imm(rd, make_imm_format3 gp_operand)])
		      in
			case opcode of
			  Sparc_Assembly.SUB => make_reverse_sub opcode
			| Sparc_Assembly.SUBCC => make_reverse_sub opcode
			| Sparc_Assembly.SUBX => make_reverse_sub opcode
			| Sparc_Assembly.SUBXCC => make_reverse_sub opcode
			| Sparc_Assembly.SLL =>
			    Crash.impossible"SLL constant by register"
			| Sparc_Assembly.SRL =>
			    Crash.impossible"SRL constant by register"
			| Sparc_Assembly.SRA =>
			    Crash.impossible"SRA constant by register"
			| _ =>
			    ((if is_reg gp_operand' then
				lookup_gp_operand gp_operand'
			      else
				Crash.impossible"Binary of IMM, IMM"),
				make_imm_format3 gp_operand, [])
		      end
		in
		  (extra @@
		   [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		     (opcode, rd, reg_or_imm, rs1), absent, "")],
		   opcode_list, block_list, final_result)
		end
*)
a792 12
(*
		  val reg_or_imm =
		    if is_reg gp_operand then
		      Sparc_Assembly.REG(lookup_gp_operand gp_operand)
		    else
		      make_imm_for_store gp_operand
		in
		  ([(Sparc_Assembly.,
		     absent,
		     "")], opcode_list, block_list, final_result)
		end
*)
d1106 6
a1111 8
      fun proc_cg(proc as MirTypes.PROC(tag,
					MirTypes.PROC_PARAMS
					{leaf = leaf,
					 registers_used = regs_used,
					 spill_sizes = spills,
					 stack_allocated = stack
					 },
					block_list)) =
d1113 1
a1113 27
	  fun check_for_locals_or_outs reg_set =
	    let
	      fun list_check [] = false
	      | list_check(x :: xs) =
		case x of
		  MachTypes.L0 => true
		| MachTypes.L1 => true
		| MachTypes.L2 => true
		| MachTypes.L3 => true
		| MachTypes.L4 => true
		| MachTypes.L5 => true
		| MachTypes.L6 => true
		| MachTypes.L7 => true
		| MachTypes.O0 => true
		| MachTypes.O1 => true
		| MachTypes.O2 => true
		| MachTypes.O3 => true
		| MachTypes.O4 => true
		| MachTypes.O5 => true
(* We don't count this as an output
		| MachTypes.O6 => true
*)
		| MachTypes.O7 => true
		| _ => list_check xs
	    in
	      list_check(Set.set_to_list reg_set)
	    end
d1115 24
a1138 1
	  val refs = get_refs_for_proc proc
d1142 7
a1148 1
	    check_for_locals_or_outs(get_refs_for_proc proc)
d1168 1
d1185 1
a1185 1
	      val _ = print"Sparc_Assembly Code"
d1187 1
a1187 1
	      map (print o (fn (x, y) => Sparc_Assembly.print x ^
a1207 3
(*
      val _ = print"Doing set-up proc"
*)
@


1.26
log
@Changed the structure of the allocation instructions yet again. This
change is to allow offsets to be inserted for stack allocation. It's
also a bit more orthogonal.
@
text
@d4 5
d312 1
d327 1
d341 8
d352 1
d354 1
d356 1
d358 1
d361 1
d471 1
d614 1
a614 1
		      Crash.unimplemented"do_opcodes(TBINARY(MULV))"
d616 1
a616 1
		      Crash.unimplemented"do_opcodes(TBINARY(DIVV))"
d618 1
a618 1
		      Crash.unimplemented"do_opcodes(TBINARY(MODV))"
@


1.25
log
@Fixed bug in instruction swapping where store interactions might occur
Added large constant handling everywhere
Started on better algorithm for choosing best next block for lineariser
@
text
@d4 5
d1080 6
a1099 2
		    | MirTypes.ALLOC_STACK =>
			Crash.unimplemented "ALLOC_STACK"
d1180 1
a1180 2
              | MirTypes.DEALLOCATE(deallocate, i) =>
		  Crash.unimplemented "DEALLOCATE"
@


1.24
log
@Changed code generated for ALLOCATE to use the implicit vector to
call the garbage collector instead of having the garbage collector
mentioned in the function closure.
@
text
@d4 5
d101 1
d119 1
d130 1
a130 1
  sharing Set = MirTypes.Set = MirTables.Set
d132 1
a132 1
    Sparc_Schedule.MirTypes
d230 1
a230 1
    (* So they must be reordered again by any other means *)
d276 26
d317 21
a337 9
	    let
	      val (next_block, remainder, found_next) =
		find_next_block(rest, remainder)
	    in
	      if found_next then
		do_fall_throughs(block :: done, next_block, remainder)
	      else
		rev(rev rest @@ (block :: done))
	    end
a460 1

d573 3
d593 57
d675 1
a675 1
				Crash.impossible"Binary of IMM, IMM"),
d686 1
d714 57
d839 1
a889 5
		  val reg_or_imm =
		    if is_reg gp_operand then
		      Sparc_Assembly.REG(lookup_gp_operand gp_operand)
		    else
		      make_imm_for_store gp_operand
d898 32
a929 2
		  ([(Sparc_Assembly.LOAD_AND_STORE(store, rd, rs1,
						   reg_or_imm),
d933 1
d1316 3
a1318 1
	  val linear_code = linearise_list new_code_list
@


1.23
log
@General tidy up and re-implementation of allocation code to use
the garbage collector entry point contained in the the implicit
vector. The global register is now used as a temporary so we
don't need a special temporary register (or call_c code either).
@
text
@d4 6
d887 1
a887 2
	      | MirTypes.ALLOCATE(allocate, reg_operand, i, reg_operand',
				  proc_ref) =>
d944 1
d959 1
@


1.22
log
@Started adding code to deal with constants too large for the
instructions which require them.
@
text
@d4 4
d489 33
a521 13
      fun do_block(_, []) = []
      | do_block(needs_preserve,
		 MirTypes.BLOCK(tag, opcode_list) :: block_list) =
	let
	  fun lookup_reg(reg, table) =
	    let
	      val reg = Table.lookup(reg, table)
	    in
	      if needs_preserve then
		reg
	      else
		MachTypes.after_restore reg
	    end
d523 59
a581 72
	  fun lookup_reg_operand(MirTypes.GC_REG reg) =
	    lookup_reg(reg, gc_table)
	  | lookup_reg_operand(MirTypes.NON_GC_REG reg) =
	    lookup_reg(reg, non_gc_table)

	  fun lookup_gp_operand(MirTypes.GP_GC_REG reg) =
	    lookup_reg(reg, gc_table)
	  | lookup_gp_operand(MirTypes.GP_NON_GC_REG reg) =
	    lookup_reg(reg, non_gc_table)
	  | lookup_gp_operand _ = Crash.impossible"lookup_gp_operand(constant)"

	  fun do_opcodes([], done) = done
	  | do_opcodes(opcode :: opcode_list, done) =
	    let
	      val (result_list, opcode_list) =
		case opcode of
		  MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
				   gp_operand, gp_operand') =>
		  let
		    val rd = lookup_reg_operand reg_operand
		    val opcode = case tagged_binary_op of
		      MirTypes.ADDV =>
			Sparc_Assembly.TADDCC
		    | MirTypes.SUBV =>
			Sparc_Assembly.TSUBCC
		    | MirTypes.MULV =>
			Crash.unimplemented"do_opcodes(TBINARY(MULV))"
		    | MirTypes.DIVV =>
			Crash.unimplemented"do_opcodes(TBINARY(DIVV))"
		    | MirTypes.MODV =>
			Crash.unimplemented"do_opcodes(TBINARY(MODV))"
		    val (rs1, reg_or_imm, extra) =
		      if is_reg gp_operand then
			(lookup_gp_operand gp_operand,
			 if is_reg gp_operand' then
			   Sparc_Assembly.REG(lookup_gp_operand
					      gp_operand')
			 else
			   make_imm_format3 gp_operand', [])
		      else
			let
			  fun make_reverse_sub opcode =
			    (rd,
			     (if is_reg gp_operand' then
			       Sparc_Assembly.REG(lookup_gp_operand
						  gp_operand')
			     else
			       make_imm_format3 gp_operand'),
				[move_imm(rd, make_imm_format3 gp_operand)])
			in
			  case opcode of
			    Sparc_Assembly.TSUBCC => make_reverse_sub opcode
			  | _ =>
			      ((if is_reg gp_operand' then
				  lookup_gp_operand gp_operand'
				else
				  Crash.impossible"Binary of IMM, IMM"),
				  make_imm_format3 gp_operand, [])
			end
		  in
		    (extra @@
		    [(Sparc_Assembly.TAGGED_ARITHMETIC
		      (opcode, rd, reg_or_imm, rs1), absent, ""),
		     (Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BVSA, 0),
		      MirTypes.PRESENT tag, "Do the branch"),
		     nop], opcode_list)
		  end
		| MirTypes.BINARY(binary_op, reg_operand, gp_operand,
				  gp_operand') =>
		  let
		    val rd = lookup_reg_operand reg_operand
		    val opcode = case binary_op of
d603 75
a677 1
		    val (rs1, reg_or_imm, extra) =
d680 1
a680 1
			  val rs1 = lookup_gp_operand gp_operand
d682 3
a684 27
			  (if is_reg gp_operand' then
			     (rs1, Sparc_Assembly.REG(lookup_gp_operand
						      gp_operand'), [])
			   else
			     let
			       val (high, low) = split_int gp_operand'
			     in
			       if gp_check_range(gp_operand', true,
						 arith_imm_limit) then
				 (rs1, make_imm_format3 gp_operand', [])
			       else
				 let
				   val temp_reg =
				     if rd <> rs1 then rd
				     else MachTypes.global
				 in
				   (temp_reg, Sparc_Assembly.IMM low,
				    [(Sparc_Assembly.SetHI
				      (Sparc_Assembly.SETHI, temp_reg, high),
				      absent, "Get high part"),
				     (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				      (opcode, temp_reg,
				       Sparc_Assembly.REG rs1,
				       temp_reg), absent,
				      "First part of add")])
				 end
			     end)
d688 1
a688 8
			  fun make_reverse_sub opcode =
			    (rd,
			     (if is_reg gp_operand' then
			       Sparc_Assembly.REG(lookup_gp_operand
						  gp_operand')
			     else
			       make_imm_format3 gp_operand'),
				[move_imm(rd, make_imm_format3 gp_operand)])
d690 9
a698 17
			  case opcode of
			    Sparc_Assembly.SUB => make_reverse_sub opcode
			  | Sparc_Assembly.SUBCC => make_reverse_sub opcode
			  | Sparc_Assembly.SUBX => make_reverse_sub opcode
			  | Sparc_Assembly.SUBXCC => make_reverse_sub opcode
			  | Sparc_Assembly.SLL =>
			      Crash.impossible"SLL constant by register"
			  | Sparc_Assembly.SRL =>
			      Crash.impossible"SRL constant by register"
			  | Sparc_Assembly.SRA =>
			    Crash.impossible"SRA constant by register"
			  | _ =>
			      ((if is_reg gp_operand' then
				  lookup_gp_operand gp_operand'
				else
				  Crash.impossible"Binary of IMM, IMM"),
				  make_imm_format3 gp_operand, [])
d701 6
a706 3
		    (extra @@
		    [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		      (opcode, rd, reg_or_imm, rs1), absent, "")], opcode_list)
d708 32
a739 46
		| MirTypes.UNARY(unary_op, reg_operand, gp_operand) =>
		    let
		      val rd = lookup_reg_operand reg_operand
		      val opcode = case unary_op of
			MirTypes.MOVE => Sparc_Assembly.ADD
		      | MirTypes.NOT => Sparc_Assembly.ANDN
		      val (extra, reg_or_imm, is_null, rs1) =
			if is_reg gp_operand then
			  let
			    val rs2 = lookup_gp_operand gp_operand
			  in
			    ([], Sparc_Assembly.REG rs2,
			     rd = rs2 andalso opcode = Sparc_Assembly.ADD,
			     MachTypes.G0)
			  end
			else
			  let
			    val (high, low) = split_int gp_operand
			  in
			    if gp_check_range(gp_operand, true,
					      arith_imm_limit) then
			      ([], make_imm_format3 gp_operand, false,
			       MachTypes.G0)
			    else
			      ([(Sparc_Assembly.SetHI
				 (Sparc_Assembly.SETHI, rd, high),
				 absent, "Get high part")],
			       Sparc_Assembly.IMM low, false, rd)
			  end
		    in
		      (if is_null then
			[]
		      else
			extra @@ [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			  (opcode, rd, reg_or_imm, rs1), absent, "")],
			 opcode_list)
		    end
		| MirTypes.BINARYFP(binary_fp_op, fp_operand, fp_operand',
				    fp_operand'') =>
		  Crash.unimplemented"do_opcodes(BINARYFP)"
		| MirTypes.UNARYFP(unary_fp_op, fp_operand,
				   fp_operand') =>
		  Crash.unimplemented"do_opcodes(UNARYFP)"
		| MirTypes.STACKOP(stack_op, reg_operand) =>
		    Crash.unimplemented"do_opcodes(STACKOP)"
		| MirTypes.STOREOP(store_op, reg_operand, reg_operand',
d741 5
a745 28
		  let
		    val rd = lookup_reg_operand reg_operand
		    val rs1 = lookup_reg_operand reg_operand'
		    val reg_or_imm =
		      if is_reg gp_operand then
			Sparc_Assembly.REG(lookup_gp_operand gp_operand)
		      else
			make_imm_for_store gp_operand
		    val store = case store_op of
		      MirTypes.LD => Sparc_Assembly.LD
		    | MirTypes.ST => Sparc_Assembly.ST
		    | MirTypes.LDB => Sparc_Assembly.LDUB
		    | MirTypes.STB => Sparc_Assembly.STB
		    | MirTypes.LDREF => Sparc_Assembly.LD
		    | MirTypes.STREF => Sparc_Assembly.ST
		  in
		    ([(Sparc_Assembly.LOAD_AND_STORE(store, rd, rs1,
						     reg_or_imm),
		       absent,
		       "")], opcode_list)
		  end
		| MirTypes.STOREFPOP(store_fp_op, fp_operand, reg_operand,
				     gp_operand) =>
		  Crash.unimplemented"do_opcodes(STOREFPOP)"
		| MirTypes.CONVOP(int_to_float, fp_operand, gp_operand) =>
		    Crash.unimplemented"do_opcodes(CONVOP)"
		| MirTypes.BRANCH(branch, bl_dest) =>
		    ((case bl_dest of
d751 1
a751 1
			  nop]
d754 54
a807 54
			   MirTypes.PRESENT tag, "Branch relative")]),
			opcode_list)
		| MirTypes.TEST(cond_branch, tag, gp_operand,
				gp_operand') =>
		  let
		    val branch = case cond_branch of
		      MirTypes.BNT => Sparc_Assembly.BEA
		    | MirTypes.BTA => Sparc_Assembly.BNEA
		    | MirTypes.BEQ => Sparc_Assembly.BEA
		    | MirTypes.BNE => Sparc_Assembly.BNEA
		    | MirTypes.BHI => Sparc_Assembly.BGUA
		    | MirTypes.BLS => Sparc_Assembly.BLEUA
		    | MirTypes.BHS => Sparc_Assembly.BCCA
		    | MirTypes.BLO => Sparc_Assembly.BCSA
		    | MirTypes.BGT => Sparc_Assembly.BGA
		    | MirTypes.BLE => Sparc_Assembly.BLEA
		    | MirTypes.BGE => Sparc_Assembly.BGEA
		    | MirTypes.BLT => Sparc_Assembly.BLA
		    val (branch, gp_op, gp_op') =
		      case gp_operand of
			MirTypes.GP_GC_REG _ =>
			  (branch, gp_operand, gp_operand')
		      | MirTypes.GP_NON_GC_REG _ =>
			  (branch, gp_operand, gp_operand')
		      | _ => (Sparc_Assembly.reverse_branch_annul branch,
			      gp_operand', gp_operand)
		    val _ = case gp_op of
		      MirTypes.GP_GC_REG _ => ()
		    | MirTypes.GP_NON_GC_REG _ => ()
		    | _ => Crash.impossible"Two constant operands to test"
		    val rs1 = lookup_gp_operand gp_op
		    val reg_or_imm =
		      if is_reg gp_op' then
			Sparc_Assembly.REG(lookup_gp_operand gp_op')
		      else
			make_imm_format3 gp_op'
		    val test_instr = case cond_branch of
		      MirTypes.BTA => Sparc_Assembly.ANDCC
		    | MirTypes.BNT => Sparc_Assembly.ANDCC
		    | _ => Sparc_Assembly.SUBCC
		  in
		    ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		      (test_instr, MachTypes.G0,
		       reg_or_imm, rs1),
		      absent, "Do the test"),
		     (Sparc_Assembly.BRANCH_ANNUL(branch, 0),
		      MirTypes.PRESENT tag, "Do the branch"),
		     nop], opcode_list)
		  end
		| MirTypes.FTEST(fcond_branch, tag, fp_operand,
				 fp_operand') =>
		  Crash.unimplemented"do_opcodes(FTEST)"
		| MirTypes.BRANCH_AND_LINK(branch_and_link, bl_dest) =>
		    ((case branch_and_link of
d823 4
a826 2
			  val tag = case bl_dest of MirTypes.TAG tag => tag
			  | _ => Crash.impossible"BSR to reg"
d832 2
a833 2
			end), opcode_list)
		| MirTypes.SWITCH(computed_goto, reg_operand, tag_list) =>
d835 23
a857 22
		    let
		      val reg = lookup_reg_operand reg_operand
		      val (numbered_tag_list, _) =
			Lists.number_from(tag_list, 0, 4, fn x=> x)
		      fun do_tests(done, []) = rev done
		      | do_tests(done, (tag, imm) :: (rest as _ :: _)) =
			do_tests((Sparc_Assembly.BRANCH
			 (Sparc_Assembly.BE, 0),
			 MirTypes.PRESENT tag, "Do the branch") ::
			(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			 (Sparc_Assembly.SUBCC, MachTypes.G0,
			  Sparc_Assembly.IMM imm, reg),
			 absent, "Do the test") :: done, rest)
		      | do_tests(done, (tag, imm) :: rest) =
			do_tests((Sparc_Assembly.BRANCH_ANNUL
			 (Sparc_Assembly.BAA, 0),
			 MirTypes.PRESENT tag, "Do the branch") ::
			(nop_code, absent,
			 "No test required in final case") :: done, rest)
		    in
		      do_tests([], numbered_tag_list)
		    end
d879 1
a879 1
		      opcode_list)
d881 8
a888 3
		| MirTypes.ALLOCATE(allocate, reg_operand, i, reg_operand',
				    proc_ref) =>
		    (case allocate of
d890 1
a890 63
			let
			  val rd = lookup_reg_operand reg_operand
			in
			  (if i = 2 then
			     ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, rd,
				 Sparc_Assembly.IMM 8,
				 MachTypes.gc1),
				absent, "Calculate next pointer after pair"),
			       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.SUBCC, MachTypes.G0,
				 Sparc_Assembly.REG(MachTypes.gc2), rd),
				absent, "Check if collection needed"),
			       (* Now test and do something if the allocate fails *)
			       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, rd,
				 Sparc_Assembly.IMM 1, MachTypes.gc1),
				absent, "Tag the pointer as a pair"),
			       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, MachTypes.gc1,
				 Sparc_Assembly.IMM 8,
				 MachTypes.gc1), absent,
				"Update gc pointer")],
			     opcode_list)
			   else
			     let
			       val word_size = 8 * ((i + 2) div 2)
			     in
			       ([(* Calculate new end pointer *)
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, rd,
				   Sparc_Assembly.IMM word_size,
				   MachTypes.gc1),
				  absent,
				  "Calculate next pointer after tuple"),
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.SUBCC, MachTypes.G0,
				   Sparc_Assembly.REG(MachTypes.gc2), rd),
				  absent, "Check if collection needed"),
				 (* Now test and do something if the allocate fails *)
				 (* Now set up the header word *)
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, rd,
				   Sparc_Assembly.IMM(2 + 64 * i),
				   MachTypes.G0),
				  absent, "Generate header word value"),
				 (Sparc_Assembly.LOAD_AND_STORE
				  (Sparc_Assembly.ST, rd, MachTypes.gc1,
				   Sparc_Assembly.IMM 0),
				  absent, "Store the header word"),
				 (* Now put in the header tag *)
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, rd,
				   Sparc_Assembly.IMM 5, MachTypes.gc1),
				  absent, "Tag the pointer as a tuple"),
				 (* Now update gc1 *)
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, MachTypes.gc1,
				   Sparc_Assembly.IMM word_size,
				   MachTypes.gc1),
				  absent, "Update gc pointer")], opcode_list)
			     end)
			end
d892 1
a892 38
			let
			  val rd = lookup_reg_operand reg_operand
			  val string_size = ((i + 12) div 8) * 8
			in
			  ([(* Calculate new end pointer *)
			    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (Sparc_Assembly.ADD, rd,
			      Sparc_Assembly.IMM string_size,
			      MachTypes.gc1),
			     absent,
			     "Calculate next pointer after string"),
			    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (Sparc_Assembly.SUBCC, MachTypes.G0,
			      Sparc_Assembly.REG(MachTypes.gc2), rd),
			     absent, "Check if collection needed"),
			    (* Now test and do something if the allocate fails *)
			    (* Now set up the header word *)
			    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (Sparc_Assembly.ADD, rd,
			      Sparc_Assembly.IMM(10 + 64 * i),
			      MachTypes.G0),
			     absent, "Generate header word value"),
			    (Sparc_Assembly.LOAD_AND_STORE
			     (Sparc_Assembly.ST, rd, MachTypes.gc1,
			      Sparc_Assembly.IMM 0),
			     absent, "Store the header word"),
			    (* Now put in the header tag *)
			    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (Sparc_Assembly.ADD, rd,
			      Sparc_Assembly.IMM 5, MachTypes.gc1),
			     absent, "Tag the pointer as a tuple"),
			    (* Now update gc1 *)
			    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			     (Sparc_Assembly.ADD, MachTypes.gc1,
			      Sparc_Assembly.IMM string_size,
			      MachTypes.gc1),
			     absent, "Update gc pointer")], opcode_list)
			end
d894 1
a894 1
			Crash.unimplemented"ALLOC_REAL"
d896 1
a896 1
			Crash.unimplemented"ALLOC_STACK"
d898 4
a901 7
			Crash.unimplemented"ALLOC_REF")
		| MirTypes.DEALLOCATE(deallocate, i) =>
		    Crash.unimplemented"DEALLOCATE"
		| MirTypes.ADR(adr, reg_operand, tag) =>
		    ([(Sparc_Assembly.Call
		      (Sparc_Assembly.CALL, 0),
		      absent, "Call self"),
d903 94
a996 14
		      (Sparc_Assembly.ADD, lookup_reg_operand reg_operand,
		       Sparc_Assembly.IMM ~4, MachTypes.lr),
		      absent, "Update gc pointer")], opcode_list)
		| MirTypes.ENTER =>
		    (if needs_preserve then
		      [(Sparc_Assembly.SAVE_AND_RESTORE
			(Sparc_Assembly.SAVE, MachTypes.sp,
			 Sparc_Assembly.IMM ~64,
			 (* This should change in the light of real info *)
			 MachTypes.sp), absent, "New frame")]
		    else
		      [], opcode_list)
	       | MirTypes.PRESERVE_ALL_REGS =>
		   ([(Sparc_Assembly.SAVE_AND_RESTORE
d999 31
a1029 28
		      MachTypes.sp), absent, "New frame")], opcode_list)
	       | MirTypes.PREVIOUS_ENVIRONMENT =>
		   Crash.unimplemented"do_opcodes(PREVIOUS_ENVIRONMENT)"
	       | MirTypes.RTS =>
		   (if needs_preserve then
		      [(Sparc_Assembly.JUMP_AND_LINK
			(Sparc_Assembly.JMPL, MachTypes.G0,
			 Sparc_Assembly.IMM 8,
			 MachTypes.after_preserve MachTypes.lr),
			absent, "Scheduled return"),
		       (Sparc_Assembly.SAVE_AND_RESTORE
			(Sparc_Assembly.RESTORE, MachTypes.G0,
			 Sparc_Assembly.IMM 0,
			 MachTypes.sp), absent, "Restore in the delay slot")]
		    else
		      [(Sparc_Assembly.JUMP_AND_LINK
			(Sparc_Assembly.JMPL, MachTypes.G0,
			 Sparc_Assembly.IMM 8, MachTypes.lr),
			absent, "Ordinary return"),
		       nop], opcode_list)
	       | MirTypes.NEW_HANDLER tag => ([], opcode_list)
	       | MirTypes.OLD_HANDLER => ([], opcode_list)
	       | MirTypes.RAISE reg_operand =>
		   let
		     val reg_or_imm =
		       Sparc_Assembly.REG(lookup_reg_operand reg_operand)
		   in
		     ([(Sparc_Assembly.JUMP_AND_LINK
d1033 10
a1042 10
		      nop], opcode_list)
		   end
	       | MirTypes.COMMENT string => ([], opcode_list)
	    in
	      do_opcodes(opcode_list, done @@ result_list)
	    end
	in
	  (tag, do_opcodes(opcode_list, [])) ::
	  do_block(needs_preserve, block_list)
	end
d1044 4
a1084 3
(*
	  val _ = print"Getting refs"
*)
d1086 1
a1086 3
(*
	  val _ = print"Got refs"
*)
d1090 9
a1098 33
(*
	    (case regs_used of
	      MirTypes.ABSENT => false
	    | MirTypes.PRESENT{gc = gc,
			       non_gc = non_gc,
			       fp = fp,
			       fp_double = fp_double} =>
	       let
		 val _ = print"real registers used"
		 val _ =
		 Set.map
		 (print o MachTypes.reg_to_string o
		  (fn x => Table.lookup(x, gc_table)))
		 gc
	       in
		 check_for_locals_or_outs(Set.map
					  (fn x => Table.lookup(x, gc_table))
					  gc)
	       end
	     )
*)
(*
	  val _ = print"Refs for proc"
	  val _ =
	    map
	    (print o MachTypes.reg_to_string)
	    (Set.set_to_list refs)
	  val _ = print(if needs_preserve then
			  "Needs_preserve"
			else 
			  "Preserve not needed")
*)
	  val code = do_block(needs_preserve, block_list)
@


1.21
log
@Updated to use the results of the instruction scheduler
@
text
@d4 3
d131 10
d151 15
d594 31
a624 6
			(lookup_gp_operand gp_operand,
			 if is_reg gp_operand' then
			   Sparc_Assembly.REG(lookup_gp_operand
					      gp_operand')
			 else
			   make_imm_format3 gp_operand', [])
a661 1
		      val rs1 = MachTypes.G0 (* Always reads zero *)
d665 1
a665 1
		      val (reg_or_imm, is_null) =
d670 3
a672 2
			    (Sparc_Assembly.REG rs2,
			     rd = rs2 andalso opcode = Sparc_Assembly.ADD)
d675 13
a687 1
			  (make_imm_format3 gp_operand, false)
d692 1
a692 1
			[(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
@


1.20
log
@Added BTA and BNT for tagged value testing
@
text
@d4 3
d1072 1
a1072 1
	  val _ =
d1074 4
a1077 4
	    (fn proc =>
	     map
	     (fn x => Sparc_Schedule.reschedule_block(#2 x))
	     (#2 proc))
d1079 1
a1079 1
	  val linear_code = linearise_list code_list
@


1.19
log
@Added range checking on immediate values
@
text
@d4 3
d680 3
a682 1
		      MirTypes.BEQ => Sparc_Assembly.BEA
d710 4
d716 1
a716 1
		      (Sparc_Assembly.SUBCC, MachTypes.G0,
@


1.18
log
@Added fall through branch elimination, along with block reordering
to make this more likely
@
text
@d4 4
d118 37
d292 9
a300 3
		((Sparc_Assembly.BRANCH(branch,
					 (Lists.assoc(tag, tag_env) - offset) div 4),
		   comment) handle Lists.Assoc => Crash.impossible"Assoc do_opcode branch")
d303 9
a311 3
		((Sparc_Assembly.BRANCH_ANNUL(branch,
					       (Lists.assoc(tag, tag_env) - offset) div 4),
		   comment) handle Lists.Assoc => Crash.impossible"Assoc do_opcode branch_annul")
d314 9
a322 3
		((Sparc_Assembly.Call(Sparc_Assembly.CALL,
				       (Lists.assoc(tag, tag_env) - offset) div 4),
		   comment) handle Lists.Assoc => Crash.impossible"Assoc do_opcode call")
d326 11
a336 4
		((Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		   (Sparc_Assembly.ADD, rd,
		    Sparc_Assembly.IMM(Lists.assoc(tag, tag_env) - offset - i), rs1),
		   comment) handle Lists.Assoc => Crash.impossible"Assoc do_opcode arith")
d390 2
a391 11
      fun make_imm(MirTypes.GP_IMM_INT i) = Sparc_Assembly.IMM(4 * i)
      | make_imm(MirTypes.GP_IMM_ANY i) = Sparc_Assembly.IMM i
      | make_imm(MirTypes.GP_IMM_SYMB _) =
	let
	  val _ = print"Warning, symbolic value not translated"
	in
	  Sparc_Assembly.IMM 0
	end
      | make_imm _ = Crash.impossible"make_imm of non-immediate"

      fun make_imm_for_store(MirTypes.GP_IMM_ANY i) = Sparc_Assembly.IMM i
d503 1
a503 1
			   make_imm gp_operand', [])
d512 2
a513 2
			       make_imm gp_operand'),
				[move_imm(rd, make_imm gp_operand)])
d522 1
a522 1
				  make_imm gp_operand, [])
d565 1
a565 1
			   make_imm gp_operand', [])
d574 2
a575 2
			       make_imm gp_operand'),
				[move_imm(rd, make_imm gp_operand)])
d593 1
a593 1
				  make_imm gp_operand, [])
d616 1
a616 1
			  (make_imm gp_operand, false)
d704 1
a704 1
			make_imm gp_op'
d1060 7
@


1.17
log
@Added code to attempt fall through elimination.
Fixed faulty encoding of RESTORE
@
text
@d4 4
d78 1
d95 1
d101 3
a103 1
  sharing MirTypes = MirTables.MirTypes = MirPrint.MirTypes
d112 2
d128 2
a129 3
  fun last_but_one [] = (nop, false)
  | last_but_one [_] = (nop, false)
  | last_but_one [elem as (opcode, _, _), _] =
d131 1
a131 2
      Sparc_Assembly.BRANCH _ => (elem, true)
    | Sparc_Assembly.BRANCH_ANNUL _ => (elem, true)
d133 1
a133 1
  | last_but_one(_ :: xs) = last_but_one xs
d140 3
d149 5
d156 4
a159 1
	else find_dest_block(dest_tag, block :: done, rest)
d171 1
a171 1
	      val (last_opcode, is_ok) = last_but_one opcode_list
d188 3
d196 1
a196 1
		find_next_block(rest, block :: tl to_look_in)
d214 1
a214 1
		(block_tag, rev(tl(tl(rev opcode_list))))
d241 2
a242 3
      val tag_env = tag_offsets_for_list(0, proc_list)
      fun linearise_proc(offset, [], done) = (offset, done)
      | linearise_proc(start, blocks as (block :: block_list), done) =
d281 1
a281 1
	  linearise_proc(next, block_list, done @@ this_block)
d283 1
a283 2
      fun do_linearise(_, []) = []
      | do_linearise(offset, (tag, proc) :: rest) =
d285 14
a298 2
	  val new_proc = reorder_blocks(tag, proc)
	  val (offset', done') = linearise_proc(offset, proc, [])
d300 1
a300 1
	  (tag, done') :: do_linearise(offset' + 4, rest)
d303 1
a303 1
      do_linearise(0, proc_list)
d614 2
a615 2
			   MirTypes.PRESENT tag, "Branch relative"),
			  nop]), opcode_list)
d687 23
a709 19
		      let
			val reg = lookup_reg_operand reg_operand
			val (numbered_tag_list, _) =
			  Lists.number_from(tag_list, 0, 4, fn x=> x)
			fun do_test(tag, imm) =
			  [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.SUBCC, MachTypes.G0,
			     Sparc_Assembly.IMM imm, reg),
			    absent, "Do the test"),
			   (Sparc_Assembly.BRANCH
			    (Sparc_Assembly.BE, 0),
			    MirTypes.PRESENT tag, "Do the branch")]
		      in
			(Lists.reducel
			 op @@
			 ([], map do_test numbered_tag_list)) @@
			[nop]
		      end
		  else
d731 1
a731 1

@


1.16
log
@Handled cgt. Modified call to strip out tag bits
@
text
@d4 3
d118 89
d265 1
d668 4
a671 3
			Lists.reducel
			op @@
			([], map do_test numbered_tag_list)
d842 1
a842 1
			(Sparc_Assembly.RESTORE, MachTypes.sp,
@


1.15
log
@Got strings and procs incorrect order (strings first)
@
text
@d4 3
d109 2
a110 1
  val nop =
d113 1
d138 1
a138 4
		let
		  val _ = print("Looking up tag for branch " ^ MirTypes.print_tag tag)
		in
		  (Sparc_Assembly.BRANCH(branch,
d140 1
a140 2
		   comment)
		end
d143 1
a143 4
		let
		  val _ = print("Looking up tag for branch annul " ^ MirTypes.print_tag tag)
		in
		  (Sparc_Assembly.BRANCH_ANNUL(branch,
d145 1
a145 2
		   comment)
		end
d148 1
a148 4
		let
		  val _ = print("Looking up tag for call " ^ MirTypes.print_tag tag)
		in
		  (Sparc_Assembly.Call(Sparc_Assembly.CALL,
d150 1
a150 2
		   comment)
		end
d154 1
a154 4
		let
		  val _ = print("Looking up tag for ADR" ^ MirTypes.print_tag tag)
		in
		  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
d157 1
a157 2
		   comment)
		end
a188 10
      val proc_tags =
	map (fn (MirTypes.PROC(tag, _, _)) => tag)
	(Lists.reducel op @@ ([], proc_list_list))
      val (numbered_procs, next) =
	Lists.number_from_by_one(proc_tags, 0, fn x => x)
      val value_tags =
	map (fn(MirTypes.VALUE(tag, _)) => tag) value_list
      val (numbered_vals, next) =
	Lists.number_from_by_one(value_tags, next, fn x => x)
      val all_tags = numbered_vals @@ numbered_procs
d190 1
a190 1
	map
d192 2
a193 2
	 value_cg(Lists.assoc(tag, numbered_vals), x))
	value_list
a217 2
      val absent = MirTypes.ABSENT

d348 1
a348 1
		     (nop, absent, "Delay slot")], opcode_list)
d486 1
a486 1
			  (nop, absent, "Delay slot")]
d490 1
a490 1
			  (nop, absent, "Delay slot")]), opcode_list)
d530 1
a530 1
		     (nop, absent, "Delay slot")], opcode_list)
d539 1
a539 1
			  val reg_or_imm = case bl_dest of
d541 1
a541 2
			      Sparc_Assembly.REG(lookup_reg_operand
						 reg_operand)
d546 3
a548 3
			     reg_or_imm, MachTypes.G0),
			    absent, "Call"),
			   (nop, absent, "Delay slot")]
d558 1
a558 1
			   (nop, absent, "Delay slot")]
d561 41
a601 1
		    Crash.unimplemented"do_opcodes(SWITCH)"
d756 1
a756 1
		       (nop, absent, "Delay nop")], opcode_list)
d768 1
a768 1
		      (nop, absent, "Delay slot")], opcode_list)
d865 1
a865 1
	     code @@ [(MirTypes.new_tag(), [(nop, absent, "Padding")])]
d884 1
a884 1
	    map
d886 1
a886 1
	     (Lists.assoc(tag, numbered_procs),
d892 1
a892 1
	    linear_code
a901 2
      val (ext_elements, next) =
	Lists.number_from_by_one(ext_refs, next, fn x => x)
d903 1
a903 3
	map
	(fn (x, y) => MachTypes.EXTERNAL(y, x))
	ext_elements
@


1.14
log
@Coded ALLOC_STRING.
@
text
@d4 3
a199 4
      val value_tags =
	map (fn(MirTypes.VALUE(tag, _)) => tag) value_list
      val (numbered_vals, next) =
	Lists.number_from_by_one(value_tags, 0, fn x => x)
d204 5
a208 1
	Lists.number_from_by_one(proc_tags, next, fn x => x)
@


1.13
log
@Revised code generation for linearisation to allow for mutually
recusrive functions. New ALLOC in place, ready for real calls to c
@
text
@d4 4
d227 1
a227 1
      fun make_imm_for_store(MirTypes.GP_IMM_INT i) = Sparc_Assembly.IMM i
d234 1
a234 1
      | make_imm_for_store _ = Crash.impossible"make_imm of non-immediate"
d613 1
a613 4
			       val word_size =
				 if (i div 2) * 2 = i then
				   (i+2) * 4
				 else (i+1) * 4
d630 1
a630 1
				   Sparc_Assembly.IMM(1 + 64 * i),
d651 38
a688 1
			Crash.unimplemented"ALLOC_STRING"
a842 1
	  val _ = print("Code length = " ^ Integer.makestring code_len)
a853 1
	  val _ = print"Linearising"
@


1.12
log
@Updated to reflect new simplified module structure
Added parameter to heap allocation to indicate position in closure
of call_c function
@
text
@d4 5
d103 1
a103 2
  fun linearise(_, [], done) = done
  | linearise(start, blocks as (block :: block_list), done) =
d105 1
a105 4
      (* Insert algorithm for optimal linearisation of blocks here *)
      (* Present algorithm just uses the current order *)
      (* Also assumes NOPs inserted after all control transfers *)
      fun tag_offsets([], _, tag_env) = tag_env
d108 2
a109 2
      val tag_env = tag_offsets(blocks, 0, [])
      fun do_block(offset, (_, opcode_list)) =
d111 1
a111 27
	  fun do_opcode((Sparc_Assembly.BRANCH(branch, i),
			 MirTypes.PRESENT tag, comment), offset) =
	    (Sparc_Assembly.BRANCH(branch,
				   (Lists.assoc(tag, tag_env) - offset) div 4),
	     comment)
	  | do_opcode((Sparc_Assembly.BRANCH_ANNUL(branch, i),
			 MirTypes.PRESENT tag, comment), offset) =
	    (Sparc_Assembly.BRANCH_ANNUL(branch,
				   (Lists.assoc(tag, tag_env) - offset) div 4),
	     comment)
	  | do_opcode((Sparc_Assembly.Call(Sparc_Assembly.CALL, i),
		       MirTypes.PRESENT tag, comment), offset) =
	    (Sparc_Assembly.Call(Sparc_Assembly.CALL,
				 (Lists.assoc(tag, tag_env) - offset) div 4),
	     comment)
	  | do_opcode((Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		       (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM i, rs1),
		       MirTypes.PRESENT tag, comment), offset) =
	    (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
	     (Sparc_Assembly.ADD, rd,
	      Sparc_Assembly.IMM(Lists.assoc(tag, tag_env) - offset - i), rs1),
	     comment)
	  | do_opcode((opcode, MirTypes.ABSENT, comment), offset) =
	    (opcode, comment)
	  | do_opcode _ = Crash.impossible"Bad tagged instruction"
	  val (opcodes_and_offsets, next) =
	    Lists.number_from(opcode_list, offset, 4, fn x => x)
d113 1
a113 1
	  (map do_opcode opcodes_and_offsets, next)
d115 66
a180 1
      val (this_block, next) = do_block(start, block)
d182 1
a182 1
      linearise(next, block_list, done @@ this_block)
d185 1
d223 9
d313 1
a313 4
(*
	      val _ = print(MirPrint.opcode opcode)
*)
	      val result_list =
d347 1
a347 1
				[move_imm(rd,  make_imm gp_operand)])
d359 1
a359 1
		    extra @@
d364 1
a364 1
		     (nop, absent, "Delay slot")]
d409 1
a409 1
				[move_imm(rd,  make_imm gp_operand)])
d430 1
a430 1
		    extra @@
d432 1
a432 1
		      (opcode, rd, reg_or_imm, rs1), absent, "")]
d452 1
a452 1
		      if is_null then
d456 2
a457 1
			  (opcode, rd, reg_or_imm, rs1), absent, "")]
d476 1
a476 1
			make_imm gp_operand
d488 1
a488 1
		       "")])
d496 1
a496 1
		    (case bl_dest of
d506 1
a506 1
			  (nop, absent, "Delay slot")])
d540 1
a540 1
		    [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
d546 1
a546 1
		     (nop, absent, "Delay slot")]
d552 1
a552 1
		    (case branch_and_link of
d576 1
a576 1
			end)
d579 2
a580 1
		| MirTypes.ALLOCATE(allocate, reg_operand, i, offset) =>
d587 20
a606 17
			     [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			       (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM 8,
				MachTypes.gc1),
			       absent, "Calculate next pointer after pair"),
			      (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			       (Sparc_Assembly.SUBCC, MachTypes.G0,
				Sparc_Assembly.REG(MachTypes.gc2), rd),
			       absent, "Check if collection needed"),
			      (* Now test and do something if the allocate fails *)
			      (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			       (Sparc_Assembly.ADD, rd,
				Sparc_Assembly.IMM 3, MachTypes.gc1),
			       absent, "Tag the pointer as a pair"),
			      (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			       (Sparc_Assembly.ADD, MachTypes.gc1,
				Sparc_Assembly.IMM 8,
				MachTypes.gc1), absent, "Update gc pointer")]
d614 33
a646 32
			       [(* Calculate new end pointer *)
				(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				 (Sparc_Assembly.ADD, rd,
				  Sparc_Assembly.IMM word_size,
				  MachTypes.gc1),
				  absent, "Calculate next pointer after tuple"),
				(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				 (Sparc_Assembly.SUBCC, MachTypes.G0,
				  Sparc_Assembly.REG(MachTypes.gc2), rd),
				 absent, "Check if collection needed"),
				(* Now test and do something if the allocate fails *)
				(* Now set up the header word *)
				(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				 (Sparc_Assembly.ADD, rd,
				  Sparc_Assembly.IMM(1 + 64 * i),
				  MachTypes.G0),
				 absent, "Generate header word value"),
				(Sparc_Assembly.LOAD_AND_STORE
				 (Sparc_Assembly.ST, rd, MachTypes.gc1,
				  Sparc_Assembly.IMM 0),
				 absent, "Store the header word"),
				(* Now put in the header tag *)
				(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				 (Sparc_Assembly.ADD, rd,
				  Sparc_Assembly.IMM 5, MachTypes.gc1),
				 absent, "Tag the pointer as a tuple"),
				(* Now update gc1 *)
				(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				 (Sparc_Assembly.ADD, MachTypes.gc1,
				  Sparc_Assembly.IMM word_size,
				  MachTypes.gc1),
				 absent, "Update gc pointer")]
d649 8
a656 8
		      | MirTypes.ALLOC_STRING =>
			  Crash.unimplemented"ALLOC_STRING"
		      | MirTypes.ALLOC_REAL =>
			  Crash.unimplemented"ALLOC_REAL"
		      | MirTypes.ALLOC_STACK =>
			  Crash.unimplemented"ALLOC_STACK"
		      | MirTypes.ALLOC_REF =>
			  Crash.unimplemented"ALLOC_REF")
d660 1
a660 1
		    [(Sparc_Assembly.Call
d666 1
a666 1
		      absent, "Update gc pointer")]
d668 1
a668 1
		    if needs_preserve then
d675 1
a675 1
		      []
d677 1
a677 1
		   [(Sparc_Assembly.SAVE_AND_RESTORE
d680 1
a680 1
		      MachTypes.sp), absent, "New frame")]
d699 3
a701 3
		       (nop, absent, "Delay nop")])
	       | MirTypes.NEW_HANDLER tag => []
	       | MirTypes.OLD_HANDLER => []
d705 1
a705 2
		       Sparc_Assembly.REG(lookup_reg_operand
					  reg_operand)
d707 1
a707 1
		     [(Sparc_Assembly.JUMP_AND_LINK
d711 1
a711 1
		      (nop, absent, "Delay slot")]
d713 1
a713 1
	       | MirTypes.COMMENT string => []
d802 4
a805 4
	  val linear_code = linearise(0, code, [])
	  val _ = print"Sparc_Assembly Code"
	  val _ = map (print o (fn (x, y) => Sparc_Assembly.print x ^
				" ; " ^ y)) linear_code
d807 5
a811 5
	  (Lists.assoc(tag, numbered_procs),
	   implode
	   (map
	    (Sparc_Opcodes.output_opcode o Sparc_Assembly.assemble o #1)
	    linear_code))
d815 26
a840 1
	MachTypes.WORDSET(MachTypes.WORD_SET(map proc_cg proc_list))
@


1.11
log
@Added code encapsulation code
@
text
@d4 3
d86 3
a88 3
  fun value_cg(Ident.STRING x) = MachTypes.STRING x
  | value_cg(Ident.REAL x) = Crash.unimplemented"VALUE(REAL)"
  | value_cg(Ident.INT _) = Crash.impossible"VALUE(INT)"
d145 2
a146 112
  fun output_int i =
    if i < 0 then
      Crash.impossible"Negative size of code object"
    else
      let
	fun make_list(bytes, value) =
	  if bytes <= 0 then []
	  else
	    chr(value mod 256) :: make_list(bytes-1, value div 256)
      in
	implode(rev(make_list(4, i)))
      end
      
  fun extend_string s =
    case (size s) mod 4 of
      0 => s
    | 1 => s ^ "   "
    | 2 => s ^ "  "
    | 3 => s ^ " "
    | _ => Crash.impossible"Mod out of range"

  val code_words = 0
  val code_record = 1
  val code_fn_call = 2
  val code_int = 3
  val code_real = 4
  val code_string = 5
  val code_loc_ref = 6
  val code_ext_ref = 7
  val code_wordset = 8

  fun output_module(MachTypes.MODULE element_list) =
    let
      fun output_module_element_list(offset, [], result) = (offset, result)
      | output_module_element_list(offset, element :: rest_list, result) =
	let
	  val element_code =
	    case element of
	      MachTypes.REAL r => Crash.unimplemented"Output real"
	    | MachTypes.STRING s =>
		output_int code_string ^ output_int(size s) ^ extend_string s
	    | MachTypes.WORDSET(MachTypes.WORD_SET w_list) =>
		let
		  val wordset_len = length w_list
		  val wordset_size =
		    Lists.reducel op +
		    (2 * wordset_len, map size w_list)
		in
		  Lists.reducel
		  op ^
		  (output_int code_wordset ^ output_int wordset_len ^
		   output_int wordset_size,
		   map
		   (fn w => output_int code_words ^ output_int(size w) ^ w)
		   w_list)
		end
	    | MachTypes.RECORD(MachTypes.REC record_element_list) =>
		let
		  fun do_record_element(MachTypes.INT i) =
		    (* output_int i *)
		    Crash.unimplemented"Record_element of int"
		  | do_record_element(MachTypes.LOC_REF(MachTypes.LOC l)) =
		    output_int code_loc_ref ^ output_int l
		  | do_record_element(MachTypes.EXT_REF(MachTypes.EXT e)) =
		    output_int code_loc_ref ^ extend_string e
		in
		   Lists.reducel op ^
		   (output_int code_record ^
		    output_int(8*(length record_element_list)),
		    map do_record_element record_element_list)
		end

	    | MachTypes.INTEGER i => Crash.unimplemented"Output integer"
	    | MachTypes.FN_CALL(MachTypes.CALL(proc, tag)) =>
		output_int code_fn_call ^ output_int proc ^ output_int tag
	  val element_size = size element_code
	in
	  output_module_element_list(offset + element_size, rest_list,
				     result ^ element_code)
	end

      val (module_size, code) =
	output_module_element_list(0, element_list, "")
    in
      code ^ output_int module_size
    end

(*
  datatype ext_ref = EXT of string (* Note index not required *)
  datatype local_ref = LOC of int
  datatype record_element =
    INT of int |
    LOC_REF of local_ref |
    EXT_REF of ext_ref
  datatype record = REC of record_element list
  datatype fn_call = CALL of int * record_element
  datatype wordset = WORD_SET of string list
  datatype module_element =
    REAL of string |
    STRING of string |
    WORDSET of wordset |
    RECORD of record |
    INTEGER of string |
    FN_CALL of fn_call
  datatype module = MODULE of module_element list
*)


  fun mach_cg(MirTypes.CODE(MirTypes.FN_CALL(fn_proc_tag, fn_data_tag),
			    MirTypes.REFS(ref_tag, loc_refs, ext_refs),
			    value_list, proc_list_list,
			    top_proc as MirTypes.PROC(top_tag,_,_)),
a155 4
      val value_elements =
	map
	(fn(MirTypes.VALUE(_, x)) => value_cg x)
	value_list
d157 1
a157 1
	top_tag :: map (fn (MirTypes.PROC(tag, _, _)) => tag)
d162 5
a166 12
(*
      val _ = print"Got all_tags"
*)
      val ref_record =
	MachTypes.RECORD(MachTypes.REC(
	  (map (fn x => MachTypes.LOC_REF(
	    MachTypes.LOC(Lists.assoc(x, all_tags)))) loc_refs)
		      @@
	  (map (fn x => MachTypes.EXT_REF(MachTypes.EXT x)) ext_refs)))
      val final_call =
	MachTypes.FN_CALL(MachTypes.CALL(Lists.assoc(fn_proc_tag,
						     numbered_procs), next))
d531 1
a531 1
		| MirTypes.ALLOCATE(allocate, reg_operand, i) =>
d674 4
a677 15
(*				 {gc = gc,
                                  non_gc = non_gc,
				  fp = fp,
				  fp_double = fp_double},
*)
				 spill_sizes = spills,
(*
				 {gc = gc,
				  non_gc = non_gc,
				  fp = fp,
				  fp_double = fp_double}
*)
				 stack_allocated = stack
				 },
				block_list)) =
d755 5
a759 4
	  implode
	  (map
	   (Sparc_Opcodes.output_opcode o Sparc_Assembly.assemble o #1)
	   linear_code)
a764 3
(*
      val _ = print"Compiling ordinary procedures"
*)
d770 6
a775 3
      val binary_final_block =
	MachTypes.WORDSET(MachTypes.WORD_SET [proc_cg(top_proc)])

d778 2
a779 5
			 proc_elements @@ [binary_final_block] @@
			 [ref_record, final_call])
      val result = output_module module
      val _ = print"Code ="
      val _ = print result
@


1.10
log
@Got leaf procedures working. Optimised out MOV to self.
Did tagged operations and exception raising.
@
text
@d4 4
d142 108
d284 1
a284 5
						     numbered_procs),
			  MachTypes.LOC_REF(MachTypes.LOC next)))
(*
      val _ = print"Got final_call"
*)
d904 7
d912 1
a912 3
      MachTypes.MODULE(value_elements @@
		       proc_elements @@ [binary_final_block] @@
		       [ref_record, final_call])
a914 1

@


1.9
log
@Did load/store with register indexing, and reverse subtracts.
Also added stuff to spot procedures not requiring frames.
@
text
@d4 4
d43 2
d59 2
d69 2
a70 1
  sharing Set = MirTypes.Set
d161 3
d174 3
d202 43
d273 4
a276 1
	      val (result_list, opcode_list) =
d280 49
a328 1
		  Crash.unimplemented"do_opcodes(TBINARY)"
d393 3
a395 3
		    (extra @@ [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		      (opcode, rd, reg_or_imm, rs1), absent, "")],
		     opcode_list)
a400 5
		      val reg_or_imm =
			if is_reg gp_operand then
			  Sparc_Assembly.REG(lookup_gp_operand gp_operand)
			else
			  make_imm gp_operand
d404 10
d415 5
a419 3
		      ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			(opcode, rd, reg_or_imm, rs1), absent, "")],
		       opcode_list)
d447 4
a450 5
		    (([(Sparc_Assembly.LOAD_AND_STORE(store, rd, rs1,
						      reg_or_imm),
			absent,
			"")]),
			opcode_list)
d460 5
a464 5
			([(Sparc_Assembly.JUMP_AND_LINK
			   (Sparc_Assembly.JMPL, MachTypes.G0,
			    Sparc_Assembly.IMM 0, lookup_reg_operand reg),
			   absent, "Branch indirect"),
			  (nop, absent, "Delay slot")], opcode_list)
d466 1
a466 1
			([(Sparc_Assembly.BRANCH_ANNUL(Sparc_Assembly.BAA, 0),
d468 1
a468 1
			  (nop, absent, "Delay slot")], opcode_list))
d502 7
a508 7
		    ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		       (Sparc_Assembly.SUBCC, MachTypes.G0,
			reg_or_imm, rs1),
		       absent, "Do the test"),
		      (Sparc_Assembly.BRANCH_ANNUL(branch, 0),
		       MirTypes.PRESENT tag, "Do the branch"),
		      (nop, absent, "Delay slot")], opcode_list)
d523 5
a527 5
			  ([(Sparc_Assembly.JUMP_AND_LINK
			     (Sparc_Assembly.JMPL, MachTypes.lr,
			      reg_or_imm, MachTypes.lr),
			     absent, "Call"),
			    (nop, absent, "Delay slot")], opcode_list)
d534 4
a537 4
			  ([(Sparc_Assembly.Call
			     (Sparc_Assembly.CALL, 0),
			     MirTypes.PRESENT tag, "Call"),
			    (nop, absent, "Delay slot")], opcode_list)
d547 30
a576 30
			  ((if i = 2 then
			      [(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM 8,
				 MachTypes.gc1),
				absent, "Calculate next pointer after pair"),
			       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.SUBCC, MachTypes.G0,
				 Sparc_Assembly.REG(MachTypes.gc2), rd),
				absent, "Check if collection needed"),
			       (* Now test and do something if the allocate fails *)
			       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, rd,
				 Sparc_Assembly.IMM 3, MachTypes.gc1),
				absent, "Tag the pointer as a pair"),
			       (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				(Sparc_Assembly.ADD, MachTypes.gc1,
				 Sparc_Assembly.IMM 8,
				 MachTypes.gc1), absent, "Update gc pointer")]
			    else
			      let
				val word_size =
				  if (i div 2) * 2 = i then
				    (i+2) * 4
				  else (i+1) * 4
			      in
				[(* Calculate new end pointer *)
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, rd,
				   Sparc_Assembly.IMM word_size,
				   MachTypes.gc1),
d578 27
a604 28
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.SUBCC, MachTypes.G0,
				   Sparc_Assembly.REG(MachTypes.gc2), rd),
				  absent, "Check if collection needed"),
				 (* Now test and do something if the allocate fails *)
				 (* Now set up the header word *)
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, rd,
				   Sparc_Assembly.IMM(1 + 64 * i),
				   MachTypes.G0),
				  absent, "Generate header word value"),
				 (Sparc_Assembly.LOAD_AND_STORE
				  (Sparc_Assembly.ST, rd, MachTypes.gc1,
				   Sparc_Assembly.IMM 0),
				  absent, "Store the header word"),
				 (* Now put in the header tag *)
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, rd,
				   Sparc_Assembly.IMM 5, MachTypes.gc1),
				  absent, "Tag the pointer as a tuple"),
				 (* Now update gc1 *)
				 (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
				  (Sparc_Assembly.ADD, MachTypes.gc1,
				   Sparc_Assembly.IMM word_size,
				   MachTypes.gc1),
				  absent, "Update gc pointer")]
			      end),
			      opcode_list)
d617 7
a623 7
		    ([(Sparc_Assembly.Call
		       (Sparc_Assembly.CALL, 0),
		       absent, "Call self"),
		      (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
		       (Sparc_Assembly.ADD, lookup_reg_operand reg_operand,
			Sparc_Assembly.IMM ~4, MachTypes.lr),
		       absent, "Update gc pointer")], opcode_list)
d625 8
a632 6
		    ([(Sparc_Assembly.SAVE_AND_RESTORE
		       (Sparc_Assembly.SAVE, MachTypes.sp,
			Sparc_Assembly.IMM ~64,
			(* This should change in the light of real info *)
			MachTypes.sp), absent, "New frame")],
		    opcode_list)
d634 4
a637 5
		   ([(Sparc_Assembly.SAVE_AND_RESTORE
		      (Sparc_Assembly.SAVE, MachTypes.sp,
		       Sparc_Assembly.IMM ~64,
		       MachTypes.sp), absent, "New frame")],
		    opcode_list)
d641 31
a671 23
		   ([(Sparc_Assembly.JUMP_AND_LINK
		      (Sparc_Assembly.JMPL, MachTypes.G0,
		       Sparc_Assembly.IMM 8,
		       MachTypes.after_preserve MachTypes.lr),
		      absent, "Scheduled return"),
		     (Sparc_Assembly.SAVE_AND_RESTORE
		      (Sparc_Assembly.RESTORE, MachTypes.sp,
		       Sparc_Assembly.IMM 0,
		       MachTypes.sp), absent, "Restore in the delay slot")],
		       opcode_list)
(* Leaf case, saved for later
		   ([(Sparc_Assembly.JUMP_AND_LINK
		   (Sparc_Assembly.JMPL, MachTypes.G0,
		   Sparc_Assembly.IMM 8,
		   MachTypes.lr), absent, "Ordinary return"),
		   (nop, absent, "Delay slot")],
		   opcode_list)
*)
	       | MirTypes.NEW_HANDLER tag => ([], opcode_list)
	       | MirTypes.OLD_HANDLER => ([], opcode_list)
	       | MirTypes.RAISE tag =>
		   Crash.unimplemented"do_opcodes(RAISE)"
	       | MirTypes.COMMENT string => ([], opcode_list)
d680 6
a685 7
      fun proc_cg(MirTypes.PROC(tag,
				MirTypes.PROC_PARAMS
				{leaf = leaf,
				 registers_used = regs_used,
(*
				 {gc = gc,
				  non_gc = non_gc,
d719 1
d721 1
d728 7
d737 2
d758 7
d769 1
d785 3
d790 1
d792 1
d802 1
@


1.8
log
@Slight alterations to cope with new MirTypes.
@
text
@d4 3
d33 1
d47 1
d61 1
d118 1
a118 1
	  | do_opcode _ = Crash.impossible"Non-branch with tag"
d177 3
a179 1
      fun move(rd, rs) =
d181 1
a181 2
	(Sparc_Assembly.ADD, rd,
	 Sparc_Assembly.IMM 0, rs), "")
d183 4
a214 1
	      val absent = MirTypes.ABSENT
a223 10
		    val (rs1, reg_or_imm) =
		      if is_reg gp_operand then
			(lookup_gp_operand gp_operand,
			 if is_reg gp_operand' then
			   Sparc_Assembly.REG(lookup_gp_operand
					      gp_operand')
			 else
			   make_imm gp_operand')
		      else
			Crash.unimplemented"gp_operand constant"
d246 37
d284 1
a284 1
		    ([(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
d288 1
a288 1
		| MirTypes.UNARY(unary_op, reg_operand, gp_operand) => 
d306 1
a306 1
				    fp_operand'') => 
d311 1
a311 1
		| MirTypes.STACKOP(stack_op, reg_operand) => 
d318 12
a329 17
		    val offset =
		      case gp_operand of
			MirTypes.GP_IMM_INT i => i
		      | _ => Crash.unimplemented"do_opcode(STORE(rs1, rs2))"
		    val (is_store, store, load) = case store_op of
		      MirTypes.LD =>
			(false, Sparc_Assembly.ST, Sparc_Assembly.LD)
		    | MirTypes.ST =>
			(true, Sparc_Assembly.ST, Sparc_Assembly.LD)
		    | MirTypes.LDB =>
			(false, Sparc_Assembly.STB, Sparc_Assembly.LDUB)
		    | MirTypes.STB =>
			(true, Sparc_Assembly.STB, Sparc_Assembly.LDUB)
		    | MirTypes.LDREF =>
			(false, Sparc_Assembly.ST, Sparc_Assembly.LD)
		    | MirTypes.STREF =>
			(true, Sparc_Assembly.ST, Sparc_Assembly.LD)
d331 4
a334 6
		    ((if is_store then
			[(Sparc_Assembly.STORE(store, rd, rs1, offset), absent,
			  "")]
		      else
			[(Sparc_Assembly.LOAD(load, rd, rs1, offset), absent,
			  "")]),
d338 1
a338 1
				     gp_operand) => 
d340 1
a340 1
		| MirTypes.CONVOP(int_to_float, fp_operand, gp_operand) => 
d342 1
a342 1
		| MirTypes.BRANCH(branch, bl_dest) => 
d396 1
a396 1
				 fp_operand') => 
d424 1
a424 1
		| MirTypes.SWITCH(computed_goto, reg_operand, tag_list) => 
d474 3
a476 2
				 (Sparc_Assembly.STORE
				  (Sparc_Assembly.ST, rd, MachTypes.gc1, 0),
d500 3
a502 1
		| MirTypes.ADR(adr, reg_operand, tag) => 
d525 1
a525 1
	       | MirTypes.RTS => 
d557 20
a576 1
      fun proc_cg(MirTypes.PROC(tag, _, block_list)) =
d578 51
a628 3
	  val needs_preserve = case block_list of
	    MirTypes.BLOCK(_, _) :: _ => true
	  | _ => Crash.impossible"PROC Missing block entry"
@


1.7
log
@Added support for adr, and added delay slots to CALLs and JMPLs
@
text
@d4 3
d126 1
a126 1
			    top_proc as MirTypes.BLOCK(top_tag, top_block)),
d141 1
a141 1
	top_tag :: map (fn (MirTypes.PROC(tag, _)) => tag)
d477 1
a477 1
		| MirTypes.ENTER _ =>
a515 1
	       | MirTypes.END => ([], opcode_list)
d524 1
a524 1
      fun proc_cg(MirTypes.PROC(tag, block_list)) =
d546 1
a546 8
      val _ = print"Doing final block"
      val final_proc = do_block(true, [top_proc])
      val _ = print"Linearising final block"
      val linear_code = linearise(0, final_proc, [])
      val _ = print"Sparc_Assembly Code for top block"
      val _ = map (print o (fn (x, y) => Sparc_Assembly.print x ^ " ; " ^ y))
	linear_code

d548 1
a548 6
	MachTypes.WORDSET(MachTypes.WORD_SET
			  [implode
			   (map
			    (Sparc_Opcodes.output_opcode o
			     Sparc_Assembly.assemble o #1)
			    linear_code)])
@


1.6
log
@Added BLR and BSR. Altered to use new improved MirTypes
@
text
@d4 3
d100 7
d310 11
a320 1
		    Crash.unimplemented"do_opcodes(BRANCH)"
d378 2
a379 1
			     absent, "Call")], opcode_list)
d388 2
a389 1
			     MirTypes.PRESENT tag, "Call")], opcode_list)
d419 1
a419 1
				val size =
d426 2
a427 1
				  (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM size,
d452 2
a453 1
				   Sparc_Assembly.IMM size, MachTypes.gc1),
d467 7
a473 1
		    Crash.unimplemented"do_opcodes(ADR)"
d502 5
a506 4
			 (Sparc_Assembly.JMPL, MachTypes.G0,
			  Sparc_Assembly.IMM 8,
			  MachTypes.lr), absent, "Ordinary return")],
		    opcode_list)
@


1.5
log
@More code generation, plus comments and linearisation
@
text
@d4 3
d92 5
a143 11
      fun lookup_reg_operand(MirTypes.GC_REG reg) =
	Table.lookup(reg, gc_table)
      | lookup_reg_operand(MirTypes.NON_GC_REG reg) =
	Table.lookup(reg, non_gc_table)

      fun lookup_gp_operand(MirTypes.GP_GC_REG reg) =
	Table.lookup(reg, gc_table)
      | lookup_gp_operand(MirTypes.GP_NON_GC_REG reg) =
	Table.lookup(reg, non_gc_table)
      | lookup_gp_operand _ = Crash.impossible"lookup_gp_operand(constant)"

d163 3
a165 2
      fun do_block [] = []
      | do_block(MirTypes.BLOCK(tag, opcode_list) :: block_list) =
d167 21
d345 24
a368 2
		| MirTypes.BRANCH_AND_LINK(branch_and_link, bl_dest) => 
		    Crash.unimplemented"do_opcodes(BRANCH_AND_LINK)"
d372 2
a373 22
		    let
		      val rd = lookup_reg_operand reg_operand
		    in
		      ((if i = 2 then
			[(Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			  (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM 8,
			   MachTypes.gc1),
			  absent, "Calculate next pointer after pair"),
			  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			  (Sparc_Assembly.SUBCC, MachTypes.G0,
			   Sparc_Assembly.REG(MachTypes.gc2), rd),
			   absent, "Check if collection needed"),
			  (* Now test and do something if the allocate fails *)
			  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			  (Sparc_Assembly.ADD, rd,
			   Sparc_Assembly.IMM 3, MachTypes.gc1),
			   absent, "Tag the pointer as a pair"),
			  (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			  (Sparc_Assembly.ADD, MachTypes.gc1,
			   Sparc_Assembly.IMM 8,
			   MachTypes.gc1), absent, "Update gc pointer")]
		      else
d375 1
a375 4
			  val size =
			    if (i div 2) * 2 = i then
			      (i+2) * 4
			    else (i+1) * 4
d377 65
a441 31
			  [(* Calculate new end pointer *)
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.ADD, rd, Sparc_Assembly.IMM size,
			    MachTypes.gc1),
			   absent, "Calculate next pointer after tuple"),
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.SUBCC, MachTypes.G0,
			    Sparc_Assembly.REG(MachTypes.gc2), rd),
			   absent, "Check if collection needed"),
			   (* Now test and do something if the allocate fails *)
			   (* Now set up the header word *)
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			   (Sparc_Assembly.ADD, rd,
			    Sparc_Assembly.IMM(1 + 64 * i), MachTypes.G0),
			   absent, "Generate header word value"),
			   (Sparc_Assembly.STORE
			   (Sparc_Assembly.ST, rd, MachTypes.gc1, ~4),
			    absent, "Store the header word"),
			   (* Now put in the header tag *)
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.ADD, rd,
			    Sparc_Assembly.IMM 1, MachTypes.gc1),
			    absent, "Tag the pointer as a tuple"),
			   (* Now update gc1 *)
			   (Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			    (Sparc_Assembly.ADD, MachTypes.gc1,
			    Sparc_Assembly.IMM size, MachTypes.gc1),
			    absent, "Update gc pointer")]
			end),
		      opcode_list)
		    end
d444 7
a450 14
		| MirTypes.ENTER =>
		    (case hd opcode_list of
		       MirTypes.PRESERVE_REGS(reg_operand_list,
					      fp_operand_list) =>
		       ([(Sparc_Assembly.SAVE_AND_RESTORE
			 (Sparc_Assembly.SAVE, MachTypes.sp,
			  Sparc_Assembly.IMM ~64,
			  (* This should change in the light of real info *)
			  MachTypes.sp), absent, "New frame")],
			tl opcode_list)
		     | _ => ([], opcode_list))
	       | MirTypes.PRESERVE_REGS(reg_operand_list,
					fp_operand_list) =>
		 Crash.impossible"PRESERVE_REGS not following ENTER"
d457 2
d461 11
d476 1
a476 17
	       | MirTypes.RESTORE_REGS(reg_operand_list,
				       fp_operand_list) => 
		    (case hd opcode_list of
		       MirTypes.RTS =>
		       ([(Sparc_Assembly.JUMP_AND_LINK
			 (Sparc_Assembly.JMPL, MachTypes.G0,
			  Sparc_Assembly.IMM 8,
			  MachTypes.after_preserve MachTypes.lr),
			  absent, "Scheduled return"),
			 (Sparc_Assembly.SAVE_AND_RESTORE
			 (Sparc_Assembly.RESTORE, MachTypes.sp,
			  Sparc_Assembly.IMM 0,
			  MachTypes.sp), absent, "Restore in the delay slot")],
			tl opcode_list)
		     | _ =>
			 Crash.impossible
			 "do_opcode(RESTORE_REGS not followed by RTS")
d479 2
a480 1
	       | MirTypes.RAISE => ([], opcode_list)
d487 2
a488 1
	  (tag, do_opcodes(opcode_list, [])) :: do_block block_list
d493 4
a496 1
	  val code = do_block block_list
d513 3
a515 1
      val final_proc = do_block[top_proc]
@


1.4
log
@More work on proc_cg
Pased results out into module structure
@
text
@d4 4
d23 1
d36 1
d68 1
a68 1
  | linearise(start, block :: block_list, done) =
d76 1
a76 1
      val tag_env = tag_offsets(block_list, 0, [])
d80 4
a83 3
			 MirTypes.PRESENT tag), offset) =
	    Sparc_Assembly.BRANCH(branch,
				   (Lists.assoc(tag, tag_env) - offset) div 4)
d85 6
a90 4
			 MirTypes.PRESENT tag), offset) =
	    Sparc_Assembly.BRANCH_ANNUL(branch,
				   (Lists.assoc(tag, tag_env) - offset) div 4)
	  | do_opcode((opcode, MirTypes.ABSENT), offset) = opcode
d95 1
a95 1
	  (map do_opcode opcode_list, next)
d105 1
a105 1
			    MirTypes.BLOCK(top_tag, top_block)),
d120 1
a120 1
	map (fn (MirTypes.PROC(tag, _)) => tag)
d153 6
d161 7
a167 1
      fun proc_cg(MirTypes.PROC(tag, block_list)) =
d169 2
a170 2
	  fun do_block [] = []
	  | do_block(MirTypes.BLOCK(_, opcode_list) :: block_list) =
d172 268
a439 117
	      fun do_opcodes([], done) = rev done
	      | do_opcodes(opcode :: opcode_list, done) =
		let
		  val result_list =
		    case opcode of
		      MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
				       gp_operand, gp_operand') =>
		      Crash.unimplemented"do_opcodes"
		    | MirTypes.BINARY(binary_op, reg_operand, gp_operand,
				      gp_operand') =>
		      let
			val rd = lookup_reg_operand reg_operand
			val (rs1, reg_or_imm) =
			  if is_reg gp_operand then
			    (lookup_gp_operand gp_operand,
			      if is_reg gp_operand' then
				Sparc_Assembly.REG(lookup_gp_operand
						   gp_operand')
			      else
				make_imm gp_operand')
			  else
			    Crash.unimplemented"gp_operand constant"
			val opcode = case binary_op of
			  MirTypes.ADD => Sparc_Assembly.ADD
			| MirTypes.SUB => Sparc_Assembly.SUB
			| MirTypes.MULU =>
			    Crash.unimplemented"MirTypes.MULU"
			| MirTypes.MULS =>
			    Crash.unimplemented"MirTypes.MULS"
			| MirTypes.DIVU =>
			    Crash.unimplemented"MirTypes.DIVU"
			| MirTypes.DIVS =>
			    Crash.unimplemented"MirTypes.DIVS"
			| MirTypes.MODU =>
			    Crash.unimplemented"MirTypes.MODU"
			| MirTypes.MODS =>
			    Crash.unimplemented"MirTypes.MODS"
			| MirTypes.AND => Sparc_Assembly.AND
			| MirTypes.OR => Sparc_Assembly.OR
			| MirTypes.BIC => Sparc_Assembly.ANDN
			| MirTypes.EOR => Sparc_Assembly.XOR
			| MirTypes.LSR => Sparc_Assembly.SRL
			| MirTypes.ASL => Sparc_Assembly.SLL
			| MirTypes.ASR => Sparc_Assembly.SRA
		      in
			[Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			  (opcode, rd, reg_or_imm, rs1)]
		      end
		    | MirTypes.UNARY(unary_op, reg_operand, gp_operand) => 
		      let
			val rd = lookup_reg_operand reg_operand
			val rs1 = MachTypes.G0 (* Always reads zero *)
			val reg_or_imm =
			  if is_reg gp_operand then
			    Sparc_Assembly.REG(lookup_gp_operand gp_operand)
			  else
			    make_imm gp_operand
			val opcode = case unary_op of
			  MirTypes.MOVE => Sparc_Assembly.ADD
			| MirTypes.NOT => Sparc_Assembly.ANDN
		      in
			[Sparc_Assembly.ARITHMETIC_AND_LOGICAL
			  (opcode, rd, reg_or_imm, rs1)]
		      end
		    | MirTypes.BINARYFP(binary_fp_op, fp_operand, fp_operand',
					fp_operand'') => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.UNARYFP(unary_fp_op, fp_operand,
				       fp_operand') => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.STACKOP(stack_op, reg_operand) => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.STOREOP(store_op, reg_operand, reg_operand',
				       gp_operand) => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.STOREFPOP(store_fp_op, fp_operand, reg_operand,
					 gp_operand) => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.CONVOP(int_to_float, fp_operand, gp_operand) => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.BRANCH(branch, bl_dest) => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.TEST(cond_branch, tag, gp_operand,
				    gp_operand') => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.FTEST(fcond_branch, tag, fp_operand,
				     fp_operand') => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.BRANCH_AND_LINK(branch_and_link, bl_dest) => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.SWITCH(computed_goto, reg_operand, tag_list) => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.ALLOCATE(allocate, reg_operand, int) => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.ADR(adr, reg_operand, tag) => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.ENTER => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.PRESERVE_REGS(reg_operand_list,
					     fp_operand_list) => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.PRESERVE_ALL_REGS =>
			Crash.unimplemented"do_opcodes"
		    | MirTypes.RTS => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.RESTORE_REGS(reg_operand_list,
					    fp_operand_list) => 
			Crash.unimplemented"do_opcodes"
		    | MirTypes.NEW_HANDLER tag => []
		    | MirTypes.OLD_HANDLER => []
		    | MirTypes.RAISE => []
		    | MirTypes.COMMENT(string) => []
		    | MirTypes.END =>
			Crash.unimplemented"do_opcodes"
		in
		  do_opcodes(opcode_list, done @@ result_list)
		end
d441 1
a441 1
	      do_opcodes(opcode_list, []) @@ do_block block_list
d443 6
d450 1
d452 2
a453 1
	  val _ = map (print o Sparc_Assembly.print) code
d455 4
a458 4
	  Lists.reducel
	  (fn (e, x) => e ^
	    (Sparc_Opcodes.output_opcode(Sparc_Assembly.assemble x)))
	  ("", code)
d466 14
d481 3
a483 2
      (MachTypes.MODULE(value_elements @@ [ref_record, final_call]);
      Crash.unimplemented"mach_cg")
@


1.3
log
@Started on proc_cg
@
text
@d4 3
a19 1
require "../lambda/lambdasub";
a31 1
  structure LambdaSub : LAMBDASUB
d41 1
d57 6
a62 1
  fun linearise block_list =
d65 2
d69 1
a69 1
	tag_offsets(rest, disp + length ho_list, (tag, disp) :: tag_env)
d71 18
d90 1
a90 1
      ()
d105 1
a105 1
	LambdaSub.number_from(value_tags, 0, fn x => x)
d114 1
a114 1
	LambdaSub.number_from(proc_tags, next, fn x => x)
d127 4
a130 3
      fun list_proc_cg [] = []
      | list_proc_cg(proc :: proc_tail) =
	Crash.unimplemented"list_proc_cg"
d132 14
d148 126
a273 4
	  val tag_env =
	    map
	    (fn (MirTypes.BLOCK(tag, _)) => (tag, MirTypes.ABSENT))
	    block_list
d275 4
a278 1
	  MachTypes.WORDS""
d280 6
@


1.2
log
@Changed dependencies on MachRegisters to MachSpec.
@
text
@d4 3
d22 1
d35 1
d38 2
a39 1
  sharing MachTypes = Sparc_Opcodes.MachTypes
d51 1
a51 1
  type half_op = Sparc_Opcodes.opcode * MirTypes.tag MirTypes.Opt
a65 10
  fun proc_cg proc =
    let
      val tag_env =
	map
	(fn (MirTypes.BLOCK(tag, _)) => (tag, MirTypes.ABSENT))
	proc
    in
      MachTypes.WORDS""
    end

d98 15
a112 1
	  MachTypes.LOC_REF(MachTypes.LOC next)))
@


1.1
log
@Initial revision
@
text
@d3 4
a6 1
$Log$
d17 1
a17 1
require "machregisters";
d29 1
a29 1
  structure MachRegisters : MACHREGISTERS
d39 1
a39 1
  structure MachRegisters = MachRegisters
@
