head	1.29;
access;
symbols
	MLW_daveb_inline_1_4_99:1.29.3
	MLWorks_21c0_1999_03_25:1.29
	MLWorks_20c1_1998_08_20:1.29
	MLWorks_20c0_1998_08_04:1.29
	MLWorks_20b2c2_1998_06_19:1.29
	MLWorks_20b2_Windows_1998_06_12:1.29
	MLWorks_20b1c1_1998_05_07:1.29
	MLWorks_20b0_1998_04_07:1.29
	MLWorks_20b0_1998_03_20:1.29
	MLWorks_20m2_1998_02_16:1.29
	MLWorks_20m1_1997_10_23:1.29
	MLWorks_11r1:1.28.7.1.1.1.1
	MLWorks_workspace_97:1.29.2
	MLWorks_dt_wizard:1.29.1
	MLWorks_11c0_1997_09_09:1.28.7.1.1.1
	MLWorks_10r3:1.28.7.1.3
	MLWorks_10r2_551:1.28.7.1.2
	MLWorks_11:1.28.7.1.1
	MLWorks_1_0_r2c2_1997_07_28:1.28.7.1
	MLWorks_20m0_1997_06_20:1.29
	MLWorks_1_0_r2c2_1997_06_14:1.28.7.1
	MLWorks_1_0_r2c1_released_1997_05_23:1.28.7.1
	MLWorks_1_0_r2c1_1997_05_12:1.28.7
	MLWorks_BugFix_1997_04_24:1.28
	MLWorks_1_0_r2_Win32_1997_04_11:1.28
	MLWorks_1_0_r2_Unix_1997_04_04:1.28
	MLWorks_1_0_1_ULTRASPARC_1997_02_24:1.28.5.1.1
	MLWorks_gui_1996_12_18:1.28.6
	MLWorks_1_0_Win32_1996_12_17:1.28.5
	MLWorks_1_0_Irix_1996_11_28_released_1996_12_17:1.28.3.1.1.1
	MLWorks_1_0_Unix_1996_11_14_released_1996_12_17:1.28.3.1
	MLWorks_1_0_Irix_1996_11_28:1.28.3.1.1
	MLWorks_1_0_Win32_1996_11_22:1.28.4
	MLWorks_1_0_Unix_1996_11_14:1.28.3
	MLWorks_Open_Beta2_1996_10_11:1.28.2
	MLWorks_License_dev:1.28.1
	MLWorks_1_open_beta_1996_09_13:1.27.2
	MLWorks_Open_Beta_1996_08_22:1.27
	MLWlexer_basis_io_1996:1.27.1
	MLWorks_Beta_1996_07_02:1.27
	MLWorks_Beta_1996_06_07:1.27
	MLWorks_Beta_1996_06_06:1.27
	MLWorks_Beta_1996_06_05:1.27
	MLWorks_Beta_1996_06_03:1.27
	MLWorks_Beta_1996_05_31:1.27
	MLWorks_Beta_1996_05_30:1.27
	ML_beta_release_12/08/94:1.25
	ML_beta_release_03/08/94:1.25
	ML_revised_beta_release_25/05/94:1.25
	ML_final_beta_release_02/03/94:1.25
	mlworks-28-01-1994:1.25
	Release:1.24
	mlworks-beta-01-09-1993:1.24
	MLWorks-1-0-4-29/01/1993:1.17
	MLWorks-1-0-3-21/12/1992:1.17
	MLWorks-1-0-2-15/12/1992:1.16
	MLWorks-1-0-1-04/12/1992:1.16
	checkpoint_17_08_92:1.7
	Ten15_release_19-11-91:1.1.1.1
	Ten15_release_21-08-91:1.1;
locks; strict;
comment	@ * @;


1.29
date	97.05.28.11.29.01;	author daveb;	state Exp;
branches
	1.29.1.1
	1.29.2.1
	1.29.3.1;
next	1.28;

1.28
date	96.09.25.10.13.59;	author matthew;	state Exp;
branches
	1.28.1.1
	1.28.2.1
	1.28.3.1
	1.28.4.1
	1.28.5.1
	1.28.6.1
	1.28.7.1;
next	1.27;

1.27
date	96.04.30.14.57.08;	author jont;	state Exp;
branches
	1.27.1.1
	1.27.2.1;
next	1.26;

1.26
date	95.02.14.12.28.36;	author matthew;	state Exp;
branches;
next	1.25;

1.25
date	93.12.23.13.24.39;	author daveb;	state Exp;
branches;
next	1.24;

1.24
date	93.08.12.12.08.44;	author jont;	state Exp;
branches
	1.24.1.1;
next	1.23;

1.23
date	93.06.15.14.50.48;	author matthew;	state Exp;
branches;
next	1.22;

1.22
date	93.04.01.09.33.45;	author daveb;	state Exp;
branches;
next	1.21;

1.21
date	93.03.31.14.14.50;	author daveb;	state Exp;
branches;
next	1.20;

1.20
date	93.03.30.14.45.33;	author daveb;	state Exp;
branches;
next	1.19;

1.19
date	93.03.29.11.03.23;	author daveb;	state Exp;
branches;
next	1.18;

1.18
date	93.03.24.11.24.09;	author daveb;	state Exp;
branches;
next	1.17;

1.17
date	92.12.21.11.03.11;	author matthew;	state Exp;
branches;
next	1.16;

1.16
date	92.11.20.13.34.35;	author matthew;	state Exp;
branches;
next	1.15;

1.15
date	92.11.19.14.33.09;	author matthew;	state Exp;
branches;
next	1.14;

1.14
date	92.11.17.14.26.10;	author matthew;	state Exp;
branches;
next	1.13;

1.13
date	92.11.09.18.39.19;	author daveb;	state Exp;
branches;
next	1.12;

1.12
date	92.10.14.11.30.54;	author richard;	state Exp;
branches;
next	1.11;

1.11
date	92.09.04.08.44.43;	author richard;	state Exp;
branches;
next	1.10;

1.10
date	92.08.31.15.41.40;	author richard;	state Exp;
branches;
next	1.9;

1.9
date	92.08.26.13.02.32;	author matthew;	state Exp;
branches;
next	1.8;

1.8
date	92.08.18.13.37.06;	author davidt;	state Exp;
branches;
next	1.7;

1.7
date	92.08.05.13.31.07;	author jont;	state Exp;
branches;
next	1.6;

1.6
date	92.05.19.17.12.58;	author clive;	state Exp;
branches;
next	1.5;

1.5
date	92.04.13.13.39.34;	author clive;	state Exp;
branches;
next	1.4;

1.4
date	91.11.19.12.39.21;	author jont;	state Exp;
branches;
next	1.3;

1.3
date	91.10.14.08.42.34;	author davidt;	state Exp;
branches;
next	1.2;

1.2
date	91.09.06.16.49.46;	author nickh;	state Exp;
branches;
next	1.1;

1.1
date	91.06.20.20.10.56;	author jont;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	91.11.19.11.11.53;	author jont;	state Exp;
branches;
next	;

1.24.1.1
date	93.08.12.12.08.44;	author jont;	state Exp;
branches;
next	;

1.27.1.1
date	96.08.19.11.49.31;	author hope;	state Exp;
branches;
next	1.27.1.2;

1.27.1.2
date	96.08.20.13.43.08;	author davids;	state Exp;
branches;
next	1.27.1.3;

1.27.1.3
date	96.08.22.10.43.52;	author davids;	state Exp;
branches;
next	;

1.27.2.1
date	96.09.13.11.17.54;	author hope;	state Exp;
branches;
next	;

1.28.1.1
date	96.10.07.16.07.44;	author hope;	state Exp;
branches;
next	;

1.28.2.1
date	96.10.17.11.25.59;	author hope;	state Exp;
branches;
next	;

1.28.3.1
date	96.11.14.12.51.09;	author hope;	state Exp;
branches
	1.28.3.1.1.1;
next	;

1.28.3.1.1.1
date	96.11.28.15.02.13;	author hope;	state Exp;
branches;
next	;

1.28.4.1
date	96.11.22.18.10.26;	author hope;	state Exp;
branches;
next	;

1.28.5.1
date	96.12.17.17.49.02;	author hope;	state Exp;
branches
	1.28.5.1.1.1;
next	;

1.28.5.1.1.1
date	97.02.24.11.39.06;	author hope;	state Exp;
branches;
next	;

1.28.6.1
date	96.12.18.09.43.04;	author hope;	state Exp;
branches;
next	;

1.28.7.1
date	97.05.12.10.35.32;	author hope;	state Exp;
branches
	1.28.7.1.1.1
	1.28.7.1.2.1
	1.28.7.1.3.1;
next	;

1.28.7.1.1.1
date	97.07.28.18.20.54;	author daveb;	state Exp;
branches
	1.28.7.1.1.1.1.1;
next	;

1.28.7.1.1.1.1.1
date	97.10.07.11.46.17;	author jkbrook;	state Exp;
branches;
next	;

1.28.7.1.2.1
date	97.09.08.17.14.21;	author daveb;	state Exp;
branches;
next	;

1.28.7.1.3.1
date	97.09.09.14.10.07;	author daveb;	state Exp;
branches;
next	;

1.29.1.1
date	97.09.10.19.26.04;	author brucem;	state Exp;
branches;
next	;

1.29.2.1
date	97.09.11.20.56.11;	author daveb;	state Exp;
branches;
next	;

1.29.3.1
date	99.04.01.17.57.33;	author daveb;	state Exp;
branches;
next	;


desc
@@


1.29
log
@[Bug #30090]
[Bug #30090]
Converted lexer to Basis IO.
@
text
@(*
 $Log: lexer.sml,v $
 * Revision 1.28  1996/09/25  10:13:59  matthew
 * Removing lastToken function
 *
 * Revision 1.27  1996/04/30  14:57:08  jont
 * String functions explode, implode, chr and ord now only available from String
 * io functions and types
 * instream, oustream, open_in, open_out, close_in, close_out, input, output and end_of_stream
 * now only available from MLWorks.IO
 *
 * Revision 1.26  1995/02/14  12:28:36  matthew
 * Removing require options
 *
Revision 1.25  1993/12/23  13:24:39  daveb
Removed mkInteractiveTokenStream.

Revision 1.24  1993/08/12  12:08:44  jont
Modified to allow multiple ungets

Revision 1.23  1993/06/15  14:50:48  matthew
Added single character unGetToken function and lastToken function

Revision 1.22  1993/04/01  09:33:45  daveb
Added the eof argument to mkLineTokenStream for use with the incremental
parser.

Revision 1.21  1993/03/31  14:14:50  daveb
Removed misleading comment.

Revision 1.20  1993/03/30  14:45:33  daveb
Removed ungetToken; no longer used.

Revision 1.19  1993/03/29  11:03:23  daveb
getToken now takes a Lexerstate argument.

Revision 1.18  1993/03/24  11:24:09  daveb
getToken now takes an options parameter.

Revision 1.17  1992/12/21  11:03:11  matthew
Added mkLineTokenStream

Revision 1.16  1992/11/20  13:34:35  matthew
Added an "unget" facility.

 Revision 1.15  1992/11/19  14:33:09  matthew
 Added flush_to_nl
 
 Revision 1.14  1992/11/17  14:26:10  matthew
 Changed Error structure to Info
 
 Revision 1.13  1992/11/09  18:39:19  daveb
 Added clear_eof function.
 
 Revision 1.12  1992/10/14  11:30:54  richard
 Added line number to token stream input functions.
 Added mkFileTokenStream.
 
 Revision 1.11  1992/09/04  08:44:43  richard
 Installed central error reporting mechanism.
 
 Revision 1.10  1992/08/31  15:41:40  richard
 Removed LexError.  Errors are handled by the global Error structure.
 
 Revision 1.9  1992/08/26  13:02:32  matthew
 Added interactive token streams.
 
 Revision 1.8  1992/08/18  13:37:06  davidt
 Took out structure LexGen, flushTokenStream and getbuffer since
 they were never used.
 
 Revision 1.7  1992/08/05  13:31:07  jont
 Removed some structures and sharing
 
 Revision 1.6  1992/05/19  17:12:58  clive
 Fixed line position output from lexer
 
 Revision 1.5  1992/04/13  13:39:34  clive
 First version of the profiler
 
 Revision 1.4  1991/11/19  12:39:21  jont
 Merging in comments from Ten15 branch to main trunk
 
 Revision 1.3  91/10/14  08:42:34  davidt
 Put in the missing require for the LEXGEN signature.
 
 Revision 1.2  91/09/06  16:49:46  nickh
 Lexer signature. This is the same as for the old lexer (before the
 generator was a functor). This interface could do with reworking, but
 the parser would have to be changed to allow that.
 
 Copyright (c) 1991 Harlequin Ltd.
 *)

require "../basis/__text_io";
require "../basics/token";
require "../main/info";

(* This module is automatically generated from the lexer descriptions
in generator/LexA, LexB and LexC. It provides the type TokenStream,
and functions for manipulating TokenStreams. See comments later in
this file on those functions. The generation method is essentially
that described by Aho, Sethi, Ullman in "Compilers : Principles,
Techniques and Tools", section 3. See lexgen/generator.sml for more
details. *)

signature LEXER =
    sig
        structure Token : TOKEN
        structure Info : INFO

        type TokenStream
	type Options

        (* The internal representation of a TokenStream is a (potentially
         large) buffer string together with some information about it,
	 including Lexer state info. *)

        val mkTokenStream : (int -> string) * string -> TokenStream
        val mkLineTokenStream :
	      (int -> string) * string * int * bool -> TokenStream
        val mkFileTokenStream : TextIO.instream * string -> TokenStream

        (* mkTokenStream f creates a token stream which gets input characters
         from the function f. Each application of f should return an
         arbitrary-length prefix of the remaining input. f should only return
         the empty string when there is no further input. f is passed the line
         number that will be assigned to the first line it returns. *)

        val getToken : Info.options ->
			 (Options * Token.LexerState * TokenStream) ->
			 Token.Token

        val ungetToken : (Token.Token * Info.Location.T) * TokenStream -> unit
        (* getToken ts removes the next token from ts and returns it. It is a
         table-driven lexer, with tables (arrays) created by the lexer
         generator. *)

        val associated_filename : TokenStream -> string
        val locate : TokenStream -> Info.Location.T
	val eof : TokenStream -> bool
	val clear_eof : TokenStream -> unit
        val is_interactive : TokenStream -> bool

        (* need to flush the input in the buffer for shell error handling *)
        val flush_to_nl : TokenStream -> unit

    end;
@


1.29.3.1
log
@branched from trunk for label MLW_daveb_inline_1_4_99
@
text
@a2 5
 * Revision 1.29  1997/05/28  11:29:01  daveb
 * [Bug #30090]
 * [Bug #30090]
 * Converted lexer to Basis IO.
 *
@


1.29.2.1
log
@branched from trunk for label MLWorks_workspace_97
@
text
@a2 5
 * Revision 1.29  1997/05/28  11:29:01  daveb
 * [Bug #30090]
 * [Bug #30090]
 * Converted lexer to Basis IO.
 *
@


1.29.1.1
log
@branched from trunk for label MLWorks_dt_wizard
@
text
@a2 5
 * Revision 1.29  1997/05/28  11:29:01  daveb
 * [Bug #30090]
 * [Bug #30090]
 * Converted lexer to Basis IO.
 *
@


1.28
log
@Removing lastToken function
@
text
@d3 3
d95 1
d122 1
a122 1
        val mkFileTokenStream : MLWorks.IO.instream * string -> TokenStream
@


1.28.7.1
log
@branched from 1.28
@
text
@a2 3
 * Revision 1.28  1996/09/25  10:13:59  matthew
 * Removing lastToken function
 *
@


1.28.7.1.3.1
log
@branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_10r3
@
text
@a2 3
 * Revision 1.28.7.1  1997/05/12  10:35:32  hope
 * branched from 1.28
 *
@


1.28.7.1.2.1
log
@branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_10r2_551
@
text
@a2 3
 * Revision 1.28.7.1  1997/05/12  10:35:32  hope
 * branched from 1.28
 *
@


1.28.7.1.1.1
log
@branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_11
@
text
@a2 3
 * Revision 1.28.7.1  1997/05/12  10:35:32  hope
 * branched from 1.28
 *
@


1.28.7.1.1.1.1.1
log
@branched from MLWorks_11 for label MLWorks_11r1
@
text
@a2 3
 * Revision 1.28.7.1.1.1  1997/07/28  18:20:54  daveb
 * branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_11
 *
@


1.28.6.1
log
@branched from 1.28
@
text
@a2 3
 * Revision 1.28  1996/09/25  10:13:59  matthew
 * Removing lastToken function
 *
@


1.28.5.1
log
@branched from 1.28
@
text
@a2 3
 * Revision 1.28  1996/09/25  10:13:59  matthew
 * Removing lastToken function
 *
@


1.28.5.1.1.1
log
@branched from 1.28.5.1
@
text
@a2 3
 * Revision 1.28.5.1  1996/12/17  17:49:02  hope
 * branched from 1.28
 *
@


1.28.4.1
log
@branched from 1.28
@
text
@a2 3
 * Revision 1.28  1996/09/25  10:13:59  matthew
 * Removing lastToken function
 *
@


1.28.3.1
log
@branched from 1.28
@
text
@a2 3
 * Revision 1.28  1996/09/25  10:13:59  matthew
 * Removing lastToken function
 *
@


1.28.3.1.1.1
log
@branched from 1.28.3.1
@
text
@a2 3
 * Revision 1.28.3.1  1996/11/14  12:51:09  hope
 * branched from 1.28
 *
@


1.28.2.1
log
@branched from 1.28
@
text
@a2 3
 * Revision 1.28  1996/09/25  10:13:59  matthew
 * Removing lastToken function
 *
@


1.28.1.1
log
@branched from 1.28
@
text
@a2 3
 * Revision 1.28  1996/09/25  10:13:59  matthew
 * Removing lastToken function
 *
@


1.27
log
@String functions explode, implode, chr and ord now only available from String
io functions and types
instream, oustream, open_in, open_out, close_in, close_out, input, output and end_of_stream
now only available from MLWorks.IO
@
text
@d3 6
d130 1
a130 2
        val ungetToken : Token.Token * TokenStream -> unit
        val lastToken : TokenStream -> Token.Token
@


1.27.2.1
log
@branched from 1.27
@
text
@a2 6
 * Revision 1.27  1996/04/30  14:57:08  jont
 * String functions explode, implode, chr and ord now only available from String
 * io functions and types
 * instream, oustream, open_in, open_out, close_in, close_out, input, output and end_of_stream
 * now only available from MLWorks.IO
 *
@


1.27.1.1
log
@branched from 1.27
@
text
@a2 6
 * Revision 1.27  1996/04/30  14:57:08  jont
 * String functions explode, implode, chr and ord now only available from String
 * io functions and types
 * instream, oustream, open_in, open_out, close_in, close_out, input, output and end_of_stream
 * now only available from MLWorks.IO
 *
@


1.27.1.2
log
@Changing IO to use basis library.
@
text
@a2 3
 * Revision 1.27.1.1  1996/08/19  11:49:31  hope
 * branched from 1.27
 *
a91 1
require "../basis/__text_io";
d111 3
a113 3
        (* The internal representation of a TokenStream is an instream 
         together with some information about it, including Lexer state
	 info. *)
d115 1
a115 1
        val mkTokenStream : string * string -> TokenStream
d117 8
a124 2
	      string * string * int -> TokenStream
        val mkFileTokenStream : TextIO.instream * string -> TokenStream
d139 1
@


1.27.1.3
log
@Changing TextIO to a functor argument.
@
text
@a2 3
 * Revision 1.27.1.2  1996/08/20  13:43:08  davids
 * Changing IO to use basis library.
 *
d95 1
a113 1
	type instream
d122 1
a122 1
        val mkFileTokenStream : instream * string -> TokenStream
@


1.26
log
@Removing require options
@
text
@d3 3
d112 1
a112 1
        val mkFileTokenStream : instream * string -> TokenStream
@


1.25
log
@Removed mkInteractiveTokenStream.
@
text
@d3 3
a83 1
require "../main/options";
d100 1
a100 1
	type options
d118 1
a118 1
			 (options * Token.LexerState * TokenStream) ->
@


1.24
log
@Modified to allow multiple ungets
@
text
@d3 3
a106 1
        val mkInteractiveTokenStream : (int -> string) * string -> TokenStream
@


1.24.1.1
log
@Fork for bug fixing
@
text
@a2 3
Revision 1.24  1993/08/12  12:08:44  jont
Modified to allow multiple ungets

@


1.23
log
@Added single character unGetToken function and lastToken function
@
text
@d3 3
d117 1
a117 1
        val unGetToken : TokenStream -> unit
@


1.22
log
@Added the eof argument to mkLineTokenStream for use with the incremental
parser.
@
text
@d3 4
d114 2
@


1.21
log
@Removed misleading comment.
@
text
@d3 3
d95 2
a96 1
        val mkLineTokenStream : (int -> string) * string * int -> TokenStream
@


1.20
log
@Removed ungetToken; no longer used.
@
text
@d3 3
a114 8

        (* This set of functions extract information from the other slots in
         the TokenStream record. The other slots in the TokenStream record are:
         the line-number, the buffer position, the position on the line, and an
         Eof flag. These are manipulated by functions put into the lexer by the
         generator, which can be used by the user-defined actions in the lexer
         specification. The linepos is not kept up-to-date by the ML Lexer,
         although the linenum is. *)
@


1.19
log
@getToken now takes a Lexerstate argument.
@
text
@d3 3
a106 5
        val ungetToken : Token.Token * Info.Location.T * TokenStream -> unit

          (* not used now *)
(*        val linenum : TokenStream -> int *)
(*	val linepos : TokenStream -> int *)
@


1.18
log
@getToken now takes an options parameter.
@
text
@d3 3
d82 2
a83 1
         large) buffer string together with some information about it *)
d97 1
a97 1
			 (options * TokenStream) ->
@


1.17
log
@Added mkLineTokenStream
@
text
@d3 3
d59 1
d76 1
d89 2
a90 2
         the empty string when there is no further input. f is passed the line number
         that will be assigned to the first line it returns. *)
d92 3
a94 1
        val getToken : Info.options -> TokenStream -> Token.Token
@


1.16
log
@Added an "unget" facility.
@
text
@d3 3
d77 1
@


1.15
log
@Added flush_to_nl
@
text
@d2 49
a50 3
$Log: lexer.sml,v $
Revision 1.14  1992/11/17  14:26:10  matthew
Changed Error structure to Info
a51 43
Revision 1.13  1992/11/09  18:39:19  daveb
Added clear_eof function.

Revision 1.12  1992/10/14  11:30:54  richard
Added line number to token stream input functions.
Added mkFileTokenStream.

Revision 1.11  1992/09/04  08:44:43  richard
Installed central error reporting mechanism.

Revision 1.10  1992/08/31  15:41:40  richard
Removed LexError.  Errors are handled by the global Error structure.

Revision 1.9  1992/08/26  13:02:32  matthew
Added interactive token streams.

Revision 1.8  1992/08/18  13:37:06  davidt
Took out structure LexGen, flushTokenStream and getbuffer since
they were never used.

Revision 1.7  1992/08/05  13:31:07  jont
Removed some structures and sharing

Revision 1.6  1992/05/19  17:12:58  clive
Fixed line position output from lexer

Revision 1.5  1992/04/13  13:39:34  clive
First version of the profiler

Revision 1.4  1991/11/19  12:39:21  jont
Merging in comments from Ten15 branch to main trunk

Revision 1.3  91/10/14  08:42:34  davidt
Put in the missing require for the LEXGEN signature.

Revision 1.2  91/09/06  16:49:46  nickh
Lexer signature. This is the same as for the old lexer (before the
generator was a functor). This interface could do with reworking, but
the parser would have to be changed to allow that.

Copyright (c) 1991 Harlequin Ltd.
*)

d70 2
a71 2
(* The internal representation of a TokenStream is a (potentially
large) buffer string together with some information about it *)
d77 5
a81 5
(* mkTokenStream f creates a token stream which gets input characters
from the function f. Each application of f should return an
arbitrary-length prefix of the remaining input. f should only return
the empty string when there is no further input. f is passed the line number
that will be assigned to the first line it returns. *)
d85 3
a87 3
(* getToken ts removes the next token from ts and returns it. It is a
table-driven lexer, with tables (arrays) created by the lexer
generator. *)
d89 5
a93 2
        val linenum : TokenStream -> int
	val linepos : TokenStream -> int
a98 7
(* This set of functions extract information from the other slots in
the TokenStream record. The other slots in the TokenStream record are:
the line-number, the buffer position, the position on the line, and an
Eof flag. These are manipulated by functions put into the lexer by the
generator, which can be used by the user-defined actions in the lexer
specification. The linepos is not kept up-to-date by the ML Lexer,
although the linenum is. *)
d100 9
a108 1
    (* need to flush the input in the buffer for shell error handling *)
@


1.14
log
@Changed Error structure to Info
@
text
@d3 3
d100 3
@


1.13
log
@Added clear_eof function.
@
text
@d3 3
d47 1
a47 1
require "../main/error";
d60 1
a60 1
        structure Error : ERROR
d77 1
a77 1
        val getToken : TokenStream -> Token.Token
d86 1
a86 1
        val locate : TokenStream -> Error.Location.T
@


1.12
log
@Added line number to token stream input functions.
Added mkFileTokenStream.
@
text
@d3 4
d85 1
@


1.11
log
@Installed central error reporting mechanism.
@
text
@d3 3
d60 3
a62 1
        val mkTokenStream : (unit -> string) * string -> TokenStream
a63 4
        (* also make a token stream with the interactive attribute *)

        val mkInteractiveTokenStream : (unit -> string) * string -> TokenStream

d67 2
a68 1
the empty string when there is no further input. *)
@


1.10
log
@Removed LexError.  Errors are handled by the global Error structure.
@
text
@d3 3
d37 1
d50 1
d76 2
a78 1
        val associated_filename : TokenStream -> string
@


1.9
log
@Added interactive token streams.
@
text
@d3 3
a50 9

        exception LexError of string    

(* LexError is raised when no prefix of the remaining input forms a
token as defined in the lexgen input. The string in the exception
packet is the prefix read at the point of reaching this conclusion.
LexError can also be raised by the user-defined actions given in the
LexGen input. For instance, a mismatched comment bracket in the input
to the ML lexer will raise LexError "Mismatched comment" *)
@


1.8
log
@Took out structure LexGen, flushTokenStream and getbuffer since
they were never used.
@
text
@d3 4
d60 4
d79 1
@


1.7
log
@Removed some structures and sharing
@
text
@d3 3
a26 1
require "lexgen";
a38 3
	structure LexGen : LEXGEN

	sharing type LexGen.result = Token.Token
a66 6
        val flushTokenStream : TokenStream -> unit

(* flushTokenStream ts flushes the input buffer of ts---i.e. it
discards any unlexed characters that have been read by the function
given to mkTokenStream to create ts *)

a68 1
        val getbuffer : TokenStream -> string
d79 1
a79 1
    end
@


1.6
log
@Fixed line position output from lexer
@
text
@d3 3
a23 1
require "../basics/symbol";
a36 1
        structure Symbol : SYMBOL
a38 1
        sharing Symbol = Token.Symbol
@


1.5
log
@First version of the profiler
@
text
@d3 3
a74 1
	val getpos : TokenStream -> int
@


1.4
log
@Merging in comments from Ten15 branch to main trunk
@
text
@d2 4
a5 1
$Log:	lexer.sml,v $
d52 1
a52 1
        val mkTokenStream : (unit -> string) -> TokenStream
d76 1
@


1.3
log
@Put in the missing require for the LEXGEN signature.
@
text
@d3 3
d18 8
d36 4
d42 7
d50 6
d57 5
d63 5
d73 9
a81 1
    end;
@


1.2
log
@Lexer signature. This is the same as for the old lexer (before the
generator was a functor). This interface could do with reworking, but
the parser would have to be changed to allow that.
@
text
@d2 6
a7 1
$Log$
d10 2
d13 1
a13 1
require "../basics/token";
d35 1
a35 3
    end
	   
    
@


1.1
log
@Initial revision
@
text
@d1 4
d12 1
d15 1
@


1.1.1.1
log
@Added comments for DRA on functions
@
text
@a3 8
(* This module is automatically generated from the lexer descriptions
in generator/LexA, LexB and LexC. It provides the type TokenStream,
and functions for manipulating TokenStreams. See comments later in
this file on those functions. The generation method is essentially
that described by Aho, Sethi, Ullman in "Compilers : Principles,
Techniques and Tools", section 3. See lexgen/generator.sml for more
details. *)

a11 4

(* The internal representation of a TokenStream is a (potentially
large) buffer string together with some information about it *)

a13 7
(* LexError is raised when no prefix of the remaining input forms a
token as defined in the lexgen input. The string in the exception
packet is the prefix read at the point of reaching this conclusion.
LexError can also be raised by the user-defined actions given in the
LexGen input. For instance, a mismatched comment bracket in the input
to the ML lexer will raise LexError "Mismatched comment" *)

a14 6

(* mkTokenStream f creates a token stream which gets input characters
from the function f. Each application of f should return an
arbitrary-length prefix of the remaining input. f should only return
the empty string when there is no further input. *)

a15 5

(* getToken ts removes the next token from ts and returns it. It is a
table-driven lexer, with tables (arrays) created by the lexer
generator. *)

a16 5

(* flushTokenStream ts flushes the input buffer of ts---i.e. it
discards any unlexed characters that have been read by the function
given to mkTokenStream to create ts *)

a21 9

(* This set of functions extract information from the other slots in
the TokenStream record. The other slots in the TokenStream record are:
the line-number, the buffer position, the position on the line, and an
Eof flag. These are manipulated by functions put into the lexer by the
generator, which can be used by the user-defined actions in the lexer
specification. The linepos is not kept up-to-date by the ML Lexer,
although the linenum is. *)

d23 2
@
