head	1.84;
access;
symbols
	MLW_daveb_inline_1_4_99:1.84.1
	MLWorks_21c0_1999_03_25:1.84
	MLWorks_20c1_1998_08_20:1.84
	MLWorks_20c0_1998_08_04:1.84
	MLWorks_20b2c2_1998_06_19:1.79
	MLWorks_20b2_Windows_1998_06_12:1.79
	MLWorks_20b1c1_1998_05_07:1.79
	MLWorks_20b0_1998_04_07:1.79
	MLWorks_20b0_1998_03_20:1.79
	MLWorks_20m2_1998_02_16:1.77
	MLWorks_20m1_1997_10_23:1.72
	MLWorks_11r1:1.65.1.1.1.1.1
	MLWorks_workspace_97:1.71.2
	MLWorks_dt_wizard:1.71.1
	MLWorks_11c0_1997_09_09:1.65.1.1.1.1
	MLWorks_10r3:1.65.1.1.3
	MLWorks_10r2_551:1.65.1.1.2
	MLWorks_11:1.65.1.1.1
	MLWorks_1_0_r2c2_1997_07_28:1.65.1.1
	MLWorks_20m0_1997_06_20:1.69
	MLWorks_1_0_r2c2_1997_06_14:1.65.1.1
	MLWorks_1_0_r2c1_released_1997_05_23:1.65.1.1
	MLWorks_1_0_r2c1_1997_05_12:1.65.1
	MLWorks_BugFix_1997_04_24:1.65
	MLWorks_1_0_r2_Win32_1997_04_11:1.65
	MLWorks_1_0_r2_Unix_1997_04_04:1.65
	MLWorks_1_0_1_ULTRASPARC_1997_02_24:1.61.3.1.1
	MLWorks_gui_1996_12_18:1.61.4
	MLWorks_1_0_Win32_1996_12_17:1.61.3
	MLWorks_1_0_Irix_1996_11_28_released_1996_12_17:1.61.1.1.1.1
	MLWorks_1_0_Unix_1996_11_14_released_1996_12_17:1.61.1.1
	MLWorks_1_0_Irix_1996_11_28:1.61.1.1.1
	MLWorks_1_0_Win32_1996_11_22:1.61.2
	MLWorks_1_0_Unix_1996_11_14:1.61.1
	MLWorks_Open_Beta2_1996_10_11:1.57.3
	MLWorks_License_dev:1.57.2
	MLWorks_1_open_beta_1996_09_13:1.57.1
	MLWorks_Open_Beta_1996_08_22:1.56
	MLWorks_Beta_1996_07_02:1.54
	MLWorks_Beta_1996_06_07:1.54
	MLWorks_Beta_1996_06_06:1.54
	MLWorks_Beta_1996_06_05:1.54
	MLWorks_Beta_1996_06_03:1.53
	MLWorks_Beta_1996_05_31:1.53
	MLWorks_Beta_1996_05_30:1.52;
locks; strict;
comment	@ * @;


1.84
date	98.07.14.17.17.57;	author jont;	state Exp;
branches
	1.84.1.1;
next	1.83;

1.83
date	98.07.01.17.51.48;	author jont;	state Exp;
branches;
next	1.82;

1.82
date	98.06.26.10.40.46;	author jont;	state Exp;
branches;
next	1.81;

1.81
date	98.06.24.14.51.54;	author jont;	state Exp;
branches;
next	1.80;

1.80
date	98.06.23.15.00.51;	author jont;	state Exp;
branches;
next	1.79;

1.79
date	98.02.19.17.07.00;	author mitchell;	state Exp;
branches;
next	1.78;

1.78
date	98.02.12.14.49.32;	author jont;	state Exp;
branches;
next	1.77;

1.77
date	98.02.10.17.58.51;	author jont;	state Exp;
branches;
next	1.76;

1.76
date	98.01.30.09.38.46;	author johnh;	state Exp;
branches;
next	1.75;

1.75
date	97.12.22.15.24.33;	author jont;	state Exp;
branches;
next	1.74;

1.74
date	97.12.15.17.31.29;	author jont;	state Exp;
branches;
next	1.73;

1.73
date	97.11.13.11.17.13;	author jont;	state Exp;
branches;
next	1.72;

1.72
date	97.09.19.09.19.27;	author brucem;	state Exp;
branches;
next	1.71;

1.71
date	97.08.11.09.37.47;	author jont;	state Exp;
branches
	1.71.1.1
	1.71.2.1;
next	1.70;

1.70
date	97.08.06.11.22.54;	author jont;	state Exp;
branches;
next	1.69;

1.69
date	97.06.03.09.21.53;	author jont;	state Exp;
branches;
next	1.68;

1.68
date	97.05.30.12.08.40;	author jont;	state Exp;
branches;
next	1.67;

1.67
date	97.05.06.10.09.04;	author jont;	state Exp;
branches;
next	1.66;

1.66
date	97.04.25.12.46.04;	author jont;	state Exp;
branches;
next	1.65;

1.65
date	97.03.13.14.39.31;	author jont;	state Exp;
branches
	1.65.1.1;
next	1.64;

1.64
date	97.03.13.12.02.36;	author jont;	state Exp;
branches;
next	1.63;

1.63
date	97.02.10.13.57.52;	author matthew;	state Exp;
branches;
next	1.62;

1.62
date	97.01.16.16.48.09;	author matthew;	state Exp;
branches;
next	1.61;

1.61
date	96.11.06.11.12.23;	author matthew;	state Exp;
branches
	1.61.1.1
	1.61.2.1
	1.61.3.1
	1.61.4.1;
next	1.60;

1.60
date	96.11.01.15.09.40;	author andreww;	state Exp;
branches;
next	1.59;

1.59
date	96.10.31.15.14.31;	author io;	state Exp;
branches;
next	1.58;

1.58
date	96.10.29.17.34.01;	author jont;	state Exp;
branches;
next	1.57;

1.57
date	96.08.27.11.37.40;	author jont;	state Exp;
branches
	1.57.1.1
	1.57.2.1
	1.57.3.1;
next	1.56;

1.56
date	96.08.01.16.39.44;	author jont;	state Exp;
branches;
next	1.55;

1.55
date	96.08.01.13.09.41;	author jont;	state Exp;
branches;
next	1.54;

1.54
date	96.06.05.13.01.15;	author jont;	state Exp;
branches;
next	1.53;

1.53
date	96.05.30.12.44.42;	author daveb;	state Exp;
branches;
next	1.52;

1.52
date	96.05.17.09.47.11;	author matthew;	state Exp;
branches;
next	1.51;

1.51
date	96.05.14.13.20.46;	author jont;	state Exp;
branches;
next	1.50;

1.50
date	96.05.14.10.47.04;	author matthew;	state Exp;
branches;
next	1.49;

1.49
date	96.05.07.17.00.58;	author jont;	state Exp;
branches;
next	1.48;

1.48
date	96.05.01.12.50.51;	author jont;	state Exp;
branches;
next	1.47;

1.47
date	96.04.30.13.20.52;	author matthew;	state Exp;
branches;
next	1.46;

1.46
date	96.04.22.15.12.41;	author matthew;	state Exp;
branches;
next	1.45;

1.45
date	96.04.04.14.07.23;	author jont;	state Exp;
branches;
next	1.44;

1.44
date	96.04.03.16.41.12;	author jont;	state Exp;
branches;
next	1.43;

1.43
date	96.02.06.11.29.24;	author jont;	state Exp;
branches;
next	1.42;

1.42
date	96.01.23.14.34.02;	author matthew;	state Exp;
branches;
next	1.41;

1.41
date	95.12.22.12.53.19;	author jont;	state Exp;
branches;
next	1.40;

1.40
date	95.12.18.16.41.38;	author matthew;	state Exp;
branches;
next	1.39;

1.39
date	95.11.21.13.58.18;	author jont;	state Exp;
branches;
next	1.38;

1.38
date	95.10.26.17.08.06;	author jont;	state Exp;
branches;
next	1.37;

1.37
date	95.09.22.16.10.29;	author jont;	state Exp;
branches;
next	1.36;

1.36
date	95.09.18.16.59.38;	author jont;	state Exp;
branches;
next	1.35;

1.35
date	95.09.01.14.59.59;	author nickb;	state Exp;
branches;
next	1.34;

1.34
date	95.07.25.15.59.38;	author jont;	state Exp;
branches;
next	1.33;

1.33
date	95.07.19.14.30.32;	author jont;	state Exp;
branches;
next	1.32;

1.32
date	95.07.13.09.41.52;	author jont;	state Exp;
branches;
next	1.31;

1.31
date	95.06.20.17.56.47;	author jont;	state Exp;
branches;
next	1.30;

1.30
date	95.06.14.12.21.37;	author jont;	state Exp;
branches;
next	1.29;

1.29
date	95.06.08.08.55.41;	author jont;	state Exp;
branches;
next	1.28;

1.28
date	95.06.02.15.19.09;	author jont;	state Exp;
branches;
next	1.27;

1.27
date	95.05.19.09.27.57;	author jont;	state Exp;
branches;
next	1.26;

1.26
date	95.05.02.15.31.11;	author matthew;	state Exp;
branches;
next	1.25;

1.25
date	95.03.02.11.06.53;	author matthew;	state Exp;
branches;
next	1.24;

1.24
date	95.02.15.13.35.25;	author jont;	state Exp;
branches;
next	1.23;

1.23
date	95.02.09.17.22.48;	author jont;	state Exp;
branches;
next	1.22;

1.22
date	95.01.30.14.20.46;	author matthew;	state Exp;
branches;
next	1.21;

1.21
date	94.12.13.11.00.04;	author matthew;	state Exp;
branches;
next	1.20;

1.20
date	94.12.08.13.27.25;	author matthew;	state Exp;
branches;
next	1.19;

1.19
date	94.11.28.21.01.04;	author jont;	state Exp;
branches;
next	1.18;

1.18
date	94.11.24.16.34.11;	author matthew;	state Exp;
branches;
next	1.17;

1.17
date	94.11.22.15.51.45;	author jont;	state Exp;
branches;
next	1.16;

1.16
date	94.11.18.14.02.51;	author jont;	state Exp;
branches;
next	1.15;

1.15
date	94.11.16.11.23.37;	author jont;	state Exp;
branches;
next	1.14;

1.14
date	94.11.07.16.07.52;	author jont;	state Exp;
branches;
next	1.13;

1.13
date	94.11.04.17.22.48;	author jont;	state Exp;
branches;
next	1.12;

1.12
date	94.11.02.17.14.48;	author jont;	state Exp;
branches;
next	1.11;

1.11
date	94.10.27.15.17.11;	author jont;	state Exp;
branches;
next	1.10;

1.10
date	94.10.20.16.38.44;	author jont;	state Exp;
branches;
next	1.9;

1.9
date	94.10.18.14.11.55;	author jont;	state Exp;
branches;
next	1.8;

1.8
date	94.10.07.16.21.12;	author jont;	state Exp;
branches;
next	1.7;

1.7
date	94.10.06.13.03.21;	author jont;	state Exp;
branches;
next	1.6;

1.6
date	94.10.05.12.59.04;	author jont;	state Exp;
branches;
next	1.5;

1.5
date	94.09.27.16.32.07;	author jont;	state Exp;
branches;
next	1.4;

1.4
date	94.09.23.15.11.57;	author jont;	state Exp;
branches;
next	1.3;

1.3
date	94.09.21.15.27.08;	author jont;	state Exp;
branches;
next	1.2;

1.2
date	94.09.16.14.55.48;	author jont;	state Exp;
branches;
next	1.1;

1.1
date	94.09.15.17.07.14;	author jont;	state Exp;
branches;
next	;

1.57.1.1
date	96.09.13.11.15.11;	author hope;	state Exp;
branches;
next	;

1.57.2.1
date	96.10.07.16.05.30;	author hope;	state Exp;
branches;
next	;

1.57.3.1
date	96.10.17.11.23.46;	author hope;	state Exp;
branches;
next	;

1.61.1.1
date	96.11.14.12.48.10;	author hope;	state Exp;
branches
	1.61.1.1.1.1;
next	;

1.61.1.1.1.1
date	96.11.28.14.59.43;	author hope;	state Exp;
branches;
next	;

1.61.2.1
date	96.11.22.18.08.10;	author hope;	state Exp;
branches;
next	;

1.61.3.1
date	96.12.17.17.46.51;	author hope;	state Exp;
branches
	1.61.3.1.1.1;
next	;

1.61.3.1.1.1
date	97.02.24.11.36.29;	author hope;	state Exp;
branches;
next	;

1.61.4.1
date	96.12.18.09.40.50;	author hope;	state Exp;
branches;
next	;

1.65.1.1
date	97.05.12.10.33.13;	author hope;	state Exp;
branches
	1.65.1.1.1.1
	1.65.1.1.2.1
	1.65.1.1.3.1;
next	;

1.65.1.1.1.1
date	97.07.28.18.18.35;	author daveb;	state Exp;
branches
	1.65.1.1.1.1.1.1;
next	;

1.65.1.1.1.1.1.1
date	97.10.07.11.43.39;	author jkbrook;	state Exp;
branches;
next	;

1.65.1.1.2.1
date	97.09.08.17.12.09;	author daveb;	state Exp;
branches;
next	;

1.65.1.1.3.1
date	97.09.09.14.07.47;	author daveb;	state Exp;
branches;
next	;

1.71.1.1
date	97.09.10.19.22.43;	author brucem;	state Exp;
branches;
next	;

1.71.2.1
date	97.09.11.20.53.53;	author daveb;	state Exp;
branches;
next	1.71.2.2;

1.71.2.2
date	97.11.20.17.08.45;	author daveb;	state Exp;
branches;
next	;

1.84.1.1
date	99.04.01.17.56.20;	author daveb;	state Exp;
branches;
next	;


desc
@new file
@


1.84
log
@[Bug #70073]
Remove half word aligned pushes and pops of AX
during floating point sequences
@
text
@(* _i386_cg.sml the functor *)
(*
$Log: _i386_cg.sml,v $
 * Revision 1.83  1998/07/01  17:51:48  jont
 * [Bug #20117]
 * Add align directive for benefit of jump tables
 *
 * Revision 1.82  1998/06/26  10:40:46  jont
 * [Bug #20109]
 * Modify branch size algorithm to start small
 *
 * Revision 1.81  1998/06/24  14:51:54  jont
 * [Bug #20108]
 * Ensure LEO uses short form of mov when destination is real register
 *
 * Revision 1.80  1998/06/23  15:00:51  jont
 * [Bug #20107]
 * Modify stack overflow test to compare with small immediate
 *
 * Revision 1.79  1998/02/19  17:07:00  mitchell
 * [Bug #30349]
 * Fix to avoid non-unit sequence warnings
 *
 * Revision 1.78  1998/02/12  14:49:32  jont
 * [Bug #70022]
 * Make sure floor leaves the i387 stack in a clean state
 *
 * Revision 1.77  1998/02/10  17:58:51  jont
 * [Bug #70055]
 * Modify code generator to save argument if debugging or tracing/profiling
 *
 * Revision 1.76  1998/01/30  09:38:46  johnh
 * [Bug #30326]
 * Merge in change from MLWorks_workspace_97 branch.
 *
 * Revision 1.75  1997/12/22  15:24:33  jont
 * [Bug #70037]
 * Fix single push 0 in function entry sequence
 *
 * Revision 1.74  1997/12/15  17:31:29  jont
 * [Bug #70027]
 * Fix call stack chopping to use add esp, #n instead of lea esp, n[esp]
 *
 * Revision 1.73  1997/11/13  11:17:13  jont
 * [Bug #30089]
 * Modify TIMER (from utils) to be INTERNAL_TIMER to keep bootstrap happy
 *
 * Revision 1.72  1997/09/19  09:19:27  brucem
 * [Bug #30153]
 * Remove references to Old.
 * Revision 1.71.2.2  1997/11/20  17:08:45  daveb
 * [Bug #30326]
 *
 * Revision 1.71.2.1  1997/09/11  20:53:53  daveb
 * branched from trunk for label MLWorks_workspace_97
 *
 * Revision 1.71  1997/08/11  09:37:47  jont
 * [Bug #30243]
 * Remove tests for out of range shifts as we no longer generate them
 *
 * Revision 1.70  1997/08/06  11:22:54  jont
 * [Bug #30215]
 * Remove BIC in favour of INTTAG
 *
 * Revision 1.69  1997/06/03  09:21:53  jont
 * [Bug #30076]
 * Modifications to code generate stack based argument passing
 *
 * Revision 1.68  1997/05/30  12:08:40  jont
 * [Bug #30076]
 * Modifications to allow stack based parameter passing on the I386
 *
 * Revision 1.67  1997/05/06  10:09:04  jont
 * [Bug #30088]
 * Get rid of MLWorks.Option
 *
 * Revision 1.66  1997/04/25  12:46:04  jont
 * [Bug #20018]
 * Correct failure message on trying to save an fp register
 *
 * Revision 1.65  1997/03/13  14:39:31  jont
 * [Bug #0]
 * Fix real comparisons to deal with nans
 *
 * Revision 1.64  1997/03/13  12:02:36  jont
 * [Bug #1962]
 * Sort out problems overloading global during store instructions
 *
 * Revision 1.63  1997/02/10  13:57:52  matthew
 * Don't reverse real bytes in value_cg
 *
 * Revision 1.62  1997/01/16  16:48:09  matthew
 * Changed tag option to tag list in tagged instructions
 *
 * Revision 1.61  1996/11/06  11:12:23  matthew
 * [Bug #1728]
 * __integer becomes __int
 *
 * Revision 1.60  1996/11/01  15:09:40  andreww
 * [Bug #1707]
 * threading debugger information.
 * (into calls).
 *
 * Revision 1.59  1996/10/31  15:14:31  io
 * removing toplevel String.
 *
 * Revision 1.58  1996/10/29  17:34:01  jont
 * [Bug #1618]
 * Ensure real does not trash its argument if already on the stack
 *
 * Revision 1.57  1996/08/27  11:37:40  jont
 * [Bug #1572]
 * Fix problems with self multiplies producing answer too small by factor of 4
 *
 * Revision 1.56  1996/08/01  16:39:44  jont
 * Porblems with parameters to set_proc_data being wrong order
 *
 * Revision 1.55  1996/08/01  13:09:41  jont
 * [Bug #1503]
 * Add field to FUNINFO to say if arg actually saved
 *
 * Revision 1.54  1996/06/05  13:01:15  jont
 * Fix array code generation problems
 *
 * Revision 1.53  1996/05/30  12:44:42  daveb
 * The Ord exception is no longer at top level.
 *
 * Revision 1.52  1996/05/17  09:47:11  matthew
 * Moved Bits to MLWorks.Internal
 *
 * Revision 1.51  1996/05/14  13:20:46  jont
 * Fix non-reversible binary operations with stack operations
 *
 * Revision 1.50  1996/05/14  10:47:04  matthew
 * Adding NOT32 MIR instruction
 *
 * Revision 1.49  1996/05/07  17:00:58  jont
 * Array moving to MLWorks.Array
 *
 * Revision 1.48  1996/05/01  12:50:51  jont
 * String functions explode, implode, chr and ord now only available from String
 * io functions and types
 * instream, oustream, open_in, open_out, close_in, close_out, input, output and end_of_stream
 * now only available from MLWorks.IO
 *
 * Revision 1.47  1996/04/30  13:20:52  matthew
 * Removing use of MLWorks.Integer
 *
 * Revision 1.46  1996/04/22  15:12:41  matthew
 * Removing error checks for FP operations
 *
 * Revision 1.45  1996/04/04  14:07:23  jont
 * Allow offsets in mem_operands to be bigger than an int, to cope with words
 *
 * Revision 1.44  1996/04/03  16:41:12  jont
 * Fix problems when doing fstref relative to frame
 *
Revision 1.43  1996/02/06  11:29:24  jont
Add implemetations of ADDW and SUBW
These are like ADDV and SUBV, except that
they cannot use exception trapping adds etc because they are untagged
and also when they detect overflow they must clean
all registers involved in the operation
Also fixed faulty string allocation size causing 16 bytes instead
of 8 to be allocated for 32 bit integers (with an inconsistent header)

Revision 1.42  1996/01/23  14:34:02  matthew
Fixing problem with fp_spills and leafness

Revision 1.41  1995/12/22  12:53:19  jont
Add extra field to procedure_parameters to contain old (pre register allocation)
spill sizes. This is for the i386, where spill assignment is done in the backend

Revision 1.40  1995/12/18  16:41:38  matthew
Save argument register on stack when generating debug code.

Revision 1.39  1995/11/21  13:58:18  jont
Modification for improved runtime env spill offsets
to indicate the kind of data spilled

Revision 1.38  1995/10/26  17:08:06  jont
Fix local variable compilation problems

Revision 1.37  1995/09/22  16:10:29  jont
Fix bug in compiler crash when number of fp spill slots exceeded

Revision 1.36  1995/09/18  16:59:38  jont
Fix problem whereby final word of vectors may be left uninitialised

Revision 1.35  1995/09/01  14:59:59  nickb
Make intercept offset count bytes, not instructions.

Revision 1.34  1995/07/25  15:59:38  jont
Add WORD to value_cg

Revision 1.33  1995/07/19  14:30:32  jont
Add CHAR to value_cg

Revision 1.32  1995/07/13  09:41:52  jont
Fix problems in shift generation

Revision 1.31  1995/06/20  17:56:47  jont
Implement integer multiply

Revision 1.30  1995/06/14  12:21:37  jont
Implement event checking in leaf case

Revision 1.29  1995/06/08  08:55:41  jont
Fixed tagged pointer computation in variable sized allocations

Revision 1.28  1995/06/02  15:19:09  jont
Change stack_limit to register_stack_limit

Revision 1.27  1995/05/19  09:27:57  jont
Modifications for equality tests with zero

Revision 1.26  1995/05/02  15:31:11  matthew
Removing step and polyvariable options

Revision 1.25  1995/03/02  11:06:53  matthew
Changes to Parser and Lexer structures

Revision 1.24  1995/02/15  13:35:25  jont
Improvements to lineariser

Revision 1.23  1995/02/09  17:22:48  jont
Tidy up, and implement some unimplemented opcodes

Revision 1.22  1995/01/30  14:20:46  matthew
Debugger changes

Revision 1.21  1994/12/13  11:00:04  matthew
More work on fp stuff.

Revision 1.20  1994/12/08  13:27:25  matthew
Floating point code generation
,

Revision 1.19  1994/11/28  21:01:04  jont
Handle BINARY a := b - a type stuff
Modify messages for unrepresentable reals

Revision 1.18  1994/11/24  16:34:11  matthew
Adding ALLOC_VECTOR
Include variable length strings & vectors

Revision 1.17  1994/11/22  15:51:45  jont
Minor improvements to tail, rts

Revision 1.16  1994/11/18  14:02:51  jont
Rework stack clearing using push
Modify constant loading in gc sequences

Revision 1.15  1994/11/16  11:23:37  jont
Add immediate store operations

Revision 1.14  1994/11/07  16:07:52  jont
Recode binary add and sub using lea

Revision 1.13  1994/11/04  17:22:48  jont
Sort out small stack initialisation code

Revision 1.12  1994/11/02  17:14:48  jont
Fix new_handler code when handler frame pointer is spilled
Sort out some stack size and initialisation problems
Fix bug in array allocation when both size and destination are spills

Revision 1.11  1994/10/27  15:17:11  jont
Fix problems with overloaded use of ECX during store byte

Revision 1.10  1994/10/20  16:38:44  jont
Get offsets right in stack allocations

Revision 1.9  1994/10/18  14:11:55  jont
Fix various bugs, particularly in gc sequences

Revision 1.8  1994/10/07  16:21:12  jont
Get branch offsets right for cross procedure calls and tails

Revision 1.7  1994/10/06  13:03:21  jont
Sort out load/store code
Fix minor problems in tail

Revision 1.6  1994/10/05  12:59:04  jont
Do more opcodes

Revision 1.5  1994/09/27  16:32:07  jont
Add stack initialisation and overflow checking, and variable size allocation
Stack initialisation not in yet

Revision 1.4  1994/09/23  15:11:57  jont
Add more opcodes and deal with spills
First version to complete __builtin_library
No stak overflow check or initialisation

Revision 1.3  1994/09/21  15:27:08  jont
More opcodes

Revision 1.2  1994/09/16  14:55:48  jont
Compiled move, load/store, enter and rts (leaf only) and started on alloc

Revision 1.1  1994/09/15  17:07:14  jont
new file

Copyright (c) 1994 Harlequin Ltd.
*)

require "../basis/__int";

require "../utils/print";
require "../utils/mlworks_timer";
require "../utils/lists";
require "../utils/crash";
require "../utils/diagnostic";
require "../utils/sexpr";
require "../basics/ident";
require "../main/reals";
require "../main/options";
require "../main/code_module";
require "../mir/mirtables";
require "../mir/mirregisters";
require "../mir/mirprint";
require "../rts/gen/implicit";
require "../rts/gen/tags";
require "../main/info";
require "../main/machspec";
require "i386_schedule";
require "../main/mach_cg";

functor I386_Cg(
  structure Tags : TAGS
  structure Print : PRINT
  structure Timer : INTERNAL_TIMER
  structure Lists : LISTS
  structure Crash : CRASH
  structure Info : INFO
  structure Sexpr : SEXPR
  structure Reals : REALS
  structure Ident : IDENT
  structure Options : OPTIONS
  structure MirTables : MIRTABLES
  structure MirRegisters : MIRREGISTERS
  structure MirPrint : MIRPRINT
  structure MachSpec : MACHSPEC
  structure Code_Module : CODE_MODULE
  structure I386_Schedule : I386_SCHEDULE
  structure Implicit_Vector : IMPLICIT_VECTOR
  structure Diagnostic : DIAGNOSTIC

  sharing Info.Location = Ident.Location
  sharing MirTables.MirTypes.Set = MachSpec.Set
  sharing MirTables.MirTypes = MirRegisters.MirTypes = MirPrint.MirTypes

  sharing type Ident.SCon = MirTables.MirTypes.SCon

  sharing type I386_Schedule.I386_Assembly.I386_Opcodes.I386Types.I386_Reg
    = MachSpec.register
  sharing type MirTables.MirTypes.Map.object = I386_Schedule.I386_Assembly.tag
  sharing type I386_Schedule.I386_Assembly.Backend_Annotation =
    MirTables.MirTypes.Debugger_Types.Backend_Annotation
     ) : MACH_CG =
struct
  structure I386_Assembly = I386_Schedule.I386_Assembly
  structure I386_Opcodes = I386_Assembly.I386_Opcodes
  structure MirTypes = MirTables.MirTypes
  structure I386Types = I386_Opcodes.I386Types
  structure MachSpec = MachSpec
  structure Diagnostic = Diagnostic
  structure Debugger_Types = MirTypes.Debugger_Types
  structure Map = MirTypes.Map
  structure Ident = Ident
  structure Set = MirTypes.Set
  structure Info = Info
  structure RuntimeEnv = MirTypes.Debugger_Types.RuntimeEnv
  structure Options = Options

  structure Bits = MLWorks.Internal.Bits

  type Module = Code_Module.Module
  type Opcode = I386_Assembly.opcode

  val do_timings = ref false

  val trace_dummy_instructions =
    [(I386_Assembly.other_nop_code,NONE,"Dummy instructions for tracing"),
     (I386_Assembly.other_nop_code,NONE,"Dummy instructions for tracing"),
     (I386_Assembly.other_nop_code,NONE,"Dummy instructions for tracing")]

  val diagnostic_output = Diagnostic.output

  val print_code_size = ref false

  val linkage_size = 3
  val frame_offset = 4 (* Leave room for return address on stack *)
  val fp_spare_offset = frame_offset + 4 (* one down from the return address *)

  fun B l =
    let
      fun aux ([],acc) = acc
        | aux (#"0" ::rest,acc) =
          aux (rest,acc+acc)
        | aux (#"1" ::rest,acc) =
          aux (rest,acc+acc+1)
        | aux (#" " ::rest,acc) =
          aux (rest,acc)
        | aux (d::rest,acc) =
          Crash.impossible "bad binary number"
    in
      aux (explode l,0)
    end

  val fpu_error_bits = B"0000 1101" (* The bits to check for an error *)
  val fpu_control_rounding_bits           = B"1111 0011 1111 1111"
  val fpu_control_round_to_minus_infinity = B"0000 0100 0000 0000"

  fun contract_sexpr(Sexpr.NIL, [], acc) =
    Lists.reducel (fn (x, y) => y @@ x) ([], acc)
    | contract_sexpr(Sexpr.NIL, x :: xs, acc) = contract_sexpr(x, xs, acc)
    | contract_sexpr(Sexpr.ATOM x, to_do, acc) =
      contract_sexpr(Sexpr.NIL, to_do, x :: acc)
    | contract_sexpr(Sexpr.CONS(x, y), to_do, acc) =
      contract_sexpr(x, y :: to_do, acc)

  val contract_sexpr =
    fn x => contract_sexpr(x, [], [])

  fun find_nop_offsets(_, []) = ~1
    | find_nop_offsets(offset, (opcode, _) :: rest) =
      if opcode = I386_Assembly.other_nop_code then
	offset
      else
	find_nop_offsets(offset+(I386_Assembly.opcode_size opcode), rest)

  val find_nop_offsets = fn (tag, code) => find_nop_offsets(0, code)

  fun check_range(i:int, signed, pos_limit) =
    if signed then
	(i >= 0 andalso i < pos_limit) orelse
	(i < 0 andalso i >= ~pos_limit)
    else i >= 0 andalso i < pos_limit

  fun fault_range(i, signed, pos_limit) =
    if check_range(i, signed, pos_limit) then i
    else
      (diagnostic_output 3
       (fn _ => ["fault_range called with value ",
		 Int.toString i,
		 " in positive range ",
		 Int.toString pos_limit]);
       Crash.impossible"Immediate constant out of range" )

  fun mantissa_is_zero (mantissa:string):bool =
    let
      val sz = size mantissa
      fun scan i =
      if i < sz then
	(MLWorks.String.ordof (mantissa, i) = ord #"0") andalso
	scan (i+1)
      else
	true
    in
      scan 0
    end (* mantissa_is_zero *)

  fun binary_list_to_string(done, [], _, 128) = implode (rev done)
    | binary_list_to_string(_, [], _, l) =
      Crash.impossible("Binary_list_to_string length not 8, remainder length " ^
		       Int.toString l)
    | binary_list_to_string(done, x :: xs, digit, power) =
      let
	val x = ord x - ord #"0"
      in
	if power = 1 then
	  binary_list_to_string(chr (digit + x) :: done, xs, 0, 128)
	else
	  binary_list_to_string(done, xs, digit + x * power, power div 2)
      end

  fun to_binary(digits, value) =
    let
      fun to_sub(0, _, done) = done
      | to_sub(digs_to_go, value, done) =
	let
	  val digit = chr (value mod 2 + ord #"0")
	in
	  to_sub(digs_to_go - 1, value div 2, digit :: done)
	end
    in
      to_sub(digits, value, [])
    end

  fun n_zeroes(done, 0) = done
    | n_zeroes(done, n) = n_zeroes(#"0" :: done, n-1)

  fun adjust (error_info,x,location) (mantissa, exponent, max_exponent, bits) =
    if mantissa_is_zero mantissa then
      (mantissa, 0)
    else
      if exponent > 0 andalso exponent < max_exponent then
	(mantissa, exponent)
      else
	(* Need to handle subnormal numbers *)
	if exponent >= max_exponent then
	  Info.error'
          error_info
          (Info.FATAL,location,
           "Real number unrepresentable: " ^ x)
	else
	  if exponent < ~bits then (implode (n_zeroes([], bits)), 0)
	  else
	    (implode (n_zeroes([], abs exponent)) ^ mantissa, 0)

  fun to_single_string args (sign, mantissa, exponent) =
    let
      val real_exponent = exponent + 127
      val (mantissa, real_exponent) = adjust args (mantissa, real_exponent, 255, 23)
      val binary_list =
	(if sign then #"1" else #"0") ::
	   to_binary(8, real_exponent) @@
	   explode(substring (* could raise Substring *) (mantissa, 1, 23))
    in
      binary_list_to_string([], binary_list, 0, 128)
    end

  fun to_double_string args (sign, mantissa, exponent) =
    let
      val real_exponent = exponent + 1023
      val (mantissa, real_exponent) = adjust args (mantissa, real_exponent, 2047, 52)
      val binary_list =
	(if sign then #"1" else #"0") ::
	   to_binary(11, real_exponent) @@
	   explode(substring(mantissa, 1, 52))
    in
      binary_list_to_string([], binary_list, 0, 128)
    end

  fun to_extended_string args (sign, mantissa, exponent) =
    let
      val real_exponent = exponent + 16383
      val (mantissa, real_exponent) =
	adjust args (mantissa, real_exponent, 32767, 63)
      val binary_list =
	(if sign then #"1" else #"0") ::
	   to_binary(15, real_exponent) @@
	   n_zeroes([], 16) @@
	   explode(substring(mantissa, 0, 64)) @@
	   n_zeroes([], 32)	
    in
      binary_list_to_string([], binary_list, 0, 128)
    end

  fun value_cg(i, MirTypes.SCON (Ident.STRING x),_) = Code_Module.STRING(i, x)
    | value_cg(i, MirTypes.SCON (Ident.REAL(x,location)),error_info) =
      (let
	 val the_real = Reals.evaluate_real x
	 val (sign, mantissa, exponent) = Reals.find_real_components the_real
	 val encoding_function =
           case I386Types.fp_used of
             I386Types.single => to_single_string (error_info,x,location)
           | I386Types.double => to_double_string (error_info,x,location)
           | I386Types.extended => to_extended_string (error_info,x,location)
       in
	 Code_Module.REAL(i, encoding_function(sign, mantissa, exponent))
       end handle MLWorks.Internal.StringToReal =>
	 Info.error'
	 error_info
	 (Info.FATAL, location, "Real number unrepresentable: " ^ x)
      )
    | value_cg(_, MirTypes.SCON (Ident.INT _),_) = Crash.impossible"VALUE(INT)"
    | value_cg(_, MirTypes.SCON (Ident.CHAR _),_) = Crash.impossible"VALUE(CHAR)"
    | value_cg(_, MirTypes.SCON (Ident.WORD _),_) = Crash.impossible"VALUE(WORD)"
    | value_cg (i,MirTypes.MLVALUE value,_) =
      Code_Module.MLVALUE (i,value)

  type half_op = I386_Assembly.opcode * MirTypes.tag option
  type half_op_block = MirTypes.tag * half_op list
  (* A half compiled form with unresolved branches *)

  val absent = NONE

  val full_nop = (I386_Assembly.nop_code, absent, "padding nop")

  val no_tag_full_nop = (I386_Assembly.nop_code, "padding nop")

  (* A function to return the terminating branch of a block if one exists *)
  fun last_opcode [] = (I386_Assembly.no_op, false)
    | last_opcode [elem as (I386_Assembly.OPCODE(I386_Assembly.jmp, _),
                            _, _)] =
      (elem, true)
    | last_opcode(_ :: xs) = last_opcode xs

  fun make_proc_info(res as (main_tree, tag_tree), []) = res
    | make_proc_info((main_tree, tag_tree),
		     ((block_tag, opcode_list)) :: rest) =
      let
	val last_tag_exists as (tag, ok) = case last_opcode opcode_list of
	  ((_, SOME tag, _), true) => (tag, true)
	| _ => (block_tag, false)
      in
	make_proc_info
	((Map.define (main_tree, block_tag, last_tag_exists),
	  if ok then
	    Map.define (tag_tree, tag, 0)
	  else tag_tree), rest)
      end

  fun rev_app([], acc) = acc
    | rev_app(x :: xs, acc) = rev_app(xs, x :: acc)

  fun remove_trailing_branch(block_tag, opcode_list) =
    let
      val rev_opc = rev opcode_list
      val new_opc =
	case rev_opc of
	  (I386_Assembly.OPCODE(I386_Assembly.jmp, [I386_Assembly.rel32 0]), _, _) :: rest => rest
	| (I386_Assembly.OPCODE(I386_Assembly.jmp, [I386_Assembly.rel8 0]), _, _) :: rest => rest
	| opcodes as ((I386_Assembly.OPCODE(I386_Assembly.jmp, _), _, _) :: _) => opcodes
	| _ =>
	    Crash.impossible"Remove trailing branch fails"
    in
      (block_tag, rev new_opc)
    end

  (* CT this now works on the continuer and non-continuer lists in turn *)
  (* JT and now on the tails and non_continuers *)
  (* There's no point in looking through the heads, as by definition *)
  (* nothing continues into them *)

  fun find_dest_block(tag, [], [], y, z) = ((tag, []), false, y, z)
    | find_dest_block(dest_tag,
		      (block as (block_tag, opcode_list)) :: tails,
		      non_continuers,
		      tails', []) =
      if dest_tag = block_tag then
	(block, true, rev_app(tails', tails), non_continuers)
      else
	find_dest_block(dest_tag, tails, non_continuers, block :: tails', [])
    | find_dest_block(dest_tag,
		      [],
		      (block as (block_tag, opcode_list)) :: non_continuers,
		      tails', non_continuers') =
      if dest_tag = block_tag then
	(block, true, tails', rev_app(non_continuers', non_continuers))
      else
	find_dest_block(dest_tag, [], non_continuers, tails', block :: non_continuers')
    | find_dest_block _ =
      Crash.impossible "This should never happen in _mach_cg "

  fun move_first proc_tag =
    let
      fun move_sub(_, []) = Crash.impossible "move_first"
	| move_sub(L, (t, code) :: rest) =
	  if t = proc_tag then
	    (t, code) :: rev_app(L, rest)
	  else
	    move_sub ((t, code) :: L, rest)
    in
      move_sub
    end

  (* Algorithm *)
  (* Start with the first block (entry block) *)
  (* Find the block it tails into, and append that *)
  (* Repeat until we end up with a block which either doesn't tail *)
  (* into an unused block (eg a loop), or doesn't tail at all (eg ret) *)
  (* Now find all blocks which tail into something *)
  (* and pick one from these which nothing tails into from these *)
  (* This is called a chain head *)
  (* Repeat as if we'd just started *)
  (* If no such block, pick one from the cycle and repeat as before *)
  (* If no blocks which tail at all, bung them on the end and finish *)
  (* A consequence of this algorithm is *)
  (* When searching for a new head of a chain, *)
  (* we need only check that a block which continues *)
  (* was never the target of another block (ie check at proc start) *)
  (* Because if it once was, and has now ceased to be *)
  (* Then it would have been processed already (reductio ad absurdum) *)
  fun reorder_blocks(proc as (proc_tag, block_list)) =
    (* Reorder the blocks for a proc so as to allow fall throughs *)
    (* Note that this will result in blocks with dangling ends *)
    (* So they must not be reordered again by any other means *)
    (* We would also like to ensure that short blocks on the *)
    (* normal instruction path for allocation sequences tail into the following code *)
    let
      val (proc_info, tag_tree) =
	make_proc_info((Map.empty , Map.empty), block_list)

      val proc_info_map = Map.tryApply proc_info
      val tag_tree_map = Map.tryApply tag_tree
      (* We don't have to repeatedly re-calculate the continuers lists *)

      fun do_fall_throughs_with_continuers_calculated(arg as
						      (done,
						       (block as (block_tag, opcode_list)),
						       heads,
						       tails,
						       non_continuers)) =
        let
	  val (dest_tag, found_block) =
	    Map.apply_default'(proc_info, (block_tag, false), block_tag)

	in
	  if found_block then
	    let
	      val (dest_block, found_dest, non_continuers', tails') =
		find_dest_block(dest_tag, non_continuers, tails , [], [])
	    in
	      if found_dest then
		do_fall_throughs_with_continuers_calculated
		(remove_trailing_branch block :: done,
		 dest_block, heads, tails', non_continuers')
	      else
		 do_next arg
	    end
	  else
	     do_next arg
	end

      and do_next(done, block, heads, tails, non_continuers) =
	case (heads, tails) of
	  (* CT this was rev(rev rest @@ (block :: done)), but
	   rev(rev rest @@ (block::done)) = rev(block::done) @@ rest
	   = rev( [block] @@ done) @@ rest = rev done @@ rev[block] @@ rest
	   = rev done @@ (block :: rest)
	   AND now rest = continuers @@ non-continuers *)
	  ([], []) =>
	    rev_app(done, (block :: non_continuers))
	| ([], tail :: tails) =>
	    do_fall_throughs_with_continuers_calculated(block :: done,
							tail,
							[],
							tails,
							non_continuers)
	| (hd :: heads, _) =>
	    do_fall_throughs_with_continuers_calculated(block :: done,
							hd,
							heads,
							tails,
							non_continuers)

      fun do_fall_throughs(block, rest) =
	let
	  fun continues(tag, _) =
	    case proc_info_map tag of
	      SOME (_, t) => t
	    | _ => false

	  fun is_head_of_chain(tag, _) =
	    case tag_tree_map tag of
	      NONE => true
	    | _ => false

	  val (continuers,non_continuers) =
	    Lists.partition continues rest
	  val (heads, tails) =
	    Lists.partition is_head_of_chain continuers
	in
	  do_fall_throughs_with_continuers_calculated([], block, heads, tails, non_continuers)
	end

      val (hd_block_list, tl_block_list) = case move_first proc_tag ([], block_list) of
	x :: y => (x, y)
      | _ => Crash.impossible"Empty block list"
    in
      (proc_tag,
       case tl_block_list of
	 [] => [hd_block_list]
       | _ =>
	   do_fall_throughs(hd_block_list, tl_block_list))
    end

  fun opcode_list_size opcode_list =
    Lists.reducel
    (fn (x, (opcode, _, _)) => x + I386_Assembly.opcode_size opcode)
    (0, opcode_list)

  fun double_align n = ((n+7) div 8) * 8

  fun tag_offsets([], offset, tag_env) = (offset, tag_env)
    | tag_offsets((tag, ho_list) :: rest, disp, tag_env) =
      tag_offsets(rest, disp + opcode_list_size ho_list,
		  Map.define (tag_env, tag, disp))


  fun tag_offsets_for_list(_, [], env) = env
    | tag_offsets_for_list(offset, (_, proc) :: rest, env) =
      let
	val (next_offset, env) = tag_offsets(proc, offset, env)
	val next_offset' =
	  double_align(next_offset) + 4 (* Back-pointer *) +
	  4 (* Procedure number within set *)
      in
	tag_offsets_for_list(next_offset', rest, env)
      end

  fun do_offsets(start, done, []) = (rev done, start)
    | do_offsets(start, done, (opcode as (opc, _, _)) :: rest) =
      let
	val next = start + I386_Assembly.opcode_size opc
      in
	do_offsets(next, (opcode, next) :: done, rest)
      end

  val ref_redo = ref false

  fun rev_map f arg =
    let
      fun map_sub([], acc) = acc
	| map_sub(x :: xs, acc) = map_sub(xs, f x :: acc)
    in
      map_sub arg
    end

  fun rev_app([], y) = y
    | rev_app(x :: xs, y) = rev_app(xs, x :: y)

  fun copy_n(n, from, acc, new_tail) =
    if n < 0 then
      Crash.impossible"copy_n negative arg"
    else
      if n = 0 then
	rev_app(acc, new_tail)
      else
	case from of
	  (x :: xs) =>
	    copy_n(n-1, xs, x :: acc, new_tail)
	| _ => Crash.impossible"copy_n short list"

  fun drop(n, the_list) =
    if n < 0 then
      Crash.impossible"drop negative arg"
    else
      if n = 0 then the_list
      else
	case the_list of
	  [] => Crash.impossible"drop bad list"
	| _ :: rest => drop(n-1, rest)

  fun short_range i = i <= 127 andalso i >= ~128

  fun linearise_list proc_list =
    let
      val new_proc_list =
	Timer.xtime
	("reordering blocks", !do_timings,
	 fn () => map reorder_blocks proc_list)

      (* We'd now like to reschedule any small blocks that branch backwards *)

      fun do_linearise proc_list =
	let
	  fun linearise_check tag_env =
	    let
	      fun lookup_env tag = Map.tryApply'(tag_env,tag)

	      fun linearise_proc_check(_, offset, [], done, redo) = (offset, rev done, redo)
		| linearise_proc_check(proc_offset, start,
				       blocks as ((block as (block_tag, _)) :: block_list),
				       done, redo) =
		  let
		    val _ = ref_redo := redo

		    fun do_block(block_start, (block_tag, opcode_list)) =
		      let
			fun do_opcode(full_opcode as
				      (opcode as
				       I386_Assembly.OPCODE(opc as I386_Assembly.jcc _,
							    [I386_Assembly.rel8 i]),
				       tag_opt as SOME tag, comment), offset) =
			  (case lookup_env tag of
			     SOME res =>
			       let
				 val disp = res + i - offset
			       (* Calculate relative to next instruction *)
			       in
				 if short_range disp then
				   full_opcode
				 else
				   (ref_redo := true;
				    (I386_Assembly.OPCODE(opc, [I386_Assembly.rel32 i]),
				     tag_opt, comment))
			       end
			   | NONE =>
			       Crash.impossible("Assoc do_opcode:" ^
						I386_Assembly.print_mnemonic opc))
			
			  | do_opcode(full_opcode as
				      (opcode as
				       I386_Assembly.OPCODE(opc as I386_Assembly.jmp,
							    [I386_Assembly.rel8 i]),
				       tag_opt as SOME tag, comment), offset) =
			     (case lookup_env tag of
			       SOME res =>
				 let
				   val disp = res + i - offset
				 (* Calculate relative to next instruction *)
				 in
				   if short_range disp then
				     full_opcode
				   else
				     (ref_redo := true;
				      (I386_Assembly.OPCODE(opc, [I386_Assembly.rel32 i]),
				       tag_opt, comment))
				 end
			     | NONE =>
				 Crash.impossible("Assoc do_opcode:" ^
						  I386_Assembly.print_mnemonic opc))

			  | do_opcode(full_opcode, offset) = full_opcode

			val (opcodes_and_offsets, next) =
			  do_offsets(block_start, [], opcode_list)
		      in
			(rev_map do_opcode (opcodes_and_offsets, []), next)
		      end
		    val (so_far, next) = do_block(start, block)
		  in
		    linearise_proc_check(proc_offset, next, block_list,
					 (block_tag, rev so_far) :: done, !ref_redo)
		  end
	    in
	      linearise_proc_check
	    end

	  fun do_linearise_check(_, _, [], result, redo) = (rev result, redo)
	    | do_linearise_check(tag_env, offset, (tag, proc) :: rest, result, redo) =
	      let
		val (offset', done', redo') =
		  linearise_check tag_env (offset, offset, proc, [], redo)
		val offset'' =
		  double_align offset' +
		  4 (* Back-pointer *) +
		  4 (* Procedure number within set *)
	      in
		do_linearise_check(tag_env, offset'', rest, (tag, done') :: result,
				   redo')
	      end

	  fun shrink_branches proc_list =
	    let
	      val tag_env = tag_offsets_for_list(0, proc_list, Map.empty)
	      val _ = diagnostic_output 3 (fn _ => ["Tag_env ="])
	      val _ =
		diagnostic_output 3
		(fn _ => (app
			  (fn (x, y) => ignore(Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ Int.toString y ^ "\n")))
			  (Map.to_list tag_env) ;
			  [] ))
	      val (new_list, redo) = do_linearise_check(tag_env, 0, proc_list, [], false)
	    in
	      if redo then
		((*output(std_out, "Recursively shrinking branches\n");*)
		 shrink_branches new_list)
	      else
		proc_list
	    end

	  val proc_list = shrink_branches proc_list
	  val tag_env = tag_offsets_for_list(0, proc_list, Map.empty)

	  val _ = diagnostic_output 3 (fn _ => ["Tag_env ="])
	  val _ =
	    diagnostic_output 3
	    (fn _ => (app
	     (fn (x, y) => ignore(Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ Int.toString y ^ "\n")))
		      (Map.to_list tag_env) ;
		      [] ))

	  fun lookup_env tag = Map.tryApply'(tag_env,tag)

	  fun linearise_proc(_, offset, [], done) = (offset, rev done)
	    | linearise_proc(proc_offset, start, blocks as (block :: block_list), done) =
	      let
		(* Insert algorithm for optimal linearisation of blocks here *)
		(* Present algorithm just uses the current order *)
		fun do_block(block_start, (block_tag, opcode_list), done) =
		  let
		    fun do_opcodes([], res) = res
		      | do_opcodes(opcode_and_offset :: rest, done) =
		      case opcode_and_offset of
			((opcode as
				   I386_Assembly.OPCODE(opc as I386_Assembly.jcc _,
							[I386_Assembly.rel32 i]),
				   SOME tag, comment), offset) =>
			let
			  val opcode =
			    case lookup_env tag of
			      SOME res =>
				let
				  val disp = res + i - offset
				(* Calculate relative to next instruction *)
				in
				  (I386_Assembly.OPCODE(opc, [I386_Assembly.rel32 disp]),
				   comment)
				end
			    | NONE =>
				Crash.impossible("Assoc do_opcode:" ^
						 I386_Assembly.print_mnemonic opc)
			in
			  do_opcodes(rest, opcode :: done)
			end
		      | ((opcode as
			  I386_Assembly.OPCODE(opc as I386_Assembly.jcc _,
					       [I386_Assembly.rel8 i]),
			  SOME tag, comment), offset) =>
			let
			  val opcode =
			    case lookup_env tag of
			      SOME res =>
				let
				  val disp = res + i - offset
				  (* Calculate relative to next instruction *)
				  val _ =
				    if disp > 127 orelse disp < ~128 then
				      Crash.impossible
				      ("Short branch of " ^
				       Int.toString disp ^ " out of range in " ^
				       I386_Assembly.print_mnemonic opc ^ " " ^
				       MirTypes.print_tag tag ^
				       " in block with tag " ^
				       MirTypes.print_tag block_tag ^
				       ", disp = " ^
				       Int.toString disp ^
				       " res = " ^
				       Int.toString res ^
				       " i = " ^
				       Int.toString i ^
				       " offset " ^
				       Int.toString offset)
				    else
				      ()
				in
				  (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8 disp]),
				   comment)
				end
			    | NONE =>
				Crash.impossible("Assoc do_opcode:" ^
						 I386_Assembly.print_mnemonic opc)
			in
			  do_opcodes(rest, opcode :: done)
			end
		      | ((opcode as
			  I386_Assembly.OPCODE(opc as I386_Assembly.jcc _,
					       [I386_Assembly.fix_rel32 i]),
			  SOME tag, comment), offset) =>
			Crash.impossible"i386_cg: jcc fix_rel32 encountered"
		      | ((opcode as
			  I386_Assembly.OPCODE(opc as I386_Assembly.jmp,
					       [I386_Assembly.rel32 i]),
			  SOME tag, comment), offset) =>
			let
			  val opcode =
			    case lookup_env tag of
			      SOME res =>
				let
				  val disp = res + i - offset
				(* Calculate relative to next instruction *)
				in
				  (I386_Assembly.OPCODE(opc, [I386_Assembly.rel32 disp]),
				   comment)
				end
			    | NONE =>
				Crash.impossible("Assoc do_opcode:" ^
						 I386_Assembly.print_mnemonic opc)
			in
			  do_opcodes(rest, opcode :: done)
			end
		      | ((opcode as
			  I386_Assembly.OPCODE(opc as I386_Assembly.jmp,
					       [I386_Assembly.fix_rel32 i]),
			  SOME tag, comment), offset) =>
			(case lookup_env tag of
			   NONE =>
			     Crash.impossible("Assoc do_opcode:" ^
					      I386_Assembly.print_mnemonic opc)
			 | SOME res =>
			     let
			       val disp = res + i - offset
			       val jmp =
				 (I386_Assembly.OPCODE(I386_Assembly.jmp,
						       [I386_Assembly.fix_rel32 disp]),
				  comment)
			       val opcodes = jmp :: done
			       (* Calculate relative to next instruction *)
			       (* Now for the tricky part, putting in the align directives *)
			       (* We have to allow for the fact that gas may shorten *)
			       (* one of these jmps which we want to be full size *)
			       (* So we add an align statement to force the code out *)
			       (* to the correct size *)
			       (* Unfortunately, gas is defective in that it doesn't *)
			       (* have a fully functional align directive *)
			       (* ie allign to offset from boundary *)
			       (* So we place the align amongst the nops following the nop *)
			       (* which should produce the correct alignment if the *)
			       (* were not shortened. So if gas gets the instruction right *)
			       (* the align has no effect, whereas if it gets it wrong *)
			       (* the align forces the padding to be inserted *)
			       val new_arg =
				 case rest of
				   ((I386_Assembly.OPCODE(I386_Assembly.nop, []), _, _), _) ::
				   ((I386_Assembly.OPCODE(I386_Assembly.nop, []), _, _), _) ::
				   ((I386_Assembly.OPCODE(I386_Assembly.nop, []), _, _), _) ::
				   rest' =>
				     let
				       val align_val = if (offset-5) mod 8 < 4 then 8 else 4
				       val align = (offset-5) mod 4
				       nonfix before
				       val (before, after) = (3 - align, align)
				       val align_dir =
					 (I386_Assembly.OPCODE
					  (I386_Assembly.align,
					   [I386_Assembly.r_m32
					    (I386_Assembly.INR
					     (I386_Assembly.MEM
					      {base=NONE, index=NONE,
					       offset=SOME(I386_Assembly.SMALL align_val)}))]),
					     "ensure correct alignment")
				       fun insert_nops(i, opcodes) =
					 if i <= 0 then
					   opcodes
					 else
					   insert_nops(i-1, no_tag_full_nop :: opcodes)
				       val opcodes = insert_nops(before, opcodes)
				       val opcodes = insert_nops(after, align_dir :: opcodes)
				     in
				       (rest', opcodes)
				     end
				 | _ => (* Last in list, no worries *)
				     (rest, opcodes)
			     in
			       do_opcodes new_arg
			     end)
		      | ((opcode as
			  I386_Assembly.OPCODE(opc as I386_Assembly.jmp,
					       [I386_Assembly.rel8 i]),
			  SOME tag, comment), offset) =>
			let
			  val opcode =
			    case lookup_env tag of
			      SOME res =>
				let
				  val disp = res + i - offset
				  (* Calculate relative to next instruction *)
				  val _ =
				    if disp > 127 orelse disp < ~128 then
				      Crash.impossible
				      ("Short branch of " ^
				       Int.toString disp ^ " out of range in " ^
				       I386_Assembly.print_mnemonic opc ^ " " ^
				       MirTypes.print_tag tag ^
				       " in block with tag " ^
				       MirTypes.print_tag block_tag ^
				       ", disp = " ^
				       Int.toString disp ^
				       " res = " ^
				       Int.toString res ^
				       " i = " ^
				       Int.toString i ^
				       " offset " ^
				       Int.toString offset)
				    else
				      ()
				in
				  (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8 disp]),
				   comment)
				end
			    | NONE =>
				Crash.impossible("Assoc do_opcode:" ^
						 I386_Assembly.print_mnemonic opc)
			in
			  do_opcodes(rest, opcode :: done)
			end
		      | ((opcode as
			  I386_Assembly.OPCODE(opc as I386_Assembly.loop,
					       [I386_Assembly.rel8 i]),
			  SOME tag, comment), offset) =>
			let
			  val opcode =
			    case lookup_env tag of
			      SOME res =>
				let
				  val disp = res + i - offset
				  (* Calculate relative to next instruction *)
				  val _ =
				    if disp > 127 orelse disp < ~128 then
				      Crash.impossible
				      ("Short branch of " ^
				       Int.toString disp ^ " out of range in " ^
				       I386_Assembly.print_mnemonic opc ^ " " ^
				       MirTypes.print_tag tag ^
				       " in block with tag " ^
				       MirTypes.print_tag block_tag ^
				       ", disp = " ^
				       Int.toString disp ^
				       " res = " ^
				       Int.toString res ^
				       " i = " ^
				       Int.toString i ^
				       " offset " ^
				       Int.toString offset)
				    else
				      ()
				in
				  (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8 disp]),
				   comment)
				end
			    | NONE =>
				Crash.impossible("Assoc do_opcode:" ^
						 I386_Assembly.print_mnemonic opc)
			in
			  do_opcodes(rest, opcode :: done)
			end
		      | ((opcode as
			  I386_Assembly.OPCODE(opc as I386_Assembly.loopz,
					       [I386_Assembly.rel8 i]),
			  SOME tag, comment), offset) =>
			let
			  val opcode =
			    case lookup_env tag of
			      SOME res =>
				let
				  val disp = res + i - offset
				  (* Calculate relative to next instruction *)
				  val _ =
				    if disp > 127 orelse disp < ~128 then
				      Crash.impossible
				      ("Short branch of " ^
				       Int.toString disp ^ " out of range in " ^
				       I386_Assembly.print_mnemonic opc ^ " " ^
				       MirTypes.print_tag tag ^
				       " in block with tag " ^
				       MirTypes.print_tag block_tag ^
				       ", disp = " ^
				       Int.toString disp ^
				       " res = " ^
				       Int.toString res ^
				       " i = " ^
				       Int.toString i ^
				       " offset " ^
				       Int.toString offset)
				    else
				      ()
				in
				  (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8 disp]),
				   comment)
				end
			    | NONE =>
				Crash.impossible("Assoc do_opcode:" ^
						 I386_Assembly.print_mnemonic opc)
			in
			  do_opcodes(rest, opcode :: done)
			end
		      | ((opcode as
			  I386_Assembly.OPCODE(opc as I386_Assembly.loopnz,
					       [I386_Assembly.rel8 i]),
			  SOME tag, comment), offset) =>
			let
			  val opcode =
			    case lookup_env tag of
			      SOME res =>
				let
				  val disp = res + i - offset
				  (* Calculate relative to next instruction *)
				  val _ =
				    if disp > 127 orelse disp < ~128 then
				      Crash.impossible
				      ("Short branch of " ^
				       Int.toString disp ^ " out of range in " ^
				       I386_Assembly.print_mnemonic opc ^ " " ^
				       MirTypes.print_tag tag ^
				       " in block with tag " ^
				       MirTypes.print_tag block_tag ^
				       ", disp = " ^
				       Int.toString disp ^
				       " res = " ^
				       Int.toString res ^
				       " i = " ^
				       Int.toString i ^
				       " offset " ^
				       Int.toString offset)
				    else
				      ()
				in
				  (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8 disp]),
				   comment)
				end
			    | NONE =>
				Crash.impossible("Assoc do_opcode:" ^
						 I386_Assembly.print_mnemonic opc)
			in
			  do_opcodes(rest, opcode :: done)
			end
		      | ((opcode as
			  I386_Assembly.OPCODE(opc as I386_Assembly.call,
					       [I386_Assembly.rel32 i]),
			  SOME tag, comment), offset) =>
			let
			  val opcode =
			    case lookup_env tag of
			      SOME res =>
				let
				  val disp = res + i - offset
				(* Calculate relative to next instruction *)
				in
				  (I386_Assembly.OPCODE(opc, [I386_Assembly.rel32 disp]),
				   comment)
				end
			    | NONE =>
				Crash.impossible("Assoc do_opcode:" ^
						 I386_Assembly.print_mnemonic opc)
			in
			  do_opcodes(rest, opcode :: done)
			end
		      | ((opcode as
			  I386_Assembly.OPCODE(opc as I386_Assembly.mov,
					       [rd, I386_Assembly.imm32(i, j)]),
			  SOME tag, comment), offset) =>
			let
			  val opcode =
			    case lookup_env tag of
			      SOME res =>
				let
				  val disp = (res + 4*i + j) - proc_offset
				(* Must work relative to start of current proc in set *)
				in
				  (I386_Assembly.OPCODE
				   (opc, [rd, I386_Assembly.imm32(disp div 4, disp mod 4)]),
				   comment)
				end
			    | NONE => Crash.impossible "Assoc do_opcode: LEO"
			in
			  do_opcodes(rest, opcode :: done)
			end
		      | ((opcode, NONE, comment), offset) =>
			do_opcodes(rest, (opcode, comment) :: done)
		      |  _ => Crash.impossible"Bad tagged instruction"

		    val (opcodes_and_offsets, next) =
		      do_offsets(block_start, [], opcode_list)
		  in
		    (do_opcodes (opcodes_and_offsets, done), next)
		  end
		val (so_far, next) = do_block(start, block, done)
	      in
		linearise_proc(proc_offset, next, block_list, so_far)
	      end

	  fun do_linearise_sub(_, []) = []
	    | do_linearise_sub(offset, (tag, proc) :: rest) =
	      let
		val (offset', done') =
		  linearise_proc(offset, offset, proc, [])
		val offset'' =
		  double_align offset' +
		  4 (* Back-pointer *) +
		  4 (* Procedure number within set *)
	      in
		(tag, done') :: do_linearise_sub(offset'', rest)
	      end

	in
	  do_linearise_sub(0, proc_list)
	end
    in
      do_linearise new_proc_list
    end

  fun is_reg(MirTypes.GP_GC_REG reg) = true
    | is_reg(MirTypes.GP_NON_GC_REG reg) = true
    | is_reg _ = false

  fun move_reg(rd, rs, comment) =
    (I386_Assembly.OPCODE
     (I386_Assembly.mov,
      [I386_Assembly.r32 rd,
       I386_Assembly.r_m32(I386_Assembly.INL rs)]), absent, comment)

  fun move_reg_zx(rd, rs, comment) =
    (I386_Assembly.OPCODE
     (I386_Assembly.movzx,
      [I386_Assembly.r32 rd,
       I386_Assembly.r_m8(I386_Assembly.INL rs)]), absent, comment)

  fun move_imm(rd, imm, comment) =
    (I386_Assembly.OPCODE
     (I386_Assembly.mov,
      [I386_Assembly.r32 rd,
       I386_Assembly.imm32(imm div 4, imm mod 4)]), absent, comment)

  fun gp_from_reg(MirTypes.GC_REG reg) = MirTypes.GP_GC_REG reg
    | gp_from_reg(MirTypes.NON_GC_REG reg) = MirTypes.GP_NON_GC_REG reg

  datatype proc_stack =
    PROC_STACK of
    {non_gc_spill_size     : int, (* In words *)
     fp_spill_size         : int, (* In singles, doubles or extendeds as appropriate *)
     fp_save_size          : int, (* As for non_fp_spill_size *)
     gc_spill_size         : int, (* In words *)
     gc_stack_alloc_size   : int, (* In words *)
     register_save_size    : int, (* In bytes *)
     non_gc_spill_offset   : int, (* In bytes *)
     fp_spill_offset       : int, (* In bytes *)
     fp_save_offset        : int, (* In bytes*)
     gc_spill_offset       : int, (* In bytes *)
     gc_stack_alloc_offset : int, (* In bytes *)
     register_save_offset  : int, (* In bytes *)
     allow_fp_spare_slot   : bool, (* Do we need a slot for float to int conversion? *)
     float_value_size      : int,  (* Number of bytes per float value *)
     old_spill_sizes	   : {gc : int, non_gc : int, fp : int}
     }

  fun mach_cg
    error_info
    (Options.OPTIONS {compiler_options =
                      Options.COMPILEROPTIONS
		      {generate_debug_info, debug_variables, generate_moduler, opt_leaf_fns, intercept, ...},
                      ...},
     MirTypes.CODE(MirTypes.REFS(loc_refs,
                                 {requires = ext_refs,
                                  vars = vars,
                                  exns = exns,
                                  strs = strs,
                                  funs = funs}),
                    value_list,
                    proc_list_list),
    (gc_map,
     non_gc_map,
     fp_map),
    debugging_map) =
    let
      val save_arg_for_debugging = generate_debug_info orelse debug_variables orelse intercept
      val {gc, non_gc, fp} = MirRegisters.pack_next
      val gc_array = MLWorks.Internal.Array.array(gc, MachSpec.global)
      val _ =
	MirTypes.GC.Map.iterate
	(fn (mir_reg, reg) =>
	 MLWorks.Internal.Array.update(gc_array, MirTypes.GC.unpack mir_reg, reg))
	gc_map
      val non_gc_array = MLWorks.Internal.Array.array(non_gc, MachSpec.global)
      val _ =
	MirTypes.NonGC.Map.iterate
	(fn (mir_reg, reg) =>
	 MLWorks.Internal.Array.update(non_gc_array, MirTypes.NonGC.unpack mir_reg, reg))
	non_gc_map
      val fp_array = MLWorks.Internal.Array.array(fp, MachSpec.global)
      val _ =
	MirTypes.FP.Map.iterate
	(fn (mir_reg, reg) =>
	 MLWorks.Internal.Array.update(fp_array, MirTypes.FP.unpack mir_reg, reg))
	fp_map

      val debug_map = ref debugging_map

      val value_elements =
	(map
	(fn(MirTypes.VALUE(tag, x)) =>
	 value_cg(Lists.assoc(tag, loc_refs), x,error_info))
	value_list) handle Lists.Assoc => Crash.impossible"Assoc value_elements"

      exception bad_spill of string

      fun get_frame_size(register_save_offset, register_save_size, needs_preserve) =
	if needs_preserve then
	  register_save_offset - frame_offset + register_save_size
	else
	  frame_offset

      fun symb_value(PROC_STACK
		     {non_gc_spill_size,
		      fp_spill_size,
		      fp_save_size,
		      gc_spill_size,
		      gc_stack_alloc_size,
		      register_save_size,
		      non_gc_spill_offset,
		      fp_spill_offset,
		      fp_save_offset,
		      gc_spill_offset,
		      gc_stack_alloc_offset,
		      register_save_offset,
		      allow_fp_spare_slot,
		      float_value_size,
		      old_spill_sizes
		      },
		     frame_size) =
	let
	  fun symbolic_value MirTypes.GC_SPILL_SIZE = gc_spill_size * 4
	    | symbolic_value MirTypes.NON_GC_SPILL_SIZE = non_gc_spill_size * 4
	    | symbolic_value(MirTypes.GC_SPILL_SLOT i) =
	      let
		fun symbolic_value i =
		  (if i >= gc_spill_size then
		     raise bad_spill
		     ("Spill slot " ^ Int.toString i ^
		      " requested, but only " ^ Int.toString gc_spill_size ^
		      " allocated\n")
		   else
		     ();
		   frame_size - (gc_spill_offset + 4 * (1 + i))
                   )
	      in
		case i of
		  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1(i)),name) =>
		    let
		      val value = symbolic_value i
		    in
		      spill := RuntimeEnv.OFFSET2(RuntimeEnv.GC, value);
		      value
		    end
		  | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(_, i)),name) => i
		  | MirTypes.SIMPLE(i) => symbolic_value i
	      end
	    | symbolic_value(MirTypes.NON_GC_SPILL_SLOT i) =
	      let
		fun symbolic_value i =
                  (if i >= non_gc_spill_size then
		     raise bad_spill ("non gc spill slot " ^ Int.toString i ^
				      " requested, but only " ^
				      Int.toString non_gc_spill_size ^
				      " allocated\n")
                   else ();
                   frame_size - (non_gc_spill_offset + 4 * (1 + i))
                   )
	      in
		case i of
		  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1(i)),name) =>
		    let
		      val value = symbolic_value i
		    in
		      spill := RuntimeEnv.OFFSET2(RuntimeEnv.NONGC, value);
		      value
		     end
		  | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(_, i)),name) => i
		  | MirTypes.SIMPLE(i) => symbolic_value i
	      end
	    | symbolic_value(MirTypes.FP_SPILL_SLOT i) =
	      let
		fun symbolic_value i =
                  (if i >= fp_spill_size then
                     raise bad_spill ("fp spill slot " ^ Int.toString i ^
                                      " requested, but only " ^
                                      Int.toString fp_spill_size ^
                                      " allocated\n")
                   else ();
                   frame_size - (fp_spill_offset + float_value_size * (1 + i)))
	      in
		case i of
		  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1(i)),name) =>
		    let
		      val value = symbolic_value i
		    in
		      spill := RuntimeEnv.OFFSET2(RuntimeEnv.FP, value);
		      value
		    end
		  | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(_, i)),name) => i
		  | MirTypes.SIMPLE(i) => symbolic_value i
	      end
	in
	  symbolic_value
	end

      (* utility functions for enter *)
      local
	fun store_seq'(size, so_far) =
	  if size < 0 then
	    so_far
	  else
	    if size = 0 then
	      (I386_Assembly.OPCODE
	       (I386_Assembly.xor,
		[I386_Assembly.r32 I386Types.global,
		 I386_Assembly.r_m32(I386_Assembly.INL I386Types.global)]),
	       absent, "clear global prior to storing") ::
	      (I386_Assembly.OPCODE
	       (I386_Assembly.push,
		[I386_Assembly.r32 I386Types.global]),
	       absent, "initialise one stack slot") :: so_far
	    else
	      store_seq'(size-1,
			(I386_Assembly.OPCODE
			 (I386_Assembly.push,
			  [I386_Assembly.r32 I386Types.global]),
			 absent, "initialise one stack slot") :: so_far)
      in
	(* Initialise those parts of the stack that will be scanned by the gc *)
	(* The parameters are the number of slots to initialise -1 *)
        (* and the continuation jmp *)
	(* Initialising 1 or 2 slots is done by push immediate *)
	(* Initialising between 3 and 9 slots is done by clearing ecx and pushing it *)
	(* Initialising more than 9 slots is done by another piece of code entirely *)
	(* The driving force behind this is code size *)
	(* In the cases where this fails to determine which sequence *)
	(* we should use, speed of operation is used *)
	fun store_seq(0, so_far) =
	  (I386_Assembly.OPCODE
	   (I386_Assembly.push,
	    [I386_Assembly.imm8 0]),
	   absent, "initialise one stack slot") :: so_far
	  | store_seq(1, so_far) =
	  store_seq(0,
		    (I386_Assembly.OPCODE
		     (I386_Assembly.push,
		      [I386_Assembly.imm8 0]),
		     absent, "initialise one stack slot") :: so_far)
	  | store_seq x = store_seq' x
      end
      fun store_loop(loop_tag, size) =
	((I386_Assembly.OPCODE
	  (I386_Assembly.xor,
	   [I386_Assembly.r32 I386Types.global,
	    I386_Assembly.r_m32(I386_Assembly.INL I386Types.global)]),
	  absent, "clear ecx, set zero flag") ::
	 (I386_Assembly.OPCODE
	  (I386_Assembly.add,
	   [I386_Assembly.r_m32(I386_Assembly.INL I386Types.global),
	    if size <= 127 then
	      I386_Assembly.imm8 size
	    else
	      I386_Assembly.imm32(size div 4, size mod 4)]),
	  absent, "initialise counter, zero false") ::
	 (I386_Assembly.OPCODE
	  (I386_Assembly.jmp, [I386_Assembly.rel8 0]),
	  SOME loop_tag, "enter at head of initialisation loop") :: [],
	 (I386_Assembly.OPCODE
	  (I386_Assembly.push, [I386_Assembly.imm8 0]),
	  absent, "clear one stack slot") ::
	 (I386_Assembly.OPCODE
	  (I386_Assembly.loop, [I386_Assembly.rel8 0]),
	  SOME loop_tag, "loop if not finished") :: []
	 )

      fun get_binary_op MirTypes.ADDU = (I386_Assembly.add, false)
	| get_binary_op MirTypes.SUBU = (I386_Assembly.sub, false)
	| get_binary_op MirTypes.MULU = Crash.unimplemented"MirTypes.MULU"
	| get_binary_op MirTypes.MUL32U = Crash.unimplemented"MirTypes.MUL32U"
	| get_binary_op MirTypes.AND = (I386_Assembly.and_op, false)
	| get_binary_op MirTypes.OR = (I386_Assembly.or, false)
	| get_binary_op MirTypes.EOR = (I386_Assembly.xor, false)
	| get_binary_op MirTypes.LSR = (I386_Assembly.shr, true)
	| get_binary_op MirTypes.ASL = (I386_Assembly.sal, true)
	| get_binary_op MirTypes.ASR = (I386_Assembly.sar, true)

      fun do_blocks(_, [], _, _, _, _, _) = []
      | do_blocks(needs_preserve, MirTypes.BLOCK(tag,opcodes) :: rest,
		  stack_layout as PROC_STACK
		  {non_gc_spill_size,
		   fp_spill_size,
		   fp_save_size,
		   gc_spill_size,
		   gc_stack_alloc_size,
		   register_save_size,
		   non_gc_spill_offset,
		   fp_spill_offset,
		   fp_save_offset,
		   gc_spill_offset,
		   gc_stack_alloc_offset,
		   register_save_offset,
		   allow_fp_spare_slot,
		   float_value_size,
		   old_spill_sizes =
		   {gc=gc_spill_start_offset,
		    non_gc=non_gc_spill_start_offset,
		    fp=fp_spill_start_offset}
		   },
		  fps_to_preserve,
		  gcs_to_preserve,
		  (stack_parms, (* Number of parameters on the stack when called *)
		   max_tail_size, (* The maximum number of tail parameters from this fn *)
		   max_args), (* The maximum space required *)
		  procedure_name
		  ) =
	let
	  val parm_space_above_ret = max_args * 4
	  val frame_size = get_frame_size(register_save_size, register_save_offset, needs_preserve)

          (* Save fp registers -- we don't have any of these just yet *)
	  fun do_save_fp_instrs(_, []) = []
	    | do_save_fp_instrs(offset, fp :: rest) =
	      Crash.impossible"do_save_fp_instrs"

	  fun do_restore_fp_instrs(_, []) = []
	    | do_restore_fp_instrs(offset, fp :: rest) =
	      Crash.impossible"do_restore_fp_instrs"

	  fun do_save_gcs([], done) = done
	    | do_save_gcs(gc :: rest, done) =
	      do_save_gcs(rest, (I386_Assembly.OPCODE
				 (I386_Assembly.push, [I386_Assembly.r32 gc]),
				 NONE,
				 "save gcs") :: done)

	  fun do_restore_gcs([], done) = rev done
	    | do_restore_gcs(gc :: rest, done) =
	      do_restore_gcs
	      (rest, (I386_Assembly.OPCODE
		      (I386_Assembly.pop, [I386_Assembly.r32 gc]), NONE,
		      "restore gcs") :: done)

	  fun do_restore_gcs_from_offset([], offset, done) = done
	    | do_restore_gcs_from_offset(gc :: rest, offset, done) =
	      do_restore_gcs_from_offset
	      (rest, offset+4,
	       (I386_Assembly.OPCODE
		(I386_Assembly.mov,
		 [I386_Assembly.r32 gc,
		  I386_Assembly.r_m32
		  (I386_Assembly.INR
		   (I386_Assembly.MEM
		    {base=SOME I386Types.sp,
		     index=absent,
		     offset=SOME(I386_Assembly.SMALL offset)}))]), NONE,
		"restore gcs") :: done)

          (* Save the callee saves and the argument if we are debugging *)

	  val do_save_gcs = fn x =>
            let
              val regs = do_save_gcs (x,[])
            in
              if save_arg_for_debugging then
                (I386_Assembly.OPCODE
                 (I386_Assembly.push, [I386_Assembly.r32 I386Types.caller_arg]),
                 NONE,
                 "save arg for debugging") :: regs
              else regs
            end

          (* The number of bytes to pop above the callee save registers *)
          (* If we have saved the arg, have an extra 4 bytes in frame *)
          val frame_left = frame_size - register_save_size +
            (if save_arg_for_debugging then 4 else 0)

	  val do_restore_gcs = fn x => do_restore_gcs(x, [])

	  val fp_save_start = gc_spill_offset
	  val save_fps = do_save_fp_instrs(~fp_save_start, fps_to_preserve)

	  val restore_fps = do_restore_fp_instrs(~fp_save_start, fps_to_preserve)

	  val save_gcs = do_save_gcs gcs_to_preserve

	  val restore_gcs = do_restore_gcs gcs_to_preserve
	
	  fun is_comment(MirTypes.COMMENT _) = true
	    | is_comment _ = false

	  fun is_load MirTypes.LD = (true)
	    | is_load MirTypes.ST = false
	    | is_load MirTypes.LDB = true
	    | is_load MirTypes.STB = false
	    | is_load MirTypes.LDREF = true
	    | is_load MirTypes.STREF = false

	  fun lookup_reg(reg, table) =
	    let
	      val mach_reg = MLWorks.Internal.Array.sub(table, reg)
	    in
	      if needs_preserve orelse
		reg <> MirTypes.GC.unpack MirRegisters.callee_closure then
		mach_reg
	      else
		I386Types.caller_closure
	    end

	  fun reg_from_gp(MirTypes.GP_GC_REG reg) = reg
	    | reg_from_gp _ = Crash.impossible"reg_from_gp: not reg"

	  fun lookup_reg_operand(MirTypes.GC_REG reg) =
	    lookup_reg(MirTypes.GC.unpack reg, gc_array)
	    | lookup_reg_operand(MirTypes.NON_GC_REG reg) =
	      lookup_reg(MirTypes.NonGC.unpack reg, non_gc_array)

	  fun lookup_gp_operand(MirTypes.GP_GC_REG reg) =
	    lookup_reg(MirTypes.GC.unpack reg, gc_array)
	    | lookup_gp_operand(MirTypes.GP_NON_GC_REG reg) =
	      lookup_reg(MirTypes.NonGC.unpack reg, non_gc_array)
	    | lookup_gp_operand _ =
	      Crash.impossible"lookup_gp_operand(constant)"

	  fun looked_up_gc_reg_is_arg I386Types.i_arg1 = true
	    | looked_up_gc_reg_is_arg I386Types.i_arg2 = true
	    | looked_up_gc_reg_is_arg I386Types.i_arg3 = true
	    | looked_up_gc_reg_is_arg I386Types.i_arg4 = true
	    | looked_up_gc_reg_is_arg I386Types.i_arg5 = true
	    | looked_up_gc_reg_is_arg I386Types.i_arg6 = true
	    | looked_up_gc_reg_is_arg I386Types.i_arg7 = true
	    | looked_up_gc_reg_is_arg I386Types.o_arg1 = true
	    | looked_up_gc_reg_is_arg I386Types.o_arg2 = true
	    | looked_up_gc_reg_is_arg I386Types.o_arg3 = true
	    | looked_up_gc_reg_is_arg I386Types.o_arg4 = true
	    | looked_up_gc_reg_is_arg I386Types.o_arg5 = true
	    | looked_up_gc_reg_is_arg I386Types.o_arg6 = true
	    | looked_up_gc_reg_is_arg I386Types.o_arg7 = true
	    | looked_up_gc_reg_is_arg _ = false

	  fun looked_up_gc_reg_input_value I386Types.i_arg1 = ~1
	    | looked_up_gc_reg_input_value I386Types.i_arg2 = ~2
	    | looked_up_gc_reg_input_value I386Types.i_arg3 = ~3
	    | looked_up_gc_reg_input_value I386Types.i_arg4 = ~4
	    | looked_up_gc_reg_input_value I386Types.i_arg5 = ~5
	    | looked_up_gc_reg_input_value I386Types.i_arg6 = ~6
	    | looked_up_gc_reg_input_value I386Types.i_arg7 = ~7
	    | looked_up_gc_reg_input_value _ =
	    Crash.impossible"looked_up_gc_reg_input_value:not i_arg"

	  fun looked_up_gc_reg_output_value I386Types.o_arg1 = ~1
	    | looked_up_gc_reg_output_value I386Types.o_arg2 = ~2
	    | looked_up_gc_reg_output_value I386Types.o_arg3 = ~3
	    | looked_up_gc_reg_output_value I386Types.o_arg4 = ~4
	    | looked_up_gc_reg_output_value I386Types.o_arg5 = ~5
	    | looked_up_gc_reg_output_value I386Types.o_arg6 = ~6
	    | looked_up_gc_reg_output_value I386Types.o_arg7 = ~7
	    | looked_up_gc_reg_output_value _ =
	    Crash.impossible"looked_up_gc_reg_output_value:not i_arg"

	  fun non_spill_gc_reg_is_arg reg =
	    looked_up_gc_reg_is_arg(lookup_reg(reg, gc_array))

	  fun gc_reg_is_arg' reg = non_spill_gc_reg_is_arg reg

	  fun gc_reg_is_arg reg =
	    reg < #gc(MirRegisters.pack_next) andalso
	    gc_reg_is_arg' reg

	  fun gc_reg_is_spill reg =
	    let
	      val reg = MirTypes.GC.unpack reg
	    in
	      reg >= #gc(MirRegisters.pack_next) orelse
	      gc_reg_is_arg' reg
	    end

	  fun reg_operand_is_spill(MirTypes.GC_REG reg) =
	    gc_reg_is_spill reg
	    | reg_operand_is_spill _ = false

	  fun gp_operand_is_spill(MirTypes.GP_GC_REG reg) =
	    gc_reg_is_spill reg
	    | gp_operand_is_spill _ = false

	  fun lookup_fp_operand(MirTypes.FP_REG reg) =
	    MLWorks.Internal.Array.sub(fp_array, MirTypes.FP.unpack reg)

	  fun fp_operand_is_spill(MirTypes.FP_REG reg) =
	    MirTypes.FP.unpack reg >= #fp(MirRegisters.pack_next)

	  val symbolic_value = symb_value(stack_layout, frame_size)

	  val doing_move = ref false

	  fun do_everything
	    (_, tag, [], stack_drop, param_slots, done, [], final_result, _) =
	    let
	      val _ =
		if stack_drop = 0 andalso param_slots = 0 then
		  ()
		else
		  Crash.impossible("stack_drop or param_slots not zero at block end in " ^ procedure_name)
	    in
	      (tag, contract_sexpr done) :: final_result
	    end
	  | do_everything
	    (needs_preserve, tag, [], stack_drop, param_slots, done,
	     MirTypes.BLOCK(tag',opcodes) :: blocks,
	     final_result, stack_drop_ok) =
	    let
	      val _ =
		if stack_drop_ok orelse
		  (stack_drop = 0 andalso param_slots = 0) then
		  ()
		else
		  Crash.impossible("stack_drop or param_slots not zero at block end" ^ procedure_name)
	    in
	      do_everything
	      (needs_preserve, tag', Lists.filter_outp is_comment opcodes, stack_drop, param_slots, Sexpr.NIL,
	       blocks, (tag, contract_sexpr done) :: final_result, stack_drop_ok)
	    end

	  | do_everything
	    (needs_preserve, tag, opcode :: opcode_list, stack_drop, param_slots, done,
	     block_list, final_result, _) =
	    let
(*
	      val _ = print(MirPrint.opcode opcode ^ "\n")
*)
	      val symbolic_value =
		fn x => stack_drop + param_slots + symbolic_value x

	      fun assemble_imm32(MirTypes.GP_IMM_INT i) = (i, 0)
		| assemble_imm32(MirTypes.GP_IMM_ANY i) = (i div 4, i mod 4)
		| assemble_imm32(MirTypes.GP_IMM_SYMB symb) =
		  let
		    val i = symbolic_value symb
		  in
		    (i div 4, i mod 4)
		  end
		| assemble_imm32 _ =
		  Crash.impossible"assemble_imm32:non-immediate"

	      fun assemble_sized_gp_imm gp_imm =
		let
		  val (i, j) = assemble_imm32 gp_imm
		in
		  if i <= 31 andalso i >= ~32 then
		    I386_Assembly.imm8(4*i+j)
		  else
		    I386_Assembly.imm32(i, j)
		end

	      fun assemble_large_offset gp_operand =
		let
		  val (i, j) = assemble_imm32 gp_operand
		in
		  if i <= 134217727 andalso i >= ~134217728 then
		    I386_Assembly.SMALL(4*i+j)
		  else
		    I386_Assembly.LARGE(i, j)
		end

	      fun gc_spill_value reg =
		let
		  val reg' = MirTypes.GC.unpack reg
		in
		  if gc_reg_is_arg reg' then
		    if Lists.member(reg, MirRegisters.callee_arg_regs) then
		      (* Lives above the return address *)
		      (frame_size + stack_drop + param_slots +
		       4*(max_args + looked_up_gc_reg_input_value
			  (lookup_reg(reg', gc_array))))
		    else
		      let
			val neg_param_slots = ~param_slots
			val offset =
			  if
			    Lists.member(reg, MirRegisters.caller_arg_regs) then
			    (looked_up_gc_reg_output_value
			     (lookup_reg(reg', gc_array)) * 4)
			  else
			    Crash.unimplemented("i386_cg:stack parameter unknown in " ^ procedure_name)
		      in
			if offset < neg_param_slots andalso
			  stack_drop <> 0 then
			  Crash.impossible"i386_cg:stack parameter generated when stack already dropped"
			else
			  if !doing_move orelse offset >= neg_param_slots then
			    (* Ok if we've already generated this parameter *)
			    offset
			  else
			    Crash.impossible("i386_cg:gc_spill_value: parameter reg found in non-move context in " ^ procedure_name)
		      end
		  else
		    symbolic_value
		    (MirTypes.GC_SPILL_SLOT
		     (MirTypes.SIMPLE(gc_spill_start_offset + reg' - #gc(MirRegisters.pack_next))))
		end

	      fun reg_spill_value(MirTypes.GC_REG reg) = gc_spill_value reg
		| reg_spill_value _ =
		Crash.impossible"reg_spill_value:bad argument"

	      fun gp_spill_value(MirTypes.GP_GC_REG reg) = gc_spill_value reg
		| gp_spill_value _ =
		Crash.impossible"gp_spill_value:bad argument"

	      fun fp_spill_value(MirTypes.FP_REG reg) =
		symbolic_value
		(MirTypes.FP_SPILL_SLOT
		 (MirTypes.SIMPLE(fp_spill_start_offset + MirTypes.FP.unpack reg - #fp(MirRegisters.pack_next))))

              (* Make a memory operand for a fp "register" *)

              fun convert_fp_operand operand =
                if fp_operand_is_spill operand
                  then
                    I386_Assembly.fp_mem
                    (I386_Assembly.MEM
                     {base=SOME I386Types.sp,
                      index=absent,
                      offset=SOME(I386_Assembly.SMALL(fp_spill_value operand))})
                else Crash.impossible "Can't do non-spill fp's yet"

	      fun reg_equals_gp(r as MirTypes.GC_REG r', s as MirTypes.GP_GC_REG s') =
(* This bit believed to be irrelevant.
		(reg_operand_is_spill r andalso gp_operand_is_spill s andalso
		 reg_spill_value r = gp_spill_value s) orelse
*)
		r' = s'
		| reg_equals_gp(MirTypes.NON_GC_REG r, MirTypes.GP_NON_GC_REG s) =
		  r = s
		| reg_equals_gp _ = false

	      fun move_gp_to_reg(rd, gp_operand, other_code) =
		let
		  val opcode = I386_Assembly.mov
		  val code_list =
		    if is_reg gp_operand then
		      (* May be spill here *)
		      if gp_operand_is_spill gp_operand then
			let
			  val spill = gp_spill_value gp_operand
			  val spill =
			    if spill < 0 then
			      if ~spill <= param_slots then
				param_slots+stack_drop+spill
			      else
				Crash.impossible"i386_cg:move_gp_to_reg: spill (parameter) out of range"
			    else
			      spill
			  val offset =
			    if spill = 0 then
			      absent
			    else
			      SOME (I386_Assembly.SMALL spill)
			in
			  (I386_Assembly.OPCODE
			   (opcode,
			    [I386_Assembly.r32 rd,
			     I386_Assembly.r_m32
			     (I386_Assembly.INR
			      (I386_Assembly.MEM
			       {base=SOME I386Types.sp,
				index=absent,
				offset=offset}))]),
			   absent, "") :: other_code
			end
		      else
			let
			  val rs1 = lookup_gp_operand gp_operand
			in
			  if rd = rs1 then
			    [] (* Null move rn -> rn *)
			  else
			    (I386_Assembly.OPCODE
			     (opcode,
			      [I386_Assembly.r32 rd,
			       I386_Assembly.r_m32
			       (I386_Assembly.INL rs1)]),
			     absent, "") :: other_code
			end
		    else
		      case assemble_imm32 gp_operand of
			(0, 0) =>
			  (I386_Assembly.OPCODE
			   (I386_Assembly.xor,
			    [I386_Assembly.r32 rd,
			     I386_Assembly.r_m32
			     (I386_Assembly.INL rd)]),
			   absent, "") :: other_code
		      | x =>
			  (I386_Assembly.OPCODE
			   (opcode,
			    [I386_Assembly.r32 rd,
			     I386_Assembly.imm32 x]),
			   absent, "") :: other_code
		in
		  code_list
		end

	      val (result_list, opcode_list, new_blocks, new_final_result,
		   new_stack_drop, new_param_slots, stack_drop_ok) =
		(case opcode of
		  MirTypes.TBINARY(tagged_binary_op, taglist, reg_operand,
				   gp_operand, gp_operand') =>
                 let
                   val tag = case taglist of [] => NONE | a::_ => SOME a
                 in
                   if reg_equals_gp(reg_operand, gp_operand) then
		    let
		      val (opcode, cleaing_operation) = case tagged_binary_op of
			MirTypes.ADDS => (I386_Assembly.add, false)
		      | MirTypes.SUBS => (I386_Assembly.sub, false)
		      | MirTypes.MULS => (I386_Assembly.imul, false)
		      | MirTypes.DIVS => Crash.impossible"do_opcodes(TBINARY(DIVS))"
		      | MirTypes.MODS => Crash.impossible"do_opcodes(TBINARY(MODS))"
		      | MirTypes.ADD32S => (I386_Assembly.add, true)
		      | MirTypes.SUB32S => (I386_Assembly.sub, true)
		      | MirTypes.MUL32S => (*I386_Assembly.imul*)Crash.impossible"do_opcodes(TBINARY(MUL32S))"
		      | MirTypes.DIV32S => Crash.impossible"do_opcodes(TBINARY(DIV32S))"
		      | MirTypes.MOD32S => Crash.impossible"do_opcodes(TBINARY(MOD32S))"
		      | MirTypes.DIVU => Crash.impossible"do_opcodes(TBINARY(DIVU))"
		      | MirTypes.MODU => Crash.impossible"do_opcodes(TBINARY(MODU))"
		      | MirTypes.DIV32U => Crash.impossible"do_opcodes(TBINARY(DIV32U))"
		      | MirTypes.MOD32U => Crash.impossible"do_opcodes(TBINARY(MOD32U))"
		    in
		      if cleaing_operation then
			(* Just recycle the operation with the exception *)
			(* tag intercepted to do the cleaing first *)
			let
			  val clean_tag = MirTypes.new_tag()
			  val regs_to_clean = case reg_operand of
			    MirTypes.GC_REG reg => [reg]
			  | _ => []
			  val regs_to_clean = case gp_operand of
			    MirTypes.GP_GC_REG reg => reg :: regs_to_clean
			  | _ => regs_to_clean
			  val regs_to_clean = case gp_operand' of
			    MirTypes.GP_GC_REG reg => reg :: regs_to_clean
			  | _ => regs_to_clean
			  val regs_to_clean = Lists.rev_remove_dups regs_to_clean
			  val regs_to_clean =
			    Lists.filterp
			    (fn reg => reg <> MirRegisters.global)
			    regs_to_clean
			  val clean_instrs =
			    map
			    (fn reg => MirTypes.NULLARY(MirTypes.CLEAN, MirTypes.GC_REG reg))
			    regs_to_clean
			  val exn_tag = case taglist of
                            [tag] => tag
			  | _ => Crash.impossible"TBINARY: missing tag"
			  val new_op = case tagged_binary_op of
			    MirTypes.ADD32S => MirTypes.ADDS
			  | MirTypes.SUB32S => MirTypes.SUBS
			  | MirTypes.MUL32S => MirTypes.MUL32S
			  | MirTypes.DIV32S => MirTypes.DIV32S
			  | MirTypes.MOD32S => MirTypes.MOD32S
			  | _ => Crash.impossible"Converting TBINARY V type"
			in
			  ([],
			   MirTypes.TBINARY
			   (new_op, [clean_tag], reg_operand,
			    gp_operand, gp_operand') :: opcode_list,
			   MirTypes.BLOCK(clean_tag, clean_instrs @@ [MirTypes.BRANCH(MirTypes.BRA, MirTypes.TAG exn_tag)]) :: block_list,
			   final_result, stack_drop, param_slots, true)
			end
		      else
		      if reg_operand_is_spill reg_operand andalso
			gp_operand_is_spill gp_operand' then
			if tagged_binary_op = MirTypes.MULS then
			  (* Restricted to result in a register for imul *)
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  MirTypes.GC_REG MirRegisters.global,
					  gp_operand) ::
			   MirTypes.TBINARY(tagged_binary_op, taglist,
					    MirTypes.GC_REG MirRegisters.global,
					    MirTypes.GP_GC_REG MirRegisters.global,
					    gp_operand') ::
			   MirTypes.UNARY(MirTypes.MOVE,
					  reg_operand,
					  MirTypes.GP_GC_REG MirRegisters.global) ::
			   opcode_list, block_list, final_result, stack_drop, param_slots, false)
			else
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  MirTypes.GC_REG MirRegisters.global,
					  gp_operand') ::
			   MirTypes.TBINARY(tagged_binary_op, taglist, reg_operand,
					    gp_operand,
					    MirTypes.GP_GC_REG MirRegisters.global) ::
			   opcode_list, block_list, final_result, stack_drop, param_slots, false)
		      else
			if tagged_binary_op = MirTypes.MULS andalso
			  reg_operand_is_spill reg_operand then
			  (* Still need to deal with case of imul here *)
			  (* gp_operand = reg_operand *)
			  (* and gp_operand' is not a spill *)
			  (* Deal with this as for gp_operand <> reg_operand *)
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  MirTypes.GC_REG MirRegisters.global,
					  gp_operand) ::
			   MirTypes.TBINARY(tagged_binary_op, taglist,
					    MirTypes.GC_REG MirRegisters.global,
					    MirTypes.GP_GC_REG MirRegisters.global,
					    gp_operand') ::
			   MirTypes.UNARY(MirTypes.MOVE,
					  reg_operand,
					  MirTypes.GP_GC_REG MirRegisters.global) ::
			   opcode_list, block_list, final_result, stack_drop, param_slots, false)
			else
			  let
			    val (operand1, operand2) =
			      if reg_operand_is_spill reg_operand then
				let
				  val spill = reg_spill_value reg_operand
				  val op2 =
				    if is_reg gp_operand' then
				      I386_Assembly.r32(lookup_gp_operand gp_operand')
				    else
				      assemble_sized_gp_imm gp_operand'
				in
				  (I386_Assembly.r_m32
				   (I386_Assembly.INR
				    (I386_Assembly.MEM
				     {base=SOME I386Types.sp,
				      index=absent,
				      offset=SOME(I386_Assembly.SMALL spill)})),
				   op2)
				end
			      else
				if gp_operand_is_spill gp_operand' then
				  let
				    val spill = gp_spill_value gp_operand'
				  in
				    (I386_Assembly.r32(lookup_reg_operand reg_operand),
				     I386_Assembly.r_m32
				     (I386_Assembly.INR
				      (I386_Assembly.MEM
				       {base=SOME I386Types.sp,
					index=absent,
					offset=SOME(I386_Assembly.SMALL spill)})))
				  end
				else
				  let
				    val op1 = lookup_reg_operand reg_operand
				  in
				    if is_reg gp_operand' then
				      (* In the case of two registers *)
				      (* Use the r32 on the first *)
				      (* This is for imul's benefit *)
				      (I386_Assembly.r32 op1,
				       I386_Assembly.r_m32
				       (I386_Assembly.INL
					(lookup_gp_operand gp_operand')))
				    else
				      (I386_Assembly.r_m32
				       (I386_Assembly.INL(lookup_reg_operand reg_operand)),
				       assemble_sized_gp_imm gp_operand')
				  end
			    val operands = [operand1, operand2]
			    val extra_instrs =
			      if tagged_binary_op = MirTypes.MULS then
				(* Need to shift one argument right two *)
				(* Unless both arguments are the same *)
				(* in which case we shift right one *)
				let
				  val (shift_size, comment) =
				    case operands of
				      [I386_Assembly.r32 r,
				       I386_Assembly.r_m32(I386_Assembly.INL r')] =>
				      if r = r' then (1, "one") else (2, "two")
				    | _ => (2, "two")
				in
				[(I386_Assembly.OPCODE
				  (I386_Assembly.sar,
				   [case operand1 of
				      I386_Assembly.r32 r =>
					I386_Assembly.r_m32(I386_Assembly.INL r)
				    | I386_Assembly.r_m32(I386_Assembly.INL r) =>
					operand1
				    | _ => Crash.impossible"imul bad dest",
					I386_Assembly.imm8 shift_size]), absent,
				  "shift source right" ^ comment ^" before multiply")]
				end
			      else
				[]
			  in
			    (extra_instrs @@
			     [(I386_Assembly.OPCODE(opcode, operands), absent, ""),
			      (I386_Assembly.OPCODE
			       (I386_Assembly.jcc(I386_Assembly.overflow),
				[I386_Assembly.rel8 0]),
			       tag, "branch on numeric overflow")],
			    opcode_list,
			    block_list,
			    final_result, stack_drop, param_slots, false)
			  end
		    end
		  else
		    if reg_equals_gp(reg_operand, gp_operand') then
		      let
			val can_reverse = case tagged_binary_op of
			  MirTypes.ADDS => true
			| MirTypes.SUBS => false
			| MirTypes.MULS => true
			| MirTypes.DIVS => Crash.impossible"do_opcodes(TBINARY(DIVS))"
			| MirTypes.MODS => Crash.impossible"do_opcodes(TBINARY(MODS))"
			| MirTypes.ADD32S => true
			| MirTypes.SUB32S => false
			| MirTypes.MUL32S => true
			| MirTypes.DIV32S => Crash.impossible"do_opcodes(TBINARY(DIV32S))"
			| MirTypes.MOD32S => Crash.impossible"do_opcodes(TBINARY(MOD32S))"
			| MirTypes.DIVU => Crash.impossible"do_opcodes(TBINARY(DIVU))"
			| MirTypes.MODU => Crash.impossible"do_opcodes(TBINARY(MODU))"
			| MirTypes.DIV32U => Crash.impossible"do_opcodes(TBINARY(DIV32IU))"
			| MirTypes.MOD32U => Crash.impossible"do_opcodes(TBINARY(MOD32U))"
		      in
			if can_reverse then
			  ([],
			   MirTypes.TBINARY(tagged_binary_op, taglist,
					    reg_operand, gp_operand', gp_operand) ::
			   opcode_list, block_list, final_result, stack_drop, param_slots, false)
			else
			  (* Subtract *)
			  if is_reg gp_operand then
			    (* Tricky case *)
			    ([],
			     MirTypes.UNARY(MirTypes.MOVE,
					    MirTypes.GC_REG MirRegisters.global,
					    gp_operand) ::
			     MirTypes.TBINARY(tagged_binary_op, taglist,
					      MirTypes.GC_REG MirRegisters.global,
					      MirTypes.GP_GC_REG MirRegisters.global,
					      gp_operand') ::
			     MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					    MirTypes.GP_GC_REG MirRegisters.global) ::
			     opcode_list, block_list, final_result, stack_drop, param_slots, false)
			  else
			    if assemble_imm32 gp_operand = (0, 0) then
			      ([(I386_Assembly.OPCODE
				 (I386_Assembly.neg,
				  [I386_Assembly.r_m32
				   (if reg_operand_is_spill reg_operand then
				      I386_Assembly.INR
				      (I386_Assembly.MEM
				       {base=SOME I386Types.sp,
					index=absent,
					offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))
					})
				    else
				      I386_Assembly.INL
				      (lookup_reg_operand reg_operand))
				      ]),
				 absent, "negate for simplicity"),
				(I386_Assembly.OPCODE
				 (I386_Assembly.jcc(I386_Assembly.overflow),
				  [I386_Assembly.rel8 0]),
				 tag, "branch on numeric overflow")],
			      opcode_list, block_list, final_result, stack_drop, param_slots, false)
			    else
			      ([],
			       MirTypes.UNARY(MirTypes.MOVE,
					      MirTypes.GC_REG MirRegisters.global,
					      gp_operand') ::
			       MirTypes.TBINARY(tagged_binary_op, taglist, reg_operand,
						gp_operand,
						MirTypes.GP_GC_REG MirRegisters.global) ::
			       opcode_list, block_list, final_result, stack_drop, param_slots, false)
		      end
		    else
		      (* No equality between result and either argument *)
		      (* But we can still do some multiplies *)
		      if tagged_binary_op = MirTypes.MULS andalso
			reg_operand_is_spill reg_operand then
			(* We need to deal better with a three spill multiply *)
			(* because of the restriction that the *)
			(* multiplicand/result must be a register *)
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					MirTypes.GC_REG MirRegisters.global,
					gp_operand) ::
			 MirTypes.TBINARY(tagged_binary_op, taglist,
					  MirTypes.GC_REG MirRegisters.global,
					  MirTypes.GP_GC_REG MirRegisters.global,
					  gp_operand') ::
			 MirTypes.UNARY(MirTypes.MOVE,
					reg_operand,
					MirTypes.GP_GC_REG MirRegisters.global) ::
			 opcode_list, block_list, final_result, stack_drop, param_slots, false)
		      else
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					reg_operand,
					gp_operand) ::
			 MirTypes.TBINARY(tagged_binary_op, taglist, reg_operand,
					  gp_from_reg reg_operand,
					  gp_operand') ::
			 opcode_list, block_list, final_result, stack_drop, param_slots, false)
                 end
	        | MirTypes.BINARY(binary_op, reg_operand, gp_operand,
				  gp_operand') =>
		  let
		    val (i_opcode, is_shift) = get_binary_op binary_op
		  in
		    if (is_reg gp_operand andalso
			not (gp_operand_is_spill gp_operand)) andalso
		      ((i_opcode = I386_Assembly.add andalso
			not (gp_operand_is_spill gp_operand')) orelse
		       (i_opcode = I386_Assembly.sub andalso
			not (is_reg gp_operand'))) then
		      (* Special nice cases where we can use lea *)
		      let
			val needs_move = reg_operand_is_spill reg_operand
			val dest =
			  if needs_move then
			    I386Types.global
			  else
			    lookup_reg_operand reg_operand
			val invert_gp' = i_opcode = I386_Assembly.sub
			val base = SOME (lookup_gp_operand gp_operand)
			val operand =
			  I386_Assembly.r_m32
			  (I386_Assembly.INR
			   (I386_Assembly.MEM
			    (if is_reg gp_operand' then
			       {base=base,
				index=SOME(lookup_gp_operand gp_operand', absent),
				offset=absent}
			     else
			       {base=base,
				index=absent,
				offset=
				SOME
				let
				  val offset = assemble_large_offset gp_operand'
				in
				  if invert_gp' then
				    case offset of
				      I386_Assembly.SMALL i => I386_Assembly.SMALL(~i)
				    | I386_Assembly.LARGE(i, j) =>
					I386_Assembly.LARGE
					(if j = 0 then
					   (~i, j)
					 else
					   (~i-1, 4-j))
				  else
				    offset
				end})))
		      in
			([(I386_Assembly.OPCODE
			   (I386_Assembly.lea,
			    [I386_Assembly.r32 dest, operand]),
			   absent, "implement add/sub with lea")],
			 if needs_move then
			   MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					  MirTypes.GP_GC_REG MirRegisters.global) ::
			   opcode_list
			 else
			   opcode_list, block_list, final_result, stack_drop, param_slots, false)
		      end
		    else
		      (* Normal stuff *)
		      if reg_equals_gp(reg_operand, gp_operand) then
			if is_shift then
			  if is_reg gp_operand' then
			    (* Nasty, all shifts controlled by CL, part of ECX *)
			    if gp_operand_is_spill gp_operand' then
			      ([],
			       (MirTypes.UNARY(MirTypes.MOVE,
					       MirTypes.GC_REG MirRegisters.global,
					       gp_operand')) ::
			       MirTypes.BINARY(binary_op, reg_operand, gp_operand,
					       MirTypes.GP_GC_REG MirRegisters.global) ::
			       opcode_list, block_list, final_result, stack_drop, param_slots, false)
			    else
			      (* Shift amount in a register *)
			      (* Must be moved to ECX *)
			      let
				val tag2 = MirTypes.new_tag()
				val tag3 = MirTypes.new_tag()
				val operand =
				  I386_Assembly.r_m32
				  (if reg_operand_is_spill reg_operand then
				     I386_Assembly.INR
				     (I386_Assembly.MEM
				      {base=SOME I386Types.sp,
				       index=absent,
				       offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
				   else
				     I386_Assembly.INL(lookup_reg_operand reg_operand))
				val continue =
				  [(I386_Assembly.OPCODE
				    (I386_Assembly.jmp,
				     [I386_Assembly.rel8 0]),
				    SOME tag3, "continue")]
				val out_of_range_shift =
				  case i_opcode of
				    I386_Assembly.shr =>
				      (if reg_operand_is_spill reg_operand then
					 (I386_Assembly.OPCODE
					  (I386_Assembly.mov,
					   [operand, I386_Assembly.imm32(0, 0)]),
					  absent, "clear to zero for out of range shift")
				       else
					 (I386_Assembly.OPCODE
					  (I386_Assembly.xor,
					   [I386_Assembly.r32(lookup_reg_operand reg_operand),
					    I386_Assembly.r_m32(I386_Assembly.INL(lookup_reg_operand reg_operand))]),
					  absent, "clear to zero for out of range shift")) ::
					 continue
				  | I386_Assembly.sal =>
				     (if reg_operand_is_spill reg_operand then
					(I386_Assembly.OPCODE
					 (I386_Assembly.mov,
					  [operand, I386_Assembly.imm32(0, 0)]),
					 absent, "clear to zero for out of range shift")
				      else
					(I386_Assembly.OPCODE
					 (I386_Assembly.xor,
					  [I386_Assembly.r32(lookup_reg_operand reg_operand),
					   I386_Assembly.r_m32(I386_Assembly.INL(lookup_reg_operand reg_operand))]),
					 absent, "clear to zero for out of range shift")) ::
					continue
				  | I386_Assembly.sar =>
				      (I386_Assembly.OPCODE
				       (i_opcode,
					[operand, I386_Assembly.imm8 31]),
				       absent, "shift by immediate value") ::
				      continue
				  | _ => Crash.impossible"mach_cg: non-shift in shift case"
				val block1 =
				  (I386_Assembly.OPCODE
				   (I386_Assembly.cmp,
				    [I386_Assembly.r_m32(I386_Assembly.INL I386Types.global),
				     I386_Assembly.imm8 31]),
				   absent, "test for shift by > 31 (unsigned)") ::
				  (I386_Assembly.OPCODE
				   (I386_Assembly.jcc(I386_Assembly.below_or_equal),
				    [I386_Assembly.rel8 0]),
				   SOME tag2, "branch if ok") ::
				  out_of_range_shift
				val block1 =
				  let
				    val reg = lookup_gp_operand gp_operand'
				  in
				    if reg = I386Types.global then
				      block1
				    else
				      (I386_Assembly.OPCODE
				       (I386_Assembly.mov,
					[I386_Assembly.r32 I386Types.global,
					 I386_Assembly.r_m32(I386_Assembly.INL reg)]),
				       absent, "put shift amount into ECX") ::
				      block1
				  end
				val block2 =
				  (I386_Assembly.OPCODE
				   (i_opcode,
				    [operand, I386_Assembly.r8 I386Types.CL]),
				   absent, "do the actual shift") :: continue
			      in
				(block1,
				 [],
				 MirTypes.BLOCK(tag3, opcode_list) :: block_list,
				 (tag2, block2) ::
				 final_result, stack_drop, param_slots, true)
			      end
			  else
			    let
			      val shift as (i, j) = assemble_imm32 gp_operand'
			      val shift =
				if i < 0 orelse i >= 8 then
				  32
				else
				  4*i+j
			      val operand =
				I386_Assembly.r_m32
				(if reg_operand_is_spill reg_operand then
				   I386_Assembly.INR
				   (I386_Assembly.MEM
				    {base=SOME I386Types.sp,
				     index=absent,
				     offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
				 else
				   I386_Assembly.INL(lookup_reg_operand reg_operand))
			    in
			      ((I386_Assembly.OPCODE
				(i_opcode,
				 [operand, I386_Assembly.imm8 shift]),
				absent, "shift by immediate value") :: [],
			       opcode_list, block_list, final_result, stack_drop, param_slots, false)
			    end
			else
			  if reg_operand_is_spill reg_operand andalso
			    gp_operand_is_spill gp_operand' then
			    ([],
			     MirTypes.UNARY(MirTypes.MOVE,
					    MirTypes.GC_REG MirRegisters.global,
					    gp_operand') ::
			     MirTypes.BINARY(binary_op, reg_operand,
					     gp_operand,
					     MirTypes.GP_GC_REG MirRegisters.global) ::
			     opcode_list, block_list, final_result, stack_drop, param_slots, false)
			  else
			    (* Not a shift, and not both spills *)
			    let
			      val operands =
				if reg_operand_is_spill reg_operand then
				  let
				    val spill = reg_spill_value reg_operand
				    val op2 =
				      if is_reg gp_operand' then
					I386_Assembly.r32(lookup_gp_operand gp_operand')
				      else
					assemble_sized_gp_imm gp_operand'
				  in
				    [I386_Assembly.r_m32
				     (I386_Assembly.INR
				      (I386_Assembly.MEM
				       {base=SOME I386Types.sp,
					index=absent,
					offset=SOME(I386_Assembly.SMALL spill)})),
				     op2]
				  end
				else
				  if gp_operand_is_spill gp_operand' then
				    let
				      val spill = gp_spill_value gp_operand'
				    in
				      [I386_Assembly.r32(lookup_reg_operand reg_operand),
				       I386_Assembly.r_m32
				       (I386_Assembly.INR
					(I386_Assembly.MEM
					 {base=SOME I386Types.sp,
					  index=absent,
					  offset=SOME(I386_Assembly.SMALL spill)}))]
				    end
				  else
				    let
				      val op2 =
					if is_reg gp_operand' then
					  I386_Assembly.r32(lookup_gp_operand gp_operand')
					else
					  assemble_sized_gp_imm gp_operand'
				    in
				      [I386_Assembly.r_m32
				       (I386_Assembly.INL(lookup_reg_operand reg_operand)),
				       op2]
				    end
			    in
			      ([(I386_Assembly.OPCODE(i_opcode, operands),
				 absent, "binary op")],
			       opcode_list, block_list, final_result, stack_drop, param_slots, false)
			    end
		      else
			if reg_equals_gp(reg_operand, gp_operand') then
			  let
			    val can_reverse = case binary_op of
			      MirTypes.ADDU => true
			    | MirTypes.SUBU => false
			    | MirTypes.MULU =>
				Crash.unimplemented"MirTypes.MULU"
			    | MirTypes.MUL32U =>
				Crash.unimplemented"MirTypes.MUL32U"
			    | MirTypes.AND => true
			    | MirTypes.OR => true
			    | MirTypes.EOR => true
			    | MirTypes.LSR => false
			    | MirTypes.ASL => false
			    | MirTypes.ASR => false
			  in
			    if can_reverse then
			      ([],
			       MirTypes.BINARY(binary_op, reg_operand, gp_operand',
					       gp_operand) :: opcode_list,
			       block_list, final_result, stack_drop, param_slots, false)
			    else
			      (* Difficult case of a := b op a *)
			      let
				val a_is_global =
				  not(reg_operand_is_spill reg_operand) andalso
				  lookup_reg_operand reg_operand = I386Types.global
				val b_is_global =
				  is_reg gp_operand andalso
				  not(gp_operand_is_spill gp_operand) andalso
				  lookup_gp_operand gp_operand = I386Types.global
			      in
				if a_is_global orelse b_is_global then
				  Crash.unimplemented
				  ("BINARY:unreversible:reg_operand = gp_operand' in " ^
				   MirPrint.opcode opcode)
				else
				  if reg_operand_is_spill reg_operand andalso
				    gp_operand_is_spill gp_operand then
				    let
				      (* Here we know reg_operand = gp_operand' *)
				      val spill = gp_spill_value gp_operand
				      val offset =
					if spill = 0 then
					  absent
					else
					  SOME (I386_Assembly.SMALL spill)
				      val xchg_code =
					(I386_Assembly.OPCODE
					 (I386_Assembly.xchg,
					  [I386_Assembly.r32 I386Types.global,
					   I386_Assembly.r_m32
					   (I386_Assembly.INR
					    (I386_Assembly.MEM
					     {base=SOME I386Types.sp,
					      index=absent,
					      offset=offset}))
					   ]),
					 absent,
					 "swap dest (= source 2) with global")
				      val binary_code =
					(I386_Assembly.OPCODE
					 (i_opcode,
					  [I386_Assembly.r_m32
					   (I386_Assembly.INR
					    (I386_Assembly.MEM
					     {base=SOME I386Types.sp,
					      index=absent,
					      offset=offset})),
					   I386_Assembly.r32 I386Types.global]),
					 absent, "the binary operation")
				      val code_list =
					move_gp_to_reg(I386Types.global, gp_operand,
						       [xchg_code])
				    in
				      (code_list,
				       MirTypes.BINARY(binary_op, reg_operand,
						       gp_operand',
						       MirTypes.GP_GC_REG
						       MirRegisters.global) ::
				       opcode_list,
				       block_list, final_result, stack_drop, param_slots, false)
				    end
				  else
				    ([],
				     MirTypes.UNARY(MirTypes.MOVE,
						    MirTypes.GC_REG MirRegisters.global,
						    gp_operand') ::
				     MirTypes.BINARY(binary_op, reg_operand, gp_operand,
						     MirTypes.GP_GC_REG MirRegisters.global) ::
				     opcode_list,
				     block_list, final_result, stack_drop, param_slots, false)
			      end
			  end
			else
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  reg_operand,
					  gp_operand) ::
			   MirTypes.BINARY(binary_op, reg_operand,
					   gp_from_reg reg_operand,
					   gp_operand') ::
			   opcode_list, block_list, final_result, stack_drop, param_slots, false)
		  end

		| MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand) =>
		  if reg_operand_is_spill reg_operand andalso
		    gp_operand_is_spill gp_operand then
		    if reg_equals_gp(reg_operand, gp_operand) then
		      ([], opcode_list, block_list, final_result, stack_drop, param_slots, false)
		    else
		      ([], MirTypes.UNARY(MirTypes.MOVE,
					  MirTypes.GC_REG MirRegisters.global,
					  gp_operand) ::
		       MirTypes.UNARY(MirTypes.MOVE, reg_operand,
				      MirTypes.GP_GC_REG MirRegisters.global) ::
		       opcode_list, block_list, final_result, stack_drop, param_slots, false)
		  else
		    (* Not both spills case *)
		    if reg_operand_is_spill reg_operand then
		      let
			val opcode = I386_Assembly.mov
			val _ = doing_move := true
			val spill = reg_spill_value reg_operand
			val _ = doing_move := false (* Catch mistakes *)
			val offset =
			  if spill = 0 then absent else SOME (I386_Assembly.SMALL spill)
			(* Deal with possible parameter push here *)
			val _ =
			  if spill < 0 (* Parameter push *) andalso stack_drop > 0 then
			    Crash.impossible"i386_cg: parameter push onto dropped stack"
			  else
			    ()
			val mem_ref =
			  I386_Assembly.r_m32
			  (I386_Assembly.INR
			   (I386_Assembly.MEM
			    {base=SOME I386Types.sp,
			     index=absent,
			     offset=offset}))
			val operand =
			  if is_reg gp_operand then
			    (* Can't be spill here *)
			    let
			      val rs1 = lookup_gp_operand gp_operand
			    in
			      I386_Assembly.r32 rs1
			    end
			  else
			    I386_Assembly.imm32(assemble_imm32 gp_operand)
			val (code_list, param_slots) =
			  if spill < 0 then
			    let
			      val neg_spill = ~spill
			    in
			      if neg_spill <= param_slots then
				(* Store via sp as normal *)
				let
				  val spill = spill + param_slots
				  (* Account for parameters already stacked *)
				  val offset =
				    if spill = 0 then absent else SOME(I386_Assembly.SMALL spill)
				in
				  ([(I386_Assembly.OPCODE
				     (opcode,
				      [I386_Assembly.r_m32
				       (I386_Assembly.INR
					(I386_Assembly.MEM
					 {base=SOME I386Types.sp,
					  index=absent,
					  offset=offset})), operand]),
				     absent, "saving arg into stack")],
				   param_slots)
				end
			      else
			      if neg_spill = param_slots+4 then
				(* Just push onto stack *)
				([(I386_Assembly.OPCODE
				   (I386_Assembly.push,
				    [operand]),
				   absent, "pushing arg onto stack")],
				 neg_spill)
			      else
				(* Drop stack then push *)
				let
				  val pushes = neg_spill - param_slots - 4
				  fun push_dummies(slots, done) =
				    if slots <= 0 then
				      done
				    else
				      push_dummies
				      (slots - 4,
				       (I386_Assembly.OPCODE
					(I386_Assembly.push,
					 [I386_Assembly.r32 I386Types.callee_closure]),
					absent, "push safe filler onto stack") ::
				      done)
				in
				  (push_dummies
				   (pushes,
				    [(I386_Assembly.OPCODE
				      (I386_Assembly.push,
				       [operand]),
				      absent, "pushing arg onto stack")]),
				   neg_spill)
				end
			    end
			  else
			    ([(I386_Assembly.OPCODE
			       (opcode,
				[mem_ref, operand]),
			       absent, "")], param_slots)
		      in
			(code_list, opcode_list, block_list, final_result, stack_drop, param_slots, false)
		      end
		    else
		      let
(*
			val _ = doing_move := true
*)
			val rd = lookup_reg_operand reg_operand
			val code_list = move_gp_to_reg(rd, gp_operand, [])
(*
			val _ = doing_move := false
*)
		      in
			(code_list, opcode_list, block_list, final_result,
			 stack_drop, param_slots, false)
		      end

		| MirTypes.UNARY(MirTypes.NOT, reg_operand, gp_operand) =>
		    if reg_equals_gp(reg_operand, gp_operand) then
		      let
			val operand =
			  I386_Assembly.r_m32
			  (if reg_operand_is_spill reg_operand then
			     I386_Assembly.INR
			     (I386_Assembly.MEM
			      {base=SOME I386Types.sp,
			       index=absent,
			       offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
			   else
			     I386_Assembly.INL(lookup_reg_operand reg_operand))
		      in
			([(I386_Assembly.OPCODE
			   (I386_Assembly.xor,
			    [operand, I386_Assembly.imm8 ~4]),
			   absent, "invert")],
			 opcode_list, block_list, final_result, stack_drop, param_slots, false)
		      end
		    else
		      ([],
		       MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand) ::
		       MirTypes.UNARY(MirTypes.NOT, reg_operand,
				      gp_from_reg reg_operand) :: opcode_list,
		       block_list, final_result, stack_drop, param_slots, false)

		| MirTypes.UNARY(MirTypes.NOT32, reg_operand, gp_operand) =>
		    if reg_equals_gp(reg_operand, gp_operand) then
		      let
			val operand =
			  I386_Assembly.r_m32
			  (if reg_operand_is_spill reg_operand then
			     I386_Assembly.INR
			     (I386_Assembly.MEM
			      {base=SOME I386Types.sp,
			       index=absent,
			       offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
			   else
			     I386_Assembly.INL(lookup_reg_operand reg_operand))
		      in
			([(I386_Assembly.OPCODE
			   (I386_Assembly.not,
			    [operand]),
			   absent, "invert")],
			 opcode_list, block_list, final_result, stack_drop, param_slots, false)
		      end
		    else
		      ([],
		       MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand) ::
		       MirTypes.UNARY(MirTypes.NOT32, reg_operand,
				      gp_from_reg reg_operand) :: opcode_list,
		       block_list, final_result, stack_drop, param_slots, false)
		| MirTypes.UNARY(MirTypes.INTTAG, reg_operand, gp_operand) =>
		    if reg_equals_gp(reg_operand, gp_operand) then
		      let
			val operand =
			  I386_Assembly.r_m32
			  (if reg_operand_is_spill reg_operand then
			     I386_Assembly.INR
			     (I386_Assembly.MEM
			      {base=SOME I386Types.sp,
			       index=absent,
			       offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
			   else
			     I386_Assembly.INL(lookup_reg_operand reg_operand))
		      in
			([(I386_Assembly.OPCODE
			   (I386_Assembly.and_op,
			    [operand, I386_Assembly.imm8 0xfc]),
			   absent, "tag as int")],
			 opcode_list, block_list, final_result, stack_drop, param_slots, false)
		      end
		    else
		      ([],
		       MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand) ::
		       MirTypes.UNARY(MirTypes.INTTAG, reg_operand,
				      gp_from_reg reg_operand) :: opcode_list,
		       block_list, final_result, stack_drop, param_slots, false)

		| MirTypes.NULLARY(MirTypes.CLEAN, reg_operand) =>
                    ([if reg_operand_is_spill reg_operand then
			(I386_Assembly.OPCODE
			 (I386_Assembly.mov,
			  [I386_Assembly.r_m32
			   (I386_Assembly.INR
			    (I386_Assembly.MEM
			     {base=SOME I386Types.sp,
			      index=absent,
			      offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})),
			   I386_Assembly.imm32(0, 0)]),
			 absent, "clean")
		      else
                        (I386_Assembly.OPCODE
			 (I386_Assembly.xor,
			  [I386_Assembly.r_m32
			   (I386_Assembly.INL(lookup_reg_operand reg_operand)),
			   I386_Assembly.r32(lookup_reg_operand reg_operand)]),
			 absent, "clean")],
                    opcode_list, block_list, final_result, stack_drop, param_slots, false)

		| MirTypes.BINARYFP(binary_fp_op, fp_operand, fp_operand',fp_operand'') =>
		  let
		    val rd = convert_fp_operand fp_operand
		    val rs1 = convert_fp_operand fp_operand'
		    val rs2 = convert_fp_operand fp_operand''
		    val operation =
                      case binary_fp_op of
                        MirTypes.FADD => I386_Assembly.fadd
                      | MirTypes.FSUB => I386_Assembly.fsub
                      | MirTypes.FMUL => I386_Assembly.fmul
                      | MirTypes.FDIV => I386_Assembly.fdiv
		  in
		    ([(I386_Assembly.OPCODE (I386_Assembly.fld, [rs1]),absent,""),
                      (I386_Assembly.OPCODE (operation, [rs2]),absent,""),
                      (I386_Assembly.OPCODE (I386_Assembly.fstp, [rd]),absent,"")],
                     opcode_list, block_list, final_result,stack_drop, param_slots, false)
		  end

	        | MirTypes.UNARYFP(unary_fp_op, fp_operand, fp_operand') =>
                    let
                      val rd = convert_fp_operand fp_operand
                      val rs = convert_fp_operand fp_operand'
                      val complex_trig =
                        case unary_fp_op of
                          MirTypes.FSIN => true
                        | MirTypes.FCOS => true
                        | _ => false
                    in
                      if not complex_trig
                        then
                          let
                            val mnemonics =
                              case unary_fp_op of
                                MirTypes.FSQRT => [I386_Assembly.fsqrt]
                              | MirTypes.FMOVE => []
                              | MirTypes.FABS => [I386_Assembly.fabs]
                              | MirTypes.FNEG => [I386_Assembly.fchs]
                              (* fpatan is actually atan2 *)
                              | MirTypes.FATAN => [I386_Assembly.fld1,I386_Assembly.fpatan]
                              | _ => Crash.impossible"Bad unary fp generated"
                          in
                            ([(I386_Assembly.OPCODE (I386_Assembly.fld, [rs]), absent, "Get unary fp arg")] @@
                             (map (fn m => (I386_Assembly.OPCODE (m, []), absent, "")) mnemonics) @@
                             [(I386_Assembly.OPCODE (I386_Assembly.fstp, [rd]), absent, "Write it back")],
                             opcode_list, block_list,
                             final_result,stack_drop, param_slots, false)
                          end
                      else
                        (* sin and cos only partially implemented by the 387 *)
                        (* For ridiculously big x, we make sin x = 0.0 and cos x = 1.0 *)
                        let
                          val end_tag = MirTypes.new_tag ()
                          val next_tag = MirTypes.new_tag ()
                          val (mnemonics,partial_result_op) =
                            case unary_fp_op of
                              MirTypes.FSIN => ([I386_Assembly.fsin],I386_Assembly.fldz)
                            | MirTypes.FCOS => ([I386_Assembly.fcos],I386_Assembly.fld1)
                            | _ => Crash.impossible "Bad partial unary fp op"
                          (* Once the correct value has been constructed, jump here *)
                          val final_block =
                            (end_tag,
                             [(I386_Assembly.OPCODE (I386_Assembly.fstp, [rd]), absent, "Write it back"),
                              (I386_Assembly.OPCODE (I386_Assembly.jmp, [I386_Assembly.rel8 0]), SOME next_tag, "")])
                        in
                          ([(I386_Assembly.OPCODE (I386_Assembly.fld, [rs]), absent, "Get unary fp arg")] @@
                           (map (fn m => (I386_Assembly.OPCODE (m, []), absent, "")) mnemonics) @@
                           [(I386_Assembly.OPCODE (I386_Assembly.push,[I386_Assembly.r32 I386Types.EAX]), absent,""),
                            (I386_Assembly.OPCODE (I386_Assembly.fstsw_ax,[]), absent,"Get fpu status"),
                            (I386_Assembly.OPCODE (I386_Assembly.sahf,[]), absent,"Status to flags"),
                            (I386_Assembly.OPCODE (I386_Assembly.pop,[I386_Assembly.r32 I386Types.EAX]), absent,""),
                            (* result OK if parity not set *)
                            (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.not_parity,[I386_Assembly.rel8 0]), SOME end_tag,""),
                            (I386_Assembly.OPCODE (I386_Assembly.fstp, [I386_Assembly.fp_reg 0]),absent,"Pop wrong result"),
                            (I386_Assembly.OPCODE (partial_result_op,[]), absent,"Return default result"),
                            (I386_Assembly.OPCODE (I386_Assembly.jmp, [I386_Assembly.rel8 0]), SOME end_tag, "")],
                           [],MirTypes.BLOCK(next_tag,opcode_list):: block_list,
                           final_block :: final_result,stack_drop, param_slots, true)
                        end
                    end

		| MirTypes.TBINARYFP(tagged_binary_fp_op, taglist, fp_operand,
				     fp_operand', fp_operand'') =>
		  let
		    val rd = convert_fp_operand fp_operand
		    val rs1 = convert_fp_operand fp_operand'
		    val rs2 = convert_fp_operand fp_operand''
		    val operation =
                      case tagged_binary_fp_op of
                        MirTypes.FADDV => I386_Assembly.fadd
                      | MirTypes.FSUBV => I386_Assembly.fsub
                      | MirTypes.FMULV => I386_Assembly.fmul
                      | MirTypes.FDIVV => I386_Assembly.fdiv
		  in
		    ([(I386_Assembly.OPCODE (I386_Assembly.fld, [rs1]),absent,""),
                      (I386_Assembly.OPCODE (operation, [rs2]),absent,""),
                      (I386_Assembly.OPCODE (I386_Assembly.fstp, [rd]),absent,"Store fp result")],

                     opcode_list, block_list, final_result,stack_drop, param_slots, false)
		  end

		| MirTypes.TUNARYFP(tagged_unary_fp_op, taglist, fp_operand,
				    fp_operand') =>
                    let
                      val rd = convert_fp_operand fp_operand
                      val rs = convert_fp_operand fp_operand'
		      val mnemonics =
			case tagged_unary_fp_op of
			  MirTypes.FSQRTV => [I386_Assembly.fsqrt]
			| MirTypes.FABSV => [I386_Assembly.fabs]
			| MirTypes.FNEGV => [I386_Assembly.fchs]
                        | _ => Crash.impossible"Bad unary fp generated"
		    in
		      ((I386_Assembly.OPCODE (I386_Assembly.fld, [rs]), absent, "") ::
                       (map (fn m => (I386_Assembly.OPCODE (m, []), absent, "")) mnemonics) @@
                       [(I386_Assembly.OPCODE (I386_Assembly.fstp, [rd]), absent, "Store fp result")],
                       opcode_list, block_list,
		       final_result,stack_drop, param_slots, false)
		    end
		| MirTypes.STACKOP(stack_op, reg_operand,
				   SOME offset) =>
		  Crash.impossible"do_everything:MirTypes.STACKOP"
		| MirTypes.STACKOP(stack_op, reg_operand, NONE) =>
		    let
		      val _ =
			if reg_operand_is_spill reg_operand then
			  Crash.impossible"push or pop of spill"
			else
			  ()
		      val (operation, stack_inc) = case stack_op of
			MirTypes.PUSH => (I386_Assembly.push, 4)
		      | MirTypes.POP => (I386_Assembly.pop, ~4)
		    in
		      ([(I386_Assembly.OPCODE
			 (operation,
			  [I386_Assembly.r32(lookup_reg_operand reg_operand)]),
			 absent, "push/pop register")],
		       opcode_list, block_list, final_result, stack_drop + stack_inc, param_slots, false)
		    end
		| opcode as MirTypes.IMMSTOREOP(store_op, gp_operand, reg_operand,
						gp_operand') =>
		  if is_reg gp_operand orelse is_load store_op then
		    Crash.impossible"IMMSTOREOP with load or register operand"
		  else
		    (case (reg_operand_is_spill reg_operand,
			   gp_operand_is_spill gp_operand') of
		       (false, false) =>
			 let
			   val r1 = lookup_reg_operand reg_operand
			   val gp_is_reg = is_reg gp_operand'
			   val operand =
			     I386_Assembly.r_m32
			     (I386_Assembly.INR
			      (I386_Assembly.MEM
			       (if gp_is_reg then
				  {base = SOME r1,
				   index = SOME (lookup_gp_operand gp_operand', absent),
				   offset = absent}
				else
				  let
				    val r1 =
				      if r1 = I386Types.stack then
					I386Types.ESP
				      else
					r1
				  in
				    {base = SOME r1,
				     index = absent,
				     offset = SOME (assemble_large_offset gp_operand')}
				  end
				)))
			 in
			   ([(I386_Assembly.OPCODE
			      (I386_Assembly.mov,
			       [operand, I386_Assembly.imm32(assemble_imm32 gp_operand)]),
			      absent, "store immediate value")],
			    opcode_list, block_list, final_result, stack_drop, param_slots, false)
			 end
		     | (false, true) =>
			 ([],
			  MirTypes.UNARY(MirTypes.MOVE,
					 MirTypes.GC_REG MirRegisters.global,
					 gp_operand') ::
			  MirTypes.IMMSTOREOP(store_op, gp_operand, reg_operand,
					      MirTypes.GP_GC_REG MirRegisters.global) ::
			  opcode_list,
			  block_list, final_result, stack_drop, param_slots, false)
		     | (true, false) =>
			 ([],
			  MirTypes.UNARY(MirTypes.MOVE,
					 MirTypes.GC_REG MirRegisters.global,
					 gp_from_reg reg_operand) ::
			  MirTypes.IMMSTOREOP(store_op, gp_operand,
					      MirTypes.GC_REG MirRegisters.global,
					      gp_operand') ::
			  opcode_list,
			  block_list, final_result, stack_drop, param_slots, false)
		     | (true, true) =>
		       ([],
			MirTypes.UNARY(MirTypes.MOVE, MirTypes.GC_REG MirRegisters.global,
				       gp_from_reg reg_operand) ::
			MirTypes.BINARY(MirTypes.ADDU,
					MirTypes.GC_REG MirRegisters.global,
					MirTypes.GP_GC_REG MirRegisters.global,
					gp_operand') ::
			MirTypes.IMMSTOREOP(store_op, gp_operand,
					    MirTypes.GC_REG MirRegisters.global,
					    MirTypes.GP_IMM_ANY 0) ::
			opcode_list, block_list, final_result, stack_drop, param_slots, false))
		| opcode as MirTypes.STOREOP(store_op, reg_operand, reg_operand',
					     gp_operand) =>
		  let
		    val is_a_load = is_load store_op
		    val reg_operand_is_not_global =
		      reg_operand <> MirTypes.GC_REG MirRegisters.global
		  in
		    (case (reg_operand_is_spill reg_operand,
			   reg_operand_is_spill reg_operand',
			   gp_operand_is_spill gp_operand) of
		       (false, false, true) =>
			 if is_a_load orelse reg_operand_is_not_global then
			   ([],
			    MirTypes.UNARY(MirTypes.MOVE, MirTypes.GC_REG MirRegisters.global,
					   gp_operand) ::
			    MirTypes.STOREOP(store_op, reg_operand, reg_operand',
					     MirTypes.GP_GC_REG MirRegisters.global) ::
			    opcode_list, block_list, final_result, stack_drop, param_slots, false)
			 else
			   if reg_operand' = MirTypes.GC_REG MirRegisters.caller_closure then
			     Crash.unimplemented"StoreOp: ST ecx, ebp, spill"
			   else
			     ([],
			      MirTypes.STACKOP(MirTypes.PUSH,
					       MirTypes.GC_REG MirRegisters.caller_closure,
					       absent) ::
			      MirTypes.UNARY(MirTypes.MOVE,
					     MirTypes.GC_REG MirRegisters.caller_closure,
					     gp_operand) ::
			      MirTypes.STOREOP(store_op, reg_operand, reg_operand',
					       MirTypes.GP_GC_REG MirRegisters.caller_closure) ::
			      MirTypes.STACKOP(MirTypes.POP,
					       MirTypes.GC_REG MirRegisters.caller_closure,
					       absent) ::
			      (* Pop back again *)
			      opcode_list, block_list, final_result, stack_drop, param_slots, false)
		     | (false, true, false) =>
			 if is_a_load orelse reg_operand_is_not_global then
			   ([],
			    MirTypes.UNARY(MirTypes.MOVE, MirTypes.GC_REG MirRegisters.global,
					   gp_from_reg reg_operand') ::
			    MirTypes.STOREOP(store_op, reg_operand,
					     MirTypes.GC_REG MirRegisters.global,
					     gp_operand) ::
			    opcode_list, block_list, final_result, stack_drop, param_slots, false)
			 else
			   if is_reg gp_operand andalso
			     reg_from_gp gp_operand = MirRegisters.caller_closure then
			     Crash.unimplemented"StoreOp: ST ecx, spill, ebp"
			   else
			     ([],
			      MirTypes.STACKOP(MirTypes.PUSH,
					       MirTypes.GC_REG MirRegisters.caller_closure,
					       absent) ::
			      MirTypes.UNARY(MirTypes.MOVE,
					     MirTypes.GC_REG MirRegisters.caller_closure,
					     gp_from_reg reg_operand') ::
			      MirTypes.STOREOP(store_op, reg_operand,
					       MirTypes.GC_REG MirRegisters.caller_closure,
					       gp_operand) ::
			      MirTypes.STACKOP(MirTypes.POP,
					       MirTypes.GC_REG MirRegisters.caller_closure,
					       absent) ::
			      (* Pop back again *)
			      opcode_list, block_list, final_result, stack_drop, param_slots, false)
		     | (false, true, true) =>
			 if is_a_load orelse reg_operand_is_not_global then
			   ([],
			    MirTypes.UNARY(MirTypes.MOVE, MirTypes.GC_REG MirRegisters.global,
					   gp_from_reg reg_operand') ::
			    MirTypes.BINARY(MirTypes.ADDU,
					    MirTypes.GC_REG MirRegisters.global,
					    MirTypes.GP_GC_REG MirRegisters.global,
					    gp_operand) ::
			    MirTypes.STOREOP(store_op, reg_operand,
					     MirTypes.GC_REG MirRegisters.global,
					     MirTypes.GP_IMM_ANY 0) ::
			    opcode_list, block_list, final_result, stack_drop, param_slots, false)
			 else
			   ([],
			    MirTypes.STACKOP(MirTypes.PUSH,
					     MirTypes.GC_REG MirRegisters.caller_closure,
					     absent) ::
			    MirTypes.UNARY(MirTypes.MOVE,
					   MirTypes.GC_REG MirRegisters.caller_closure,
					   gp_from_reg reg_operand') ::
			    MirTypes.BINARY(MirTypes.ADDU,
					    MirTypes.GC_REG MirRegisters.caller_closure,
					    MirTypes.GP_GC_REG MirRegisters.caller_closure,
					    gp_operand) ::
			    MirTypes.STOREOP(store_op, reg_operand,
					     MirTypes.GC_REG MirRegisters.caller_closure,
					     MirTypes.GP_IMM_ANY 0) ::
			    MirTypes.STACKOP(MirTypes.POP,
					      MirTypes.GC_REG MirRegisters.caller_closure,
					      absent) ::
			    (* Pop back again *)
			    opcode_list, block_list, final_result, stack_drop, param_slots, false)
		   | (true, false, false) =>
		       let
			 val load = is_load store_op
		       in
			 if load then
			   ([],
			    MirTypes.STOREOP(store_op,
					     MirTypes.GC_REG MirRegisters.global,
					     reg_operand',
					     gp_operand) ::
			    (* Load the value into global *)
			    MirTypes.UNARY(MirTypes.MOVE,
					   reg_operand,
					   MirTypes.GP_GC_REG MirRegisters.global) ::
			    (* Then put it in the spill slot *)
			    opcode_list, block_list, final_result, stack_drop, param_slots, false)
			 else
			   ([],
			    MirTypes.UNARY(MirTypes.MOVE,
					   MirTypes.GC_REG MirRegisters.global,
					   gp_from_reg reg_operand) ::
			    (* Get the value from the spill slot *)
			    MirTypes.STOREOP(store_op,
					     MirTypes.GC_REG MirRegisters.global,
					     reg_operand',
					     gp_operand) ::
			    (* And store it where it should be *)
			    opcode_list, block_list, final_result, stack_drop, param_slots, false)
		       end
		   | (true, false, true) =>
		       let
			 val load = is_load store_op
		       in
			 if load then
			   (* Easier case *)
			   ([],
			    MirTypes.UNARY(MirTypes.MOVE,
					   MirTypes.GC_REG MirRegisters.global,
					   gp_operand) ::
			    (* Get the value from the spill slot *)
			    MirTypes.STOREOP(store_op,
					     MirTypes.GC_REG MirRegisters.global,
					     reg_operand',
					     MirTypes.GP_GC_REG MirRegisters.global) ::
			    (* load the value into global *)
			    MirTypes.UNARY(MirTypes.MOVE,
					   reg_operand,
					   MirTypes.GP_GC_REG MirRegisters.global) ::
			    (* And store it where it should be *)
			    opcode_list, block_list, final_result, stack_drop, param_slots, false)
			 else
			   (* Difficult case *)
			   Crash.unimplemented"store spill, reg, spill"
		       end
		   | (true, true, false) =>
		       let
			 val load = is_load store_op
		       in
			 if load then
			   (* Easier case *)
			   ([],
			    MirTypes.UNARY(MirTypes.MOVE,
					   MirTypes.GC_REG MirRegisters.global,
					   gp_from_reg reg_operand') ::
			    (* Get the value from the spill slot *)
			    MirTypes.STOREOP(store_op,
					     MirTypes.GC_REG MirRegisters.global,
					     MirTypes.GC_REG MirRegisters.global,
					     gp_operand) ::
			    (* load the value into global *)
			    MirTypes.UNARY(MirTypes.MOVE,
					   reg_operand,
					   MirTypes.GP_GC_REG MirRegisters.global) ::
			    (* And store it where it should be *)
			    opcode_list, block_list, final_result, stack_drop, param_slots, false)
			 else
			   (* Difficult case *)
			   ([],
			    MirTypes.STACKOP(MirTypes.PUSH,
					      MirTypes.GC_REG MirRegisters.caller_closure,
					      absent) ::
			    MirTypes.UNARY(MirTypes.MOVE,
					   MirTypes.GC_REG MirRegisters.caller_closure,
					   gp_from_reg reg_operand) ::
			    (* Put the argument in caller_closure *)
			    MirTypes.STOREOP(store_op,
					      MirTypes.GC_REG MirRegisters.caller_closure,
					      reg_operand', gp_operand) ::
			    MirTypes.STACKOP(MirTypes.POP,
					      MirTypes.GC_REG MirRegisters.caller_closure,
					      absent) ::
			    (* Pop back again *)
			    opcode_list, block_list, final_result, stack_drop, param_slots, false)
		       end
		   | (true, true, true) =>
		       Crash.unimplemented"store spill, spill, spill"
		   | (false, false, false) =>
		       let
			 val rd = lookup_reg_operand reg_operand
			 val rs1 = lookup_reg_operand reg_operand'
			 val is_local_variable = rs1 = I386Types.stack
			 val (store_instr, word_size, load) = case store_op of
			   MirTypes.LD => (I386_Assembly.mov, true, true)
			 | MirTypes.ST => (I386_Assembly.mov, true, false)
			 | MirTypes.LDB => (I386_Assembly.movzx, false, true)
			 | MirTypes.STB => (I386_Assembly.mov, false, false)
			 | MirTypes.LDREF => (I386_Assembly.mov, true, true)
			 | MirTypes.STREF => (I386_Assembly.mov, true, false)
			 val r_m =
			   I386_Assembly.INR
			   (I386_Assembly.MEM
			    (if is_reg gp_operand then
			       {base=SOME rs1,
				index=SOME((lookup_gp_operand gp_operand), absent),
				offset=absent}
			     else
			       let
				 val rs1 =
				   if is_local_variable then
				     I386Types.ESP
				   else
				     rs1
			       in
				 {base=SOME rs1,
				  index=absent,
				  offset=SOME(assemble_large_offset gp_operand)}
			       end
))
			 val (con1, con2) =
			   if word_size then
			     (I386_Assembly.r32, I386_Assembly.r_m32)
			   else
			     if load then
			       (I386_Assembly.r32, I386_Assembly.r_m8)
			     else
			       (I386_Assembly.r8, I386_Assembly.r_m8)
		       in
			 if word_size orelse I386Types.has_byte_name rd orelse load then
			   let
			     val rd =
			       if word_size orelse load then
				 rd
			       else
				 I386Types.byte_reg_name rd
			     val operands =
			       if load then
				 [con1 rd, con2 r_m]
			       else
				 [con2 r_m, con1 rd]
			   in
			     ([(I386_Assembly.OPCODE(store_instr, operands), absent, "")],
			      opcode_list, block_list, final_result, stack_drop, param_slots, false)
			   end
			 else
			   (* Byte, no byte register name, store *)
			   (* Tricky, our destination may already be in global *)
			   if rs1 = I386Types.global orelse
			     (is_reg gp_operand andalso lookup_gp_operand gp_operand = I386Types.global) then
			     let
			       val operands =
				 if rs1 = I386Types.ESP orelse
				   (is_reg gp_operand andalso lookup_gp_operand gp_operand = I386Types.ESP) then
				   Crash.unimplemented"store byte relative to sp"
				 else
				   [I386_Assembly.r_m8 r_m,
				    I386_Assembly.r8(I386Types.byte_reg_name I386Types.EAX)]
			     in
			       ([(I386_Assembly.OPCODE
				  (I386_Assembly.push, [I386_Assembly.r32 I386Types.EAX]),
				  absent, "create some workspace"),
				 move_reg(I386Types.EAX, rd, "can't store byte from " ^
					  I386Types.reg_to_string rd),
				 (I386_Assembly.OPCODE
				  (store_instr, operands), absent, ""),
				 (I386_Assembly.OPCODE
				  (I386_Assembly.pop, [I386_Assembly.r32 I386Types.EAX]),
				  absent, "restore EAX")],
			       opcode_list, block_list, final_result, stack_drop, param_slots, false)
			     end
			   else
			     let
			       val operands =
				 [I386_Assembly.r_m8 r_m,
				  I386_Assembly.r8(I386Types.byte_reg_name I386Types.global)]
			     in
			       ([move_reg(I386Types.global, rd, "can't store byte from " ^
					  I386Types.reg_to_string rd),
				 (I386_Assembly.OPCODE(store_instr, operands), absent, "")],
				opcode_list, block_list, final_result, stack_drop, param_slots, false)
			     end
		       end)
		       end
		| MirTypes.STOREFPOP(store_fp_op, fp_operand, reg_operand,gp_operand) =>
                    (case (reg_operand_is_spill reg_operand,
                           gp_operand_is_spill gp_operand) of
                       (false, true) =>
                         ([],
                          MirTypes.UNARY(MirTypes.MOVE, MirTypes.GC_REG MirRegisters.global,
                                         gp_operand) ::
                          MirTypes.STOREFPOP(store_fp_op, fp_operand, reg_operand,
                                             MirTypes.GP_GC_REG MirRegisters.global) ::
                          opcode_list, block_list, final_result, stack_drop, param_slots, false)
                     | (true, false) =>
                         ([],
                          MirTypes.UNARY(MirTypes.MOVE, MirTypes.GC_REG MirRegisters.global,
                                         gp_from_reg reg_operand) ::
                          MirTypes.STOREFPOP (store_fp_op, fp_operand,
                                              MirTypes.GC_REG MirRegisters.global,
                                              gp_operand) ::
                          opcode_list, block_list, final_result, stack_drop, param_slots, false)
                     | (true, true) =>
                         ([],
                          MirTypes.UNARY(MirTypes.MOVE, MirTypes.GC_REG MirRegisters.global,
                                         gp_from_reg reg_operand) ::
                          MirTypes.BINARY(MirTypes.ADDU,
                                          MirTypes.GC_REG MirRegisters.global,
                                          MirTypes.GP_GC_REG MirRegisters.global,
                                          gp_operand) ::
                          MirTypes.STOREFPOP(store_fp_op, fp_operand,
                                             MirTypes.GC_REG MirRegisters.global,
                                             MirTypes.GP_IMM_ANY 0) ::
                          opcode_list, block_list, final_result, stack_drop, param_slots, false)
                     | (false, false) =>
                         (* Both values are in registers or are immediates *)
                         let
                           val rs1 = lookup_reg_operand reg_operand
			   val is_local_variable = rs1 = I386Types.stack
                           val (store_instr, is_load) =
                             case store_fp_op of
                               MirTypes.FLD => (I386_Assembly.mov, true)
                             | MirTypes.FST => (I386_Assembly.mov, false)
                             | MirTypes.FLDREF => (I386_Assembly.mov, true)
                             | MirTypes.FSTREF => (I386_Assembly.mov, false)
                           (* Make the memory operand *)
                           val operand =
                             I386_Assembly.fp_mem
                             (I386_Assembly.MEM
                              (if is_reg gp_operand then
                                 {base=SOME rs1,
                                  index=SOME((lookup_gp_operand gp_operand), absent),
                                  offset=absent}
                               else
				 let
				   val rs1 =
				     if is_local_variable then
				       I386Types.ESP
				     else
				       rs1
				 in
				   {base=SOME rs1,
				    index=absent,
				    offset=SOME(assemble_large_offset gp_operand)}
				 end))
                           val fp_operand = convert_fp_operand fp_operand
                           val new_opcodes =
                             if is_load
                               then
                                 [(I386_Assembly.OPCODE (I386_Assembly.fld, [operand]),absent,""),
                                  (I386_Assembly.OPCODE (I386_Assembly.fstp, [fp_operand]),absent,"")]
                             else
                               [(I386_Assembly.OPCODE (I386_Assembly.fld, [fp_operand]),absent,""),
                                (I386_Assembly.OPCODE (I386_Assembly.fstp, [operand]),absent,""),
                                (I386_Assembly.OPCODE (I386_Assembly.wait, []),absent,"Wait for store to be done")]
                         in
                           (new_opcodes,opcode_list, block_list, final_result,stack_drop, param_slots, false)
                         end)
		| MirTypes.REAL(int_to_float, fp_operand, gp_operand) =>
                    (* This needs to move (if necessary) the argument into a memory location *)
                    (* and then load with fild *)
		    (* Also, if the argument was on the stack, it must restore it *)
                    let
                      val rd = convert_fp_operand fp_operand
                      val (mem_operand,get_arg_code, restore_arg_code) =
                        if gp_operand_is_spill gp_operand then
			  let
			    val mem_operand =
			      I386_Assembly.MEM
			      {base=SOME I386Types.sp,
			       index=absent,
			       offset=SOME(I386_Assembly.SMALL(gp_spill_value gp_operand))}
			  in
			    (mem_operand,[],
			     [(I386_Assembly.OPCODE
			       (I386_Assembly.sal,
				[I386_Assembly.r_m32 (I386_Assembly.INR mem_operand),
				 I386_Assembly.imm8 2]), absent,"Retag")])
			  end
                        else
                          let
                            val fp_spare_loc =
                              I386_Assembly.MEM {base=SOME I386Types.sp,
                                                 index=absent,
                                                 offset=SOME(I386_Assembly.SMALL(frame_size + stack_drop + param_slots - fp_spare_offset))}
                            val source_operand =
                              case gp_operand of
                                MirTypes.GP_GC_REG rs =>
                                  I386_Assembly.r32 (lookup_gp_operand gp_operand)
                              | MirTypes.GP_IMM_INT i =>
                                  I386_Assembly.imm32(assemble_imm32 gp_operand)
                              | _ => Crash.impossible "Bad gp_operand to real"
                          in
                            (fp_spare_loc,
                             [(I386_Assembly.OPCODE
                               (I386_Assembly.mov,[I386_Assembly.r_m32 (I386_Assembly.INR fp_spare_loc),
                                                   source_operand]),
                               absent,"Use stack as temporary")], [])
                          end
                    in
                      (get_arg_code @@
                       [(I386_Assembly.OPCODE(I386_Assembly.sar,[I386_Assembly.r_m32 (I386_Assembly.INR mem_operand),
                                                                  I386_Assembly.imm8 2]),
                         absent,"Untag"),
                        (I386_Assembly.OPCODE (I386_Assembly.fild,[I386_Assembly.fp_mem mem_operand]),absent,"Convert int to real"),
                        (I386_Assembly.OPCODE (I386_Assembly.fstp,[rd]),absent,"")] @@
		       restore_arg_code,
                       opcode_list, block_list, final_result, stack_drop, param_slots, false)
                    end

		| MirTypes.FLOOR(float_to_int, tag, reg_operand, fp_operand) =>
                    (* This needs to push the argument onto fp stack *)
                    (* and then store with fistp to a memory location and then tag and move to destination *)
		    (* It also need to ensure that the fp stack is left clean *)
		    (* even when an exception is raised *)
                    let
                      val rs = convert_fp_operand fp_operand
                      val fp_spare_loc =
                        I386_Assembly.MEM {base=SOME I386Types.sp,
                                           index=absent,
                                           offset=SOME(I386_Assembly.SMALL(frame_size + stack_drop + param_slots - fp_spare_offset))}
                      (* mem_operand is where the FPU should put the argument *)
                      (* result_operand is for the tagging shift *)
		      (* Get two new tags for the exception raising case *)
		      (* As we must clean the stack first *)
		      val tag1 = MirTypes.new_tag()
		      val tag2 = MirTypes.new_tag()
                      val (mem_operand,result_operand,put_arg_code) =
                        if reg_operand_is_spill reg_operand then
			  let
			    val result_operand =
			      I386_Assembly.MEM
			      {base=SOME I386Types.sp,
			       index=absent,
			       offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))}
			  in
			    (I386_Assembly.fp_mem result_operand,I386_Assembly.r_m32 (I386_Assembly.INR result_operand),[])
			  end
                        else
                          let
                            val dest_operand_reg =
                              case reg_operand of
                                MirTypes.GC_REG _ => lookup_reg_operand reg_operand
                              | _ => Crash.impossible "Bad reg_operand to floor"
                          in
                            (I386_Assembly.fp_mem fp_spare_loc,
                             I386_Assembly.r_m32 (I386_Assembly.INL dest_operand_reg),
                             [(I386_Assembly.OPCODE
                               (I386_Assembly.mov,[I386_Assembly.r32 dest_operand_reg,
                                                   I386_Assembly.r_m32 (I386_Assembly.INR fp_spare_loc)]),
                               absent,"Use stack as temporary")])
                          end
		      val tag1_code =
			(tag1,
			 [(I386_Assembly.OPCODE (I386_Assembly.fstp,[I386_Assembly.fp_reg 0]),absent,"Pop fp stack"),
			  (I386_Assembly.OPCODE (I386_Assembly.jmp,[I386_Assembly.rel8 0]), SOME tag2,"")])
		      val tag2_code =
			(tag2,
			 [(I386_Assembly.OPCODE (I386_Assembly.fstp,[I386_Assembly.fp_reg 0]),absent,"Pop fp stack"),
			  (I386_Assembly.OPCODE (I386_Assembly.jmp,[I386_Assembly.rel8 0]), SOME tag,"")])

                    in
                      ([(I386_Assembly.OPCODE (I386_Assembly.fld,[rs]),absent,"Get argument to floor"),
                        (I386_Assembly.OPCODE (I386_Assembly.mov, [I386_Assembly.r_m32 (I386_Assembly.INR (fp_spare_loc)),
                                                                   I386_Assembly.imm32(Bits.lshift (1,27), 0)]),
                         absent, "Put 2**29 in fp_spare"),
                        (I386_Assembly.OPCODE (I386_Assembly.fild,[I386_Assembly.fp_mem fp_spare_loc]),
                         absent,"Convert 2**29 to real and push"),

                        (* Now we have 2**29 and x on the stack, time for some error checking *)
                        (* We should maybe try and only push AX once. *)
                        (I386_Assembly.OPCODE (I386_Assembly.fcom,[I386_Assembly.fp_reg 1]), absent,"Compare"),
                        (I386_Assembly.OPCODE (I386_Assembly.push,[I386_Assembly.r32 I386Types.EAX]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.fstsw_ax,[]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.sahf,[]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.pop,[I386_Assembly.r32 I386Types.EAX]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.below_or_equal,[I386_Assembly.rel8 0]), SOME tag1,""),

                        (* Now have ~2**29 on stack *)
                        (I386_Assembly.OPCODE (I386_Assembly.fchs,[]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.fcomp,[I386_Assembly.fp_reg 1]), absent,"Compare and pop"),
                        (I386_Assembly.OPCODE (I386_Assembly.push,[I386_Assembly.r32 I386Types.EAX]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.fstsw_ax,[]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.sahf,[]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.pop,[I386_Assembly.r32 I386Types.EAX]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.above,[I386_Assembly.rel8 0]), SOME tag2,""),

                        (I386_Assembly.OPCODE (I386_Assembly.fstcw,[I386_Assembly.fp_mem fp_spare_loc]),absent,"Fiddle with control word"),
                        (I386_Assembly.OPCODE (I386_Assembly.mov,
                                               [I386_Assembly.r32 I386Types.global,
                                                I386_Assembly.r_m32 (I386_Assembly.INR (fp_spare_loc))]),
                         absent,"Store previous in global -- should be 16 bit move"),
                        (I386_Assembly.OPCODE (I386_Assembly.and_op,
                                               [I386_Assembly.r_m16 (I386_Assembly.INR (fp_spare_loc)),
                                                I386_Assembly.imm16 fpu_control_rounding_bits]),
                         absent, "mask out rounding mode"),
                        (I386_Assembly.OPCODE (I386_Assembly.or,
                                               [I386_Assembly.r_m16 (I386_Assembly.INR (fp_spare_loc)),
                                                I386_Assembly.imm16 fpu_control_round_to_minus_infinity]),
                         absent, "or in round to -infinity"),
                        (I386_Assembly.OPCODE (I386_Assembly.fldcw,[I386_Assembly.fp_mem fp_spare_loc]),absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.fistp,[mem_operand]),absent,"Convert real to int"),
                        (I386_Assembly.OPCODE (I386_Assembly.wait,[]),absent,"Synchronize")] @@
                       put_arg_code @@
                       [(I386_Assembly.OPCODE (I386_Assembly.sal,[result_operand,I386_Assembly.imm8 2]),
                         absent,"Tag as integer"),
                        (I386_Assembly.OPCODE (I386_Assembly.mov,
                                               [I386_Assembly.r_m32 (I386_Assembly.INR (fp_spare_loc)),
                                                I386_Assembly.r32 I386Types.global]),
                         absent,"get previous from global -- should be 16 bit move"),
                        (I386_Assembly.OPCODE (I386_Assembly.fldcw,[I386_Assembly.fp_mem fp_spare_loc]),absent,"")
                        ],
                       opcode_list, block_list, tag1_code :: tag2_code :: final_result,
		       stack_drop, param_slots, false)
                    end

		| MirTypes.BRANCH(branch, bl_dest) =>
		    ((case bl_dest of
			MirTypes.REG reg =>
			  if reg_operand_is_spill reg then
			    Crash.unimplemented"branch reg operand is spill"
			  else
			    [(I386_Assembly.OPCODE
                              (I386_Assembly.jmp,
                               [I386_Assembly.r_m32
                                (I386_Assembly.INL(lookup_reg_operand reg))]),
                               absent, "branch indirect")]
		      | MirTypes.TAG tag =>
			  [(I386_Assembly.OPCODE
			    (I386_Assembly.jmp, [I386_Assembly.rel8 0]),
			    SOME tag, "branch relative")]),
			opcode_list, block_list, final_result, stack_drop, param_slots, false)
		| MirTypes.TEST(cond_branch, test_tag, gp_operand,
				gp_operand') =>
		  if gp_operand_is_spill gp_operand andalso
		    gp_operand_is_spill gp_operand' then
		    (* Hard case, both spills *)
		    ([],
		     MirTypes.UNARY(MirTypes.MOVE,
				    MirTypes.GC_REG
				    MirRegisters.global,
				    gp_operand) ::
		     MirTypes.TEST(cond_branch, test_tag,
				   MirTypes.GP_GC_REG MirRegisters.global, gp_operand') ::
		     opcode_list, block_list, final_result, stack_drop, param_slots, false)
		  else
		    let
		      val branch = case cond_branch of
			MirTypes.BNT => I386_Assembly.jcc I386_Assembly.equal
		      | MirTypes.BTA => I386_Assembly.jcc I386_Assembly.not_equal
		      | MirTypes.BEQ => I386_Assembly.jcc I386_Assembly.equal
		      | MirTypes.BNE => I386_Assembly.jcc I386_Assembly.not_equal
		      | MirTypes.BHI => I386_Assembly.jcc I386_Assembly.above
		      | MirTypes.BLS => I386_Assembly.jcc I386_Assembly.below_or_equal
		      | MirTypes.BHS => I386_Assembly.jcc I386_Assembly.above_or_equal
		      | MirTypes.BLO => I386_Assembly.jcc I386_Assembly.below
		      | MirTypes.BGT => I386_Assembly.jcc I386_Assembly.greater
		      | MirTypes.BLE => I386_Assembly.jcc I386_Assembly.less_or_equal
		      | MirTypes.BGE => I386_Assembly.jcc I386_Assembly.greater_or_equal
		      | MirTypes.BLT => I386_Assembly.jcc I386_Assembly.less
		      val test_instr = case cond_branch of
			MirTypes.BTA => I386_Assembly.test
		      | MirTypes.BNT => I386_Assembly.test
		      | _ => I386_Assembly.cmp
		    in
		      if is_reg gp_operand orelse is_reg gp_operand' then
			let
			  val (branch, gp_op, gp_op') =
			    if is_reg gp_operand then
			      (branch, gp_operand, gp_operand')
			    else
			      (I386_Assembly.reverse_branch branch,
			       gp_operand', gp_operand)
			  (* Possibilities : *)
			  (* gp_op is a real register, gp_op' is anything *)
			  (* gp_op is a spill, gp_op' is a real register or an immediate *)
			  (* No others, we removed both spills *)
			  (* And we swapped if gp_operand was an immediate *)

			  val (rs1, reg_or_imm, convert_eq) =
			    if gp_operand_is_spill gp_op then
			      let
				val spill = gp_spill_value gp_op
			      in
				(I386_Assembly.r_m32
				 (I386_Assembly.INR
				  (I386_Assembly.MEM
				   {base=SOME I386Types.sp,
				    index=absent,
				    offset=SOME(I386_Assembly.SMALL spill)})),
				 if is_reg gp_op' then
				   I386_Assembly.r32(lookup_gp_operand gp_op')
				 else
				   (* This case needs more work *)
				   (* Here we have either a test or a cmp *)
				   (* with an immediate value *)
				   (* The cmp can be shortened, the test can't *)
				   if test_instr = I386_Assembly.test then
				     I386_Assembly.imm32(assemble_imm32 gp_op')
				   else
				     assemble_sized_gp_imm gp_op',
				     false)
			      end
			    else
			      (* gp_op is a register *)
			      let
				val gp_r = lookup_gp_operand gp_op
			      in
				if gp_operand_is_spill gp_op' then
				  (I386_Assembly.r32 gp_r,
				   I386_Assembly.r_m32
				   (I386_Assembly.INR
				    (I386_Assembly.MEM
				     {base=SOME I386Types.sp,
				      index=absent,
				      offset=SOME(I386_Assembly.SMALL(gp_spill_value gp_op'))})),
				   false)
				else
				  (* gp_op' is not a spill *)
				  if is_reg gp_op' then
				    (I386_Assembly.r_m32
				     (I386_Assembly.INL gp_r),
				     I386_Assembly.r32(lookup_gp_operand gp_op'),
				     false)
				  else
				    (* This case needs more work *)
				    (* Here we have either a test or a cmp *)
				    (* of a real register with an immediate value *)
				    (* If it's a cmp, we can shorten the immediate *)
				    (* but use the same register name *)
				    (* If it's a test, and the immediate is short *)
				    (* we can shorten both the register and the immediate *)
				    (* possibly down to 8 bits *)
				    (* Also, if doing a comparison of a real *)
				    (* register with zero, we can use test r r *)
				    (* instead *)
				    if test_instr = I386_Assembly.cmp then
				      let
					val gp_imm = assemble_sized_gp_imm gp_op'
					val is_eq = case cond_branch of
					  MirTypes.BEQ => true
					| MirTypes.BNE => true
					| _ => false
				      in
					if is_eq andalso
					  gp_imm = I386_Assembly.imm8 0 then
					  (I386_Assembly.r_m32(I386_Assembly.INL gp_r),
					   I386_Assembly.r32 gp_r,
					   true)
					 else
					   (I386_Assembly.r_m32(I386_Assembly.INL gp_r),
					    gp_imm,
					    false)
				      end
				    else
				      let
					val (i, j) = assemble_imm32 gp_op'
				      in
					if i = 0 andalso j = 3 then
					  if I386Types.has_byte_name gp_r then
					    (I386_Assembly.r_m8
					     (I386_Assembly.INL(I386Types.byte_reg_name gp_r)),
					     I386_Assembly.imm8 3,
					     false)
					  else
					    (I386_Assembly.r_m16
					     (I386_Assembly.INL(I386Types.half_reg_name gp_r)),
					     I386_Assembly.imm16 3,
					     false)
					else
					  Crash.impossible"test instruction not with immediate 3"
				      end
			      end
			  val test_instr =
			    if convert_eq then
			      I386_Assembly.test
			    else
			      test_instr
			in
			  ([(I386_Assembly.OPCODE
			     (test_instr,
			      [rs1, reg_or_imm]),
			     absent, "do the test"),
			    (I386_Assembly.OPCODE(branch, [I386_Assembly.rel8 0]),
			     SOME test_tag, "do the branch")],
			  opcode_list, block_list, final_result, stack_drop, param_slots, false)
			end
		      else
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					MirTypes.GC_REG
					MirRegisters.global,
					gp_operand') ::
			 MirTypes.TEST(cond_branch, test_tag, gp_operand,
				       MirTypes.GP_GC_REG MirRegisters.global) ::
			 opcode_list, block_list, final_result, stack_drop, param_slots, false)
		    end

		| MirTypes.FTEST(fcond_branch, tag, fp_operand,
				 fp_operand') =>
                  let
                    val cont_tag = MirTypes.new_tag()
                    val cond =
                      (* Do these conditions map correctly? *)
                      case fcond_branch of
                        MirTypes.FBEQ => I386_Assembly.equal
                      | MirTypes.FBNE => I386_Assembly.not_equal
                      | MirTypes.FBLE => I386_Assembly.below_or_equal
                      | MirTypes.FBLT => I386_Assembly.below
                    val rs1 = convert_fp_operand fp_operand
		    val rs2 = convert_fp_operand fp_operand'
                  (* Skip the branch if the comparison comes out unordered *)
                  in
                    ([
                      (I386_Assembly.OPCODE (I386_Assembly.fld,[rs1]), absent,""),
                      (I386_Assembly.OPCODE (I386_Assembly.fcomp,[rs2]), absent,""),
                      (I386_Assembly.OPCODE (I386_Assembly.push,[I386_Assembly.r32 I386Types.EAX]), absent,""),
                      (I386_Assembly.OPCODE (I386_Assembly.fstsw_ax,[]), absent,""),
                      (I386_Assembly.OPCODE (I386_Assembly.wait,[]), absent,"Synchronize"),
                      (I386_Assembly.OPCODE (I386_Assembly.sahf,[]), absent,""),
                      (I386_Assembly.OPCODE (I386_Assembly.pop,[I386_Assembly.r32 I386Types.EAX]), absent,""),
                      (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.parity,[I386_Assembly.rel8 0]), SOME cont_tag,""),
                      (I386_Assembly.OPCODE (I386_Assembly.jcc cond,[I386_Assembly.rel8 0]), SOME tag,""),
                      (I386_Assembly.OPCODE (I386_Assembly.jmp,[I386_Assembly.rel8 0]), SOME cont_tag,"")
                      ],
		     [],MirTypes.BLOCK (cont_tag,opcode_list) :: block_list, final_result, stack_drop, param_slots, true)
                  end

		| MirTypes.BRANCH_AND_LINK
                    (_, MirTypes.REG reg_operand,debug_information, _) =>
                      if reg_operand_is_spill reg_operand then
                        Crash.impossible"register to branch and link is spill"
                      else
                        ([(I386_Assembly.AugOPCODE
                           (I386_Assembly.OPCODE
                            (I386_Assembly.lea,
                             [I386_Assembly.r32 I386Types.global,
                              I386_Assembly.r_m32
                              (I386_Assembly.INR
                               (I386_Assembly.MEM
                                {base=SOME(lookup_reg_operand reg_operand),
                                 index=absent,
                                 offset=SOME(I386_Assembly.SMALL
                                             Tags.CODE_OFFSET)}))]),
                            debug_information),
                           absent, "compute real target address"),
		        (I386_Assembly.OPCODE
			 (I386_Assembly.call,
			  [I386_Assembly.r_m32(I386_Assembly.INL
					       I386Types.global)]),
			 absent, "call to tagged value")],
                        opcode_list, block_list, final_result, stack_drop, 0, false)

		| MirTypes.BRANCH_AND_LINK(_, MirTypes.TAG tag,_, _) =>
		    ([(I386_Assembly.OPCODE
		       (I386_Assembly.call, [I386_Assembly.rel32 0]),
		      SOME tag, "call relative")],
		    opcode_list, block_list, final_result, stack_drop, 0, false)
		| MirTypes.TAIL_CALL(_, bl_dest, list) =>
		    let
		      (* One less because caller_arg isn't stacked *)
		      val output_parameters =
			let
			  val len = Lists.length list
			in
			  if len = 0 then 0 else len - 1
			end
		      val jump =
			case bl_dest of
			  MirTypes.REG reg =>
			    if reg_operand_is_spill reg then
			      Crash.impossible"reg operand to tail call is spill"
			    else
			      (* This needs work to get the offset right *)
			      [(I386_Assembly.OPCODE
				(I386_Assembly.lea,
				 [I386_Assembly.r32 I386Types.global,
				  I386_Assembly.r_m32
				  (I386_Assembly.INR
				   (I386_Assembly.MEM
				    {base=SOME(lookup_reg_operand reg),
				     index=absent,
				     offset=SOME(I386_Assembly.SMALL Tags.CODE_OFFSET)}))]),
				absent, "increment destination by offset to code"),
			       (I386_Assembly.OPCODE
				(I386_Assembly.jmp,
				 [I386_Assembly.r_m32(I386_Assembly.INL I386Types.global)]),
				absent, "branch indirect(tail call)")]
			| MirTypes.TAG tag =>
			      [(I386_Assembly.OPCODE
				(I386_Assembly.jmp,
				 [I386_Assembly.rel8 0]),
				SOME tag, "branch relative(tail call)")]
(*
		      val _ = print
			("Tail call from " ^ procedure_name ^
			 "with " ^ Int.toString max_args ^
			 " input parameters and " ^
			 Int.toString output_parameters ^
			 " output parameters\n")
*)
		      val shuffle_then_jump =
			if output_parameters = max_args then
			  (* No change in parameters space above ret *)
			  jump
			else
			if output_parameters < max_args then
			  (* Less parameters than we started with *)
			  (* Easy case *)
			  let
			    val amount_to_drop =
			      (max_args - output_parameters) * 4
			    val pop_ret =
			      (I386_Assembly.OPCODE
			       (I386_Assembly.pop,
				[I386_Assembly.r_m32
				 (I386_Assembly.INR
				  (I386_Assembly.MEM
				   {base=SOME I386Types.sp,
				    index=absent,
				    offset=SOME
				    (I386_Assembly.SMALL(amount_to_drop-4))}))]),
			       absent,
			       "pop return address into correct place on stack")
			    val rest =
			      if amount_to_drop = 4 then
				(* No stack drop necessary, the pop has done it *)
				jump
			      else
				(I386_Assembly.OPCODE
				 (I386_Assembly.add,
				  [I386_Assembly.r_m32(I386_Assembly.INL I386Types.sp),
				   I386_Assembly.imm8(amount_to_drop - 4)]),
				 absent,
				 "increment stack pointer") :: jump
			  in
			    pop_ret :: rest
			  end
			else
			  (* Hard case, some parameters to be inserted *)
			  (* Shouldn't happen *)
			  Crash.impossible("i386_cg:insufficient room for new tail parameters in " ^ procedure_name)
		      val tail_seq =
			if frame_left = 0 then
			  shuffle_then_jump
			else
			  (I386_Assembly.OPCODE
			   (I386_Assembly.add,
			    [I386_Assembly.r_m32(I386_Assembly.INL I386Types.sp),
			     if frame_left <= 127 then
			       I386_Assembly.imm8 frame_left
			     else
			       I386_Assembly.imm32
			       (frame_left div 4, frame_left mod 4)]),
			   absent, "junk spill and stack alloc area") ::
			  shuffle_then_jump
		    in
		      (if needs_preserve then
			 (I386_Assembly.OPCODE
			  (I386_Assembly.pop,
			   [I386_Assembly.r32 I386Types.callee_closure]),
			  absent, "throw away frame link") ::
			 (I386_Assembly.OPCODE
			  (I386_Assembly.pop,
			   [I386_Assembly.r32 I386Types.callee_closure]),
			  absent, "restore caller's closure") :: restore_gcs @@
			 tail_seq
		       else
			 shuffle_then_jump,
			 opcode_list, block_list, final_result, stack_drop,
			 0, false)
		    end
		| MirTypes.SWITCH(computed_goto, reg_operand, tag_list) =>
		    (case opcode_list of
		       [] =>
			 (case tag_list of
			    [] => Crash.impossible"switch:empty tag list"
			  | [tag] =>
			      ([(I386_Assembly.OPCODE
				 (I386_Assembly.jmp, [I386_Assembly.rel8 0]),
				 SOME tag, "Unconditional branch")],
			       opcode_list, block_list, final_result, stack_drop, param_slots, false)
			  | [tag1, tag2] =>
			      let
				val last_branch =
				  [(I386_Assembly.OPCODE
				    (I386_Assembly.jmp, [I386_Assembly.rel8 0]),
				    SOME tag2, "Unconditional branch")]
				val operand =
				  I386_Assembly.r_m32
				  (if reg_operand_is_spill reg_operand then
				     I386_Assembly.INR
				     (I386_Assembly.MEM
				      {base=SOME I386Types.sp,
				       index=absent,
				       offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
				   else
				     I386_Assembly.INL(lookup_reg_operand reg_operand))
			      in
				((I386_Assembly.OPCODE
				  (I386_Assembly.cmp, [operand, I386_Assembly.imm8 0]),
				  absent, "check for zero") ::
				 (I386_Assembly.OPCODE
				  (I386_Assembly.jcc(I386_Assembly.equal),
				   [I386_Assembly.rel8 0]),
				  SOME tag1, "branch if zero") ::
				 last_branch,
				 opcode_list, block_list, final_result, stack_drop, param_slots, false)
			      end
			  | _ =>
			      let
				fun make_branches([], result) = rev result
				  | make_branches(tag :: tag_list, result) =
				    make_branches(tag_list,
						  full_nop ::
						  full_nop ::
						  full_nop ::
						  (I386_Assembly.OPCODE
						   (I386_Assembly.jmp,
						    [I386_Assembly.fix_rel32 0]),
						   SOME tag,
						   "part of computed goto table") ::
						  result)
				val operand =
				  I386_Assembly.r_m32
				  (if reg_operand_is_spill reg_operand then
				     I386_Assembly.INR
				     (I386_Assembly.MEM
				      {base=SOME I386Types.sp,
				       index=absent,
				       offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
				   else
				     I386_Assembly.INL(lookup_reg_operand reg_operand))
				val tag = MirTypes.new_tag()
			      in
(* This could be better done with mov ecx, -1(edi), lea ecx offset(ecx, reg, 2) *)
				([(I386_Assembly.OPCODE
				   (I386_Assembly.mov,
				    [I386_Assembly.r32 I386Types.global,
				     I386_Assembly.imm32(0, Tags.CODE_OFFSET)]),
				   SOME tag,
				   "get start of table offset"),
				  (I386_Assembly.OPCODE
				   (I386_Assembly.add,
				    [I386_Assembly.r32 I386Types.global,
				     I386_Assembly.r_m32
				     (I386_Assembly.INR
				      (I386_Assembly.MEM
				       {base=SOME I386Types.callee_closure,
					index=absent,
					offset=SOME(I386_Assembly.SMALL ~1)}))]),
				   absent, "add in start of code"),
				  (I386_Assembly.OPCODE
				   (I386_Assembly.add,
				    [I386_Assembly.r32 I386Types.global, operand]),
				   absent, "add in the switch value"),
				  (I386_Assembly.OPCODE
				   (I386_Assembly.add,
				    [I386_Assembly.r32 I386Types.global, operand]),
				   absent, "add in the switch value ( *2)"),
				  (I386_Assembly.OPCODE
				  (I386_Assembly.jmp,
				   [I386_Assembly.r_m32(I386_Assembly.INL I386Types.global)]),
				   absent,
				   "jump into table")],
				 [],
				 block_list,
				 (tag, make_branches(tag_list, [])) :: final_result,
				 stack_drop, param_slots, false)
			      end)
			    | _ => Crash.impossible"SWITCH followed by instructions")
		| MirTypes.ALLOCATE_STACK(allocate, reg_operand, alloc_size,
					  SOME fp_offset) =>
		  let
		    val _ =
		      if alloc_size + fp_offset > gc_stack_alloc_size then
			Crash.impossible("Stack allocation of " ^
					 Int.toString alloc_size ^
					 " at offset " ^
					 Int.toString fp_offset ^
					 " requested, in total area of only " ^
					 Int.toString
					 gc_stack_alloc_size)
		      else()
		  in
		    case allocate of
		      MirTypes.ALLOC =>
			let
			  val needs_spare = reg_operand_is_spill reg_operand
			  val (rd, opcode_list) =
			    if needs_spare then
			      (I386Types.global,
			       MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					      MirTypes.GP_GC_REG MirRegisters.global) ::
			       opcode_list)
			    else
			      (lookup_reg_operand reg_operand, opcode_list)
			  val offset =
			    frame_size + stack_drop + param_slots + Tags.PAIRPTR -
			    (gc_stack_alloc_offset +
			     4 * (fp_offset + alloc_size))
			in
			  ([(I386_Assembly.OPCODE
			     (I386_Assembly.lea,
			      [I386_Assembly.r32 rd,
			       I386_Assembly.r_m32
			       (I386_Assembly.INR
				(I386_Assembly.MEM
				 {base=SOME I386Types.sp,
				  index=absent,
				  offset=SOME(I386_Assembly.SMALL offset)}))]),
			     absent, "get pointer into stack")],
			  opcode_list, block_list, final_result, stack_drop, param_slots, false)
			end
		    | _ => Crash.impossible"ALLOCATE_STACK strange allocate"
		  end
		 | MirTypes.ALLOCATE_STACK _ =>
		     Crash.impossible"ALLOCATE_STACK with no offset"
		 | MirTypes.DEALLOCATE_STACK _ =>
		     ([], opcode_list, block_list, final_result, stack_drop, param_slots, false)

		 | MirTypes.ALLOCATE(allocate, reg_operand, gp_operand) =>
		     let
		       val needs_temp = reg_operand_is_spill reg_operand
		       val rd =
			 if needs_temp then
			   I386Types.global
			 else
			   lookup_reg_operand reg_operand
                       val gc_entry =
			 4 *
                         (if needs_preserve then
			    Implicit_Vector.gc
			  else
			    Implicit_Vector.gc_leaf)

		       val tag1 = MirTypes.new_tag()
		       val tag2 = MirTypes.new_tag()
		       val tag3 = MirTypes.new_tag()
		     in
		       case gp_operand of
			 MirTypes.GP_IMM_INT size =>
			   let
			     val (bytes, primary, aligned, header) =
			       case allocate of
				 MirTypes.ALLOC =>
				   if size = 2 then
				     (8, Tags.PAIRPTR, true, 0)
				   else
				     (8 * ((size+2) div 2), Tags.POINTER,
				      size mod 2 <> 0, 64*size+Tags.RECORD)
                               | MirTypes.ALLOC_VECTOR =>
                                   (8 * ((size+2) div 2), Tags.POINTER,
                                    size mod 2 <> 0, 64*size+Tags.RECORD)
			       | MirTypes.ALLOC_STRING =>
				   (((size+11) div 8) * 8,
				    Tags.POINTER, true, 64*size+Tags.STRING)
			       | MirTypes.ALLOC_REAL =>
				   (case I386Types.fp_used
				      of I386Types.single   => Crash.unimplemented "ALLOC_REAL single"
				    | I386Types.extended => Crash.unimplemented "ALLOC_REAL extended"
				    | I386Types.double   =>
					(16, Tags.POINTER, true,
					 64*(16 - 4) + Tags.BYTEARRAY))
			       | MirTypes.ALLOC_REF  =>
				   (8 + 8*((size+2) div 2),
				    Tags.REFPTR, size mod 2 <> 0, 64*size+Tags.ARRAY)
			       | MirTypes.ALLOC_BYTEARRAY =>
				   (((size+12) div 8) * 8, Tags.REFPTR, true,
				    64*size+Tags.BYTEARRAY)
			     val header_code =
			       [(I386_Assembly.OPCODE
				 (I386_Assembly.jmp, [I386_Assembly.rel8 0]),
				 SOME tag3, "jump to rest of code")]
			     val header_code =
			       if header = 0 then
				 header_code
			       else
				 (I386_Assembly.OPCODE
				  (I386_Assembly.mov,
				   [I386_Assembly.r_m32
				    (I386_Assembly.INR
				     (I386_Assembly.MEM
				      {base=SOME rd,
				       index=absent,
				       offset=SOME(I386_Assembly.SMALL(~primary))})),
				    I386_Assembly.imm32(header div 4, header mod 4)]),
				  absent, "initialise header") :: header_code
			     val header_code =
			       if aligned then
				 header_code
			       else
				 (I386_Assembly.OPCODE
				  (I386_Assembly.mov,
				   [I386_Assembly.r_m32
				    (I386_Assembly.INR
				     (I386_Assembly.MEM
				      {base=SOME rd,
				       index=absent,
				       offset=SOME(I386_Assembly.SMALL(bytes - primary - 4))})),
				    I386_Assembly.imm32(0, 0)]),
				  absent, "zero unaligned extra word") :: header_code
				
			     val decrement_imm =
			       let
				 val size = bytes-primary
			       in
				 if size <= 127 then
				   I386_Assembly.imm8 size
				 else
				   I386_Assembly.imm32(size div 4, size mod 4)
			       end
			     val opcodes1 =
				[(I386_Assembly.OPCODE
				  (I386_Assembly.jmp,
				   [I386_Assembly.rel8 0]),
				  SOME tag2,
				  "branch to continuation sequence")]
			     val opcodes1 =
			       (if rd = I386Types.global andalso primary = 1 then
				  (I386_Assembly.OPCODE
				   (I386_Assembly.inc, [I386_Assembly.r32 rd]),
				   absent,
				   "special case where we can use increment")
				else
				  (I386_Assembly.OPCODE
				   (I386_Assembly.lea,
				    [I386_Assembly.r32 rd,
				     I386_Assembly.r_m32
				     (I386_Assembly.INR
				      (I386_Assembly.MEM
				       {base=SOME I386Types.global,
					index=absent,
					offset=SOME(I386_Assembly.SMALL primary)}))]),
				   absent, "produce the answer")) :: opcodes1
			     val opcodes1 =
			       (if rd = I386Types.global then
				  move_imm(I386Types.global, bytes, "amount requested")
				else
				  (* We have zero placed in rd, and so can use lea *)
				  (* This is shorter than mov *)
				  (* as we can get an eight bit displacement *)
				  (I386_Assembly.OPCODE
				   (I386_Assembly.lea,
				    [I386_Assembly.r32 I386Types.global,
				     I386_Assembly.r_m32
				     (I386_Assembly.INR
				      (I386_Assembly.MEM
				       {base=SOME rd,
					index=absent,
					offset=SOME(I386_Assembly.SMALL bytes)}))]),
				   absent, "amount requested")) ::
				  (I386_Assembly.OPCODE
				   (I386_Assembly.call,
				    [I386_Assembly.r_m32
				     (I386_Assembly.INR
				      (I386_Assembly.MEM
				       {base=SOME I386Types.implicit,
					index=absent,
					offset=SOME(I386_Assembly.SMALL gc_entry)}))]),
				   absent, "call the gc") :: opcodes1
			     val opcodes1 =
			       if rd = I386Types.global then
				 opcodes1
			       else
				 (I386_Assembly.OPCODE
				  (I386_Assembly.xor,
				   [I386_Assembly.r32 rd,
				    I386_Assembly.r_m32(I386_Assembly.INL rd)]),
				  absent, "clear bad value before gc") ::
				 opcodes1
			     val opcodes1 =
			       (I386_Assembly.OPCODE
				(I386_Assembly.add,
				 [I386_Assembly.r_m32
				  (I386_Assembly.INR
				   (I386_Assembly.MEM
				    {base=SOME I386Types.implicit,
				     index=absent,
				     offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.gc_base))})),
				  if bytes <= 127 then
				    I386_Assembly.imm8 bytes
				  else
				    I386_Assembly.imm32(bytes div 4, bytes mod 4)]),
				absent,
				"increment base pointer") ::
			       (I386_Assembly.OPCODE
				(I386_Assembly.mov,
				 [I386_Assembly.r32 rd,
				  I386_Assembly.r_m32
				  (I386_Assembly.INR
				   (I386_Assembly.MEM
				    {base=SOME I386Types.implicit,
				     index=absent,
				     offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.gc_base))}))]),
				absent,
				"acquire base pointer for result") ::
			       (I386_Assembly.OPCODE
				(I386_Assembly.cmp,
				 [I386_Assembly.r32 rd,
				  I386_Assembly.r_m32
				  (I386_Assembly.INR
				   (I386_Assembly.MEM
				    {base=SOME I386Types.implicit,
				     index=absent,
				     offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.gc_limit))}))]),
				absent,
				"check for run out of store") ::
			       (I386_Assembly.OPCODE
				(I386_Assembly.lea,
				 [I386_Assembly.r32 rd,
				  I386_Assembly.r_m32
				  (I386_Assembly.INR
				   (I386_Assembly.MEM
				    {base=SOME rd,
				     index=absent,
				     offset=SOME(I386_Assembly.SMALL(primary-bytes))}))]),
				absent, "tag pointer correctly") ::
			       (I386_Assembly.OPCODE
				(I386_Assembly.jcc I386_Assembly.below,
				 [I386_Assembly.rel8 0]), SOME tag2,
				"branch if not run out of heap") ::
			       opcodes1
			     val opcodes2 =
			       [(I386_Assembly.OPCODE
				 (I386_Assembly.sub,
				  [I386_Assembly.r_m32(I386_Assembly.INL rd),
				   decrement_imm]),
				 absent, "tag pointer correctly"),
				(I386_Assembly.OPCODE
				 (I386_Assembly.jmp,
				  [I386_Assembly.rel8 0]),
				 SOME tag2,
				 "branch to continuation sequence")]
			     val opcodes3 = header_code
			     val opcode_list =
			       if needs_temp then
				 MirTypes.UNARY(MirTypes.MOVE, reg_operand,
						MirTypes.GP_GC_REG MirRegisters.global) ::
				 opcode_list
			       else
				 opcode_list
			   in
			     (opcodes1, [], MirTypes.BLOCK(tag3, opcode_list) :: block_list,
			      (tag2, opcodes3) :: final_result,
			      stack_drop, param_slots, true)
			
			   end
		       | MirTypes.GP_GC_REG reg =>
			   let
			     val size_is_spill = gp_operand_is_spill gp_operand
			     val size_reg =
			       if size_is_spill then
				 I386Types.global
			       else
				 lookup_gp_operand gp_operand
			     val eax_is_size = size_reg = I386Types.EAX
			     val (rd_operand, mod_rd_operand) =
			       if needs_temp then
				 (I386_Assembly.INR
				  (I386_Assembly.MEM
				   {base=SOME I386Types.sp,
				    index=absent,
				    offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))}),
				  I386_Assembly.INR
				  (I386_Assembly.MEM
				   {base=SOME I386Types.sp,
				    index=absent,
				    offset=SOME (* Offset changes from push *)
				    (I386_Assembly.SMALL(4+reg_spill_value reg_operand))}))
			       else
				 (I386_Assembly.INL(lookup_reg_operand reg_operand),
				  I386_Assembly.INL(lookup_reg_operand reg_operand))
			     val rd_operand = I386_Assembly.r_m32 rd_operand
			     val mod_rd_operand = I386_Assembly.r_m32 mod_rd_operand

			     val (primary, secondary, length_code) =
			       case allocate of
				 MirTypes.ALLOC        => Crash.unimplemented "ALLOC variable size"
                               | MirTypes.ALLOC_VECTOR =>
				   (Tags.POINTER, Tags.RECORD,
				    (if size_is_spill then
				       [(I386_Assembly.OPCODE
					 (I386_Assembly.mov,
					  [I386_Assembly.r32 I386Types.global,
					   I386_Assembly.r_m32
					   (I386_Assembly.INR
					    (I386_Assembly.MEM
					     {base=SOME I386Types.sp,
					      index=absent,
					      offset=SOME
					      (I386_Assembly.SMALL(gp_spill_value gp_operand))}))]),
					 absent, "get size into a register")]
				     else
				       []) @@
				    (if needs_temp then
				       [(I386_Assembly.OPCODE
					 (I386_Assembly.mov,
					  [rd_operand,
					   I386_Assembly.r32 size_reg]),
					 absent, "move in requested length"),
					(I386_Assembly.OPCODE
					 (I386_Assembly.add,
					  [rd_operand,
					   I386_Assembly.imm8(4+7)]),
					 absent, "add in extra length for alignment")]
				     else
				       [(I386_Assembly.OPCODE
					 (I386_Assembly.lea,
					  [I386_Assembly.r32 rd,
					   I386_Assembly.r_m32
					   (I386_Assembly.INR
					    (I386_Assembly.MEM
					     {base=SOME size_reg,
					      index=absent,
					      offset=SOME(I386_Assembly.SMALL(4+7))}))]),
					 absent, "Calculate length of Vector")]))

			       | MirTypes.ALLOC_STRING =>
                                   (Tags.POINTER, Tags.STRING,
				    (if needs_temp andalso size_is_spill then
				       [(I386_Assembly.OPCODE
					 (I386_Assembly.mov,
					  [I386_Assembly.r32 I386Types.global,
					   I386_Assembly.r_m32
					   (I386_Assembly.INR
					    (I386_Assembly.MEM
					     {base=SOME I386Types.sp,
					      index=absent,
					      offset=SOME
					      (I386_Assembly.SMALL(gp_spill_value gp_operand))}))]),
					 absent, "get size into ECX"),
				       (I386_Assembly.OPCODE
					(I386_Assembly.mov,
					 [rd_operand, I386_Assembly.r32 I386Types.global]),
					absent, "and then into rd(spill)")]
				     else
				       if size_is_spill then
					 [(I386_Assembly.OPCODE
					   (I386_Assembly.mov,
					    [I386_Assembly.r32 rd,
					     I386_Assembly.r_m32
					     (I386_Assembly.INR
					      (I386_Assembly.MEM
					       {base=SOME I386Types.sp,
						index=absent,
						offset=SOME
						(I386_Assembly.SMALL(gp_spill_value gp_operand))}))]),
					   absent, "get size in rd")]
				       else
					 [(I386_Assembly.OPCODE
					   (I386_Assembly.mov,
					    [rd_operand,
					     I386_Assembly.r32
					     (lookup_gp_operand gp_operand)]),
					   absent, "get size in rd")]
				     ) @@
				       [(I386_Assembly.OPCODE
					 (I386_Assembly.shr,
					  [rd_operand, I386_Assembly.imm8 2]),
					 absent, "remove ml tag"),
					(I386_Assembly.OPCODE
					 (I386_Assembly.add,
					  [rd_operand, I386_Assembly.imm8(4+7)]),
					 absent, "allow correct number of double words")])
			       | MirTypes.ALLOC_REAL   => Crash.unimplemented "ALLOC_REAL variable size"
			       | MirTypes.ALLOC_REF    =>
				   (Tags.REFPTR, Tags.ARRAY,
				    (if size_is_spill then
				       [(I386_Assembly.OPCODE
					 (I386_Assembly.mov,
					  [I386_Assembly.r32 I386Types.global,
					   I386_Assembly.r_m32
					   (I386_Assembly.INR
					    (I386_Assembly.MEM
					     {base=SOME I386Types.sp,
					      index=absent,
					      offset=SOME
					      (I386_Assembly.SMALL(gp_spill_value gp_operand))}))]),
					 absent, "get size into a register")]
				     else
				       []) @@
				    (if needs_temp then
				       [(I386_Assembly.OPCODE
					 (I386_Assembly.mov,
					  [rd_operand,
					   I386_Assembly.r32 size_reg]),
					 absent, "move in requested length"),
					(I386_Assembly.OPCODE
					 (I386_Assembly.add,
					  [rd_operand,
					   I386_Assembly.imm8(12+7)]),
					 absent, "add in extra length for alignment")]
				     else
				       [(I386_Assembly.OPCODE
					 (I386_Assembly.lea,
					  [I386_Assembly.r32 rd,
					   I386_Assembly.r_m32
					   (I386_Assembly.INR
					    (I386_Assembly.MEM
					     {base=SOME size_reg,
					      index=absent,
					      offset=SOME(I386_Assembly.SMALL(12+7))}))]),
					 absent, "Calculate length of Array")]))
			       | MirTypes.ALLOC_BYTEARRAY =>
				   (Tags.REFPTR, Tags.BYTEARRAY,
				    (if needs_temp andalso size_is_spill then
				       [(I386_Assembly.OPCODE
					 (I386_Assembly.mov,
					  [I386_Assembly.r32 I386Types.global,
					   I386_Assembly.r_m32
					   (I386_Assembly.INR
					    (I386_Assembly.MEM
					     {base=SOME I386Types.sp,
					      index=absent,
					      offset=SOME
					      (I386_Assembly.SMALL(gp_spill_value gp_operand))}))]),
					 absent, "get size into ECX"),
				       (I386_Assembly.OPCODE
					(I386_Assembly.mov,
					 [rd_operand, I386_Assembly.r32 I386Types.global]),
					absent, "and then into rd(spill)")]
				     else
				       if size_is_spill then
					 [(I386_Assembly.OPCODE
					   (I386_Assembly.mov,
					    [I386_Assembly.r32 rd,
					     I386_Assembly.r_m32
					     (I386_Assembly.INR
					      (I386_Assembly.MEM
					       {base=SOME I386Types.sp,
						index=absent,
						offset=SOME
						(I386_Assembly.SMALL(gp_spill_value gp_operand))}))]),
					   absent, "get size in rd")]
				       else
					 [(I386_Assembly.OPCODE
					   (I386_Assembly.mov,
					    [rd_operand,
					     I386_Assembly.r32
					     (lookup_gp_operand gp_operand)]),
					   absent, "get size in rd")]
				     ) @@
				       [(I386_Assembly.OPCODE
					 (I386_Assembly.shr,
					  [rd_operand, I386_Assembly.imm8 2]),
					 absent, "remove ml tag"),
					(I386_Assembly.OPCODE
					 (I386_Assembly.add,
					  [rd_operand, I386_Assembly.imm8(4+7)]),
					 absent, "allow correct number of double words")])
			     val do_check =
			       (I386_Assembly.OPCODE
				(I386_Assembly.mov,
				 [I386_Assembly.r32 I386Types.global,
				  I386_Assembly.r_m32
				  (I386_Assembly.INR
				   (I386_Assembly.MEM
				    {base=SOME I386Types.implicit,
				     index=absent,
				     offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.gc_base))}))]),
				absent,
				"acquire base pointer for result") ::
			       (I386_Assembly.OPCODE
				(I386_Assembly.cmp,
				 [I386_Assembly.r32 I386Types.global,
				  I386_Assembly.r_m32
				  (I386_Assembly.INR
				   (I386_Assembly.MEM
				    {base=SOME I386Types.implicit,
				     index=absent,
				     offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.gc_limit))}))]),
				absent,
				"check for run out of store") ::
			       (I386_Assembly.OPCODE
				(I386_Assembly.jcc I386_Assembly.below,
				 [I386_Assembly.rel8 0]), SOME tag1,
				"branch if not run out of heap") ::
			       []
			     val do_check =
			       if needs_temp then
				 (I386_Assembly.OPCODE
				  (I386_Assembly.mov,
				   [I386_Assembly.r32 I386Types.global,
				    rd_operand]),
				  absent, "make length available in ECX") ::
				 (I386_Assembly.OPCODE
				  (I386_Assembly.add,
				   [I386_Assembly.r_m32
				    (I386_Assembly.INR
				     (I386_Assembly.MEM
				      {base=SOME I386Types.implicit,
				       index=absent,
				       offset=SOME
				       (I386_Assembly.SMALL(4*Implicit_Vector.gc_base))})),
				    I386_Assembly.r32 I386Types.global]),
				  absent,
				  "increment base pointer") ::
				 do_check
			       else
				 (I386_Assembly.OPCODE
				  (I386_Assembly.add,
				   [I386_Assembly.r_m32
				    (I386_Assembly.INR
				     (I386_Assembly.MEM
				      {base=SOME I386Types.implicit,
				       index=absent,
				       offset=SOME
				       (I386_Assembly.SMALL(4*Implicit_Vector.gc_base))})),
				    I386_Assembly.r32 rd]),
				  absent,
				  "increment base pointer") ::
				 do_check
			     val do_check =
			       (I386_Assembly.OPCODE
				(I386_Assembly.and_op,
				 [rd_operand, I386_Assembly.imm8 ~8]),
				absent, "clear bottom three bits") :: do_check
			     val tag2_jmp =
			       [(I386_Assembly.OPCODE
				 (I386_Assembly.jmp, [I386_Assembly.rel8 0]),
				 SOME tag2, "jump to continuation point")]
			     val do_gc =
			       if needs_temp then
				 (I386_Assembly.OPCODE
				  (I386_Assembly.add,
				   [I386_Assembly.r_m32(I386_Assembly.INL I386Types.global),
				    I386_Assembly.imm8 primary]),
				   absent, "tag ECX") ::
				 (I386_Assembly.OPCODE
				  (I386_Assembly.mov,
				   [rd_operand, I386_Assembly.r32 I386Types.global]),
				  absent, "store tagged pointer in spill") ::
				 tag2_jmp
			       else
				 (I386_Assembly.OPCODE
				  (I386_Assembly.lea,
				   [I386_Assembly.r32 rd,
				    I386_Assembly.r_m32
				    (I386_Assembly.INR
				     (I386_Assembly.MEM
				      {base=SOME I386Types.global,
				       index=absent,
				       offset=SOME(I386_Assembly.SMALL primary)}))]),
				  absent, "produce the answer") ::
				 tag2_jmp
			     val do_gc =
			       (I386_Assembly.OPCODE
				(I386_Assembly.mov,
				 [I386_Assembly.r32 I386Types.global, rd_operand]),
				absent, "Acquire the length in ECX") ::
			       (I386_Assembly.OPCODE
				(I386_Assembly.call,
				 [I386_Assembly.r_m32
				  (I386_Assembly.INR
				   (I386_Assembly.MEM
				    {base=SOME I386Types.implicit,
				     index=absent,
				     offset=SOME(I386_Assembly.SMALL gc_entry)}))]),
				absent, "call the gc") ::
			       do_gc
			     val opcodes1 = length_code @@ do_check @@ do_gc
			     val opcodes2 =
			       case rd_operand of
				 I386_Assembly.r_m32(I386_Assembly.INL reg) =>
				   (I386_Assembly.OPCODE
				    (I386_Assembly.lea,
				     [I386_Assembly.r32 reg,
				      I386_Assembly.r_m32
				      (I386_Assembly.INR
				       (I386_Assembly.MEM
					{base=SOME reg,
					 index=SOME(I386Types.global, absent),
					 offset=SOME(I386_Assembly.SMALL primary)}))]),
				    absent, "compute tagged pointer") ::
				   tag2_jmp
			       | _ =>
				   (I386_Assembly.OPCODE
				    (I386_Assembly.add,
				     [rd_operand, I386_Assembly.r32 I386Types.global]),
				    absent, "add in pointer") ::
				   (I386_Assembly.OPCODE
				    (I386_Assembly.add,
				     [rd_operand, I386_Assembly.imm8 primary]),
				    absent, "add in primary tag") ::
				   tag2_jmp
			     val opcodes2 =
			       (* Stuff to set up the pointer when no gc *)
			       (I386_Assembly.OPCODE
				(I386_Assembly.neg, [rd_operand]),
				absent, "negate size computed earlier") :: opcodes2
			     val tag3_jmp =
			       [(I386_Assembly.OPCODE
				 (I386_Assembly.jmp, [I386_Assembly.rel8 0]),
				 SOME tag3, "branch to rest of code")]
			     (* At this point we assume the pointer *)
			     (* is set up in the destination *)
			     (* The secondary is set up in ecx *)
			     val set_secondary_and_initialise_rest =
			       case allocate of
				 MirTypes.ALLOC_REF =>
				   let
				     val (pointer, index) =
				       if needs_temp then
					 if eax_is_size then
					   (I386Types.EBX, I386Types.global)
					 else
					   (I386Types.EAX, I386Types.global)
				       else
					 (rd, I386Types.global)
				     val offset = 9
				     val tag_jmp =
				       if needs_temp then
					 (I386_Assembly.OPCODE
					  (I386_Assembly.pop,
					   [I386_Assembly.r32 pointer]),
					  absent, "restore temporary") ::
					 tag3_jmp
				       else
					 tag3_jmp
				     val initialise_last =
				       (I386_Assembly.OPCODE
					(I386_Assembly.and_op,
					 [I386_Assembly.r_m32(I386_Assembly.INL index),
					  I386_Assembly.imm8 ~8]),
					absent, "clamp index by 8 to avoid writing off end") ::
				       (I386_Assembly.OPCODE
					(I386_Assembly.mov,
					 [I386_Assembly.r_m32
					  (I386_Assembly.INR
					   (I386_Assembly.MEM
					    {base=SOME pointer,
					     index=SOME(index, absent),
					     offset=SOME(I386_Assembly.SMALL offset)})),
					  I386_Assembly.imm32(0, 0)]),
					absent, "initialise final word in case unaligned") ::
				       tag_jmp
				     val get_index =
				       if size_is_spill then
					 let
					   val spill_value = gp_spill_value gp_operand
					   val spill_value =
					     if needs_temp then
					       spill_value+4
					     else
					       spill_value
					 in
					   (I386_Assembly.OPCODE
					    (I386_Assembly.mov,
					     [I386_Assembly.r32 index,
					      I386_Assembly.r_m32
					      (I386_Assembly.INR
					       (I386_Assembly.MEM
						{base=SOME I386Types.sp,
						 index=absent,
						 offset=SOME(I386_Assembly.SMALL spill_value)}))]),
					    absent, "get original requested size") ::
					   initialise_last
					 end
				       else
					 (I386_Assembly.OPCODE
					  (I386_Assembly.mov,
					   [I386_Assembly.r32 index,
					    I386_Assembly.r_m32
					    (I386_Assembly.INL(lookup_gp_operand gp_operand))]),
					  absent, "get original requested size") ::
					 initialise_last
				     val store_secondary =
				       (I386_Assembly.OPCODE
					(I386_Assembly.mov,
					 [I386_Assembly.r_m32
					  (I386_Assembly.INR
					   (I386_Assembly.MEM
					    {base=SOME pointer,
					     index=absent,
					     offset=SOME(I386_Assembly.SMALL(~primary))})),
					  I386_Assembly.r32 I386Types.global]),
					absent, "store the secondary tag") :: get_index
				     val get_pointer =
				       if needs_temp then
					 (I386_Assembly.OPCODE
					  (I386_Assembly.push,
					   [I386_Assembly.r32 pointer]),
					  absent, "save temporary") ::
					 (I386_Assembly.OPCODE
					  (I386_Assembly.mov,
					   [I386_Assembly.r32 pointer, mod_rd_operand]),
					  absent, "get pointer to new store") ::
					 store_secondary
				       else
					 store_secondary
				   in
				     get_pointer
				   end
			       | MirTypes.ALLOC_VECTOR =>
				   let
				     val (pointer, index) =
				       if needs_temp then
					 if eax_is_size then
					   (I386Types.EBX, I386Types.global)
					 else
					   (I386Types.EAX, I386Types.global)
				       else
					 (rd, I386Types.global)
				     val offset = ~1
				     val tag_jmp =
				       if needs_temp then
					 (I386_Assembly.OPCODE
					  (I386_Assembly.pop,
					   [I386_Assembly.r32 pointer]),
					  absent, "restore temporary") ::
					 tag3_jmp
				       else
					 tag3_jmp
				     val initialise_last =
				       (I386_Assembly.OPCODE
					(I386_Assembly.and_op,
					 [I386_Assembly.r_m32(I386_Assembly.INL index),
					  I386_Assembly.imm8 ~8]),
					absent, "clamp index by 8 to avoid writing off end") ::
				       (I386_Assembly.OPCODE
					(I386_Assembly.mov,
					 [I386_Assembly.r_m32
					  (I386_Assembly.INR
					   (I386_Assembly.MEM
					    {base=SOME pointer,
					     index=SOME(index, absent),
					     offset=SOME(I386_Assembly.SMALL offset)})),
					  I386_Assembly.imm32(0, 0)]),
					absent, "initialise final word in case unaligned") ::
				       tag_jmp
				     val get_index =
				       if size_is_spill then
					 let
					   val spill_value = gp_spill_value gp_operand
					   val spill_value =
					     if needs_temp then
					       spill_value+4
					     else
					       spill_value
					 in
					   (I386_Assembly.OPCODE
					    (I386_Assembly.mov,
					     [I386_Assembly.r32 index,
					      I386_Assembly.r_m32
					      (I386_Assembly.INR
					       (I386_Assembly.MEM
						{base=SOME I386Types.sp,
						 index=absent,
						 offset=SOME(I386_Assembly.SMALL spill_value)}))]),
					    absent, "get original requested size") ::
					   initialise_last
					 end
				       else
					 (I386_Assembly.OPCODE
					  (I386_Assembly.mov,
					   [I386_Assembly.r32 index,
					    I386_Assembly.r_m32
					    (I386_Assembly.INL(lookup_gp_operand gp_operand))]),
					  absent, "get original requested size") ::
					 initialise_last
				     val store_secondary =
				       (I386_Assembly.OPCODE
					(I386_Assembly.mov,
					 [I386_Assembly.r_m32
					  (I386_Assembly.INR
					   (I386_Assembly.MEM
					    {base=SOME pointer,
					     index=absent,
					     offset=SOME(I386_Assembly.SMALL(~primary))})),
					  I386_Assembly.r32 I386Types.global]),
					absent, "store the secondary tag") :: get_index
				     val get_pointer =
				       if needs_temp then
					 (I386_Assembly.OPCODE
					  (I386_Assembly.push,
					   [I386_Assembly.r32 pointer]),
					  absent, "save temporary") ::
					 (I386_Assembly.OPCODE
					  (I386_Assembly.mov,
					   [I386_Assembly.r32 pointer, mod_rd_operand]),
					  absent, "get pointer to new store") ::
					 store_secondary
				       else
					 store_secondary
				   in
				     get_pointer
				   end
			       | _ =>
				   let
				     (* No initialisation for byte arrays *)
				     (* or strings *)
				     val (pointer, needs_push) =
				       if needs_temp then
					 if eax_is_size then
					   (I386Types.EBX, true)
					 else
					   (I386Types.EAX, true)
				       else
					 (rd, false)
				     val tag_jmp =
				       if needs_push then
					 (I386_Assembly.OPCODE
					  (I386_Assembly.pop,
					   [I386_Assembly.r32 pointer]),
					  absent, "restore temporary") :: tag3_jmp
				       else
					 tag3_jmp
				     val store_secondary =
				       (I386_Assembly.OPCODE
					(I386_Assembly.mov,
					 [I386_Assembly.r_m32
					  (I386_Assembly.INR
					   (I386_Assembly.MEM
					    {base=SOME pointer,
					     index=absent,
					     offset=SOME(I386_Assembly.SMALL(~primary))})),
					  I386_Assembly.r32 I386Types.global]),
					absent, "store the secondary tag") ::
				       tag_jmp
				     val get_pointer =
				       if needs_temp then
					 (I386_Assembly.OPCODE
					  (I386_Assembly.push,
					   [I386_Assembly.r32 pointer]),
					  absent, "save temporary") ::
					 (I386_Assembly.OPCODE
					  (I386_Assembly.mov,
					   [I386_Assembly.r32 pointer, mod_rd_operand]),
					  absent, "get pointer to new store") ::
					 store_secondary
				       else
					 store_secondary
				   in
				     get_pointer
				   end
			     val opcodes3 =
			       (* Stuff to set the secondary tag *)
			       (I386_Assembly.OPCODE
				(I386_Assembly.mov,
				 [I386_Assembly.r32 I386Types.global,
				  I386_Assembly.r_m32
				  (if size_is_spill then
				     I386_Assembly.INR
				     (I386_Assembly.MEM
				      {base=SOME I386Types.sp,
				       index=absent,
				       offset=SOME
				       (I386_Assembly.SMALL(gp_spill_value gp_operand))})
				   else
				     I386_Assembly.INL(lookup_gp_operand gp_operand))]),
				absent, "get requested size in ECX") ::
			       (I386_Assembly.OPCODE
				(I386_Assembly.shl,
				 [I386_Assembly.r_m32(I386_Assembly.INL I386Types.global),
				  I386_Assembly.imm8 4]),
				absent, "raw number of bytes << 6") ::
			       (I386_Assembly.OPCODE
				(I386_Assembly.add,
				 [I386_Assembly.r_m32(I386_Assembly.INL I386Types.global),
				  I386_Assembly.imm8 secondary]),
				absent, "add in secondary tag") ::
			       set_secondary_and_initialise_rest
			   in
			     (opcodes1,
			      [],
			      MirTypes.BLOCK(tag3, opcode_list) :: block_list,
			      (tag2, opcodes3) :: (tag1, opcodes2) :: final_result,
			      stack_drop, param_slots, true)
			   end
		       | _ => Crash.impossible "Strange parameter to ALLOCATE"
                     end
		 | MirTypes.ADR(adr, reg_operand, tag) =>
		     (case adr of
			MirTypes.LEA =>
			  Crash.unimplemented"MirTypes.LEA"
		      (* Note that lr points to the call instruction *)
		      (* Thus lr + 4, as computed by the ADD *)
		      (* points to the ADD instruction, which is fixed *)
		      (* up during linearisation *)
		      | MirTypes.LEO =>
			  let
			    val rd =
			      if reg_operand_is_spill reg_operand then
				I386_Assembly.r_m32
				(I386_Assembly.INR
				 (I386_Assembly.MEM
				  {base=SOME I386Types.sp,
				   index=absent,
				   offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))}))
			      else
				I386_Assembly.r32(lookup_reg_operand reg_operand)
			  in
			    (([(I386_Assembly.OPCODE
			       (I386_Assembly.mov, [rd, I386_Assembly.imm32(0, 0)]),
			       SOME tag,
			       "get offset of tag from procedure start")]),
			     opcode_list, block_list, final_result, stack_drop, param_slots, false)
			  end)

                | MirTypes.INTERCEPT =>
		    (trace_dummy_instructions, opcode_list, block_list, final_result, stack_drop, param_slots, false)

                | MirTypes.INTERRUPT =>
		    let
		      val continue_tag = MirTypes.new_tag() (* Normal flow *)
		      val check_instrs =
			[(I386_Assembly.OPCODE
			  (I386_Assembly.cmp,
			   [I386_Assembly.r_m32
			    (I386_Assembly.INR
			     (I386_Assembly.MEM
			      {base=SOME I386Types.implicit,
			       index=absent,
			       offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.register_stack_limit))})),
			    I386_Assembly.imm8 ~1]),
			  absent, "Check for stack_limit ~1"),
			 (I386_Assembly.OPCODE
			  (I386_Assembly.jcc I386_Assembly.not_equal,
			   [I386_Assembly.rel8 0]),
			  SOME continue_tag,
			  "branch if no interrupt")]
		      val continue =
			[(I386_Assembly.OPCODE
			  (I386_Assembly.jmp, [I386_Assembly.rel8 0]),
			  SOME continue_tag, "continue after interrupt")]
		      val check_offset =
			if needs_preserve then
			  (* Non-leaf case *)
			  Implicit_Vector.event_check
			else
			  (* Leaf case *)
			  Implicit_Vector.event_check_leaf
		      val irupt_code =
			(I386_Assembly.OPCODE
			 (I386_Assembly.call,
			  [I386_Assembly.r_m32
			   (I386_Assembly.INR
			    (I386_Assembly.MEM
			     {base=SOME I386Types.implicit,
			      index=absent,
			      offset=SOME(I386_Assembly.SMALL(4 * check_offset))}))]),
			 absent, "do event check") :: continue
		    in
		      (check_instrs @@ irupt_code, [],
		       MirTypes.BLOCK(continue_tag, opcode_list) :: block_list,
		       final_result, stack_drop, param_slots, true)
		    end
		| MirTypes.ENTER _ =>
		    if needs_preserve then
		      let
			val spare_for_tail =
			  if stack_parms >= max_tail_size then
			    0
			  else
			    max_tail_size - stack_parms
			val gc_stack_slots =
			  gc_stack_alloc_size + gc_spill_size
			(* No FP saving yet *)
			val post_overflow_tag = MirTypes.new_tag()
			val overflow_code_tag = MirTypes.new_tag()
			val real_proc_start_tag = MirTypes.new_tag()
			val post_make_stack_tag = MirTypes.new_tag()
			val overflow_jmp =
			  [(I386_Assembly.OPCODE
			    (I386_Assembly.jcc I386_Assembly.below,
			     [I386_Assembly.rel8 0]),
			    SOME overflow_code_tag,
			    "branch if stack limit exceeded"),
			   (I386_Assembly.OPCODE
			    (I386_Assembly.jmp,
			     [I386_Assembly.rel8 0]),
			    SOME post_overflow_tag,
			    "branch to normal procedure entry code")]
			val overflow_check =
			  if frame_size > 64 then
			    (* Need to check with decrement *)
			    (I386_Assembly.OPCODE
			     (I386_Assembly.lea,
			      [I386_Assembly.r32 I386Types.global,
			       I386_Assembly.r_m32
			       (I386_Assembly.INR
				(I386_Assembly.MEM
				 {base=SOME I386Types.sp,
				  index=absent,
				  offset=SOME(I386_Assembly.SMALL(~frame_size))}))]),
			     absent, "ECX = requested new sp") ::
			    (I386_Assembly.OPCODE
			     (I386_Assembly.cmp,
			      [I386_Assembly.r32 I386Types.global,
			       I386_Assembly.r_m32
			       (I386_Assembly.INR
				(I386_Assembly.MEM
				 {base=SOME I386Types.implicit,
				  index=absent,
				  offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.register_stack_limit))}))]
			      ), absent, "compare sp with limit") ::
			    overflow_jmp
			  else
			    (* Just compare sp with limit *)
			    (I386_Assembly.OPCODE
			     (I386_Assembly.cmp,
			      [I386_Assembly.r32 I386Types.sp,
			       I386_Assembly.r_m32
			       (I386_Assembly.INR
				(I386_Assembly.MEM
				 {base=SOME I386Types.implicit,
				  index=absent,
				  offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.register_stack_limit))}))]
			      ), absent, "compare sp with limit") ::
			    overflow_jmp
			val entry_seq =
			  if spare_for_tail = 0 then
			    overflow_check
			  else
			    (* Insert space need for largest tail *)
			    let
			      val push_ret_and_check =
				(I386_Assembly.OPCODE
				 (I386_Assembly.push,
				  [I386_Assembly.r32 I386Types.global]),
				 absent, "save return address") ::
				overflow_check
			      fun save_gc_safe(n, acc) =
				if n <= 0 then
				  acc
				else
				  save_gc_safe
				  (n-1,
				   (I386_Assembly.OPCODE
				    (I386_Assembly.push,
				     [I386_Assembly.r32 I386Types.callee_closure]),
				    absent, "save a gc safe value") :: acc)
			      val save_push_ret_check =
				save_gc_safe(spare_for_tail, push_ret_and_check)
			    in
			      (I386_Assembly.OPCODE
			       (I386_Assembly.pop,
				[I386_Assembly.r32 I386Types.global]),
			       absent, "acquire return address") ::
			      save_push_ret_check
			    end
			val overflow_entry_block =
			  (overflow_code_tag,
			   [(I386_Assembly.OPCODE
			     (I386_Assembly.mov,
			      [I386_Assembly.r32 I386Types.global,
			       I386_Assembly.imm32(frame_size div 4, frame_size mod 4)]),
			     absent, "put requested frame size in global"),
			   (I386_Assembly.OPCODE
			    (I386_Assembly.call,
			     [I386_Assembly.r_m32
			      (I386_Assembly.INR
			       (I386_Assembly.MEM
				{base=SOME I386Types.implicit,
				 index=absent,
				 offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.extend))}))]),
			    absent, "call stack extension code"),
			   (I386_Assembly.OPCODE
			    (I386_Assembly.jmp, [I386_Assembly.rel8 0]),
			    SOME post_overflow_tag,
			    "continue as normal with new stack")])

                        (* Still no FP saving.  This check will catch any attempt to do so *)
                        val _ = if fp_save_size <> 0
                                  then Crash.impossible "Can't do fp saves yet"
                                else ()

                        (* And decrement sp to take account of non-gc and fp stack *)
                        val init_non_gc_stack =
                          let
                            val num_bytes = non_gc_spill_size * 4 + fp_spill_size * float_value_size
                          in
                            if num_bytes > 0
                              then [(I386_Assembly.OPCODE
                                     (I386_Assembly.sub,
                                      [I386_Assembly.r_m32(I386_Assembly.INL I386Types.sp),
                                       if num_bytes <= 127 then
                                         I386_Assembly.imm8 num_bytes
                                       else
                                         I386_Assembly.imm32
                                         (num_bytes div 4, num_bytes mod 4)]),
                                     absent, "Make room for non-gc stack area")]
                            else []
                          end

                        (* Push zeros onto stack to initialize gc stack slots *)
			val small_frame = gc_stack_slots <= 9 (* Break even point *)
			val (frame_init_a, frame_init_b) =
			  if small_frame then
			    (store_seq(gc_stack_slots-1,
				       [(I386_Assembly.OPCODE
					 (I386_Assembly.jmp, [I386_Assembly.rel8 0]),
					 SOME post_make_stack_tag,
					 "go to gc register saving")]),
			     [])
			  else
			    store_loop(post_make_stack_tag, gc_stack_slots)

			val total_frame_size =
			  frame_size+parm_space_above_ret-4
			(* Takes account of parameters *)
			(* already on the stack *)
			val opcodes =
			  [(I386_Assembly.OPCODE
			    (I386_Assembly.push,
			     [I386_Assembly.r32 I386Types.callee_closure]),
			    absent, "save caller's closure"),
			   (I386_Assembly.OPCODE
			    (I386_Assembly.lea,
			     [I386_Assembly.r32 I386Types.global,
			      I386_Assembly.r_m32
			      (I386_Assembly.INR
			       (I386_Assembly.MEM
				{base=SOME I386Types.sp,
				 index=absent,
				 offset=SOME(I386_Assembly.SMALL total_frame_size)}))]),
			    absent, "calculate old sp"),
			   (I386_Assembly.OPCODE
			    (I386_Assembly.push,
			     [I386_Assembly.r32 I386Types.global]),
			    absent, "save old sp"),
			   move_reg(I386Types.callee_closure,
				    I386Types.caller_closure, "set up closure"),
			   (I386_Assembly.OPCODE
			    (I386_Assembly.jmp, [I386_Assembly.rel8 0]),
			    SOME real_proc_start_tag,
			    "jump to start of real code")]
		      in
			(entry_seq,
			 [],
			 MirTypes.BLOCK(real_proc_start_tag, opcode_list) :: block_list,
			 (post_overflow_tag, init_non_gc_stack @@ frame_init_a) ::
			 (post_make_stack_tag, frame_init_b @@ save_gcs @@ opcodes) ::
			 overflow_entry_block :: final_result,
			 stack_drop, param_slots, true)
		      end
		    else
		      ([], opcode_list, block_list, final_result, stack_drop, param_slots, false)

		| MirTypes.RTS =>
		      let
			val ret_instr =
			  if max_args = 0 then
			    [(I386_Assembly.OPCODE
			      (I386_Assembly.ret, []), absent,
			      "Ordinary return")]
			  else
			    [(I386_Assembly.OPCODE
			      (I386_Assembly.ret,
			       [I386_Assembly.imm16(max_args*4)]),
			      absent,
			      "Ordinary return")]
		      in
			(if needs_preserve then
			   let
			     val ret_seq =
			       if frame_left = 0 then
				 ret_instr
			       else
				 (I386_Assembly.OPCODE
				  (I386_Assembly.add,
				   [I386_Assembly.r_m32(I386_Assembly.INL I386Types.sp),
				    if frame_left <= 127 then
				      I386_Assembly.imm8 frame_left
				    else
				      I386_Assembly.imm32
				      (frame_left div 4, frame_left mod 4)]),
				  absent, "junk spill and stack alloc area") ::
				 ret_instr
			   in
			     (I386_Assembly.OPCODE
			      (I386_Assembly.pop,
			       [I386_Assembly.r32 I386Types.global]),
			      absent, "throw away frame link") ::
			     (I386_Assembly.OPCODE
			      (I386_Assembly.pop,
			       [I386_Assembly.r32 I386Types.callee_closure]),
			      absent, "restore caller's closure") :: restore_gcs @@
			     ret_seq
			   end
			 else
			   ret_instr,
			   opcode_list, block_list, final_result, stack_drop, param_slots, false)
		      end
		| MirTypes.NEW_HANDLER(frame, tag) =>
		    let
		      val needs_temp = reg_operand_is_spill frame
		      val rd =
			if needs_temp then
			  I386Types.EAX
			else
			  lookup_reg_operand frame
		      val last =
			if needs_temp then
			  [(I386_Assembly.OPCODE
			    (I386_Assembly.pop,
			     [I386_Assembly.r32 rd]),
			    absent, "pop temporary of stack")]
			 else
			   []
		      val last =
			(I386_Assembly.OPCODE
			 (I386_Assembly.mov,
			  [I386_Assembly.r_m32
			   (I386_Assembly.INR
			    (I386_Assembly.MEM
			     {base=SOME I386Types.implicit,
			      index=absent,
			      offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.handler))})),
			   I386_Assembly.r32 rd]),
			 absent, "set up new handler") :: last
		      val last =
			(I386_Assembly.OPCODE
			 (I386_Assembly.mov,
			  [I386_Assembly.r32 I386Types.global,
			   I386_Assembly.r_m32
			   (I386_Assembly.INR
			    (I386_Assembly.MEM
			     {base=SOME I386Types.implicit,
			      index=absent,
			      offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.handler))}))]),
			 absent, "get handler pointer in ECX") ::
			(I386_Assembly.OPCODE
			 (I386_Assembly.mov,
			  [I386_Assembly.r_m32
			   (I386_Assembly.INR
			    (I386_Assembly.MEM
			     {base=SOME rd,
			      index=absent,
			      offset=SOME(I386_Assembly.SMALL(~1))})),
			   I386_Assembly.r32 I386Types.global]),
			 absent, "store old handler pointer in frame") ::
			last
		      val opcodes =
			if needs_temp then
			  (I386_Assembly.OPCODE
			   (I386_Assembly.push, [I386_Assembly.r32 rd]),
			   absent, "create a temporary for the handler frame pointer") ::
			  (I386_Assembly.OPCODE
			   (I386_Assembly.mov,
			    [I386_Assembly.r32 rd,
			     I386_Assembly.r_m32
			     (I386_Assembly.INR
			      (I386_Assembly.MEM
			       {base=SOME I386Types.sp,
				index=absent,
				offset=SOME(I386_Assembly.SMALL(reg_spill_value frame + 4))}))]),
			   absent, "get handler frame pointer in register") ::
			  last
			else
			  last
		    in
		      (opcodes, opcode_list, block_list, final_result, stack_drop, param_slots, false)
		    end
		| MirTypes.OLD_HANDLER =>
		    ([(I386_Assembly.OPCODE
		       (I386_Assembly.mov,
			[I386_Assembly.r32 I386Types.global,
			 I386_Assembly.r_m32
			 (I386_Assembly.INR
			  (I386_Assembly.MEM
			   {base=SOME I386Types.implicit,
			    index=absent,
			    offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.handler))}))]),
		       absent, "get pointer to handler vector"),
		      (I386_Assembly.OPCODE
		       (I386_Assembly.mov,
			[I386_Assembly.r32 I386Types.global,
			 I386_Assembly.r_m32
			 (I386_Assembly.INR
			  (I386_Assembly.MEM
			   {base=SOME I386Types.global,
			    index=absent,
			    offset=SOME(I386_Assembly.SMALL(~1))}))]),
		       absent, "get pointer to old handler vector"),
		      (I386_Assembly.OPCODE
		       (I386_Assembly.mov,
			[I386_Assembly.r_m32
			 (I386_Assembly.INR
			  (I386_Assembly.MEM
			   {base=SOME I386Types.implicit,
			    index=absent,
			    offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.handler))})),
			 I386_Assembly.r32 I386Types.global]),
		       absent, "and set up as current handler")],
		    opcode_list, block_list, final_result, stack_drop, param_slots, false)
		| MirTypes.RAISE reg =>
		    let
		      val vector =
			4 *
			(if needs_preserve then
			   Implicit_Vector.raise_code
			 else
			   Implicit_Vector.leaf_raise_code)
		      val (arg, move_needed) =
			if reg_operand_is_spill reg then
			  let
			    val spill = reg_spill_value reg
			  in
			    (I386_Assembly.INR
			     (I386_Assembly.MEM
			      {base=SOME I386Types.sp,
			       index=absent,
			       offset=SOME(I386_Assembly.SMALL spill)}), true)
			  end
			else
			  let
			    val arg = lookup_reg_operand reg
			  in
			    if arg = I386Types.caller_arg then
			      (I386_Assembly.INL arg, false)
			    else
			      (I386_Assembly.INL arg, true)
			  end
		      val code =
			[(I386_Assembly.OPCODE
			  (I386_Assembly.call,
			   [I386_Assembly.r_m32
			    (I386_Assembly.INR
			     (I386_Assembly.MEM
			      {base=SOME I386Types.implicit,
			       index=absent,
			       offset=SOME(I386_Assembly.SMALL vector)}))]),
			  absent, "raise")]
		      val code =
			if move_needed then
			  (I386_Assembly.OPCODE
			   (I386_Assembly.mov,
			    [I386_Assembly.r32 I386Types.caller_arg,
			     I386_Assembly.r_m32 arg]),
			   absent, "get raise argument") :: code
			else
			  code
		     in
		       (code, opcode_list, block_list, final_result, stack_drop, param_slots, false)
		    end
		| MirTypes.COMMENT string =>
		    Crash.impossible"MirTypes.COMMENT not filtered out"
		| MirTypes.CALL_C =>
		    ([(I386_Assembly.OPCODE
		       (I386_Assembly.call,
			[I386_Assembly.r_m32
			 (I386_Assembly.INR
			  (I386_Assembly.MEM
			   {base=SOME I386Types.implicit,
			    index=absent,
			    offset=SOME(I386_Assembly.SMALL(4*Implicit_Vector.external))}))]),
		       absent, "Do call_c")],
		    opcode_list, block_list, final_result, stack_drop, param_slots, false)
		) handle
		   bad_spill s =>
		     Crash.impossible(s ^ " in opcode '" ^ MirPrint.opcode opcode ^
				      "'\n")
	    in
	      do_everything
	      (needs_preserve, tag, opcode_list, new_stack_drop,
	       new_param_slots,
	       Sexpr.CONS(done, Sexpr.ATOM result_list), new_blocks,
	       new_final_result, stack_drop_ok)
	    end

	in
	  do_everything(needs_preserve, tag, Lists.filter_outp is_comment opcodes, 0, 0,
			Sexpr.NIL, rest, [], false)
	end

      (* Some stuff to do with optimising unconditional branches to returns *)

      fun exit_block [] = NONE
	| exit_block((block as MirTypes.BLOCK(tag, opcode_list)) :: rest) =
	if Lists.exists
	  (fn MirTypes.RTS => true | _ => false)
	  opcode_list
	  then SOME block
	else exit_block rest

      fun small_exit_block(MirTypes.BLOCK(tag,opcode_list)) =
        let
          fun less_than_three_opcodes_that_are_not_comments([],occ) = true
            | less_than_three_opcodes_that_are_not_comments(MirTypes.COMMENT _ :: rest,occ) =
              less_than_three_opcodes_that_are_not_comments(rest,occ)
            | less_than_three_opcodes_that_are_not_comments(_,2) = false
            | less_than_three_opcodes_that_are_not_comments(h::t,occ) =
              less_than_three_opcodes_that_are_not_comments(t,occ+1)
        in
          less_than_three_opcodes_that_are_not_comments(opcode_list,0)
        end

      fun append_small_exit(MirTypes.BLOCK(tag, opcode_list), block_list) =
	let
	  fun do_block(block as MirTypes.BLOCK(tag', opc_list)) =
	    if Lists.exists
	      (fn (MirTypes.BRANCH(MirTypes.BRA, MirTypes.TAG t)) => tag = t
	      | _ => false)
	      opc_list then
	      (* Difficult case. Append the exit block onto the block *)
	      (* branching to it, and remove the branch and tag *)
	      let
		val opc' = rev opc_list
		fun get_new_opc_list((comm as MirTypes.COMMENT _) :: rest) =
		  comm :: get_new_opc_list rest
		| get_new_opc_list(MirTypes.BRANCH(MirTypes.BRA,
						   MirTypes.TAG t) ::
				   rest) =
		  if t = tag then rest
		  else
		    Crash.impossible"get_new_opc fails to find proper branch"
		| get_new_opc_list _ =
		  Crash.impossible"get_new_opc fails to find proper branch"
		val new_opc = get_new_opc_list opc'
		fun rev_app([], x) = x
		  | rev_app(y, []) = y
		  | rev_app(y :: ys, x) = rev_app(ys, y :: x)
	      in
		MirTypes.BLOCK(tag', rev_app(new_opc, opcode_list))
	      end
	    else
	      block
	in
	  map do_block block_list
	end

      fun lookup_entry_block(proc_tag, []) =
	Crash.impossible"i386_cg: no entry block found"
	| lookup_entry_block(proc_tag,
			     MirTypes.BLOCK(tag, instrs) :: blocks) =
	if proc_tag = tag then
	  instrs
	else
	  lookup_entry_block(proc_tag, blocks)

      fun proc_cg(MirTypes.PROC
		  (procedure_name,
                   proc_tag, MirTypes.PROC_PARAMS
		   {spill_sizes, stack_allocated, old_spill_sizes},
		   block_list,runtime_env)) =
	let
	  fun find_stack_parms [] =
	    Crash.impossible"i386_cg: no entry block found"
	    | find_stack_parms(MirTypes.ENTER list :: _) =
	    (case list of
	       MirTypes.GC gc :: rest =>
		 if gc = MirRegisters.callee_arg then
		   rest
		 else
		   Crash.impossible("i386_cg: first arg is not callee_arg in " ^
				    procedure_name)
	     | _ => [])
	    | find_stack_parms(MirTypes.COMMENT _ :: instrs) =
	    find_stack_parms instrs
	    | find_stack_parms _ =
	    Crash.impossible"i386_cg: ENTER missing from start of entry block"

	  val exit_block = exit_block block_list

	  val block_list =
	    case exit_block of
	      NONE => block_list
	    | SOME exit_block =>
		if small_exit_block exit_block then
		  append_small_exit(exit_block, block_list)
		else
		  block_list

	  fun define_fp(map, MirTypes.FP_REG fp) =
	    case MirTypes.FP.Map.tryApply'(map, fp) of
	      NONE => MirTypes.FP.Map.define(map, fp, true)
	    | _ => map

	  fun get_fps_from_opcode(map, MirTypes.TBINARYFP(_, _, fp1, fp2, fp3)) =
	    define_fp(define_fp(define_fp(map, fp1), fp2), fp3)
	    | get_fps_from_opcode(map, MirTypes.TUNARYFP(_, _, fp1, fp2)) =
	      define_fp(define_fp(map, fp1), fp2)
	    | get_fps_from_opcode(map, MirTypes.BINARYFP(_, fp1, fp2, fp3)) =
	      define_fp(define_fp(define_fp(map, fp1), fp2), fp3)
	    | get_fps_from_opcode(map, MirTypes.UNARYFP(_, fp1, fp2)) =
	      define_fp(define_fp(map, fp1), fp2)
	    | get_fps_from_opcode(map, MirTypes.STOREFPOP(_, fp1, _, _)) =
	      define_fp(map, fp1)
	    | get_fps_from_opcode(map, MirTypes.REAL(_, fp1, _)) =
	      define_fp(map, fp1)
	    | get_fps_from_opcode(map, MirTypes.FLOOR(_, _, _, fp1)) =
	      define_fp(map, fp1)
	    | get_fps_from_opcode(map, MirTypes.FTEST(_, _, fp1, fp2)) =
	      define_fp(define_fp(map, fp1), fp2)
	    | get_fps_from_opcode(map, _) = map

	  fun get_fps_from_block(map, MirTypes.BLOCK(_, instr_list)) =
	    Lists.reducel get_fps_from_opcode (map, instr_list)

	  val fp = MirTypes.FP.Map.domain(Lists.reducel get_fps_from_block (MirTypes.FP.Map.empty, block_list))

	  fun define_gc(map, MirTypes.GC_REG r) =
	    (case MirTypes.GC.Map.tryApply'(map, r) of
	       NONE => MirTypes.GC.Map.define(map, r, true)
	     | _ => map)
	    | define_gc(map, _) = map

	  fun define_gp(map, MirTypes.GP_GC_REG r) =
	    (case MirTypes.GC.Map.tryApply'(map, r) of
	       NONE => MirTypes.GC.Map.define(map, r, true)
	     | _ => map)
	    | define_gp(map, _) = map

	  fun define_bl_dest(map, MirTypes.REG r) = define_gc(map, r)
	    | define_bl_dest(map, _) = map

	  fun get_gcs_from_opcode(map, MirTypes.TBINARY(_, _, rd, g1, g2)) =
	    define_gp(define_gp(define_gc(map, rd), g1), g2)
	    | get_gcs_from_opcode(map, MirTypes.BINARY(_, rd, g1, g2)) =
	      define_gp(define_gp(define_gc(map, rd), g1), g2)
	    | get_gcs_from_opcode(map, MirTypes.UNARY(_, rd, g)) =
	      define_gp(define_gc(map, rd), g)
	    | get_gcs_from_opcode(map, MirTypes.NULLARY(_, rd)) =
	      define_gc(map, rd)
	    | get_gcs_from_opcode(map, MirTypes.TBINARYFP _) = map
	    | get_gcs_from_opcode(map, MirTypes.TUNARYFP _) = map
	    | get_gcs_from_opcode(map, MirTypes.BINARYFP _) = map
	    | get_gcs_from_opcode(map, MirTypes.UNARYFP _) = map
	    | get_gcs_from_opcode(map, MirTypes.STACKOP(_, rd, _)) =
	      define_gc(map, rd)
	    | get_gcs_from_opcode(map, MirTypes.STOREOP(_, rd, rs, g)) =
	      define_gp(define_gc(define_gc(map, rd), rs), g)
	    | get_gcs_from_opcode(map, MirTypes.IMMSTOREOP(_, g, rs, g')) =
	      define_gp(define_gc(define_gp(map, g'), rs), g)
	    | get_gcs_from_opcode(map, MirTypes.STOREFPOP(_, _, rs, g)) =
	      define_gp(define_gc(map, rs), g)
	    | get_gcs_from_opcode(map, MirTypes.REAL(_, _, g)) =
	      define_gp(map, g)
	    | get_gcs_from_opcode(map, MirTypes.FLOOR(_, _, rd, _)) =
	      define_gc(map, rd)
	    | get_gcs_from_opcode(map, MirTypes.BRANCH(_, dest)) =
	      define_bl_dest(map, dest)
	    | get_gcs_from_opcode(map, MirTypes.TEST(_, _, g1, g2)) =
	      define_gp(define_gp(map, g1), g2)
	    | get_gcs_from_opcode(map, MirTypes.FTEST _) = map
	    | get_gcs_from_opcode(map, MirTypes.BRANCH_AND_LINK(_, dest, _, _)) =
	      define_bl_dest(map, dest)
	    | get_gcs_from_opcode(map, MirTypes.TAIL_CALL(_, dest, _)) =
	      define_bl_dest(map, dest)
	    | get_gcs_from_opcode(map, MirTypes.CALL_C) = map
	    | get_gcs_from_opcode(map, MirTypes.SWITCH(_, rs, _)) =
	      define_gc(map, rs)
	    | get_gcs_from_opcode(map, MirTypes.ALLOCATE(_, rd, g)) =
	      define_gp(define_gc(map, rd), g)
	    | get_gcs_from_opcode(map, MirTypes.ALLOCATE_STACK(_, rd, _, _)) =
	      define_gc(map, rd)
	    | get_gcs_from_opcode(map, MirTypes.DEALLOCATE_STACK _) = map
	    | get_gcs_from_opcode(map, MirTypes.ADR(_, rd, _)) =
	      define_gc(map, rd)
	    | get_gcs_from_opcode(map, MirTypes.INTERCEPT) = map
	    | get_gcs_from_opcode(map, MirTypes.INTERRUPT) = map
	    | get_gcs_from_opcode(map, MirTypes.ENTER _) = map
	    | get_gcs_from_opcode(map, MirTypes.RTS) = map
	    | get_gcs_from_opcode(map, MirTypes.NEW_HANDLER _) = map
	    | get_gcs_from_opcode(map, MirTypes.OLD_HANDLER) = map
	    | get_gcs_from_opcode(map, MirTypes.RAISE rd) =
	      define_gc(map, rd)
	    | get_gcs_from_opcode(map, MirTypes.COMMENT _) = map

	  fun get_gcs_from_block(map, MirTypes.BLOCK(_, instr_list)) =
	    Lists.reducel get_gcs_from_opcode (map, instr_list)

	  val gc = MirTypes.GC.Map.domain(Lists.reducel get_gcs_from_block (MirTypes.GC.Map.empty, block_list))

	  val fp' =
	    Lists.reducel
	    (fn (acc, r) =>
	     case MirTypes.FP.Map.tryApply'(fp_map, r) of
	       SOME x => x :: acc
	     | _ => acc)
	    ([], fp)

	  val gc' =
	    Lists.reducel
	    (fn (acc, r) =>
	     case MirTypes.GC.Map.tryApply'(gc_map, r) of
	       SOME x => x :: acc
	     | _ => acc)
	    ([], gc)

	  val fps = Set.list_to_set fp'
	  val gcs = Set.list_to_set gc'

	  val fps_to_preserve =
	    Set.set_to_list(Set.setdiff(fps,
					#fp MachSpec.corrupted_by_callee))
	
	  val fp_save_size = length fps_to_preserve

	  exception NeedsFrame

	  fun check_instr(MirTypes.BRANCH_AND_LINK _) = true
	    | check_instr MirTypes.CALL_C = true
	    | check_instr(MirTypes.SWITCH _) = true
            | check_instr(MirTypes.NEW_HANDLER _) = true
	    | check_instr(MirTypes.ADR _) = true
(* Warning. If we ever make a leaf adr, we must ensure *)
(* handler continuations are done safely. This is not currently *)
(* true since they use o1 as the address. *)
(* This comment is incorrect for the intel, but the conclusion may still hold *)
            | check_instr(MirTypes.STACKOP _) = true
	    | check_instr(MirTypes.ALLOCATE _) = true
	    | check_instr(MirTypes.ALLOCATE_STACK _) = true
	    | check_instr _ = false

	  fun check_instr_block(MirTypes.BLOCK(_, instr_list)) =
	    Lists.exists check_instr instr_list

	  val stack_extra =
            case stack_allocated of
	    SOME stack_extra => stack_extra
	  | _ =>  Crash.impossible"Stack size missing to mach_cg"

	  fun check_reg I386Types.EAX = raise NeedsFrame
	    | check_reg I386Types.EBX = ()
	    | check_reg I386Types.ECX = ()
	    | check_reg I386Types.EDX = raise NeedsFrame
	    | check_reg I386Types.ESP = raise NeedsFrame
	    | check_reg I386Types.EBP = ()
	    | check_reg I386Types.EDI = raise NeedsFrame
	    | check_reg I386Types.ESI = ()
	    (* We let this one through because *)
	    (* it's used by the local variable debugger *)
	    | check_reg I386Types.i_arg1 = ()
	    | check_reg I386Types.i_arg2 = ()
	    | check_reg I386Types.i_arg3 = ()
	    | check_reg I386Types.i_arg4 = ()
	    | check_reg I386Types.i_arg5 = ()
	    | check_reg I386Types.i_arg6 = ()
	    | check_reg I386Types.i_arg7 = ()
	    | check_reg I386Types.o_arg1 = raise NeedsFrame
	    | check_reg I386Types.o_arg2 = raise NeedsFrame
	    | check_reg I386Types.o_arg3 = raise NeedsFrame
	    | check_reg I386Types.o_arg4 = raise NeedsFrame
	    | check_reg I386Types.o_arg5 = raise NeedsFrame
	    | check_reg I386Types.o_arg6 = raise NeedsFrame
	    | check_reg I386Types.o_arg7 = raise NeedsFrame
	    | check_reg I386Types.stack = raise NeedsFrame
	    | check_reg x = Crash.impossible("check_reg:bad register " ^
					     I386Types.reg_to_string x)

	  fun check_gc_reg r =
	    case MirTypes.GC.Map.tryApply'(gc_map, r) of
	      SOME x => check_reg x
	    | _ => raise NeedsFrame

	  fun check_non_gc_reg r =
	    case MirTypes.NonGC.Map.tryApply'(non_gc_map, r) of
	      SOME x => check_reg x
	    | _ => raise NeedsFrame

	  fun check_reg_op(MirTypes.GC_REG r) =
	    check_gc_reg r
	    | check_reg_op(MirTypes.NON_GC_REG r) =
	      check_non_gc_reg r

	  fun check_gp_op(MirTypes.GP_GC_REG r) =
	    check_gc_reg r
	    | check_gp_op(MirTypes.GP_NON_GC_REG r) =
	      check_non_gc_reg r
	    | check_gp_op(MirTypes.GP_IMM_INT _) = ()
	    | check_gp_op(MirTypes.GP_IMM_ANY _) = ()
	    | check_gp_op(MirTypes.GP_IMM_SYMB symbolic) =
	      case symbolic of
		MirTypes.GC_SPILL_SIZE => ()
	      | MirTypes.NON_GC_SPILL_SIZE => ()
	      | MirTypes.GC_SPILL_SLOT _ => raise NeedsFrame
	      | MirTypes.NON_GC_SPILL_SLOT _ => raise NeedsFrame
	      | MirTypes.FP_SPILL_SLOT _ => raise NeedsFrame

	  fun check_instr_regs(MirTypes.TBINARY(_, _, reg_op, gp_op, gp_op')) =
	    (check_reg_op reg_op;
	     check_gp_op gp_op;
	     check_gp_op gp_op')
	    | check_instr_regs(MirTypes.BINARY(_, reg_op, gp_op, gp_op')) =
	      (check_reg_op reg_op;
	       check_gp_op gp_op;
	     check_gp_op gp_op')
	    | check_instr_regs(MirTypes.UNARY(_, reg_op, gp_op )) =
	      (check_reg_op reg_op;
	       check_gp_op gp_op)
	    | check_instr_regs(MirTypes.NULLARY(_, reg_op )) =
	      (check_reg_op reg_op)
	    | check_instr_regs(MirTypes.TBINARYFP _) = ()
	    | check_instr_regs(MirTypes.TUNARYFP _) = ()
	    | check_instr_regs(MirTypes.BINARYFP _) = ()
	    | check_instr_regs(MirTypes.UNARYFP _) = ()
	    | check_instr_regs(MirTypes.STACKOP _) =
	      raise NeedsFrame
	    | check_instr_regs(MirTypes.STOREOP(_, reg_op, reg_op', gp_op)) =
	      (check_reg_op reg_op;
	       check_reg_op reg_op';
	       check_gp_op gp_op)
	    | check_instr_regs(MirTypes.IMMSTOREOP(_, gp_op, reg_op, gp_op')) =
	      (check_gp_op gp_op;
	       check_reg_op reg_op;
	       check_gp_op gp_op')
	    | check_instr_regs(MirTypes.STOREFPOP(_, _, reg_op, gp_op )) =
	      (check_reg_op reg_op;
	       check_gp_op gp_op)
	    | check_instr_regs(MirTypes.REAL _) =
	      raise NeedsFrame
	    | check_instr_regs(MirTypes.FLOOR _) =
	      raise NeedsFrame
	    | check_instr_regs(MirTypes.BRANCH(_, bl_dest )) =
	      (case bl_dest of
		 MirTypes.REG reg_op => (check_reg_op reg_op)
	       | _ => ())
	    | check_instr_regs(MirTypes.TEST(_, _, gp_op, gp_op')) =
	      (check_gp_op gp_op;
	     check_gp_op gp_op')
	    | check_instr_regs(MirTypes.FTEST _) = ()
	    | check_instr_regs(MirTypes.BRANCH_AND_LINK _) =
	      raise NeedsFrame
	    | check_instr_regs(MirTypes.TAIL_CALL(_, bl_dest, _)) =
	      (case bl_dest of
		 MirTypes.REG reg_op => (check_reg_op reg_op)
	       | _ => ())
	    | check_instr_regs(MirTypes.CALL_C) =
	      raise NeedsFrame
	    | check_instr_regs(MirTypes.SWITCH _) =
	      raise NeedsFrame
	    | check_instr_regs(MirTypes.ALLOCATE(_, reg_op, gp_op )) =
	      (check_reg_op reg_op;
	       check_gp_op gp_op)
	    | check_instr_regs(MirTypes.ALLOCATE_STACK _) =
	      raise NeedsFrame
	    | check_instr_regs(MirTypes.DEALLOCATE_STACK _) =
	      raise NeedsFrame
	    | check_instr_regs(MirTypes.ADR _) =
	      raise NeedsFrame
	    | check_instr_regs(MirTypes.INTERCEPT) = ()
	    | check_instr_regs(MirTypes.INTERRUPT) = ()
	    | check_instr_regs(MirTypes.ENTER _) = ()
	    | check_instr_regs(MirTypes.RTS) = ()
	    | check_instr_regs(MirTypes.NEW_HANDLER _) =
	      raise NeedsFrame
	    | check_instr_regs(MirTypes.OLD_HANDLER) =
	      raise NeedsFrame
	    | check_instr_regs(MirTypes.RAISE reg_op) =
	      (check_reg_op reg_op)
	    | check_instr_regs(MirTypes.COMMENT _) = ()

	  fun check_instr_block_regs(MirTypes.BLOCK(_, instr_list)) =
	    app check_instr_regs instr_list

	  (* Moved this from do_block as it's independent of block number *)
	  val spills_opt = spill_sizes

	  val (gc_spill_size, non_gc_spill_size, fp_spill_size) =
	    case spills_opt of
	      SOME{gc = gc_spill_size,
                                  non_gc = non_gc_spill_size,
                                  fp = fp_spill_size} =>
	      (gc_spill_size, non_gc_spill_size, fp_spill_size)
	     | _ => Crash.impossible"Spill sizes missing to mach_cg"

	  val needs_stack = fp_save_size <> 0 orelse fp_spill_size <> 0 orelse gc_spill_size <> 0

	  val needs_preserve =
	    (* First check that leaf optimisation is allowed *)
	    not (opt_leaf_fns) orelse
	    (* Then see if any stack has been used *)
	    stack_extra <> 0 orelse (* This should catch the big procedures easily *)
	    (* Then see if we already know about any stack usage *)
	    needs_stack orelse
	    (* Now see if any instructions force non-leaf *)
            Lists.exists check_instr_block block_list orelse
	    (* See if we use any non-leaf registers *)
	    ((app check_instr_block_regs block_list;
	      false) handle NeedsFrame => true)

          val _ =
            if generate_debug_info orelse debug_variables orelse generate_moduler
              then
                debug_map := Debugger_Types.set_proc_data (procedure_name,
                                                           not needs_preserve,
							   generate_debug_info,
                                                           runtime_env,
                                                           !debug_map)
            else ()
	  val _ =
	    if needs_preserve then ()
	    else
	      diagnostic_output 3
	      (fn _ => [procedure_name, " is leaf\n"])

	  fun compare_reg(r, s) = (#gc MachSpec.allocation_order)(r, s)

	  fun check_callee_save_reg I386Types.EAX = true
	    | check_callee_save_reg I386Types.EBX = false
	    | check_callee_save_reg I386Types.ECX = false
	    | check_callee_save_reg I386Types.EDX = true
	    | check_callee_save_reg I386Types.ESP = false
	    | check_callee_save_reg I386Types.EBP = false
	    | check_callee_save_reg I386Types.EDI = false
	    | check_callee_save_reg I386Types.ESI = false
	    (* We let this one through because *)
	    (* it's used by the local variable debugger *)
	    (* It's not a callee save though, it's converted into ESP *)
	    | check_callee_save_reg I386Types.stack = false
	    | check_callee_save_reg I386Types.i_arg1 = false
	    | check_callee_save_reg I386Types.i_arg2 = false
	    | check_callee_save_reg I386Types.i_arg3 = false
	    | check_callee_save_reg I386Types.i_arg4 = false
	    | check_callee_save_reg I386Types.i_arg5 = false
	    | check_callee_save_reg I386Types.i_arg6 = false
	    | check_callee_save_reg I386Types.i_arg7 = false
	    | check_callee_save_reg I386Types.o_arg1 = false
	    | check_callee_save_reg I386Types.o_arg2 = false
	    | check_callee_save_reg I386Types.o_arg3 = false
	    | check_callee_save_reg I386Types.o_arg4 = false
	    | check_callee_save_reg I386Types.o_arg5 = false
	    | check_callee_save_reg I386Types.o_arg6 = false
	    | check_callee_save_reg I386Types.o_arg7 = false
 	    | check_callee_save_reg x =
	    Crash.impossible("check_callee_save_reg:bad register " ^
					     I386Types.reg_to_string x)

	  fun block_needs_fp_spare(MirTypes.BLOCK(_, opc_list)) =
	    let
	      fun opc_needs_fp_spare [] = false
		| opc_needs_fp_spare(MirTypes.REAL _ :: _) = true
		| opc_needs_fp_spare(MirTypes.FLOOR _ :: _) = true
		| opc_needs_fp_spare(_ :: rest) = opc_needs_fp_spare rest
	    in
	      opc_needs_fp_spare opc_list
	    end

	  fun proc_needs_fp_spare [] = false
	    | proc_needs_fp_spare(block :: block_list) =
	      block_needs_fp_spare block orelse proc_needs_fp_spare block_list

	  val needs_fp_spare = proc_needs_fp_spare block_list

          (* Allow an extra slot if we need an fp_spare *)
	  val non_gc_spill_size =
	    if needs_fp_spare then non_gc_spill_size + 1
	    else non_gc_spill_size

	  val float_value_size = case I386Types.fp_used of
	    I386Types.single => 4
	  | I386Types.double => 8
	  | I386Types.extended => 16

	  val non_gc_stack_size =
	    non_gc_spill_size * 4 + (fp_spill_size + fp_save_size) * float_value_size

	  val callee_saves =
	    Lists.qsort compare_reg (Lists.filterp check_callee_save_reg (Set.set_to_list gcs))

          val number_of_saves = length callee_saves

	  val callee_save_area = number_of_saves + (if save_arg_for_debugging then 1 else 0)

	  val fp_spill_offset = frame_offset + non_gc_spill_size * 4
	  val fp_save_offset = fp_spill_offset + fp_spill_size * float_value_size
	  val gc_spill_offset  = frame_offset + non_gc_stack_size

	  val gc_stack_alloc_offset = gc_spill_offset + gc_spill_size * 4
          (* Offset (from top) to top of linkage and callee save area *)
	  val register_save_offset = gc_stack_alloc_offset + stack_extra * 4

	  val needs_preserve = needs_preserve orelse needs_fp_spare
	  val register_save_size = 4 * (linkage_size + callee_save_area)
	  val stack_layout =
	    PROC_STACK
	    {non_gc_spill_size = non_gc_spill_size,
	     fp_spill_size = fp_spill_size,
	     fp_save_size = fp_save_size,
	     gc_spill_size = gc_spill_size,
	     gc_stack_alloc_size = stack_extra,
	     register_save_size = register_save_size,
	     non_gc_spill_offset = frame_offset,
	     fp_spill_offset = fp_spill_offset,
	     fp_save_offset = fp_save_offset,
	     gc_spill_offset = gc_spill_offset,
	     gc_stack_alloc_offset = gc_stack_alloc_offset,
	     register_save_offset = register_save_offset,
	     allow_fp_spare_slot = needs_fp_spare,
	     float_value_size = float_value_size,
	     old_spill_sizes = case old_spill_sizes of
	       SOME old => old
	     | _ => {gc=0, non_gc=0, fp=0}
             }

(*
	  val _ = output(std_out, "In procedure " ^ procedure_name ^ "\n")
	  val _ = output(std_out, "non_gc_spill_size = " ^ Int.toString non_gc_spill_size ^ "\n")
	  val _ = output(std_out, "fp_spill_size = " ^ Int.toString fp_spill_size ^ "\n")
	  val _ = output(std_out, "fp_save_size = " ^ Int.toString fp_save_size ^ "\n")
	  val _ = output(std_out, "gc_spill_size = " ^ Int.toString gc_spill_size ^ "\n")
	  val _ = output(std_out, "gc_stack_alloc_size = " ^ Int.toString stack_extra ^ "\n")
	  val _ = output(std_out, "register_save_size = " ^ Int.toString register_save_size ^ "\n")
	  val _ = output(std_out, "non_gc_spill_offset = " ^ Int.toString frame_offset ^ "\n")
	  val _ = output(std_out, "fp_spill_offset = " ^ Int.toString fp_spill_offset ^ "\n")
	  val _ = output(std_out, "fp_save_offset = " ^ Int.toString fp_save_offset ^ "\n")
	  val _ = output(std_out, "gc_spill_offset = " ^ Int.toString gc_spill_offset ^ "\n")
	  val _ = output(std_out, "gc_stack_alloc_offset = " ^ Int.toString gc_stack_alloc_offset ^ "\n")
	  val _ = output(std_out, "register_save_offset = " ^ Int.toString register_save_offset ^ "\n")
*)

	  val stack_parm_list =
	    find_stack_parms(lookup_entry_block(proc_tag, block_list))

	  val max_tail_size =
	    Lists.reducel
	    (fn (max, MirTypes.BLOCK(_, instrs)) =>
	     Lists.reducel
	     (fn (max, MirTypes.TAIL_CALL(_, _, list)) =>
	      let
		val len = Lists.length list - 1
	      in
		if len > max then len else max
	      end
	      | (max, _) => max)
	     (max, instrs))
	    (0, block_list)

	  val stack_parms = Lists.length stack_parm_list

	  val max_args =
	    if stack_parms > max_tail_size then stack_parms else max_tail_size

	  val stack_args = (stack_parms, max_tail_size, max_args)

(*
	  val _ = print(procedure_name ^ " has " ^ Int.toString stack_parms ^
			" stacked parameters\n")
*)

	  fun coalesce block_list =
	    let
	      val block_map =
		Lists.reducel
		(fn (map, arg as MirTypes.BLOCK(tag, _)) =>
		 MirTypes.Map.define(map, tag, arg))
		(MirTypes.Map.empty, block_list)
	      datatype referenced = ONCE_AT_END of MirTypes.tag | MANY
	      fun is_comment list =
		Lists.forall
		(fn (MirTypes.COMMENT _) => true
		 | _ => false)
		list
	      fun process_instrs(map, block_tag, []) = map
		| process_instrs(map, block_tag, instr :: list) =
		let
		  val (tags, is_branch) =
		    case instr of
		      MirTypes.TBINARY(_, tag_list, _, _, _) =>
			(tag_list, false)
		    | MirTypes.TBINARYFP(_, tag_list, _, _, _) =>
			(tag_list, false)
		    | MirTypes.TUNARYFP(_, tag_list, _, _) =>
			(tag_list, false)
		    | MirTypes.FLOOR(_, tag, _, _) =>
			([tag], false)
		    | MirTypes.BRANCH(_, MirTypes.TAG tag) =>
			([tag], true)
		    | MirTypes.TEST(_, tag, _, _) =>
			([tag], false)
		    | MirTypes.FTEST(_, tag, _, _) =>
			([tag], false)
		    | MirTypes.SWITCH(_, _, tag_list) =>
			(tag_list, false)
		    | MirTypes.NEW_HANDLER(_, tag) =>
			([tag], false)
		    | _ => ([], false)
		in
		  case tags of
		    [] => process_instrs(map, block_tag, list)
		  | _ =>
		      if is_branch andalso is_comment list then
			Lists.reducel
			(fn (map, tag) =>
			 case MirTypes.Map.tryApply'(map, tag) of
			   NONE => MirTypes.Map.define(map, tag, ONCE_AT_END block_tag)
		         | _ => MirTypes.Map.define(map, tag, MANY))
			(map, tags)
		      else
			process_instrs
			(Lists.reducel
			 (fn (map, tag) =>
			  MirTypes.Map.define(map, tag, MANY))
			 (map, tags), block_tag, list)
		end

	      val ref_map =
		Lists.reducel
		(fn (map, MirTypes.BLOCK(tag, instrs)) =>
		 process_instrs(map, tag, instrs))
		(MirTypes.Map.empty, block_list)

	      fun rev_app([], x) = x
		| rev_app(y :: ys, x) = rev_app(ys, y :: x)

	      fun coalesce(instrs1, instrs2) =
		case instrs1 of
		  [] => Crash.impossible"i386_cg:colaesce: empty block"
		| (MirTypes.COMMENT _ :: rest) => coalesce(rest, instrs2)
		| (MirTypes.BRANCH(_, MirTypes.TAG tag) :: rest) =>
		    rev_app(rest, instrs2)
		| opcode :: _ =>
		    Crash.impossible("i386_cg:coalesce: opcode " ^
				     MirPrint.opcode opcode ^
				     " found at end of first coalesce block")

	      fun follow_fwd_map(arg as (map, tag)) =
		case MirTypes.Map.tryApply' arg of
		  NONE => tag
		| SOME tag' =>
		    ((*print("Following forwarding map for tag " ^
			   MirTypes.print_tag tag ^ " to " ^
			   MirTypes.print_tag tag' ^ "\n");*)
		     follow_fwd_map(map, tag'))

	      val (block_map, _) =
		MirTypes.Map.fold
		(fn ((map, fwd_map), tag, ONCE_AT_END block_tag) =>
		 let
		   val block_tag' = follow_fwd_map(fwd_map, block_tag)
(*
		   val _ =
		     print("Coalescing block " ^
			   MirTypes.print_tag block_tag ^ " and block " ^
			   MirTypes.print_tag tag ^ "\n")
*)
		   val MirTypes.BLOCK(_, instrs1) =
		     case MirTypes.Map.tryApply'(map, block_tag') of
		       SOME block => block
		     | _ => Crash.impossible("i386_cg:coalesce: block " ^
					     MirTypes.print_tag block_tag ^
					     " not in block_map")
		   val MirTypes.BLOCK(_, instrs2) =
		     case MirTypes.Map.tryApply'(map, tag) of
		       SOME block => block
		     | _ => Crash.impossible("i386_cg:coalesce: block " ^
					     MirTypes.print_tag tag ^
					     " not in block_map")

		   val new_instrs = coalesce(rev instrs1, instrs2)
		   val new_map =
		     MirTypes.Map.define(map, block_tag',
					 MirTypes.BLOCK(block_tag', new_instrs))
		   val fwd_map =
		     MirTypes.Map.define(fwd_map, tag, block_tag')
		 in
		   (MirTypes.Map.undefine(new_map, tag), fwd_map)
		 end
	         | (maps, tag, _) => maps)
		((block_map, MirTypes.Map.empty), ref_map)
	    in
	      MirTypes.Map.range block_map
	    end

	  val block_list = coalesce block_list

	  val code =
	    move_first proc_tag ([], do_blocks(needs_preserve,
                                               block_list,
                                               stack_layout,
                                               fps_to_preserve,
                                               callee_saves,
					       stack_args,
					       procedure_name))

	  val code_len =
	    Lists.reducel op +
	    (0, map (fn (_, opcodes) => length opcodes) code)

          val padded_name =
            let
              fun generate_nulls 0 = ""
                | generate_nulls n = "\000" ^ generate_nulls (n-1)
              fun normalise_to_four_bytes (x) =
                x ^ generate_nulls((4 - ((size x) mod 4)) mod 4)
            in
              normalise_to_four_bytes(procedure_name ^ "\000")
            end
	in
	  {code=(proc_tag, code),
	   non_gc_area_size=non_gc_stack_size,
           name=procedure_name,
           padded_name=padded_name,
	   leaf=not needs_preserve,
           saves=number_of_saves,
	   parms=max_args}
	end

      fun list_proc_cg proc_list =
	let
	  fun print_unscheduled_code((tag, block_list),name) =
	    let
	      fun print_block(tag, opcode_list) =
		let
		  fun print_opcode(opcode, tag_opt, comment) =
		    Print.print(
			  I386_Assembly.print opcode ^
			  (case tag_opt of
			    SOME tag =>
			       " tag " ^ MirTypes.print_tag tag
			  | NONE => " no tag") ^
			     " ; " ^ comment ^ "\n")
		in
		  (Print.print("Block tag " ^ MirTypes.print_tag tag ^ "\n");
		   map print_opcode opcode_list)
		end
	    in
	      (Print.print("Procedure entry tag " ^ MirTypes.print_tag tag ^
                           " " ^ name ^
			   "\n");
	       map print_block block_list)
	    end

	  val temp_code_list =
	    Timer.xtime
	    ("main proc_cg stage", !do_timings,
	     fn () => map proc_cg proc_list)

	  val code_list = map #code temp_code_list
          val procedure_name_list = map #name temp_code_list
	  val leaf_list = map #leaf temp_code_list
	  val stack_parameters = map #parms temp_code_list

	  val code_list' = code_list

	  val _ = diagnostic_output 3
	    (fn _ => ["Unscheduled code\n"])

	  val _ = diagnostic_output 3
	    (fn _ => (app (ignore o print_unscheduled_code)
                      (Lists.zip(code_list',procedure_name_list)) ;
		      []))

	  fun do_reschedule code_list =
	    let
	      val code_list' =
		Timer.xtime
		("rescheduling blocks", !do_timings,
		 fn () =>
		 map
		 (fn (proc_tag, proc) =>
		  (proc_tag, map
		   (fn (tag, x) => (tag, I386_Schedule.reschedule_block x))
		   proc))
		 code_list)

	      val _ = diagnostic_output 3 (fn _ => ["Rescheduled at block level, now doing proc level\n"])
	      val _ = diagnostic_output 3 (fn _ => ["Result so far\n"])
	      val _ = diagnostic_output 3 (fn _ => (app (ignore o print_unscheduled_code)
                                                    (Lists.zip(code_list',procedure_name_list)) ;
						    []))

	      val code_list'' =
		Timer.xtime
		("rescheduling procs", !do_timings,
		 fn () => map I386_Schedule.reschedule_proc code_list')
	    in
	      code_list''
	    end

	  fun print_scheduled_code (code_list) =
	    let
	      fun print_proc((proc_tag, proc),name) =
		let
		  fun print_block(tag, opcode_list) =
		    let
		      fun print_opcode(opcode, tag_opt, comment) =
			Print.print(
			      I386_Assembly.print opcode ^
			      (case tag_opt of
				 SOME tag =>
				   " tag " ^ MirTypes.print_tag tag
			       | NONE => " no tag") ^
				 " ; " ^ comment ^ "\n")
		    in
		      (Print.print("Block tag " ^ MirTypes.print_tag tag ^ " " ^ name ^ "\n");
		       map print_opcode opcode_list)
		    end
		in
		  (Print.print("Procedure tag " ^ MirTypes.print_tag proc_tag ^ "\n");
		   map print_block proc)
		end
	    in
	      map print_proc code_list
	    end

	  val _ = diagnostic_output 3 (fn _ => (["Rescheduling code\n"]))

	  val new_code_list' =
	    Timer.xtime
	    ("rescheduling", !do_timings,
	     fn () => do_reschedule code_list')

	  val _ = diagnostic_output 3 (fn _ => ["Rescheduled code\n"])
	  val _ = diagnostic_output 3 (fn _ => (ignore(print_scheduled_code (Lists.zip(new_code_list',procedure_name_list))) ;
						 []))
	  val _ = diagnostic_output 3 (fn _ => ["Linearising\n"])

	  val linear_code' =
	    Timer.xtime
	    ("linearising", !do_timings,
	     fn () => linearise_list new_code_list')

	  val nop_offsets = map find_nop_offsets linear_code'
	  val _ = diagnostic_output 3 (fn _ => ["Linearised\n"])

	  val nop_instruction =
	    I386_Opcodes.output_opcode
	    (I386_Assembly.assemble (I386_Assembly.nop_code))

	  val assemble = I386_Assembly.assemble

	  fun make_tagged_code linear_code =
            (map
	     (fn ((tag, code),{non_gc_area_size, padded_name, saves, ...}) =>
		{a_clos=Lists.assoc(tag, loc_refs),
		 b_spills=non_gc_area_size,
		 c_saves=saves,
		 d_code=
		 let
                   fun annotation_points ([],_,res) = rev res
                     | annotation_points ((inst,_)::t,count,res) =
                       (case inst of
                          I386_Assembly.AugOPCODE(_,Debugger_Types.NOP) => ()
                        | I386_Assembly.AugOPCODE (_,debug) =>
                            let
                              val unpadded_name =
                                let
                                  val s = size padded_name
                                  fun check_index to =
                                    if MLWorks.String.ordof(padded_name,to) = 0
                                      then check_index(to-1)
                                    else MLWorks.String.substring(padded_name,0,to+1)
                                in
                                  check_index (s-1)
                                  handle MLWorks.String.Substring => ""
                                       | MLWorks.String.Ord => ""
                                end
			     in
                               debug_map := Debugger_Types.add_annotation
                               (unpadded_name, count, debug,
                                !debug_map)
                            end
                        | _ => ();
                            let val outpt = I386_Opcodes.output_opcode
                                                             (assemble inst)
                             in
                               annotation_points(t,count+(size outpt),
                                                 outpt::res)
                            end)

                   val code =
                     if generate_debug_info
                       then concat (annotation_points (code,0,[]))
                     else
                       concat
                       (map
                        (fn (x, _) =>
                         I386_Opcodes.output_opcode(assemble x))
                        code)

		   fun make_nops(0, nops) = nops
		     | make_nops(n, nops) = make_nops(n-1, nop_instruction :: nops)

                   val padded_code =
                     if size code mod 8 <> 0 then
		       concat(code :: make_nops(8 - size code mod 8, []))
                     else
		       code
		 in
                   padded_code
		 end})
	       (Lists.zip(linear_code,temp_code_list)))
	      handle Lists.Assoc => Crash.impossible"Assoc tagged_code"
	    handle Lists.Assoc => Crash.impossible"Assoc tagged_code"

	  val tagged_code' = make_tagged_code linear_code'
	(* Here we have leaf_list corresponding to procedure_name_list *)
	in
	  (Code_Module.WORDSET(Code_Module.WORD_SET
			       {a_names=procedure_name_list,
				b=tagged_code',
				c_leafs=leaf_list,
				d_intercept=nop_offsets,
				e_stack_parameters=stack_parameters}),
	   Lists.zip(linear_code', procedure_name_list))
	end

      val (proc_elements, code_list) = Lists.unzip(map list_proc_cg proc_list_list)

      val _ =
        if ! print_code_size then
	  print("Normalised code size is " ^
		Int.toString
		(Lists.reducel
		 (fn(x,Code_Module.WORDSET(Code_Module.WORD_SET{b=tagged_code', ...})) =>
		  (Lists.reducel (fn (x,{d_code=y, ...}) => (size y) + x) (x,tagged_code'))
	       | _ => Crash.impossible "what the ?")
		 (0,proc_elements)) ^ "\n")
        else ()

      fun make_external_refs(con, list) =
	map (fn (x, y) => con(y, x)) list

      val ext_elements = make_external_refs(Code_Module.EXTERNAL, ext_refs)
      val ext_vars = make_external_refs(Code_Module.VAR, vars)
      val ext_exns = make_external_refs(Code_Module.EXN, exns)
      val ext_strs = make_external_refs(Code_Module.STRUCT, strs)
      val ext_funs = make_external_refs(Code_Module.FUNCT, funs)

      val module =
	Code_Module.MODULE(value_elements @@
			 proc_elements @@
			 ext_elements @@
			 ext_vars @@
			 ext_exns @@
			 ext_strs @@
			 ext_funs)
    in
     ((module, !debug_map), code_list)
    end
end
@


1.84.1.1
log
@branched from trunk for label MLW_daveb_inline_1_4_99
@
text
@a3 5
 * Revision 1.84  1998/07/14  17:17:57  jont
 * [Bug #70073]
 * Remove half word aligned pushes and pops of AX
 * during floating point sequences
 *
@


1.83
log
@[Bug #20117]
Add align directive for benefit of jump tables
@
text
@d4 4
d3014 1
a3014 1
                           [(I386_Assembly.OPCODE (I386_Assembly.push,[I386_Assembly.r16 I386Types.AX]), absent,""),
d3017 1
a3017 1
                            (I386_Assembly.OPCODE (I386_Assembly.pop,[I386_Assembly.r16 I386Types.AX]), absent,""),
d3878 1
a3878 1
                      (I386_Assembly.OPCODE (I386_Assembly.push,[I386_Assembly.r16 I386Types.AX]), absent,""),
d3882 1
a3882 1
                      (I386_Assembly.OPCODE (I386_Assembly.pop,[I386_Assembly.r16 I386Types.AX]), absent,""),
@


1.82
log
@[Bug #20109]
Modify branch size algorithm to start small
@
text
@d4 4
d1075 5
d1081 45
a1125 13
			       (* Can we shorten this and pad with nops? *)
			       val opcodes =
				 if short_range(disp+3) then
				   no_tag_full_nop ::
				   no_tag_full_nop ::
				   no_tag_full_nop ::
				   (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8(disp+3)]),
				    comment) ::
				   done
				 else
				   (I386_Assembly.OPCODE(opc, [I386_Assembly.rel32 disp]),
				    comment) ::
				   done
d1127 1
a1127 1
			       do_opcodes(rest, opcodes)
d2859 1
a2859 1
			    [operand, I386_Assembly.imm8 0xfc]),
@


1.81
log
@[Bug #20108]
Ensure LEO uses short form of mov when destination is real register
@
text
@d4 4
d575 2
a787 17
  exception bad_offset of
  MirTypes.tag * (I386_Assembly.opcode * MirTypes.tag option * string) list

  fun do_little_block(block as (tag, opcode_list)) =
    case opcode_list of
(*
      [ins,
       (I386_Assembly.BRANCH_ANNUL(I386_Assembly.BA, i), SOME tag', comm),
       _] =>
      (tag,
       [(I386_Assembly.BRANCH(I386_Assembly.BA, i), SOME tag', comm),
	 ins])
     |*) _ => block

  fun reschedule_little_blocks(proc_tag, block_list) =
    (proc_tag, map do_little_block block_list)

d831 1
a831 2
  fun short_range i = i <= 120 andalso i >= ~121
  (* We allow an extra 7 on the range in case of cross procedure branches *)
a841 2
      val new_proc_list = map reschedule_little_blocks new_proc_list

d860 1
a860 1
							    [I386_Assembly.rel32 i]),
d869 2
d872 1
a872 1
				    (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8 i]),
a873 2
				 else
				   full_opcode
d882 1
a882 1
							    [I386_Assembly.rel32 i]),
d884 1
a884 1
			    (case lookup_env tag of
d891 2
d894 1
a894 1
				      (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8 i]),
a895 2
				   else
				     full_opcode
a967 1
		(* Also assumes NOPs inserted after all control transfers *)
d970 4
a973 1
		    fun do_opcode((opcode as
d976 88
a1063 87
				   SOME tag, comment), offset) =
		      (case lookup_env tag of
			 SOME res =>
			   let
			     val disp = res + i - offset
			   (* Calculate relative to next instruction *)
			   in
			     (I386_Assembly.OPCODE(opc, [I386_Assembly.rel32 disp]),
			      comment)
			   end
		       | NONE =>
			   Crash.impossible("Assoc do_opcode:" ^
					    I386_Assembly.print_mnemonic opc))
			
		      | do_opcode((opcode as
				   I386_Assembly.OPCODE(opc as I386_Assembly.jcc _,
							[I386_Assembly.rel8 i]),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - offset
			     (* Calculate relative to next instruction *)
			       val _ =
				 if disp > 127 orelse disp < ~128 then
				   Crash.impossible
				   ("Short branch of " ^
				    Int.toString disp ^ " out of range in " ^
				    I386_Assembly.print_mnemonic opc ^ " " ^
				    MirTypes.print_tag tag ^
				    " in block with tag " ^
				    MirTypes.print_tag block_tag ^
				    ", disp = " ^
				    Int.toString disp ^
				    " res = " ^
				    Int.toString res ^
				    " i = " ^
				    Int.toString i ^
				    " offset " ^
				    Int.toString offset)
				 else
				   ()
			     in
			       (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8 disp]),
				comment)
			     end
		       | NONE =>
			   Crash.impossible("Assoc do_opcode:" ^
					    I386_Assembly.print_mnemonic opc))
			
		      | do_opcode((opcode as
				   I386_Assembly.OPCODE(opc as I386_Assembly.jcc _,
							[I386_Assembly.fix_rel32 i]),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - offset
			     (* Calculate relative to next instruction *)
			     in
			       (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8 disp]),
				comment)
			     end
		       | NONE =>
			   Crash.impossible("Assoc do_opcode:" ^
					    I386_Assembly.print_mnemonic opc))
			
		      | do_opcode((opcode as
				   I386_Assembly.OPCODE(opc as I386_Assembly.jmp,
							[I386_Assembly.rel32 i]),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - offset
			       (* Calculate relative to next instruction *)
			     in
			       (I386_Assembly.OPCODE(opc, [I386_Assembly.rel32 disp]),
				comment)
			     end
			 | NONE =>
			     Crash.impossible("Assoc do_opcode:" ^
					      I386_Assembly.print_mnemonic opc))
		      | do_opcode((opcode as
				   I386_Assembly.OPCODE(opc as I386_Assembly.jmp,
							[I386_Assembly.fix_rel32 i]),
				   SOME tag, comment), offset) =
d1065 1
a1065 9
			   SOME res =>
			     let
			       val disp = res + i - offset
			       (* Calculate relative to next instruction *)
			     in
			       (I386_Assembly.OPCODE(opc, [I386_Assembly.rel32 disp]),
				comment)
			     end
			 | NONE =>
d1067 2
a1068 7
					      I386_Assembly.print_mnemonic opc))
		      | do_opcode((opcode as
				   I386_Assembly.OPCODE(opc as I386_Assembly.jmp,
							[I386_Assembly.rel8 i]),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
d1072 9
a1080 17
			       val _ =
				 if disp > 127 orelse disp < ~128 then
				   Crash.impossible
				   ("Short branch of " ^
				    Int.toString disp ^ " out of range in " ^
				    I386_Assembly.print_mnemonic opc ^ " " ^
				    MirTypes.print_tag tag ^
				    " in block with tag " ^
				    MirTypes.print_tag block_tag ^
				    ", disp = " ^
				    Int.toString disp ^
				    " res = " ^
				    Int.toString res ^
				    " i = " ^
				    Int.toString i ^
				    " offset " ^
				    Int.toString offset)
d1082 3
a1084 1
				   ()
d1086 206
a1291 299
			       (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8 disp]),
				comment)
			     end
			 | NONE =>
			     Crash.impossible("Assoc do_opcode:" ^
					      I386_Assembly.print_mnemonic opc))

		      | do_opcode((opcode as
				   I386_Assembly.OPCODE(opc as I386_Assembly.loop,
							[I386_Assembly.rel8 i]),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - offset
			     (* Calculate relative to next instruction *)
			       val _ =
				 if disp > 127 orelse disp < ~128 then
				   Crash.impossible
				   ("Short branch of " ^
				    Int.toString disp ^ " out of range in " ^
				    I386_Assembly.print_mnemonic opc ^ " " ^
				    MirTypes.print_tag tag ^
				    " in block with tag " ^
				    MirTypes.print_tag block_tag ^
				    ", disp = " ^
				    Int.toString disp ^
				    " res = " ^
				    Int.toString res ^
				    " i = " ^
				    Int.toString i ^
				    " offset " ^
				    Int.toString offset)
				 else
				   ()
			     in
			       (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8 disp]),
				comment)
			     end
		       | NONE =>
			   Crash.impossible("Assoc do_opcode:" ^
					    I386_Assembly.print_mnemonic opc))
			
		      | do_opcode((opcode as
				   I386_Assembly.OPCODE(opc as I386_Assembly.loopz,
							[I386_Assembly.rel8 i]),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - offset
			     (* Calculate relative to next instruction *)
			       val _ =
				 if disp > 127 orelse disp < ~128 then
				   Crash.impossible
				   ("Short branch of " ^
				    Int.toString disp ^ " out of range in " ^
				    I386_Assembly.print_mnemonic opc ^ " " ^
				    MirTypes.print_tag tag ^
				    " in block with tag " ^
				    MirTypes.print_tag block_tag ^
				    ", disp = " ^
				    Int.toString disp ^
				    " res = " ^
				    Int.toString res ^
				    " i = " ^
				    Int.toString i ^
				    " offset " ^
				    Int.toString offset)
				 else
				   ()
			     in
			       (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8 disp]),
				comment)
			     end
		       | NONE =>
			   Crash.impossible("Assoc do_opcode:" ^
					    I386_Assembly.print_mnemonic opc))
			
		      | do_opcode((opcode as
				   I386_Assembly.OPCODE(opc as I386_Assembly.loopnz,
							[I386_Assembly.rel8 i]),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - offset
			     (* Calculate relative to next instruction *)
			       val _ =
				 if disp > 127 orelse disp < ~128 then
				   Crash.impossible
				   ("Short branch of " ^
				    Int.toString disp ^ " out of range in " ^
				    I386_Assembly.print_mnemonic opc ^ " " ^
				    MirTypes.print_tag tag ^
				    " in block with tag " ^
				    MirTypes.print_tag block_tag ^
				    ", disp = " ^
				    Int.toString disp ^
				    " res = " ^
				    Int.toString res ^
				    " i = " ^
				    Int.toString i ^
				    " offset " ^
				    Int.toString offset)
				 else
				   ()
			     in
			       (I386_Assembly.OPCODE(opc, [I386_Assembly.rel8 disp]),
				comment)
			     end
		       | NONE =>
			   Crash.impossible("Assoc do_opcode:" ^
					    I386_Assembly.print_mnemonic opc))
			
		      | do_opcode((opcode as
				   I386_Assembly.OPCODE(opc as I386_Assembly.call,
							[I386_Assembly.rel32 i]),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - offset
			     (* Calculate relative to next instruction *)
			     in
			       (I386_Assembly.OPCODE(opc, [I386_Assembly.rel32 disp]),
				comment)
			     end
			 | NONE =>
			     Crash.impossible("Assoc do_opcode:" ^
					      I386_Assembly.print_mnemonic opc))
		      | do_opcode((opcode as
				   I386_Assembly.OPCODE(opc as I386_Assembly.call,
							[I386_Assembly.fix_rel32 i]),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - offset
			     (* Calculate relative to next instruction *)
			     in
			       (I386_Assembly.OPCODE(opc, [I386_Assembly.rel32 disp]),
				comment)
			     end
			 | NONE =>
			     Crash.impossible("Assoc do_opcode:" ^
					      I386_Assembly.print_mnemonic opc))

		      | do_opcode((opcode as
				   I386_Assembly.OPCODE(opc as I386_Assembly.mov,
							[rd, I386_Assembly.imm32(i, j)]),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = (res + 4*i + j) - proc_offset
			     (* Must work relative to start of current proc in set *)
			     in
			       (I386_Assembly.OPCODE
				(opc, [rd, I386_Assembly.imm32(disp div 4, disp mod 4)]),
				comment)
			     end
			 | NONE => Crash.impossible "Assoc do_opcode: LEO")
		
(*
		      | do_opcode((I386_Assembly.FBRANCH(branch, i),
			       SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp =
                             fault_range((res - offset) div 4,
                                         true, branch_disp_limit)
			     in
			       (I386_Assembly.FBRANCH(branch, disp), comment)
			     end
			 | NONE =>
			     Crash.impossible"Assoc do_opcode fbranch")
		      | do_opcode((I386_Assembly.FBRANCH_ANNUL(branch, i),
			       SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp =
				 fault_range((res - offset) div 4,
					     true, branch_disp_limit)
			     in
			       (I386_Assembly.FBRANCH_ANNUL(branch, disp), comment)
			     end
			 | NONE =>
			     Crash.impossible"Assoc do_opcode fbranch_annul")
		      | do_opcode((I386_Assembly.ARITHMETIC_AND_LOGICAL
				   (I386_Assembly.ADD, rd, I386_Assembly.IMM i,
				    rs1),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - offset
			     in
			       if check_range(disp, true, arith_imm_limit) then
				 (I386_Assembly.ARITHMETIC_AND_LOGICAL
				  (I386_Assembly.ADD, rd, I386_Assembly.IMM disp,
				   rs1),
				  comment)
			       else
				 let
				   val _ =
				     diagnostic_output 3
				     (fn _ => ["Found bad LEA, substituting\n"])
				   val head_size = (offset - block_start) div 4
				   val tail = drop(1 + head_size, opcode_list)
				   (* get the opcodes after this one *)
				   val _ =
				     if rs1 = rd then
				       Crash.impossible"ADR has dest in lr"
				     else ()
				   val new_comment = comment ^ " (expanded adr)"
				   val new_tail =
				     (I386_Assembly.SetHI
				      (I386_Assembly.SETHI, rd, i),
				      SOME tag, new_comment) ::
				     (I386_Assembly.SPECIAL_ARITHMETIC
				      (I386_Assembly.ADD_AND_MASK, rd,
				       I386_Assembly.IMM(i + 4), rd),
				      SOME tag, new_comment) ::
				     (I386_Assembly.ARITHMETIC_AND_LOGICAL
				      (I386_Assembly.ADD, rd,
				       I386_Assembly.REG rd, rs1),
				      NONE, new_comment) :: tail
				 in
				   raise bad_offset
				     (block_tag,
				      copy_n(head_size, opcode_list, [], new_tail))
				 end
			     end
			 | NONE =>
			     Crash.impossible"Assoc do_opcode arith")

		      | do_opcode((I386_Assembly.SPECIAL_ARITHMETIC
				   (_, rd, I386_Assembly.IMM i, rs1),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp =
				 make_imm_fault
				 ((res + i - offset) mod 1024,
				  true, arith_imm_limit)
			     in
			       (I386_Assembly.ARITHMETIC_AND_LOGICAL
				(I386_Assembly.ADD, rd, disp, rs1),
				comment)
			     end
			 | NONE =>
			     Crash.impossible"Assoc do_opcode arith")
		      | do_opcode((I386_Assembly.SPECIAL_LOAD_OFFSET(load, rd, rn, i),
				   SOME tag, comment), _) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - proc_offset
			     (* Must work relative to start of current proc in set *)
			     in
			       case load of
				 I386_Assembly.LOAD_OFFSET_HIGH =>
				   (I386_Assembly.SetHI
				    (I386_Assembly.SETHI, rd,
				     (disp div 1024) mod (1024 * 1024 * 4)),
				    comment)
			       | I386_Assembly.LOAD_OFFSET_AND_MASK =>
				   (I386_Assembly.ARITHMETIC_AND_LOGICAL
				    (I386_Assembly.ADD, rd,
				     make_imm_fault(disp mod 1024, true, arith_imm_limit),
				     rn),
				    comment)
			     end
			 | NONE =>
			     Crash.impossible"Assoc do_opcode SPECIAL_LOAD_OFFSET")

		      | do_opcode((I386_Assembly.SetHI(_, rd, i),
				   SOME tag, comment), offset) =
			(case lookup_env tag of
			   SOME res =>
			     let
			       val disp = res + i - offset
			       val disp = (disp div 1024) mod (1024 * 1024 * 4)
			     (* Ensure positive *)
			     in
			       (I386_Assembly.SetHI(I386_Assembly.SETHI, rd, disp),
				comment)
			     end
			 | NONE =>
			     Crash.impossible"Assoc do_opcode arith")

		      | do_opcode*)
		      | do_opcode((opcode, NONE, comment), offset) =
			(opcode, comment)
		      | do_opcode _ = Crash.impossible"Bad tagged instruction"
d1296 1
a1296 1
		    (rev_map do_opcode (opcodes_and_offsets, done), next)
a1315 12
	  fun subst_bad_offset_block(proc_list, block as (tag, opcode_list)) =
	    let
	      fun remap(proc_tag, block_list) =
		(proc_tag,
		 map
		 (fn (block' as (block_tag, _)) =>
		  if block_tag = tag then block else block')
		 block_list)
	    in
	      map remap proc_list
	    end

a1317 2
	  handle bad_offset bad_offset_block =>
	    do_linearise (subst_bad_offset_block(proc_list, bad_offset_block))
d1577 1
a1577 1
	  (I386_Assembly.jmp, [I386_Assembly.rel32 0]),
d2208 1
a2208 1
				[I386_Assembly.rel32 0]),
d2273 1
a2273 1
				  [I386_Assembly.rel32 0]),
d2410 1
a2410 1
				     [I386_Assembly.rel32 0]),
d2455 1
a2455 1
				    [I386_Assembly.rel32 0]),
d2965 1
a2965 1
                              (I386_Assembly.OPCODE (I386_Assembly.jmp, [I386_Assembly.rel32 0]), SOME next_tag, "")])
d2974 1
a2974 1
                            (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.not_parity,[I386_Assembly.rel32 0]), SOME end_tag,""),
d2977 1
a2977 1
                            (I386_Assembly.OPCODE (I386_Assembly.jmp, [I386_Assembly.rel32 0]), SOME end_tag, "")],
d3572 1
a3572 1
			  (I386_Assembly.OPCODE (I386_Assembly.jmp,[I386_Assembly.rel32 0]), SOME tag2,"")])
d3576 1
a3576 1
			  (I386_Assembly.OPCODE (I386_Assembly.jmp,[I386_Assembly.rel32 0]), SOME tag,"")])
d3593 1
a3593 1
                        (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.below_or_equal,[I386_Assembly.rel32 0]), SOME tag1,""),
d3602 1
a3602 1
                        (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.above,[I386_Assembly.rel32 0]), SOME tag2,""),
d3646 1
a3646 1
			    (I386_Assembly.jmp, [I386_Assembly.rel32 0]),
d3800 1
a3800 1
			    (I386_Assembly.OPCODE(branch, [I386_Assembly.rel32 0]),
d3838 3
a3840 3
                      (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.parity,[I386_Assembly.rel32 0]), SOME cont_tag,""),
                      (I386_Assembly.OPCODE (I386_Assembly.jcc cond,[I386_Assembly.rel32 0]), SOME tag,""),
                      (I386_Assembly.OPCODE (I386_Assembly.jmp,[I386_Assembly.rel32 0]), SOME cont_tag,"")
d3908 1
a3908 1
				 [I386_Assembly.rel32 0]),
d3996 1
a3996 1
				 (I386_Assembly.jmp, [I386_Assembly.rel32 0]),
d4003 1
a4003 1
				    (I386_Assembly.jmp, [I386_Assembly.rel32 0]),
d4021 1
a4021 1
				   [I386_Assembly.rel32 0]),
d4055 1
a4055 1
				    [I386_Assembly.r_m32(I386_Assembly.INL I386Types.global),
d4189 1
a4189 1
				 (I386_Assembly.jmp, [I386_Assembly.rel32 0]),
d4232 1
a4232 1
				   [I386_Assembly.rel32 0]),
d4337 1
a4337 1
				 [I386_Assembly.rel32 0]), SOME tag2,
d4348 1
a4348 1
				  [I386_Assembly.rel32 0]),
d4593 1
a4593 1
				 [I386_Assembly.rel32 0]), SOME tag1,
d4637 1
a4637 1
				 (I386_Assembly.jmp, [I386_Assembly.rel32 0]),
d4710 1
a4710 1
				 (I386_Assembly.jmp, [I386_Assembly.rel32 0]),
d5036 1
a5036 1
			   [I386_Assembly.rel32 0]),
d5041 1
a5041 1
			  (I386_Assembly.jmp, [I386_Assembly.rel32 0]),
d5083 1
a5083 1
			     [I386_Assembly.rel32 0]),
d5088 1
a5088 1
			     [I386_Assembly.rel32 0]),
d5176 1
a5176 1
			    (I386_Assembly.jmp, [I386_Assembly.rel32 0]),
d5209 1
a5209 1
					 (I386_Assembly.jmp, [I386_Assembly.rel32 0]),
d5242 1
a5242 1
			    (I386_Assembly.jmp, [I386_Assembly.rel32 0]),
@


1.80
log
@[Bug #20107]
Modify stack overflow test to compare with small immediate
@
text
@d4 4
d5127 1
a5127 1
		     ((case adr of
d5135 5
a5139 5
			  [(I386_Assembly.OPCODE
			    (I386_Assembly.mov,
			     [I386_Assembly.r_m32
			      (if reg_operand_is_spill reg_operand then
				 I386_Assembly.INR
d5143 10
a5152 7
				   offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
			       else
				 I386_Assembly.INL(lookup_reg_operand reg_operand)),
			     I386_Assembly.imm32(0, 0)]),
			    SOME tag,
			    "get offset of tag from procedure start")]
			  ), opcode_list, block_list, final_result, stack_drop, param_slots, false)
@


1.79
log
@[Bug #30349]
Fix to avoid non-unit sequence warnings
@
text
@d4 4
d4766 1
a4766 1
				 [rd_operand, I386_Assembly.imm32(~2, 0)]),
d4874 1
a4874 1
					  I386_Assembly.imm32(~2, 0)]),
d4968 1
a4968 1
					  I386_Assembly.imm32(~2, 0)]),
d5162 1
a5162 1
			    I386_Assembly.imm32(~1, 3)]),
@


1.78
log
@[Bug #70022]
Make sure floor leaves the i387 stack in a clean state
@
text
@d4 4
d943 2
a944 2
		(fn _ => (map
			  (fn (x, y) => Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ Int.toString y ^ "\n"))
d962 2
a963 2
	    (fn _ => (map
	     (fn (x, y) => Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ Int.toString y ^ "\n"))
d6375 1
a6375 1
	    (fn _ => (map print_unscheduled_code
d6394 1
a6394 1
	      val _ = diagnostic_output 3 (fn _ => (map print_unscheduled_code
d6440 1
a6440 1
	  val _ = diagnostic_output 3 (fn _ => (print_scheduled_code (Lists.zip(new_code_list',procedure_name_list)) ;
@


1.77
log
@[Bug #70055]
Modify code generator to save argument if debugging or tracing/profiling
@
text
@d4 4
d3655 2
d3665 4
d3694 9
d3714 1
a3714 1
                        (I386_Assembly.OPCODE (I386_Assembly.push,[I386_Assembly.r16 I386Types.AX]), absent,""),
d3717 2
a3718 2
                        (I386_Assembly.OPCODE (I386_Assembly.pop,[I386_Assembly.r16 I386Types.AX]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.below_or_equal,[I386_Assembly.rel32 0]), SOME tag,""),
d3723 1
a3723 1
                        (I386_Assembly.OPCODE (I386_Assembly.push,[I386_Assembly.r16 I386Types.AX]), absent,""),
d3726 2
a3727 2
                        (I386_Assembly.OPCODE (I386_Assembly.pop,[I386_Assembly.r16 I386Types.AX]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.above,[I386_Assembly.rel32 0]), SOME tag,""),
d3754 2
a3755 1
                       opcode_list, block_list, final_result, stack_drop, param_slots, false)
@


1.76
log
@[Bug #30326]
Merge in change from MLWorks_workspace_97 branch.
@
text
@d4 4
d1491 2
a1492 1
                      Options.COMPILEROPTIONS {generate_debug_info, debug_variables, generate_moduler, opt_leaf_fns, ...},
d1507 1
a1507 1
      val save_arg_for_debugging = generate_debug_info
@


1.75
log
@[Bug #70037]
Fix single push 0 in function entry sequence
@
text
@d4 4
d19 5
d279 1
a279 1
require "../utils/timer";
@


1.74
log
@[Bug #70027]
Fix call stack chopping to use add esp, #n instead of lea esp, n[esp]
@
text
@d4 4
d1625 4
a1628 14
      fun store_seq(size, so_far) =
	if size < 0 then
	  so_far
	else
	  if size = 0 then
	    (I386_Assembly.OPCODE
	     (I386_Assembly.xor,
	      [I386_Assembly.r32 I386Types.global,
	       I386_Assembly.r_m32(I386_Assembly.INL I386Types.global)]),
	     absent, "clear global prior to storing") ::
	    (I386_Assembly.OPCODE
	     (I386_Assembly.push,
	      [I386_Assembly.r32 I386Types.global]),
	     absent, "initialise one stack slot") :: so_far
d1630 39
a1668 6
	    store_seq(size-1,
		      (I386_Assembly.OPCODE
		       (I386_Assembly.push,
			[I386_Assembly.r32 I386Types.global]),
		       absent, "initialise one stack slot") :: so_far)

d1989 3
a1991 2
		      ((*print"Generating existing stack arg\n";*)
		      frame_size + stack_drop + param_slots + 4*(max_args + looked_up_gc_reg_input_value(lookup_reg(reg', gc_array))))
d1998 2
a1999 2
			    ((*print"Generating new output parameter\n";*)
			     looked_up_gc_reg_output_value(lookup_reg(reg', gc_array)) * 4)
@


1.73
log
@[Bug #30089]
Modify TIMER (from utils) to be INTERNAL_TIMER to keep bootstrap happy
@
text
@d4 4
d4010 3
a4012 9
				 (I386_Assembly.lea,
				  [I386_Assembly.r32 I386Types.sp,
				   I386_Assembly.r_m32
				   (I386_Assembly.INR
				    (I386_Assembly.MEM
				     {base=SOME I386Types.sp,
				      index=absent,
				      offset=SOME
				      (I386_Assembly.SMALL(amount_to_drop - 4))}))]),
@


1.72
log
@[Bug #30153]
Remove references to Old.
@
text
@d4 4
d284 1
a284 1
  structure Timer : TIMER
@


1.71
log
@[Bug #30243]
Remove tests for out of range shifts as we no longer generate them
@
text
@d4 4
a275 2
require "^.basis.__old";

@


1.71.2.1
log
@branched from trunk for label MLWorks_workspace_97
@
text
@a3 4
 * Revision 1.71  1997/08/11  09:37:47  jont
 * [Bug #30243]
 * Remove tests for out of range shifts as we no longer generate them
 *
@


1.71.2.2
log
@[Bug #30326]
@
text
@a3 3
 * Revision 1.71.2.1  1997/09/11  20:53:53  daveb
 * branched from trunk for label MLWorks_workspace_97
 *
d258 1
a258 1
require "../utils/mlworks_timer";
@


1.71.1.1
log
@branched from trunk for label MLWorks_dt_wizard
@
text
@a3 4
 * Revision 1.71  1997/08/11  09:37:47  jont
 * [Bug #30243]
 * Remove tests for out of range shifts as we no longer generate them
 *
@


1.70
log
@[Bug #30215]
@
text
@d4 4
a9 1
 * [Bug #30076]
d2572 5
a2576 29
			      if shift >= 32 then
				(* Special case stuff *)
				case i_opcode of
				  I386_Assembly.shr =>
				    ([],
				     MirTypes.UNARY(MirTypes.MOVE, reg_operand,
						    MirTypes.GP_IMM_INT 0) ::
				     opcode_list, block_list, final_result,
				     stack_drop, param_slots, false)
				| I386_Assembly.sal =>
				    ([],
				     MirTypes.UNARY(MirTypes.MOVE, reg_operand,
						    MirTypes.GP_IMM_INT 0) ::
				     opcode_list, block_list, final_result,
				     stack_drop, param_slots, false)
				| I386_Assembly.sar =>
				    ((I386_Assembly.OPCODE
				      (i_opcode,
				       [operand, I386_Assembly.imm8 31]),
				      absent, "shift by immediate value") :: [],
				     opcode_list, block_list, final_result,
				     stack_drop, param_slots, false)
				| _ => Crash.impossible"mach_cg: non-shift in shift case"
			      else
				((I386_Assembly.OPCODE
				  (i_opcode,
				   [operand, I386_Assembly.imm8 shift]),
				  absent, "shift by immediate value") :: [],
				 opcode_list, block_list, final_result, stack_drop, param_slots, false)
@


1.69
log
@[Bug #30076]
[Bug #30076]
Modifications to code generate stack based argument passing
@
text
@d4 5
a1659 1
	| get_binary_op MirTypes.BIC = (I386_Assembly.not, false)
d2446 11
a2456 105
			if is_shift orelse i_opcode = I386_Assembly.not then
			  if is_shift then
			    if is_reg gp_operand' then
			      (* Nasty, all shifts controlled by CL, part of ECX *)
			      if gp_operand_is_spill gp_operand' then
				([],
				 (MirTypes.UNARY(MirTypes.MOVE,
						 MirTypes.GC_REG MirRegisters.global,
						 gp_operand')) ::
				 MirTypes.BINARY(binary_op, reg_operand, gp_operand,
						 MirTypes.GP_GC_REG MirRegisters.global) ::
				 opcode_list, block_list, final_result, stack_drop, param_slots, false)
			      else
				(* Shift amount in a register *)
				(* Must be moved to ECX *)
				let
				  val tag2 = MirTypes.new_tag()
				  val tag3 = MirTypes.new_tag()
				  val operand =
				    I386_Assembly.r_m32
				    (if reg_operand_is_spill reg_operand then
				       I386_Assembly.INR
				       (I386_Assembly.MEM
					{base=SOME I386Types.sp,
					 index=absent,
					 offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
				     else
				       I386_Assembly.INL(lookup_reg_operand reg_operand))
				  val continue =
				    [(I386_Assembly.OPCODE
				      (I386_Assembly.jmp,
				       [I386_Assembly.rel32 0]),
				      SOME tag3, "continue")]
				  val out_of_range_shift =
				    case i_opcode of
				      I386_Assembly.shr =>
					(if reg_operand_is_spill reg_operand then
					   (I386_Assembly.OPCODE
					    (I386_Assembly.mov,
					     [operand, I386_Assembly.imm32(0, 0)]),
					    absent, "clear to zero for out of range shift")
					 else
					   (I386_Assembly.OPCODE
					    (I386_Assembly.xor,
					     [I386_Assembly.r32(lookup_reg_operand reg_operand),
					      I386_Assembly.r_m32(I386_Assembly.INL(lookup_reg_operand reg_operand))]),
					    absent, "clear to zero for out of range shift")) ::
					   continue
				    | I386_Assembly.sal =>
					(if reg_operand_is_spill reg_operand then
					   (I386_Assembly.OPCODE
					    (I386_Assembly.mov,
					     [operand, I386_Assembly.imm32(0, 0)]),
					    absent, "clear to zero for out of range shift")
					 else
					   (I386_Assembly.OPCODE
					    (I386_Assembly.xor,
					     [I386_Assembly.r32(lookup_reg_operand reg_operand),
					      I386_Assembly.r_m32(I386_Assembly.INL(lookup_reg_operand reg_operand))]),
					    absent, "clear to zero for out of range shift")) ::
					   continue
				    | I386_Assembly.sar =>
					(I386_Assembly.OPCODE
					  (i_opcode,
					   [operand, I386_Assembly.imm8 31]),
					  absent, "shift by immediate value") ::
					continue
				    | _ => Crash.impossible"mach_cg: non-shift in shift case"
				  val block1 =
				    (I386_Assembly.OPCODE
				     (I386_Assembly.cmp,
				      [I386_Assembly.r_m32(I386_Assembly.INL I386Types.global),
				       I386_Assembly.imm8 31]),
				     absent, "test for shift by > 31 (unsigned)") ::
				    (I386_Assembly.OPCODE
				     (I386_Assembly.jcc(I386_Assembly.below_or_equal),
				      [I386_Assembly.rel32 0]),
				     SOME tag2, "branch if ok") ::
				    out_of_range_shift
				  val block1 =
				    let
				      val reg = lookup_gp_operand gp_operand'
				    in
				      if reg = I386Types.global then
					block1
				      else
					(I386_Assembly.OPCODE
					 (I386_Assembly.mov,
					  [I386_Assembly.r32 I386Types.global,
					   I386_Assembly.r_m32(I386_Assembly.INL reg)]),
					 absent, "put shift amount into ECX") ::
					block1
				    end
				  val block2 =
				    (I386_Assembly.OPCODE
				     (i_opcode,
				      [operand, I386_Assembly.r8 I386Types.CL]),
				     absent, "do the actual shift") :: continue
				in
				  (block1,
				   [],
				   MirTypes.BLOCK(tag3, opcode_list) :: block_list,
				   (tag2, block2) ::
				   final_result, stack_drop, param_slots, true)
				end
d2458 2
d2461 2
a2462 6
				val shift as (i, j) = assemble_imm32 gp_operand'
				val shift =
				  if i < 0 orelse i >= 8 then
				    32
				  else
				    4*i+j
d2473 6
a2478 3
			      in
				if shift >= 32 then
				  (* Special case stuff *)
d2481 12
a2492 5
				      ([],
				       MirTypes.UNARY(MirTypes.MOVE, reg_operand,
						      MirTypes.GP_IMM_INT 0) ::
				       opcode_list, block_list, final_result,
				       stack_drop, param_slots, false)
d2494 12
a2505 5
				      ([],
				       MirTypes.UNARY(MirTypes.MOVE, reg_operand,
						      MirTypes.GP_IMM_INT 0) ::
				       opcode_list, block_list, final_result,
				       stack_drop, param_slots, false)
d2507 5
a2511 6
				      ((I386_Assembly.OPCODE
					(i_opcode,
					 [operand, I386_Assembly.imm8 31]),
					absent, "shift by immediate value") :: [],
				       opcode_list, block_list, final_result,
				       stack_drop, param_slots, false)
d2513 43
d2557 36
d2598 1
a2598 51
			      end
			  else
			    (* BIC *)
			    if is_reg gp_operand' then
			      let
				val operand =
				  I386_Assembly.r_m32
				  (if gp_operand_is_spill gp_operand' then
				     I386_Assembly.INR
				     (I386_Assembly.MEM
				      {base=SOME I386Types.sp,
				       index=absent,
				       offset=SOME(I386_Assembly.SMALL(gp_spill_value gp_operand'))})
				   else
				     I386_Assembly.INL(lookup_gp_operand gp_operand'))
			      in
				([(I386_Assembly.OPCODE
				   (I386_Assembly.mov,
				    [I386_Assembly.r32 I386Types.global, operand]),
				   absent, "get BIC value into ECX"),
				  (I386_Assembly.OPCODE
				   (I386_Assembly.not,
				    [I386_Assembly.r_m32(I386_Assembly.INL I386Types.global)]),
				   absent, "invert it")],
				MirTypes.BINARY(MirTypes.AND, reg_operand, gp_operand,
						MirTypes.GP_GC_REG MirRegisters.global) ::
				opcode_list, block_list, final_result, stack_drop, param_slots, false)
			      end
			    else
			      let
				val mask as (i, j) = assemble_imm32 gp_operand'
				val new_mask as (i, j) =
				  (Bits.xorb(i, ~1),
				   Bits.xorb(j, 3))
				val operand =
				  I386_Assembly.r_m32
				  (if reg_operand_is_spill reg_operand then
				     I386_Assembly.INR
				     (I386_Assembly.MEM
				      {base=SOME I386Types.sp,
				       index=absent,
				       offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
				   else
				     I386_Assembly.INL(lookup_reg_operand reg_operand))
			      in
				([(I386_Assembly.OPCODE
				   (I386_Assembly.and_op,
				    [operand, I386_Assembly.imm32 new_mask]),
				   absent, "BIC by immediate value")],
				 opcode_list, block_list, final_result, stack_drop, param_slots, false)
			      end
a2672 1
			    | MirTypes.BIC => false
a2894 4
			val opcode_list =
			    MirTypes.BINARY(MirTypes.BIC, reg_operand,
					    gp_from_reg reg_operand,
					    MirTypes.GP_IMM_ANY 3) :: opcode_list
d2907 2
a2908 2
			   (I386_Assembly.not,
			    [operand]),
d2943 26
@


1.68
log
@[Bug #30076]
Modifications to allow stack based parameter passing on the I386
@
text
@d4 4
d350 1
a350 1
  val fpu_control_rounding_bits           = B"1111 0011 1111 1111"                
d494 1
a494 1
	 val encoding_function = 
d792 1
a792 1
  (* We allow an extra 7 on the range in case of cross procedure branches *) 
d970 1
a970 1
				    Int.toString disp ^ 
d1055 1
a1055 1
				    Int.toString disp ^ 
d1091 1
a1091 1
				    Int.toString disp ^ 
d1127 1
a1127 1
				    Int.toString disp ^ 
d1163 1
a1163 1
				    Int.toString disp ^ 
d1502 5
a1506 2
      fun get_frame_size(register_save_offset, register_save_size) =
	register_save_offset - frame_offset + register_save_size
d1524 2
a1525 1
		      }) =
a1526 2
	  val frame_size = get_frame_size(register_save_size, register_save_offset)

d1531 1
a1531 2
		val symbolic_value =
		  fn i =>
d1555 1
a1555 2
		val symbolic_value =
		  fn i =>
a1682 2
		  spills_need_init,
		  stack_need_init,
d1684 5
a1688 1
		  gcs_to_preserve
d1691 2
a1692 1
	  val frame_size = get_frame_size(register_save_size, register_save_offset)
d1717 15
d1734 1
a1734 1
	  val do_save_gcs = fn x => 
d1798 53
d1852 1
a1852 1
	    MirTypes.GC.unpack reg >= #gc(MirRegisters.pack_next)
d1856 1
a1856 1
	    MirTypes.GC.unpack reg >= #gc(MirRegisters.pack_next)
d1865 15
a1879 2
	  fun do_everything(_, tag, [], _, done, [], final_result) =
	    (tag, contract_sexpr done) :: final_result
d1881 1
a1881 1
	    (needs_preserve, tag, [], stack_drop, done,
d1883 1
a1883 1
	     final_result) =
d1886 2
a1887 1
		if stack_drop = 0 then
d1890 1
a1890 1
		  Crash.impossible"stack_drop is not zero at block end"
d1893 2
a1894 2
	      (needs_preserve, tag', Lists.filter_outp is_comment opcodes, 0, Sexpr.NIL,
	       blocks, (tag, contract_sexpr done) :: final_result)
d1896 1
d1898 2
a1899 2
	    (needs_preserve, tag, opcode :: opcode_list, stack_drop, done,
	     block_list, final_result) =
d1901 3
a1903 1
	      val symbolic_value = symb_value stack_layout
d1905 1
a1905 1
		fn x => stack_drop + symbolic_value x
d1918 10
d1938 1
a1938 1
	      fun assemble_sized_gp_imm gp_imm =
d1940 1
a1940 1
		  val (i, j) = assemble_imm32 gp_imm
d1942 26
a1967 2
		  if i <= 31 andalso i >= ~32 then
		    I386_Assembly.imm8(4*i+j)
d1969 3
a1971 1
		    I386_Assembly.imm32(i, j)
d1974 7
a1980 11
	      fun reg_spill_value(MirTypes.GC_REG reg) =
		symbolic_value
		(MirTypes.GC_SPILL_SLOT
		 (MirTypes.SIMPLE(gc_spill_start_offset + MirTypes.GC.unpack reg - #gc(MirRegisters.pack_next))))
		| reg_spill_value _ = Crash.impossible"reg_spill_value:bad argument"

	      fun gp_spill_value(MirTypes.GP_GC_REG reg) =
		symbolic_value
		(MirTypes.GC_SPILL_SLOT
		 (MirTypes.SIMPLE(gc_spill_start_offset + MirTypes.GC.unpack reg - #gc(MirRegisters.pack_next))))
		| gp_spill_value _ = Crash.impossible"gp_spill_value:bad argument"
d2000 1
d2003 1
d2018 8
d2077 1
a2077 1
		   new_stack_drop) =
d2141 1
a2141 1
			   final_result, stack_drop)
d2159 1
a2159 1
			   opcode_list, block_list, final_result, stack_drop)
d2168 1
a2168 1
			   opcode_list, block_list, final_result, stack_drop)
d2187 1
a2187 1
			   opcode_list, block_list, final_result, stack_drop)
d2274 1
a2274 1
			    final_result, stack_drop)
d2300 1
a2300 1
			   opcode_list, block_list, final_result, stack_drop)
d2315 1
a2315 1
			     opcode_list, block_list, final_result, stack_drop)
d2337 1
a2337 1
			      opcode_list, block_list, final_result, stack_drop)
d2346 1
a2346 1
			       opcode_list, block_list, final_result, stack_drop)
d2367 1
a2367 1
			 opcode_list, block_list, final_result, stack_drop)
d2376 1
a2376 1
			 opcode_list, block_list, final_result, stack_drop)
d2437 1
a2437 1
			   opcode_list, block_list, final_result, stack_drop)
d2453 1
a2453 1
				 opcode_list, block_list, final_result, stack_drop)
d2545 1
a2545 1
				   final_result, stack_drop)
d2574 1
a2574 1
				       stack_drop)
d2580 1
a2580 1
				       stack_drop)
d2587 1
a2587 1
				       stack_drop)
d2594 1
a2594 1
				 opcode_list, block_list, final_result, stack_drop)
d2621 1
a2621 1
				opcode_list, block_list, final_result, stack_drop)
d2644 1
a2644 1
				 opcode_list, block_list, final_result, stack_drop)
d2656 1
a2656 1
			     opcode_list, block_list, final_result, stack_drop)
d2706 1
a2706 1
			       opcode_list, block_list, final_result, stack_drop)
d2730 1
a2730 1
			       block_list, final_result, stack_drop)
d2791 1
a2791 1
				       block_list, final_result, stack_drop)
d2801 1
a2801 1
				     block_list, final_result, stack_drop)
d2812 1
a2812 1
			   opcode_list, block_list, final_result, stack_drop)
a2814 1

d2816 51
a2866 22
		      if reg_operand_is_spill reg_operand andalso
			gp_operand_is_spill gp_operand then
			if reg_equals_gp(reg_operand, gp_operand) then
			  ([], opcode_list, block_list, final_result, stack_drop)
			else
			  ([], MirTypes.UNARY(MirTypes.MOVE,
					      MirTypes.GC_REG MirRegisters.global,
					      gp_operand) ::
			   MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					  MirTypes.GP_GC_REG MirRegisters.global) ::
			   opcode_list, block_list, final_result, stack_drop)
		      else
			(* Not both spills case *)
			if reg_operand_is_spill reg_operand then
			  let
			    val opcode = I386_Assembly.mov
			    val spill = reg_spill_value reg_operand
			    val offset =
			      if spill = 0 then absent else SOME (I386_Assembly.SMALL spill)
			    val code_list =
			      if is_reg gp_operand then
				(* Can't be spill here *)
d2868 4
a2871 1
				  val rs1 = lookup_gp_operand gp_operand
d2873 10
a2882 10
				  [(I386_Assembly.OPCODE
				    (opcode,
				     [I386_Assembly.r_m32
				      (I386_Assembly.INR
				       (I386_Assembly.MEM
					{base=SOME I386Types.sp,
					 index=absent,
					 offset=offset})),
				      I386_Assembly.r32 rs1]),
				    absent, "")]
d2885 54
a2938 21
				[(I386_Assembly.OPCODE
				  (opcode,
				   [I386_Assembly.r_m32
				    (I386_Assembly.INR
				     (I386_Assembly.MEM
				      {base=SOME I386Types.sp,
				       index=absent,
				       offset=offset})),
				    I386_Assembly.imm32(assemble_imm32 gp_operand)]),
				  absent, "")]
			  in
			    (code_list, opcode_list, block_list, final_result, stack_drop)
			  end
			else
			  let
			    val rd = lookup_reg_operand reg_operand
			    val code_list = move_gp_to_reg(rd, gp_operand, [])
			  in
			    (code_list, opcode_list, block_list, final_result,
			     stack_drop)
			  end
d2962 1
a2962 1
			 opcode_list, block_list, final_result, stack_drop)
d2969 1
a2969 1
		       block_list, final_result, stack_drop)
d2989 1
a2989 1
			 opcode_list, block_list, final_result, stack_drop)
d2996 1
a2996 1
		       block_list, final_result, stack_drop)
d3017 1
a3017 1
                    opcode_list, block_list, final_result, stack_drop)
d3024 1
a3024 1
		    val operation = 
d3034 1
a3034 1
                     opcode_list, block_list, final_result,stack_drop)
d3064 1
a3064 1
                             final_result,stack_drop)
d3095 1
a3095 1
                           final_block :: final_result,stack_drop)
a3098 1
(*
a3101 1
                    val tag = case taglist of [] => NONE | a::_ => SOME a
d3105 1
a3105 61
		    val operation = 
                      case tagged_binary_fp_op of
                        MirTypes.FADDV => I386_Assembly.fadd
                      | MirTypes.FSUBV => I386_Assembly.fsub
                      | MirTypes.FMULV => I386_Assembly.fmul
                      | MirTypes.FDIVV => I386_Assembly.fdiv
		  in
		    ([(I386_Assembly.OPCODE (I386_Assembly.fld, [rs1]),absent,""),
                      (I386_Assembly.OPCODE (I386_Assembly.fnclex, []),absent,"Clear flags"),
                      (I386_Assembly.OPCODE (operation, [rs2]),absent,""),
                      (I386_Assembly.OPCODE (I386_Assembly.fstp, [rd]),absent,"Store fp result"),

                      (I386_Assembly.OPCODE (I386_Assembly.push,[I386_Assembly.r16 I386Types.AX]), absent,""),
                      (I386_Assembly.OPCODE (I386_Assembly.fstsw_ax,[]), absent,"Get fpu status"),
                      (* Now we have an error if al AND fpu_error_bits <> 0 *)
                      (I386_Assembly.OPCODE (I386_Assembly.test, [I386_Assembly.r_m8 (I386_Assembly.INL I386Types.AL),
                                                                  I386_Assembly.imm8 fpu_error_bits]),
                       absent,"Test if any conditions are set"),
                      (I386_Assembly.OPCODE (I386_Assembly.pop,[I386_Assembly.r16 I386Types.AX]), absent,""),
                      (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.not_equal,[I386_Assembly.rel32 0]), tag,"")
                      ],
                     opcode_list, block_list, final_result,stack_drop)
		  end

		| MirTypes.TUNARYFP(tagged_unary_fp_op, tag, fp_operand,
				    fp_operand') =>
                    let
                      val tag = case taglist of [] => NONE | a::_ => SOME a
                      val rd = convert_fp_operand fp_operand
                      val rs = convert_fp_operand fp_operand'
		      val mnemonics =
			case tagged_unary_fp_op of
			  MirTypes.FSQRTV => [I386_Assembly.fsqrt]
			| MirTypes.FABSV => [I386_Assembly.fabs]
			| MirTypes.FNEGV => [I386_Assembly.fchs]
                        | _ => Crash.impossible"Bad unary fp generated"
		    in
		      ([(I386_Assembly.OPCODE (I386_Assembly.fld, [rs]), absent, ""),
                        (I386_Assembly.OPCODE (I386_Assembly.fnclex, []),absent,"Clear flags")] @@
                       (map (fn m => (I386_Assembly.OPCODE (m, []), absent, "")) mnemonics) @@
                       [(I386_Assembly.OPCODE (I386_Assembly.fstp, [rd]), absent, "Store fp result"),
                        (I386_Assembly.OPCODE (I386_Assembly.push,[I386_Assembly.r16 I386Types.AX]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.fstsw_ax,[]), absent,"Get fpu status"),
                        (* Now we have an error if al AND fpu_error_bits <> 0 *)
                        (I386_Assembly.OPCODE (I386_Assembly.test, [I386_Assembly.r_m8 (I386_Assembly.INL I386Types.AL),
                                                                    I386_Assembly.imm8 fpu_error_bits]),
                        absent,"Test if any conditions are set"),
                        (I386_Assembly.OPCODE (I386_Assembly.pop,[I386_Assembly.r16 I386Types.AX]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.not_equal,[I386_Assembly.rel32 0]), tag,"")
                        ],
                       opcode_list, block_list,
		       final_result,stack_drop)
		    end
*)
		| MirTypes.TBINARYFP(tagged_binary_fp_op, taglist, fp_operand,
				     fp_operand', fp_operand'') =>
		  let
		    val rd = convert_fp_operand fp_operand
		    val rs1 = convert_fp_operand fp_operand'
		    val rs2 = convert_fp_operand fp_operand''
		    val operation = 
d3116 1
a3116 1
                     opcode_list, block_list, final_result,stack_drop)
d3131 1
a3131 1
		      ((I386_Assembly.OPCODE (I386_Assembly.fld, [rs]), absent, "") :: 
d3135 1
a3135 1
		       final_result,stack_drop)
d3155 1
a3155 1
		       opcode_list, block_list, final_result, stack_drop + stack_inc)
d3194 1
a3194 1
			    opcode_list, block_list, final_result, stack_drop)
d3204 1
a3204 1
			  block_list, final_result, stack_drop)
d3214 1
a3214 1
			  block_list, final_result, stack_drop)
d3226 1
a3226 1
			opcode_list, block_list, final_result, stack_drop))
d3244 1
a3244 1
			    opcode_list, block_list, final_result, stack_drop)
d3262 1
a3262 1
			      opcode_list, block_list, final_result, stack_drop)
d3271 1
a3271 1
			    opcode_list, block_list, final_result, stack_drop)
d3291 1
a3291 1
			      opcode_list, block_list, final_result, stack_drop)
d3304 1
a3304 1
			    opcode_list, block_list, final_result, stack_drop)
d3324 1
a3324 1
			    opcode_list, block_list, final_result, stack_drop)
d3340 1
a3340 1
			    opcode_list, block_list, final_result, stack_drop)
d3352 1
a3352 1
			    opcode_list, block_list, final_result, stack_drop)
d3374 1
a3374 1
			    opcode_list, block_list, final_result, stack_drop)
d3399 1
a3399 1
			    opcode_list, block_list, final_result, stack_drop)
d3417 1
a3417 1
			    opcode_list, block_list, final_result, stack_drop)
d3476 1
a3476 1
			      opcode_list, block_list, final_result, stack_drop)
d3502 1
a3502 1
			       opcode_list, block_list, final_result, stack_drop)
d3513 1
a3513 1
				opcode_list, block_list, final_result, stack_drop)
d3526 1
a3526 1
                          opcode_list, block_list, final_result, stack_drop)
d3534 1
a3534 1
                          opcode_list, block_list, final_result, stack_drop)
d3546 1
a3546 1
                          opcode_list, block_list, final_result, stack_drop)
d3552 1
a3552 1
                           val (store_instr, is_load) = 
d3589 1
a3589 1
                           (new_opcodes,opcode_list, block_list, final_result,stack_drop)
d3598 1
a3598 1
                        if gp_operand_is_spill gp_operand then 
d3617 1
a3617 1
                                                 offset=SOME(I386_Assembly.SMALL(frame_size + stack_drop - fp_spare_offset))}
d3622 1
a3622 1
                              | MirTypes.GP_IMM_INT i => 
d3627 1
a3627 1
                             [(I386_Assembly.OPCODE 
d3640 1
a3640 1
                       opcode_list, block_list, final_result, stack_drop)
d3651 1
a3651 1
                                           offset=SOME(I386_Assembly.SMALL(frame_size + stack_drop - fp_spare_offset))}
d3655 10
a3664 11
                        if reg_operand_is_spill reg_operand
                          then 
                            let
                              val result_operand =
                                I386_Assembly.MEM
                                {base=SOME I386Types.sp,
                                 index=absent,
                                 offset=SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))}
                            in
                              (I386_Assembly.fp_mem result_operand,I386_Assembly.r_m32 (I386_Assembly.INR result_operand),[])
                            end
d3674 1
a3674 1
                             [(I386_Assembly.OPCODE 
d3682 1
a3682 1
                                                                   I386_Assembly.imm32(Bits.lshift (1,27), 0)]), 
d3730 1
a3730 1
                       opcode_list, block_list, final_result, stack_drop)
d3748 1
a3748 1
			opcode_list, block_list, final_result, stack_drop)
d3761 1
a3761 1
		     opcode_list, block_list, final_result, stack_drop)
d3902 1
a3902 1
			  opcode_list, block_list, final_result, stack_drop)
d3912 1
a3912 1
			 opcode_list, block_list, final_result, stack_drop)
d3942 1
a3942 1
		     [],MirTypes.BLOCK (cont_tag,opcode_list) :: block_list, final_result, stack_drop)
d3959 1
a3959 1
                                 offset=SOME(I386_Assembly.SMALL 
d3965 2
a3966 2
			  [I386_Assembly.r_m32(I386_Assembly.INL 
                                                        I386Types.global)]),
d3968 1
a3968 1
                        opcode_list, block_list, final_result, stack_drop)
d3974 2
a3975 2
		    opcode_list, block_list, final_result, stack_drop)
		| MirTypes.TAIL_CALL(_, bl_dest, _) =>
d3977 7
d4003 1
a4003 1
				 [I386_Assembly.r_m32(I386_Assembly.INL(lookup_reg_operand reg))]),
d4006 73
a4078 4
			    [(I386_Assembly.OPCODE
			      (I386_Assembly.jmp,
			       [I386_Assembly.rel32 0]),
			      SOME tag, "branch relative(tail call)")]
d4081 9
a4089 26
			 let
			   val tail_seq =
			     if frame_left = 0 then
			       jump
			     else
			       (I386_Assembly.OPCODE
				(I386_Assembly.add,
				 [I386_Assembly.r_m32(I386_Assembly.INL I386Types.sp),
				  if frame_left <= 127 then
				    I386_Assembly.imm8 frame_left
				  else
				    I386_Assembly.imm32
				    (frame_left div 4, frame_left mod 4)]),
				absent, "junk spill and stack alloc area") ::
			       jump
			 in
			   (I386_Assembly.OPCODE
			    (I386_Assembly.pop,
			     [I386_Assembly.r32 I386Types.callee_closure]),
			    absent, "throw away frame link") ::
			   (I386_Assembly.OPCODE
			    (I386_Assembly.pop,
			     [I386_Assembly.r32 I386Types.callee_closure]),
			    absent, "restore caller's closure") :: restore_gcs @@
			   tail_seq
			 end
d4091 3
a4093 2
			 jump,
			 opcode_list, block_list, final_result, stack_drop)
d4104 1
a4104 1
			       opcode_list, block_list, final_result, stack_drop)
d4130 1
a4130 1
				 opcode_list, block_list, final_result, stack_drop)
d4191 1
a4191 1
				 stack_drop)
d4221 1
a4221 1
			    frame_size + stack_drop + Tags.PAIRPTR -
a4223 3
			(* The -4 accounts for the fact that *)
			(* the return address is at the top of the frame *)
			(* Now out of date *)
d4235 1
a4235 1
			  opcode_list, block_list, final_result, stack_drop)
d4242 1
a4242 1
		     ([], opcode_list, block_list, final_result, stack_drop)
d4468 1
a4468 1
			      stack_drop)
d4540 1
a4540 1
                                   
d5091 1
a5091 1
			      stack_drop)
d5118 1
a5118 1
			  ), opcode_list, block_list, final_result, stack_drop)
d5121 1
a5121 1
		    (trace_dummy_instructions, opcode_list, block_list, final_result, stack_drop)
d5166 1
a5166 1
		       final_result, stack_drop)
d5171 5
d5231 31
d5284 1
a5284 1
                        val _ = if fp_save_size <> 0 
d5289 1
a5289 1
                        val init_non_gc_stack = 
d5319 4
d5336 1
a5336 1
				 offset=SOME(I386_Assembly.SMALL(frame_size-4))}))]),
d5349 1
a5349 1
			(overflow_check,
d5355 1
a5355 1
			 stack_drop)
d5358 1
a5358 1
		      ([], opcode_list, block_list, final_result, stack_drop)
d5361 34
a5394 10
		    (if needs_preserve then
		       let
			 val ret_instr =
			   [(I386_Assembly.OPCODE
			     (I386_Assembly.ret, []), absent,
			     "Ordinary return")]
			 val ret_seq =
			   if frame_left = 0 then
			     ret_instr
			   else
d5396 9
a5404 24
			      (I386_Assembly.add,
			       [I386_Assembly.r_m32(I386_Assembly.INL I386Types.sp),
				if frame_left <= 127 then
				  I386_Assembly.imm8 frame_left
				else
				  I386_Assembly.imm32
				  (frame_left div 4, frame_left mod 4)]),
			      absent, "junk spill and stack alloc area") ::
			     ret_instr
		       in
			 (I386_Assembly.OPCODE
			  (I386_Assembly.pop,
			   [I386_Assembly.r32 I386Types.global]),
			  absent, "throw away frame link") ::
			 (I386_Assembly.OPCODE
			  (I386_Assembly.pop,
			   [I386_Assembly.r32 I386Types.callee_closure]),
			  absent, "restore caller's closure") :: restore_gcs @@
			 ret_seq
		       end
		     else
		       [(I386_Assembly.OPCODE(I386_Assembly.ret, []), absent,
			 "Ordinary return")],
		       opcode_list, block_list, final_result, stack_drop)
d5473 1
a5473 1
		      (opcodes, opcode_list, block_list, final_result, stack_drop)
d5506 1
a5506 1
		    opcode_list, block_list, final_result, stack_drop)
d5555 1
a5555 1
		       (code, opcode_list, block_list, final_result, stack_drop)
d5569 1
a5569 1
		    opcode_list, block_list, final_result, stack_drop)
d5577 1
d5579 1
a5579 1
	       new_final_result)
d5583 2
a5584 2
	  do_everything(needs_preserve, tag, Lists.filter_outp is_comment opcodes, 0,
			Sexpr.NIL, rest, [])
d5643 9
d5658 16
d5830 1
a5830 1
	  val stack_extra = 
d5845 14
d5995 1
a5995 1
            if generate_debug_info orelse debug_variables orelse generate_moduler 
d6011 8
a6018 8
	  fun check_reg I386Types.EAX = true
	    | check_reg I386Types.EBX = false
	    | check_reg I386Types.ECX = false
	    | check_reg I386Types.EDX = true
	    | check_reg I386Types.ESP = false
	    | check_reg I386Types.EBP = false
	    | check_reg I386Types.EDI = false
	    | check_reg I386Types.ESI = false
d6022 17
a6038 2
	    | check_reg I386Types.stack = false
 	    | check_reg x = Crash.impossible("check_reg:bad register " ^
d6071 1
a6071 1
	    Lists.qsort compare_reg (Lists.filterp check_reg (Set.set_to_list gcs))
d6124 154
a6282 2
                                               (*spills_need_init*)true,
                                               (*stack_need_init*)true,
d6284 3
a6286 1
                                               callee_saves))
a6300 1

d6307 2
a6308 2
	   saves=number_of_saves,
	   parms=0}
d6473 1
a6473 1
                                            
d6515 7
a6521 7
	  MLWorks.IO.output(MLWorks.IO.std_out, "Normalised code size is " ^
		 Int.toString
		 (Lists.reducel
		  (fn(x,Code_Module.WORDSET(Code_Module.WORD_SET{b=tagged_code', ...})) =>
		   (Lists.reducel (fn (x,{d_code=y, ...}) => (size y) + x) (x,tagged_code'))
		| _ => Crash.impossible "what the ?")
		  (0,proc_elements)) ^ "\n")
@


1.67
log
@[Bug #30088]
Get rid of MLWorks.Option
@
text
@d4 4
d5853 7
a5859 6
	  ((proc_tag, code),
	   non_gc_stack_size,
           procedure_name,
           padded_name,
	   not needs_preserve,
           number_of_saves)
d5892 4
a5895 4
	  val code_list = map #1 temp_code_list

          val procedure_name_list = map #3 temp_code_list
	  val leaf_list = map #5 temp_code_list
d5988 1
a5988 1
	     (fn ((tag, code),(_, spills, _, padded_name, _, saves)) =>
d5990 1
a5990 1
		 b_spills=spills,
d6057 2
a6058 1
				d_intercept=nop_offsets}),
@


1.66
log
@[Bug #20018]
Correct failure message on trying to save an fp register
@
text
@d4 4
d314 3
a316 3
    [(I386_Assembly.other_nop_code,MLWorks.Option.NONE,"Dummy instructions for tracing"),
     (I386_Assembly.other_nop_code,MLWorks.Option.NONE,"Dummy instructions for tracing"),
     (I386_Assembly.other_nop_code,MLWorks.Option.NONE,"Dummy instructions for tracing")]
d1409 1
a1409 1
       I386_Assembly.r_m32(MLWorks.Option.INL rs)]), absent, comment)
d1415 1
a1415 1
       I386_Assembly.r_m8(MLWorks.Option.INL rs)]), absent, comment)
d1603 1
a1603 1
	       I386_Assembly.r_m32(MLWorks.Option.INL I386Types.global)]),
d1620 1
a1620 1
	    I386_Assembly.r_m32(MLWorks.Option.INL I386Types.global)]),
d1624 1
a1624 1
	   [I386_Assembly.r_m32(MLWorks.Option.INL I386Types.global),
d1866 1
a1866 1
                     {base=MLWorks.Option.SOME I386Types.sp,
d1868 1
a1868 1
                      offset=MLWorks.Option.SOME(I386_Assembly.SMALL(fp_spill_value operand))})
d1898 1
a1898 1
			     (MLWorks.Option.INR
d1900 1
a1900 1
			       {base=MLWorks.Option.SOME I386Types.sp,
d1916 1
a1916 1
			       (MLWorks.Option.INL rs1)]),
d1926 1
a1926 1
			     (MLWorks.Option.INL rd)]),
d2063 1
a2063 1
				   (MLWorks.Option.INR
d2065 1
a2065 1
				     {base=MLWorks.Option.SOME I386Types.sp,
d2067 1
a2067 1
				      offset=MLWorks.Option.SOME(I386_Assembly.SMALL spill)})),
d2077 1
a2077 1
				     (MLWorks.Option.INR
d2079 1
a2079 1
				       {base=MLWorks.Option.SOME I386Types.sp,
d2081 1
a2081 1
					offset=MLWorks.Option.SOME(I386_Assembly.SMALL spill)})))
d2093 1
a2093 1
				       (MLWorks.Option.INL
d2097 1
a2097 1
				       (MLWorks.Option.INL(lookup_reg_operand reg_operand)),
d2110 1
a2110 1
				       I386_Assembly.r_m32(MLWorks.Option.INL r')] =>
d2118 2
a2119 2
					I386_Assembly.r_m32(MLWorks.Option.INL r)
				    | I386_Assembly.r_m32(MLWorks.Option.INL r) =>
d2184 1
a2184 1
				      MLWorks.Option.INR
d2186 1
a2186 1
				       {base=MLWorks.Option.SOME I386Types.sp,
d2188 1
a2188 1
					offset=MLWorks.Option.SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))
d2191 1
a2191 1
				      MLWorks.Option.INL
d2263 1
a2263 1
			  (MLWorks.Option.INR
d2267 1
a2267 1
				index=MLWorks.Option.SOME(lookup_gp_operand gp_operand', absent),
d2273 1
a2273 1
				MLWorks.Option.SOME
d2325 1
a2325 1
				       MLWorks.Option.INR
d2327 1
a2327 1
					{base=MLWorks.Option.SOME I386Types.sp,
d2329 1
a2329 1
					 offset=MLWorks.Option.SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
d2331 1
a2331 1
				       MLWorks.Option.INL(lookup_reg_operand reg_operand))
d2349 1
a2349 1
					      I386_Assembly.r_m32(MLWorks.Option.INL(lookup_reg_operand reg_operand))]),
d2362 1
a2362 1
					      I386_Assembly.r_m32(MLWorks.Option.INL(lookup_reg_operand reg_operand))]),
d2375 1
a2375 1
				      [I386_Assembly.r_m32(MLWorks.Option.INL I386Types.global),
d2393 1
a2393 1
					   I386_Assembly.r_m32(MLWorks.Option.INL reg)]),
d2420 1
a2420 1
				     MLWorks.Option.INR
d2422 1
a2422 1
				      {base=MLWorks.Option.SOME I386Types.sp,
d2424 1
a2424 1
				       offset=MLWorks.Option.SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
d2426 1
a2426 1
				     MLWorks.Option.INL(lookup_reg_operand reg_operand))
d2465 1
a2465 1
				     MLWorks.Option.INR
d2467 1
a2467 1
				      {base=MLWorks.Option.SOME I386Types.sp,
d2469 1
a2469 1
				       offset=MLWorks.Option.SOME(I386_Assembly.SMALL(gp_spill_value gp_operand'))})
d2471 1
a2471 1
				     MLWorks.Option.INL(lookup_gp_operand gp_operand'))
d2479 1
a2479 1
				    [I386_Assembly.r_m32(MLWorks.Option.INL I386Types.global)]),
d2494 1
a2494 1
				     MLWorks.Option.INR
d2496 1
a2496 1
				      {base=MLWorks.Option.SOME I386Types.sp,
d2498 1
a2498 1
				       offset=MLWorks.Option.SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
d2500 1
a2500 1
				     MLWorks.Option.INL(lookup_reg_operand reg_operand))
d2533 1
a2533 1
				     (MLWorks.Option.INR
d2535 1
a2535 1
				       {base=MLWorks.Option.SOME I386Types.sp,
d2537 1
a2537 1
					offset=MLWorks.Option.SOME(I386_Assembly.SMALL spill)})),
d2547 1
a2547 1
				       (MLWorks.Option.INR
d2549 1
a2549 1
					 {base=MLWorks.Option.SOME I386Types.sp,
d2551 1
a2551 1
					  offset=MLWorks.Option.SOME(I386_Assembly.SMALL spill)}))]
d2562 1
a2562 1
				       (MLWorks.Option.INL(lookup_reg_operand reg_operand)),
d2624 1
a2624 1
					   (MLWorks.Option.INR
d2626 1
a2626 1
					     {base=MLWorks.Option.SOME I386Types.sp,
d2636 1
a2636 1
					   (MLWorks.Option.INR
d2638 1
a2638 1
					     {base=MLWorks.Option.SOME I386Types.sp,
d2707 1
a2707 1
				      (MLWorks.Option.INR
d2709 1
a2709 1
					{base=MLWorks.Option.SOME I386Types.sp,
d2719 1
a2719 1
				    (MLWorks.Option.INR
d2721 1
a2721 1
				      {base=MLWorks.Option.SOME I386Types.sp,
d2748 1
a2748 1
			     MLWorks.Option.INR
d2750 1
a2750 1
			      {base=MLWorks.Option.SOME I386Types.sp,
d2752 1
a2752 1
			       offset=MLWorks.Option.SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
d2754 1
a2754 1
			     MLWorks.Option.INL(lookup_reg_operand reg_operand))
d2775 1
a2775 1
			     MLWorks.Option.INR
d2777 1
a2777 1
			      {base=MLWorks.Option.SOME I386Types.sp,
d2779 1
a2779 1
			       offset=MLWorks.Option.SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
d2781 1
a2781 1
			     MLWorks.Option.INL(lookup_reg_operand reg_operand))
d2801 1
a2801 1
			   (MLWorks.Option.INR
d2803 1
a2803 1
			     {base=MLWorks.Option.SOME I386Types.sp,
d2805 1
a2805 1
			      offset=MLWorks.Option.SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})),
d2812 1
a2812 1
			   (MLWorks.Option.INL(lookup_reg_operand reg_operand)),
d2920 1
a2920 1
                      (I386_Assembly.OPCODE (I386_Assembly.test, [I386_Assembly.r_m8 (MLWorks.Option.INL I386Types.AL),
d2949 1
a2949 1
                        (I386_Assembly.OPCODE (I386_Assembly.test, [I386_Assembly.r_m8 (MLWorks.Option.INL I386Types.AL),
d3030 1
a3030 1
			     (MLWorks.Option.INR
d3294 1
a3294 1
			   MLWorks.Option.INR
d3297 2
a3298 2
			       {base=MLWorks.Option.SOME rs1,
				index=MLWorks.Option.SOME((lookup_gp_operand gp_operand), absent),
d3308 1
a3308 1
				 {base=MLWorks.Option.SOME rs1,
d3310 1
a3310 1
				  offset=MLWorks.Option.SOME(assemble_large_offset gp_operand)}
d3423 2
a3424 2
                                 {base=MLWorks.Option.SOME rs1,
                                  index=MLWorks.Option.SOME((lookup_gp_operand gp_operand), absent),
d3434 1
a3434 1
				   {base=MLWorks.Option.SOME rs1,
d3436 1
a3436 1
				    offset=MLWorks.Option.SOME(assemble_large_offset gp_operand)}
d3462 1
a3462 1
			      {base=MLWorks.Option.SOME I386Types.sp,
d3464 1
a3464 1
			       offset=MLWorks.Option.SOME(I386_Assembly.SMALL(gp_spill_value gp_operand))}
d3469 1
a3469 1
				[I386_Assembly.r_m32 (MLWorks.Option.INR mem_operand),
d3475 1
a3475 1
                              I386_Assembly.MEM {base=MLWorks.Option.SOME I386Types.sp,
d3477 1
a3477 1
                                                 offset=MLWorks.Option.SOME(I386_Assembly.SMALL(frame_size + stack_drop - fp_spare_offset))}
d3488 1
a3488 1
                               (I386_Assembly.mov,[I386_Assembly.r_m32 (MLWorks.Option.INR fp_spare_loc),
d3494 1
a3494 1
                       [(I386_Assembly.OPCODE(I386_Assembly.sar,[I386_Assembly.r_m32 (MLWorks.Option.INR mem_operand),
d3509 1
a3509 1
                        I386_Assembly.MEM {base=MLWorks.Option.SOME I386Types.sp,
d3511 1
a3511 1
                                           offset=MLWorks.Option.SOME(I386_Assembly.SMALL(frame_size + stack_drop - fp_spare_offset))}
d3520 1
a3520 1
                                {base=MLWorks.Option.SOME I386Types.sp,
d3522 1
a3522 1
                                 offset=MLWorks.Option.SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))}
d3524 1
a3524 1
                              (I386_Assembly.fp_mem result_operand,I386_Assembly.r_m32 (MLWorks.Option.INR result_operand),[])
d3534 1
a3534 1
                             I386_Assembly.r_m32 (MLWorks.Option.INL dest_operand_reg),
d3537 1
a3537 1
                                                   I386_Assembly.r_m32 (MLWorks.Option.INR fp_spare_loc)]),
d3542 1
a3542 1
                        (I386_Assembly.OPCODE (I386_Assembly.mov, [I386_Assembly.r_m32 (MLWorks.Option.INR (fp_spare_loc)),
d3569 1
a3569 1
                                                I386_Assembly.r_m32 (MLWorks.Option.INR (fp_spare_loc))]),
d3572 1
a3572 1
                                               [I386_Assembly.r_m16 (MLWorks.Option.INR (fp_spare_loc)),
d3576 1
a3576 1
                                               [I386_Assembly.r_m16 (MLWorks.Option.INR (fp_spare_loc)),
d3586 1
a3586 1
                                               [I386_Assembly.r_m32 (MLWorks.Option.INR (fp_spare_loc)),
d3603 1
a3603 1
                                (MLWorks.Option.INL(lookup_reg_operand reg))]),
d3663 1
a3663 1
				 (MLWorks.Option.INR
d3665 1
a3665 1
				   {base=MLWorks.Option.SOME I386Types.sp,
d3667 1
a3667 1
				    offset=MLWorks.Option.SOME(I386_Assembly.SMALL spill)})),
d3689 1
a3689 1
				   (MLWorks.Option.INR
d3691 1
a3691 1
				     {base=MLWorks.Option.SOME I386Types.sp,
d3693 1
a3693 1
				      offset=MLWorks.Option.SOME(I386_Assembly.SMALL(gp_spill_value gp_op'))})),
d3699 1
a3699 1
				     (MLWorks.Option.INL gp_r),
d3724 1
a3724 1
					  (I386_Assembly.r_m32(MLWorks.Option.INL gp_r),
d3728 1
a3728 1
					   (I386_Assembly.r_m32(MLWorks.Option.INL gp_r),
d3739 1
a3739 1
					     (MLWorks.Option.INL(I386Types.byte_reg_name gp_r)),
d3744 1
a3744 1
					     (MLWorks.Option.INL(I386Types.half_reg_name gp_r)),
d3816 1
a3816 1
                              (MLWorks.Option.INR
d3826 1
a3826 1
			  [I386_Assembly.r_m32(MLWorks.Option.INL 
d3849 1
a3849 1
				  (MLWorks.Option.INR
d3851 1
a3851 1
				    {base=MLWorks.Option.SOME(lookup_reg_operand reg),
d3853 1
a3853 1
				     offset=MLWorks.Option.SOME(I386_Assembly.SMALL Tags.CODE_OFFSET)}))]),
d3857 1
a3857 1
				 [I386_Assembly.r_m32(MLWorks.Option.INL(lookup_reg_operand reg))]),
d3873 1
a3873 1
				 [I386_Assembly.r_m32(MLWorks.Option.INL I386Types.sp),
d3915 1
a3915 1
				     MLWorks.Option.INR
d3917 1
a3917 1
				      {base=MLWorks.Option.SOME I386Types.sp,
d3919 1
a3919 1
				       offset=MLWorks.Option.SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
d3921 1
a3921 1
				     MLWorks.Option.INL(lookup_reg_operand reg_operand))
d3950 1
a3950 1
				     MLWorks.Option.INR
d3952 1
a3952 1
				      {base=MLWorks.Option.SOME I386Types.sp,
d3954 1
a3954 1
				       offset=MLWorks.Option.SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
d3956 1
a3956 1
				     MLWorks.Option.INL(lookup_reg_operand reg_operand))
d3962 1
a3962 1
				    [I386_Assembly.r_m32(MLWorks.Option.INL I386Types.global),
d3970 1
a3970 1
				     (MLWorks.Option.INR
d3972 1
a3972 1
				       {base=MLWorks.Option.SOME I386Types.callee_closure,
d3974 1
a3974 1
					offset=MLWorks.Option.SOME(I386_Assembly.SMALL ~1)}))]),
d3986 1
a3986 1
				   [I386_Assembly.r_m32(MLWorks.Option.INL I386Types.global)]),
d4033 1
a4033 1
			       (MLWorks.Option.INR
d4035 1
a4035 1
				 {base=MLWorks.Option.SOME I386Types.sp,
d4037 1
a4037 1
				  offset=MLWorks.Option.SOME(I386_Assembly.SMALL offset)}))]),
d4108 1
a4108 1
				    (MLWorks.Option.INR
d4110 1
a4110 1
				      {base=MLWorks.Option.SOME rd,
d4112 1
a4112 1
				       offset=MLWorks.Option.SOME(I386_Assembly.SMALL(~primary))})),
d4122 1
a4122 1
				    (MLWorks.Option.INR
d4124 1
a4124 1
				      {base=MLWorks.Option.SOME rd,
d4126 1
a4126 1
				       offset=MLWorks.Option.SOME(I386_Assembly.SMALL(bytes - primary - 4))})),
d4156 1
a4156 1
				     (MLWorks.Option.INR
d4158 1
a4158 1
				       {base=MLWorks.Option.SOME I386Types.global,
d4160 1
a4160 1
					offset=MLWorks.Option.SOME(I386_Assembly.SMALL primary)}))]),
d4173 1
a4173 1
				     (MLWorks.Option.INR
d4175 1
a4175 1
				       {base=MLWorks.Option.SOME rd,
d4177 1
a4177 1
					offset=MLWorks.Option.SOME(I386_Assembly.SMALL bytes)}))]),
d4182 1
a4182 1
				     (MLWorks.Option.INR
d4184 1
a4184 1
				       {base=MLWorks.Option.SOME I386Types.implicit,
d4186 1
a4186 1
					offset=MLWorks.Option.SOME(I386_Assembly.SMALL gc_entry)}))]),
d4195 1
a4195 1
				    I386_Assembly.r_m32(MLWorks.Option.INL rd)]),
d4202 1
a4202 1
				  (MLWorks.Option.INR
d4204 1
a4204 1
				    {base=MLWorks.Option.SOME I386Types.implicit,
d4206 1
a4206 1
				     offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.gc_base))})),
d4217 1
a4217 1
				  (MLWorks.Option.INR
d4219 1
a4219 1
				    {base=MLWorks.Option.SOME I386Types.implicit,
d4221 1
a4221 1
				     offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.gc_base))}))]),
d4228 1
a4228 1
				  (MLWorks.Option.INR
d4230 1
a4230 1
				    {base=MLWorks.Option.SOME I386Types.implicit,
d4232 1
a4232 1
				     offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.gc_limit))}))]),
d4239 1
a4239 1
				  (MLWorks.Option.INR
d4241 1
a4241 1
				    {base=MLWorks.Option.SOME rd,
d4243 1
a4243 1
				     offset=MLWorks.Option.SOME(I386_Assembly.SMALL(primary-bytes))}))]),
d4253 1
a4253 1
				  [I386_Assembly.r_m32(MLWorks.Option.INL rd),
d4286 1
a4286 1
				 (MLWorks.Option.INR
d4288 1
a4288 1
				   {base=MLWorks.Option.SOME I386Types.sp,
d4290 2
a4291 2
				    offset=MLWorks.Option.SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))}),
				  MLWorks.Option.INR
d4293 1
a4293 1
				   {base=MLWorks.Option.SOME I386Types.sp,
d4295 1
a4295 1
				    offset=MLWorks.Option.SOME (* Offset changes from push *)
d4298 2
a4299 2
				 (MLWorks.Option.INL(lookup_reg_operand reg_operand),
				  MLWorks.Option.INL(lookup_reg_operand reg_operand))
d4313 1
a4313 1
					   (MLWorks.Option.INR
d4315 1
a4315 1
					     {base=MLWorks.Option.SOME I386Types.sp,
d4317 1
a4317 1
					      offset=MLWorks.Option.SOME
d4338 1
a4338 1
					   (MLWorks.Option.INR
d4340 1
a4340 1
					     {base=MLWorks.Option.SOME size_reg,
d4342 1
a4342 1
					      offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4+7))}))]),
d4352 1
a4352 1
					   (MLWorks.Option.INR
d4354 1
a4354 1
					     {base=MLWorks.Option.SOME I386Types.sp,
d4356 1
a4356 1
					      offset=MLWorks.Option.SOME
d4369 1
a4369 1
					     (MLWorks.Option.INR
d4371 1
a4371 1
					       {base=MLWorks.Option.SOME I386Types.sp,
d4373 1
a4373 1
						offset=MLWorks.Option.SOME
d4400 1
a4400 1
					   (MLWorks.Option.INR
d4402 1
a4402 1
					     {base=MLWorks.Option.SOME I386Types.sp,
d4404 1
a4404 1
					      offset=MLWorks.Option.SOME
d4425 1
a4425 1
					   (MLWorks.Option.INR
d4427 1
a4427 1
					     {base=MLWorks.Option.SOME size_reg,
d4429 1
a4429 1
					      offset=MLWorks.Option.SOME(I386_Assembly.SMALL(12+7))}))]),
d4438 1
a4438 1
					   (MLWorks.Option.INR
d4440 1
a4440 1
					     {base=MLWorks.Option.SOME I386Types.sp,
d4442 1
a4442 1
					      offset=MLWorks.Option.SOME
d4455 1
a4455 1
					     (MLWorks.Option.INR
d4457 1
a4457 1
					       {base=MLWorks.Option.SOME I386Types.sp,
d4459 1
a4459 1
						offset=MLWorks.Option.SOME
d4483 1
a4483 1
				  (MLWorks.Option.INR
d4485 1
a4485 1
				    {base=MLWorks.Option.SOME I386Types.implicit,
d4487 1
a4487 1
				     offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.gc_base))}))]),
d4494 1
a4494 1
				  (MLWorks.Option.INR
d4496 1
a4496 1
				    {base=MLWorks.Option.SOME I386Types.implicit,
d4498 1
a4498 1
				     offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.gc_limit))}))]),
d4516 1
a4516 1
				    (MLWorks.Option.INR
d4518 1
a4518 1
				      {base=MLWorks.Option.SOME I386Types.implicit,
d4520 1
a4520 1
				       offset=MLWorks.Option.SOME
d4530 1
a4530 1
				    (MLWorks.Option.INR
d4532 1
a4532 1
				      {base=MLWorks.Option.SOME I386Types.implicit,
d4534 1
a4534 1
				       offset=MLWorks.Option.SOME
d4553 1
a4553 1
				   [I386_Assembly.r_m32(MLWorks.Option.INL I386Types.global),
d4566 1
a4566 1
				    (MLWorks.Option.INR
d4568 1
a4568 1
				      {base=MLWorks.Option.SOME I386Types.global,
d4570 1
a4570 1
				       offset=MLWorks.Option.SOME(I386_Assembly.SMALL primary)}))]),
d4581 1
a4581 1
				  (MLWorks.Option.INR
d4583 1
a4583 1
				    {base=MLWorks.Option.SOME I386Types.implicit,
d4585 1
a4585 1
				     offset=MLWorks.Option.SOME(I386_Assembly.SMALL gc_entry)}))]),
d4591 1
a4591 1
				 I386_Assembly.r_m32(MLWorks.Option.INL reg) =>
d4596 1
a4596 1
				      (MLWorks.Option.INR
d4598 3
a4600 3
					{base=MLWorks.Option.SOME reg,
					 index=MLWorks.Option.SOME(I386Types.global, absent),
					 offset=MLWorks.Option.SOME(I386_Assembly.SMALL primary)}))]),
d4650 1
a4650 1
					 [I386_Assembly.r_m32(MLWorks.Option.INL index),
d4656 1
a4656 1
					  (MLWorks.Option.INR
d4658 3
a4660 3
					    {base=MLWorks.Option.SOME pointer,
					     index=MLWorks.Option.SOME(index, absent),
					     offset=MLWorks.Option.SOME(I386_Assembly.SMALL offset)})),
d4678 1
a4678 1
					      (MLWorks.Option.INR
d4680 1
a4680 1
						{base=MLWorks.Option.SOME I386Types.sp,
d4682 1
a4682 1
						 offset=MLWorks.Option.SOME(I386_Assembly.SMALL spill_value)}))]),
d4691 1
a4691 1
					    (MLWorks.Option.INL(lookup_gp_operand gp_operand))]),
d4698 1
a4698 1
					  (MLWorks.Option.INR
d4700 1
a4700 1
					    {base=MLWorks.Option.SOME pointer,
d4702 1
a4702 1
					     offset=MLWorks.Option.SOME(I386_Assembly.SMALL(~primary))})),
d4744 1
a4744 1
					 [I386_Assembly.r_m32(MLWorks.Option.INL index),
d4750 1
a4750 1
					  (MLWorks.Option.INR
d4752 3
a4754 3
					    {base=MLWorks.Option.SOME pointer,
					     index=MLWorks.Option.SOME(index, absent),
					     offset=MLWorks.Option.SOME(I386_Assembly.SMALL offset)})),
d4772 1
a4772 1
					      (MLWorks.Option.INR
d4774 1
a4774 1
						{base=MLWorks.Option.SOME I386Types.sp,
d4776 1
a4776 1
						 offset=MLWorks.Option.SOME(I386_Assembly.SMALL spill_value)}))]),
d4785 1
a4785 1
					    (MLWorks.Option.INL(lookup_gp_operand gp_operand))]),
d4792 1
a4792 1
					  (MLWorks.Option.INR
d4794 1
a4794 1
					    {base=MLWorks.Option.SOME pointer,
d4796 1
a4796 1
					     offset=MLWorks.Option.SOME(I386_Assembly.SMALL(~primary))})),
d4839 1
a4839 1
					  (MLWorks.Option.INR
d4841 1
a4841 1
					    {base=MLWorks.Option.SOME pointer,
d4843 1
a4843 1
					     offset=MLWorks.Option.SOME(I386_Assembly.SMALL(~primary))})),
d4870 1
a4870 1
				     MLWorks.Option.INR
d4872 1
a4872 1
				      {base=MLWorks.Option.SOME I386Types.sp,
d4874 1
a4874 1
				       offset=MLWorks.Option.SOME
d4877 1
a4877 1
				     MLWorks.Option.INL(lookup_gp_operand gp_operand))]),
d4881 1
a4881 1
				 [I386_Assembly.r_m32(MLWorks.Option.INL I386Types.global),
d4886 1
a4886 1
				 [I386_Assembly.r_m32(MLWorks.Option.INL I386Types.global),
d4912 1
a4912 1
				 MLWorks.Option.INR
d4914 1
a4914 1
				  {base=MLWorks.Option.SOME I386Types.sp,
d4916 1
a4916 1
				   offset=MLWorks.Option.SOME(I386_Assembly.SMALL(reg_spill_value reg_operand))})
d4918 1
a4918 1
				 MLWorks.Option.INL(lookup_reg_operand reg_operand)),
d4934 1
a4934 1
			    (MLWorks.Option.INR
d4936 1
a4936 1
			      {base=MLWorks.Option.SOME I386Types.implicit,
d4938 1
a4938 1
			       offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.register_stack_limit))})),
d4961 1
a4961 1
			   (MLWorks.Option.INR
d4963 1
a4963 1
			     {base=MLWorks.Option.SOME I386Types.implicit,
d4965 1
a4965 1
			      offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4 * check_offset))}))]),
d5000 1
a5000 1
			       (MLWorks.Option.INR
d5002 1
a5002 1
				 {base=MLWorks.Option.SOME I386Types.sp,
d5004 1
a5004 1
				  offset=MLWorks.Option.SOME(I386_Assembly.SMALL(~frame_size))}))]),
d5010 1
a5010 1
			       (MLWorks.Option.INR
d5012 1
a5012 1
				 {base=MLWorks.Option.SOME I386Types.implicit,
d5014 1
a5014 1
				  offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.register_stack_limit))}))]
d5023 1
a5023 1
			       (MLWorks.Option.INR
d5025 1
a5025 1
				 {base=MLWorks.Option.SOME I386Types.implicit,
d5027 1
a5027 1
				  offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.register_stack_limit))}))]
d5040 1
a5040 1
			      (MLWorks.Option.INR
d5042 1
a5042 1
				{base=MLWorks.Option.SOME I386Types.implicit,
d5044 1
a5044 1
				 offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.extend))}))]),
d5064 1
a5064 1
                                      [I386_Assembly.r_m32(MLWorks.Option.INL I386Types.sp),
d5096 1
a5096 1
			      (MLWorks.Option.INR
d5098 1
a5098 1
				{base=MLWorks.Option.SOME I386Types.sp,
d5100 1
a5100 1
				 offset=MLWorks.Option.SOME(I386_Assembly.SMALL(frame_size-4))}))]),
d5137 1
a5137 1
			       [I386_Assembly.r_m32(MLWorks.Option.INL I386Types.sp),
d5180 1
a5180 1
			   (MLWorks.Option.INR
d5182 1
a5182 1
			     {base=MLWorks.Option.SOME I386Types.implicit,
d5184 1
a5184 1
			      offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.handler))})),
d5192 1
a5192 1
			   (MLWorks.Option.INR
d5194 1
a5194 1
			     {base=MLWorks.Option.SOME I386Types.implicit,
d5196 1
a5196 1
			      offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.handler))}))]),
d5201 1
a5201 1
			   (MLWorks.Option.INR
d5203 1
a5203 1
			     {base=MLWorks.Option.SOME rd,
d5205 1
a5205 1
			      offset=MLWorks.Option.SOME(I386_Assembly.SMALL(~1))})),
d5218 1
a5218 1
			     (MLWorks.Option.INR
d5220 1
a5220 1
			       {base=MLWorks.Option.SOME I386Types.sp,
d5222 1
a5222 1
				offset=MLWorks.Option.SOME(I386_Assembly.SMALL(reg_spill_value frame + 4))}))]),
d5235 1
a5235 1
			 (MLWorks.Option.INR
d5237 1
a5237 1
			   {base=MLWorks.Option.SOME I386Types.implicit,
d5239 1
a5239 1
			    offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.handler))}))]),
d5245 1
a5245 1
			 (MLWorks.Option.INR
d5247 1
a5247 1
			   {base=MLWorks.Option.SOME I386Types.global,
d5249 1
a5249 1
			    offset=MLWorks.Option.SOME(I386_Assembly.SMALL(~1))}))]),
d5254 1
a5254 1
			 (MLWorks.Option.INR
d5256 1
a5256 1
			   {base=MLWorks.Option.SOME I386Types.implicit,
d5258 1
a5258 1
			    offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.handler))})),
d5275 1
a5275 1
			    (MLWorks.Option.INR
d5277 1
a5277 1
			      {base=MLWorks.Option.SOME I386Types.sp,
d5279 1
a5279 1
			       offset=MLWorks.Option.SOME(I386_Assembly.SMALL spill)}), true)
d5286 1
a5286 1
			      (MLWorks.Option.INL arg, false)
d5288 1
a5288 1
			      (MLWorks.Option.INL arg, true)
d5294 1
a5294 1
			    (MLWorks.Option.INR
d5296 1
a5296 1
			      {base=MLWorks.Option.SOME I386Types.implicit,
d5298 1
a5298 1
			       offset=MLWorks.Option.SOME(I386_Assembly.SMALL vector)}))]),
d5318 1
a5318 1
			 (MLWorks.Option.INR
d5320 1
a5320 1
			   {base=MLWorks.Option.SOME I386Types.implicit,
d5322 1
a5322 1
			    offset=MLWorks.Option.SOME(I386_Assembly.SMALL(4*Implicit_Vector.external))}))]),
@


1.65
log
@[Bug #0]
Fix real comparisons to deal with nans
@
text
@d4 4
d1682 1
a1682 1
	      Crash.impossible"do_save_instrs"
d1686 1
a1686 1
	      Crash.impossible"do_restore_instrs"
@


1.65.1.1
log
@branched from 1.65
@
text
@a3 4
 * Revision 1.65  1997/03/13  14:39:31  jont
 * [Bug #0]
 * Fix real comparisons to deal with nans
 *
@


1.65.1.1.3.1
log
@branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_10r3
@
text
@a3 3
 * Revision 1.65.1.1  1997/05/12  10:33:13  hope
 * branched from 1.65
 *
@


1.65.1.1.2.1
log
@branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_10r2_551
@
text
@a3 3
 * Revision 1.65.1.1  1997/05/12  10:33:13  hope
 * branched from 1.65
 *
@


1.65.1.1.1.1
log
@branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_11
@
text
@a3 3
 * Revision 1.65.1.1  1997/05/12  10:33:13  hope
 * branched from 1.65
 *
@


1.65.1.1.1.1.1.1
log
@branched from MLWorks_11 for label MLWorks_11r1
@
text
@a3 3
 * Revision 1.65.1.1.1.1  1997/07/28  18:18:35  daveb
 * branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_11
 *
@


1.64
log
@[Bug #1962]
Sort out problems overloading global during store instructions
@
text
@d4 4
d3771 1
d3781 1
d3791 3
a3793 1
                      (I386_Assembly.OPCODE (I386_Assembly.jcc cond,[I386_Assembly.rel32 0]), SOME tag,"")
d3795 1
a3795 1
		     opcode_list, block_list, final_result, stack_drop)
@


1.63
log
@Don't reverse real bytes in value_cg
@
text
@d4 3
d1745 3
d3077 96
a3172 30
		  (case (reg_operand_is_spill reg_operand,
			 reg_operand_is_spill reg_operand',
			 gp_operand_is_spill gp_operand) of
		     (false, false, true) =>
		       ([],
			MirTypes.UNARY(MirTypes.MOVE, MirTypes.GC_REG MirRegisters.global,
				       gp_operand) ::
			MirTypes.STOREOP(store_op, reg_operand, reg_operand',
					 MirTypes.GP_GC_REG MirRegisters.global) ::
			opcode_list, block_list, final_result, stack_drop)
		   | (false, true, false) =>
		       ([],
			MirTypes.UNARY(MirTypes.MOVE, MirTypes.GC_REG MirRegisters.global,
				       gp_from_reg reg_operand') ::
			MirTypes.STOREOP(store_op, reg_operand,
					 MirTypes.GC_REG MirRegisters.global,
					 gp_operand) ::
			opcode_list, block_list, final_result, stack_drop)
		   | (false, true, true) =>
		       ([],
			MirTypes.UNARY(MirTypes.MOVE, MirTypes.GC_REG MirRegisters.global,
				       gp_from_reg reg_operand') ::
			MirTypes.BINARY(MirTypes.ADDU,
					MirTypes.GC_REG MirRegisters.global,
					MirTypes.GP_GC_REG MirRegisters.global,
					gp_operand) ::
			MirTypes.STOREOP(store_op, reg_operand,
					 MirTypes.GC_REG MirRegisters.global,
					 MirTypes.GP_IMM_ANY 0) ::
			opcode_list, block_list, final_result, stack_drop)
d3364 1
@


1.62
log
@Changed tag option to tag list in tagged instructions
@
text
@d4 3
d477 1
a477 2
         (* Reverse the string representation -- this is a bit of a hack *)
	 Code_Module.REAL(i, implode (rev (explode (encoding_function(sign, mantissa, exponent)))))
@


1.61
log
@[Bug #1728]
__integer becomes __int
@
text
@d4 4
d1624 2
a1625 2
      fun get_binary_op MirTypes.ADD = (I386_Assembly.add, false)
	| get_binary_op MirTypes.SUB = (I386_Assembly.sub, false)
d1627 1
a1627 5
	| get_binary_op MirTypes.MULS = Crash.unimplemented"MirTypes.MULS"
	| get_binary_op MirTypes.DIVU = Crash.unimplemented"MirTypes.DIVU"
	| get_binary_op MirTypes.DIVS = Crash.unimplemented"MirTypes.DIVS"
	| get_binary_op MirTypes.MODU = Crash.unimplemented"MirTypes.MODU"
	| get_binary_op MirTypes.MODS = Crash.unimplemented"MirTypes.MODS"
d1921 1
a1921 1
		  MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
d1923 4
a1926 1
		  if reg_equals_gp(reg_operand, gp_operand) then
d1929 14
a1942 10
			MirTypes.ADDV => (I386_Assembly.add, false)
		      | MirTypes.SUBV => (I386_Assembly.sub, false)
		      | MirTypes.MULV => (I386_Assembly.imul, false)
		      | MirTypes.DIVV => Crash.impossible"do_opcodes(TBINARY(DIVV))"
		      | MirTypes.MODV => Crash.impossible"do_opcodes(TBINARY(MODV))"
		      | MirTypes.ADDW => (I386_Assembly.add, true)
		      | MirTypes.SUBW => (I386_Assembly.sub, true)
		      | MirTypes.MULW => (*I386_Assembly.imul*)Crash.impossible"do_opcodes(TBINARY(MULW))"
		      | MirTypes.DIVW => Crash.impossible"do_opcodes(TBINARY(DIVW))"
		      | MirTypes.MODW => Crash.impossible"do_opcodes(TBINARY(MODW))"
d1967 2
a1968 2
			  val exn_tag = case tag of
			    SOME tag => tag
d1971 5
a1975 5
			    MirTypes.ADDW => MirTypes.ADDV
			  | MirTypes.SUBW => MirTypes.SUBV
			  | MirTypes.MULW => MirTypes.MULW
			  | MirTypes.DIVW => MirTypes.DIVW
			  | MirTypes.MODW => MirTypes.MODW
d1980 1
a1980 1
			   (new_op, SOME clean_tag, reg_operand,
d1988 1
a1988 1
			if tagged_binary_op = MirTypes.MULV then
d1994 1
a1994 1
			   MirTypes.TBINARY(tagged_binary_op, tag,
d2007 1
a2007 1
			   MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
d2012 1
a2012 1
			if tagged_binary_op = MirTypes.MULV andalso
d2022 1
a2022 1
			   MirTypes.TBINARY(tagged_binary_op, tag,
d2082 1
a2082 1
			      if tagged_binary_op = MirTypes.MULV then
d2123 14
a2136 10
			  MirTypes.ADDV => true
			| MirTypes.SUBV => false
			| MirTypes.MULV => true
			| MirTypes.DIVV => Crash.impossible"do_opcodes(TBINARY(DIVV))"
			| MirTypes.MODV => Crash.impossible"do_opcodes(TBINARY(MODV))"
			| MirTypes.ADDW => true
			| MirTypes.SUBW => false
			| MirTypes.MULW => true
			| MirTypes.DIVW => Crash.impossible"do_opcodes(TBINARY(DIVW))"
			| MirTypes.MODW => Crash.impossible"do_opcodes(TBINARY(MODW))"
d2140 1
a2140 1
			   MirTypes.TBINARY(tagged_binary_op, tag,
d2151 1
a2151 1
			     MirTypes.TBINARY(tagged_binary_op, tag,
d2185 1
a2185 1
			       MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
d2193 1
a2193 1
		      if tagged_binary_op = MirTypes.MULV andalso
d2202 1
a2202 1
			 MirTypes.TBINARY(tagged_binary_op, tag,
d2215 1
a2215 1
			 MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
d2219 1
d2554 2
a2555 2
			      MirTypes.ADD => true
			    | MirTypes.SUB => false
d2558 2
a2559 10
			    | MirTypes.MULS =>
				Crash.unimplemented"MirTypes.MULS"
			    | MirTypes.DIVU =>
				Crash.unimplemented"MirTypes.DIVU"
			    | MirTypes.DIVS =>
				Crash.unimplemented"MirTypes.DIVS"
			    | MirTypes.MODU =>
				Crash.unimplemented"MirTypes.MODU"
			    | MirTypes.MODS =>
				Crash.unimplemented"MirTypes.MODS"
d2878 1
a2878 1
		| MirTypes.TBINARYFP(tagged_binary_fp_op, tag, fp_operand,
d2881 1
d2912 1
d2939 1
a2939 1
		| MirTypes.TBINARYFP(tagged_binary_fp_op, tag, fp_operand,
d2959 1
a2959 1
		| MirTypes.TUNARYFP(tagged_unary_fp_op, tag, fp_operand,
d3059 1
a3059 1
			MirTypes.BINARY(MirTypes.ADD,
d3091 1
a3091 1
			MirTypes.BINARY(MirTypes.ADD,
d3312 1
a3312 1
                          MirTypes.BINARY(MirTypes.ADD,
@


1.61.4.1
log
@branched from 1.61
@
text
@a3 4
 * Revision 1.61  1996/11/06  11:12:23  matthew
 * [Bug #1728]
 * __integer becomes __int
 *
@


1.61.3.1
log
@branched from 1.61
@
text
@a3 4
 * Revision 1.61  1996/11/06  11:12:23  matthew
 * [Bug #1728]
 * __integer becomes __int
 *
@


1.61.3.1.1.1
log
@branched from 1.61.3.1
@
text
@a3 3
 * Revision 1.61.3.1  1996/12/17  17:46:51  hope
 * branched from 1.61
 *
@


1.61.2.1
log
@branched from 1.61
@
text
@a3 4
 * Revision 1.61  1996/11/06  11:12:23  matthew
 * [Bug #1728]
 * __integer becomes __int
 *
@


1.61.1.1
log
@branched from 1.61
@
text
@a3 4
 * Revision 1.61  1996/11/06  11:12:23  matthew
 * [Bug #1728]
 * __integer becomes __int
 *
@


1.61.1.1.1.1
log
@branched from 1.61.1.1
@
text
@a3 3
 * Revision 1.61.1.1  1996/11/14  12:48:10  hope
 * branched from 1.61
 *
@


1.60
log
@[Bug #1707]
threading debugger information.
(into calls).
@
text
@d4 5
d213 1
a213 1
require "../basis/__integer";
@


1.59
log
@removing toplevel String.
@
text
@d4 3
d261 2
d3503 4
a3506 5
			      (I386_Assembly.jmp,
			       [I386_Assembly.r_m32
				(MLWorks.Option.INL(lookup_reg_operand reg))](*,
			       Debugger_Types.null_backend_annotation*)),
			      absent, "branch indirect")]
d3704 18
a3721 14
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.REG reg_operand,debug_information, _) =>
		    if reg_operand_is_spill reg_operand then
		      Crash.impossible"register to branch and link is spill"
		    else
		      ([(I386_Assembly.OPCODE
			 (I386_Assembly.lea,
			  [I386_Assembly.r32 I386Types.global,
			   I386_Assembly.r_m32
			   (MLWorks.Option.INR
			    (I386_Assembly.MEM
			     {base=MLWorks.Option.SOME(lookup_reg_operand reg_operand),
			      index=absent,
			      offset=MLWorks.Option.SOME(I386_Assembly.SMALL Tags.CODE_OFFSET)}))]),
			 absent, "compute real target address"),
d3724 2
a3725 1
			  [I386_Assembly.r_m32(MLWorks.Option.INL I386Types.global)]),
d3727 2
a3728 1
		      opcode_list, block_list, final_result, stack_drop)
d5890 2
a5891 3
(*
                          I386_Assembly.JUMP_AND_LINK (_,_,_,_,Debugger_Types.Nop) => ()
                        | I386_Assembly.JUMP_AND_LINK (_,_,_,_,debug) =>
a5904 1
                              val Debugger_Types.INFO i = !debug_map
d5906 3
a5908 7
			       case NewMap.tryApply'(i, unpadded_name) of
				 SOME ((ty,leaf,annotations),runtime_env) =>
				   debug_map :=
                                     Debugger_Types.INFO
                                     (NewMap.define(i, unpadded_name,
                                        ((ty,leaf,(count,debug)::annotations),runtime_env)))
			       | _ => ()
d5910 8
a5917 3
                        | *)_ => ();
                            annotation_points(t,count+4,
                                              I386_Opcodes.output_opcode(assemble inst)::res))
@


1.58
log
@[Bug #1618]
Ensure real does not trash its argument if already on the stack
@
text
@d4 4
d226 1
d297 1
a297 1
        | aux ("0"::rest,acc) =
d299 1
a299 1
        | aux ("1"::rest,acc) =
d301 1
a301 1
        | aux (" "::rest,acc) =
d306 1
a306 1
      aux (MLWorks.String.explode l,0)
d349 1
a349 1
  fun mantissa_is_zero mantissa =
d351 7
a357 4
      val exp_mant = MLWorks.String.explode mantissa
      fun exp_mant_is_zero [] = true
      | exp_mant_is_zero("0" :: xs) = exp_mant_is_zero xs
      | exp_mant_is_zero _ = false
d359 2
a360 2
      exp_mant_is_zero exp_mant
    end
d362 1
a362 1
  fun binary_list_to_string(done, [], _, 128) = MLWorks.String.implode(rev done)
d368 1
a368 1
	val x = MLWorks.String.ord x - MLWorks.String.ord "0"
d371 1
a371 1
	  binary_list_to_string(MLWorks.String.chr(digit + x) :: done, xs, 0, 128)
d381 1
a381 1
	  val digit = MLWorks.String.chr(value mod 2 + MLWorks.String.ord"0")
d390 1
a390 1
    | n_zeroes(done, n) = n_zeroes("0" :: done, n-1)
d406 1
a406 1
	  if exponent < ~bits then (MLWorks.String.implode(n_zeroes([], bits)), 0)
d408 1
a408 1
	    (MLWorks.String.implode(n_zeroes([], abs exponent)) ^ mantissa, 0)
d415 1
a415 1
	(if sign then "1" else "0") ::
d417 1
a417 1
	   MLWorks.String.explode(MLWorks.String.substring(mantissa, 1, 23))
d427 1
a427 1
	(if sign then "1" else "0") ::
d429 1
a429 1
	   MLWorks.String.explode(MLWorks.String.substring(mantissa, 1, 52))
d440 1
a440 1
	(if sign then "1" else "0") ::
d443 1
a443 1
	   MLWorks.String.explode(MLWorks.String.substring(mantissa, 0, 64)) @@
d461 1
a461 1
	 Code_Module.REAL(i, MLWorks.String.implode (rev (MLWorks.String.explode (encoding_function(sign, mantissa, exponent)))))
d473 1
a473 1
  type half_op = I386_Assembly.opcode * MirTypes.tag MLWorks.Option.option
d477 1
a477 1
  val absent = MLWorks.Option.NONE
d493 1
a493 1
	  ((_, MLWorks.Option.SOME tag, _), true) => (tag, true)
d641 1
a641 1
	      MLWorks.Option.SOME(_, t) => t
d646 1
a646 1
	      MLWorks.Option.NONE => true
d693 1
a693 1
  MirTypes.tag * (I386_Assembly.opcode * MirTypes.tag MLWorks.Option.option * string) list
d699 1
a699 1
       (I386_Assembly.BRANCH_ANNUL(I386_Assembly.BA, i), MLWorks.Option.SOME tag', comm),
d702 1
a702 1
       [(I386_Assembly.BRANCH(I386_Assembly.BA, i), MLWorks.Option.SOME tag', comm),
d785 1
a785 1
				       tag_opt as MLWorks.Option.SOME tag, comment), offset) =
d787 1
a787 1
			     MLWorks.Option.SOME res =>
d799 1
a799 1
			   | MLWorks.Option.NONE =>
d807 1
a807 1
				       tag_opt as MLWorks.Option.SOME tag, comment), offset) =
d809 1
a809 1
			       MLWorks.Option.SOME res =>
d821 1
a821 1
			     | MLWorks.Option.NONE =>
d898 1
a898 1
				   MLWorks.Option.SOME tag, comment), offset) =
d900 1
a900 1
			 MLWorks.Option.SOME res =>
d908 1
a908 1
		       | MLWorks.Option.NONE =>
d915 1
a915 1
				   MLWorks.Option.SOME tag, comment), offset) =
d917 1
a917 1
			   MLWorks.Option.SOME res =>
d944 1
a944 1
		       | MLWorks.Option.NONE =>
d951 1
a951 1
				   MLWorks.Option.SOME tag, comment), offset) =
d953 1
a953 1
			   MLWorks.Option.SOME res =>
d961 1
a961 1
		       | MLWorks.Option.NONE =>
d968 1
a968 1
				   MLWorks.Option.SOME tag, comment), offset) =
d970 1
a970 1
			   MLWorks.Option.SOME res =>
d978 1
a978 1
			 | MLWorks.Option.NONE =>
d984 1
a984 1
				   MLWorks.Option.SOME tag, comment), offset) =
d986 1
a986 1
			   MLWorks.Option.SOME res =>
d994 1
a994 1
			 | MLWorks.Option.NONE =>
d1000 1
a1000 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1002 1
a1002 1
			   MLWorks.Option.SOME res =>
d1029 1
a1029 1
			 | MLWorks.Option.NONE =>
d1036 1
a1036 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1038 1
a1038 1
			   MLWorks.Option.SOME res =>
d1065 1
a1065 1
		       | MLWorks.Option.NONE =>
d1072 1
a1072 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1074 1
a1074 1
			   MLWorks.Option.SOME res =>
d1101 1
a1101 1
		       | MLWorks.Option.NONE =>
d1108 1
a1108 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1110 1
a1110 1
			   MLWorks.Option.SOME res =>
d1137 1
a1137 1
		       | MLWorks.Option.NONE =>
d1144 1
a1144 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1146 1
a1146 1
			   MLWorks.Option.SOME res =>
d1154 1
a1154 1
			 | MLWorks.Option.NONE =>
d1160 1
a1160 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1162 1
a1162 1
			   MLWorks.Option.SOME res =>
d1170 1
a1170 1
			 | MLWorks.Option.NONE =>
d1177 1
a1177 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1179 1
a1179 1
			   MLWorks.Option.SOME res =>
d1188 1
a1188 1
			 | MLWorks.Option.NONE => Crash.impossible "Assoc do_opcode: LEO")
d1192 1
a1192 1
			       MLWorks.Option.SOME tag, comment), offset) =
d1194 1
a1194 1
			   MLWorks.Option.SOME res =>
d1202 1
a1202 1
			 | MLWorks.Option.NONE =>
d1205 1
a1205 1
			       MLWorks.Option.SOME tag, comment), offset) =
d1207 1
a1207 1
			   MLWorks.Option.SOME res =>
d1215 1
a1215 1
			 | MLWorks.Option.NONE =>
d1220 1
a1220 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1222 1
a1222 1
			   MLWorks.Option.SOME res =>
d1247 1
a1247 1
				      MLWorks.Option.SOME tag, new_comment) ::
d1251 1
a1251 1
				      MLWorks.Option.SOME tag, new_comment) ::
d1255 1
a1255 1
				      MLWorks.Option.NONE, new_comment) :: tail
d1262 1
a1262 1
			 | MLWorks.Option.NONE =>
d1267 1
a1267 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1269 1
a1269 1
			   MLWorks.Option.SOME res =>
d1280 1
a1280 1
			 | MLWorks.Option.NONE =>
d1283 1
a1283 1
				   MLWorks.Option.SOME tag, comment), _) =
d1285 1
a1285 1
			   MLWorks.Option.SOME res =>
d1303 1
a1303 1
			 | MLWorks.Option.NONE =>
d1307 1
a1307 1
				   MLWorks.Option.SOME tag, comment), offset) =
d1309 1
a1309 1
			   MLWorks.Option.SOME res =>
d1318 1
a1318 1
			 | MLWorks.Option.NONE =>
d1322 1
a1322 1
		      | do_opcode((opcode, MLWorks.Option.NONE, comment), offset) =
d1601 1
a1601 1
	  MLWorks.Option.SOME loop_tag, "enter at head of initialisation loop") :: [],
d1607 1
a1607 1
	  MLWorks.Option.SOME loop_tag, "loop if not finished") :: []
d1669 1
a1669 1
				 MLWorks.Option.NONE,
d1676 1
a1676 1
		      (I386_Assembly.pop, [I386_Assembly.r32 gc]), MLWorks.Option.NONE,
d1688 1
a1688 1
                 MLWorks.Option.NONE,
d1862 1
a1862 1
			      MLWorks.Option.SOME(I386_Assembly.SMALL spill)
d1951 1
a1951 1
			    MLWorks.Option.SOME tag => tag
d1963 1
a1963 1
			   (new_op, MLWorks.Option.SOME clean_tag, reg_operand,
d2218 1
a2218 1
			val base = MLWorks.Option.SOME(lookup_gp_operand gp_operand)
d2294 1
a2294 1
				      MLWorks.Option.SOME tag3, "continue")]
d2339 1
a2339 1
				     MLWorks.Option.SOME tag2, "branch if ok") ::
d2584 1
a2584 1
					  MLWorks.Option.SOME(I386_Assembly.SMALL spill)
d2663 1
a2663 1
			      if spill = 0 then absent else MLWorks.Option.SOME(I386_Assembly.SMALL spill)
d2845 1
a2845 1
                              (I386_Assembly.OPCODE (I386_Assembly.jmp, [I386_Assembly.rel32 0]), MLWorks.Option.SOME next_tag, "")])
d2854 1
a2854 1
                            (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.not_parity,[I386_Assembly.rel32 0]), MLWorks.Option.SOME end_tag,""),
d2857 1
a2857 1
                            (I386_Assembly.OPCODE (I386_Assembly.jmp, [I386_Assembly.rel32 0]), MLWorks.Option.SOME end_tag, "")],
d2962 1
a2962 1
				   MLWorks.Option.SOME offset) =>
d2964 1
a2964 1
		| MirTypes.STACKOP(stack_op, reg_operand, MLWorks.Option.NONE) =>
d2997 2
a2998 2
				  {base = MLWorks.Option.SOME r1,
				   index = MLWorks.Option.SOME(lookup_gp_operand gp_operand', absent),
d3008 1
a3008 1
				    {base = MLWorks.Option.SOME r1,
d3010 1
a3010 1
				     offset = MLWorks.Option.SOME(assemble_large_offset gp_operand')}
d3452 1
a3452 1
                        (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.below_or_equal,[I386_Assembly.rel32 0]), MLWorks.Option.SOME tag,""),
d3461 1
a3461 1
                        (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.above,[I386_Assembly.rel32 0]), MLWorks.Option.SOME tag,""),
d3506 1
a3506 1
			    MLWorks.Option.SOME tag, "branch relative")]),
d3660 1
a3660 1
			     MLWorks.Option.SOME test_tag, "do the branch")],
d3695 1
a3695 1
                      (I386_Assembly.OPCODE (I386_Assembly.jcc cond,[I386_Assembly.rel32 0]), MLWorks.Option.SOME tag,"")
d3722 1
a3722 1
		      MLWorks.Option.SOME tag, "call relative")],
d3751 1
a3751 1
			      MLWorks.Option.SOME tag, "branch relative(tail call)")]
d3792 1
a3792 1
				 MLWorks.Option.SOME tag, "Unconditional branch")],
d3799 1
a3799 1
				    MLWorks.Option.SOME tag2, "Unconditional branch")]
d3817 1
a3817 1
				  MLWorks.Option.SOME tag1, "branch if zero") ::
d3832 1
a3832 1
						   MLWorks.Option.SOME tag,
d3852 1
a3852 1
				   MLWorks.Option.SOME tag,
d3884 1
a3884 1
					  MLWorks.Option.SOME fp_offset) =>
d3988 1
a3988 1
				 MLWorks.Option.SOME tag3, "jump to rest of code")]
d4031 1
a4031 1
				  MLWorks.Option.SOME tag2,
d4135 1
a4135 1
				 [I386_Assembly.rel32 0]), MLWorks.Option.SOME tag2,
d4147 1
a4147 1
				 MLWorks.Option.SOME tag2,
d4391 1
a4391 1
				 [I386_Assembly.rel32 0]), MLWorks.Option.SOME tag1,
d4436 1
a4436 1
				 MLWorks.Option.SOME tag2, "jump to continuation point")]
d4509 1
a4509 1
				 MLWorks.Option.SOME tag3, "branch to rest of code")]
d4808 1
a4808 1
			    MLWorks.Option.SOME tag,
d4832 1
a4832 1
			  MLWorks.Option.SOME continue_tag,
d4837 1
a4837 1
			  MLWorks.Option.SOME continue_tag, "continue after interrupt")]
d4874 1
a4874 1
			    MLWorks.Option.SOME overflow_code_tag,
d4879 1
a4879 1
			    MLWorks.Option.SOME post_overflow_tag,
d4936 1
a4936 1
			    MLWorks.Option.SOME post_overflow_tag,
d4969 1
a4969 1
					 MLWorks.Option.SOME post_make_stack_tag,
d4998 1
a4998 1
			    MLWorks.Option.SOME real_proc_start_tag,
d5231 1
a5231 1
      fun exit_block [] = MLWorks.Option.NONE
d5236 1
a5236 1
	  then MLWorks.Option.SOME block
d5295 2
a5296 2
	      MLWorks.Option.NONE => block_list
	    | MLWorks.Option.SOME exit_block =>
d5304 1
a5304 1
	      MLWorks.Option.NONE => MirTypes.FP.Map.define(map, fp, true)
d5332 1
a5332 1
	       MLWorks.Option.NONE => MirTypes.GC.Map.define(map, r, true)
d5338 1
a5338 1
	       MLWorks.Option.NONE => MirTypes.GC.Map.define(map, r, true)
d5407 1
a5407 1
	       MLWorks.Option.SOME x => x :: acc
d5415 1
a5415 1
	       MLWorks.Option.SOME x => x :: acc
d5426 1
a5426 1
	  val fp_save_size = Lists.length fps_to_preserve
d5449 1
a5449 1
	    MLWorks.Option.SOME stack_extra => stack_extra
d5468 1
a5468 1
	      MLWorks.Option.SOME x => check_reg x
d5473 1
a5473 1
	      MLWorks.Option.SOME x => check_reg x
d5569 1
a5569 1
	    Lists.iterate check_instr_regs instr_list
d5576 1
a5576 1
	      MLWorks.Option.SOME{gc = gc_spill_size,
d5594 1
a5594 1
	    ((Lists.iterate check_instr_block_regs block_list;
d5661 1
a5661 1
          val number_of_saves = Lists.length callee_saves
d5692 1
a5692 1
	       MLWorks.Option.SOME old => old
d5724 1
a5724 1
	    (0, map (fn (_, opcodes) => Lists.length opcodes) code)
d5729 1
a5729 1
                | generate_nulls n = MLWorks.String.chr(0) ^ generate_nulls (n-1)
d5733 1
a5733 1
              normalise_to_four_bytes(procedure_name ^ MLWorks.String.chr(0))
d5755 1
a5755 1
			    MLWorks.Option.SOME tag =>
d5757 1
a5757 1
			  | MLWorks.Option.NONE => " no tag") ^
d5827 1
a5827 1
				 MLWorks.Option.SOME tag =>
d5829 1
a5829 1
			       | MLWorks.Option.NONE => " no tag") ^
d5899 1
a5899 1
				 MLWorks.Option.SOME ((ty,leaf,annotations),runtime_env) =>
d5911 1
a5911 1
                       then MLWorks.String.implode (annotation_points (code,0,[]))
d5913 1
a5913 1
                       MLWorks.String.implode
d5924 1
a5924 1
		       MLWorks.String.implode(code :: make_nops(8 - size code mod 8, []))
@


1.57
log
@[Bug #1572]
Fix problems with self multiplies producing answer too small by factor of 4
@
text
@d4 4
d3343 1
d3346 15
a3360 7
                      val (mem_operand,get_arg_code) =
                        if gp_operand_is_spill gp_operand
                          then 
                            (I386_Assembly.MEM
                             {base=MLWorks.Option.SOME I386Types.sp,
                              index=absent,
                              offset=MLWorks.Option.SOME(I386_Assembly.SMALL(gp_spill_value gp_operand))},[])
d3379 1
a3379 1
                               absent,"Use stack as temporary")])
d3383 1
a3383 1
                       [(I386_Assembly.OPCODE (I386_Assembly.sar,[I386_Assembly.r_m32 (MLWorks.Option.INR mem_operand),
d3387 2
a3388 1
                        (I386_Assembly.OPCODE (I386_Assembly.fstp,[rd]),absent,"")],
@


1.57.3.1
log
@branched from 1.57
@
text
@a3 4
 * Revision 1.57  1996/08/27  11:37:40  jont
 * [Bug #1572]
 * Fix problems with self multiplies producing answer too small by factor of 4
 *
@


1.57.2.1
log
@branched from 1.57
@
text
@a3 4
 * Revision 1.57  1996/08/27  11:37:40  jont
 * [Bug #1572]
 * Fix problems with self multiplies producing answer too small by factor of 4
 *
@


1.57.1.1
log
@branched from 1.57
@
text
@a3 4
 * Revision 1.57  1996/08/27  11:37:40  jont
 * [Bug #1572]
 * Fix problems with self multiplies producing answer too small by factor of 4
 *
@


1.56
log
@Porblems with parameters to set_proc_data being wrong order
@
text
@d4 3
d2055 10
d2073 3
a2075 2
					I386_Assembly.imm8 2]), absent,
				  "shift source right two before multiply")]
@


1.55
log
@[Bug #1503]
Add field to FUNINFO to say if arg actually saved
@
text
@d4 4
d5565 1
a5566 1
                                                           not needs_preserve,
@


1.54
log
@Fix array code generation problems
@
text
@d4 3
d5561 1
@


1.53
log
@The Ord exception is no longer at top level.
@
text
@d4 3
d4128 1
d4476 4
a4479 1
					 (I386Types.EAX, I386Types.global)
a4480 5
(*
					 if size_is_spill then
					   (rd, I386Types.global)
					 else
*)
d4487 2
a4488 2
					   [I386_Assembly.r32 I386Types.EAX]),
					  absent, "restore EAX") ::
d4554 2
a4555 2
					   [I386_Assembly.r32 I386Types.EAX]),
					  absent, "save EAX") ::
d4570 4
a4573 1
					 (I386Types.EAX, I386Types.global)
d4581 2
a4582 2
					   [I386_Assembly.r32 I386Types.EAX]),
					  absent, "restore EAX") ::
d4648 2
a4649 2
					   [I386_Assembly.r32 I386Types.EAX]),
					  absent, "save EAX") ::
d4666 4
a4669 1
					 (I386Types.EAX, true)
d4676 2
a4677 2
					   [I386_Assembly.r32 I386Types.EAX]),
					  absent, "restore EAX") :: tag3_jmp
d4696 2
a4697 2
					   [I386_Assembly.r32 I386Types.EAX]),
					  absent, "save EAX") ::
@


1.52
log
@Moved Bits to MLWorks.Internal
@
text
@d4 3
d284 1
a284 1
      aux (String.explode l,0)
d329 1
a329 1
      val exp_mant = String.explode mantissa
d337 1
a337 1
  fun binary_list_to_string(done, [], _, 128) = String.implode(rev done)
d343 1
a343 1
	val x = String.ord x - String.ord "0"
d346 1
a346 1
	  binary_list_to_string(String.chr(digit + x) :: done, xs, 0, 128)
d356 1
a356 1
	  val digit = String.chr(value mod 2 + String.ord"0")
d381 1
a381 1
	  if exponent < ~bits then (String.implode(n_zeroes([], bits)), 0)
d383 1
a383 1
	    (String.implode(n_zeroes([], abs exponent)) ^ mantissa, 0)
d392 1
a392 1
	   String.explode(String.substring(mantissa, 1, 23))
d404 1
a404 1
	   String.explode(String.substring(mantissa, 1, 52))
d418 1
a418 1
	   String.explode(String.substring(mantissa, 0, 64)) @@
d436 1
a436 1
	 Code_Module.REAL(i, String.implode (rev (String.explode (encoding_function(sign, mantissa, exponent)))))
d5677 1
a5677 1
                | generate_nulls n = String.chr(0) ^ generate_nulls (n-1)
d5681 1
a5681 1
              normalise_to_four_bytes(procedure_name ^ String.chr(0))
d5836 1
a5836 1
                                    if String.ordof(padded_name,to) = 0
d5838 1
a5838 1
                                    else String.substring(padded_name,0,to+1)
d5841 2
a5842 2
                                  handle String.Substring => ""
                                       | Ord => ""
d5859 1
a5859 1
                       then String.implode (annotation_points (code,0,[]))
d5861 1
a5861 1
                       String.implode
d5872 1
a5872 1
		       String.implode(code :: make_nops(8 - size code mod 8, []))
@


1.51
log
@Fix non-reversible binary operations with stack operations
@
text
@d4 3
d249 2
d2408 2
a2409 2
				  (MLWorks.Bits.xorb(i, ~1),
				   MLWorks.Bits.xorb(j, 3))
d3391 1
a3391 1
                                                                   I386_Assembly.imm32(MLWorks.Bits.lshift (1,27), 0)]), 
@


1.50
log
@Adding NOT32 MIR instruction
@
text
@d4 3
d1460 1
a1460 1
		     (*Crash.impossible*) raise bad_spill
d1816 59
d2533 44
a2576 3
				    Crash.unimplemented
				    ("BINARY:unreversible:reg_operand = gp_operand' in " ^
				     MirPrint.opcode opcode)
d2598 2
d2654 1
a2654 53
			    val opcode = I386_Assembly.mov
			    val code_list =
			      if is_reg gp_operand then
				(* May be spill here *)
				if gp_operand_is_spill gp_operand then
				  let
				    val spill = gp_spill_value gp_operand
				    val offset =
				      if spill = 0 then
					absent
				      else
					MLWorks.Option.SOME(I386_Assembly.SMALL spill)
				  in
				    [(I386_Assembly.OPCODE
				      (opcode,
				       [I386_Assembly.r32 rd,
					I386_Assembly.r_m32
					(MLWorks.Option.INR
					 (I386_Assembly.MEM
					  {base=MLWorks.Option.SOME I386Types.sp,
					   index=absent,
					   offset=offset}))]),
				      absent, "")]
				  end
				else
				  let
				    val rs1 = lookup_gp_operand gp_operand
				  in
				    if rd = rs1 then
				      [] (* Null move rn -> rn *)
				    else
				      [(I386_Assembly.OPCODE
					(opcode,
					 [I386_Assembly.r32 rd,
					  I386_Assembly.r_m32
					  (MLWorks.Option.INL rs1)]),
					absent, "")]
				  end
			      else
				case assemble_imm32 gp_operand of
				  (0, 0) =>
				    [(I386_Assembly.OPCODE
				      (I386_Assembly.xor,
				       [I386_Assembly.r32 rd,
					I386_Assembly.r_m32
					(MLWorks.Option.INL rd)]),
				      absent, "")]
				| x =>
				    [(I386_Assembly.OPCODE
				      (opcode,
				       [I386_Assembly.r32 rd,
					I386_Assembly.imm32 x]),
				      absent, "")]
d2659 1
a4730 9
(*
			  [(I386_Assembly.Call
			    (I386_Assembly.CALL, 2),
			    absent, "Call self"),
			   (I386_Assembly.ARITHMETIC_AND_LOGICAL
			    (I386_Assembly.ADD, lookup_reg_operand reg_operand,
			     I386_Assembly.IMM 4, I386Types.lr),
			    MLWorks.Option.SOME tag, "Update gc pointer")]
*)
@


1.49
log
@Array moving to MLWorks.Array
@
text
@d4 3
a2608 3
			val needs_clear = case reg_operand of
			  MirTypes.GC_REG _ => true
			| _ => false
a2609 1
			  if needs_clear then
a2612 2
			  else
			    opcode_list
d2634 27
@


1.48
log
@String functions explode, implode, chr and ord now only available from String
io functions and types
instream, oustream, open_in, open_out, close_in, close_out, input, output and end_of_stream
now only available from MLWorks.IO
@
text
@d4 6
d1395 1
a1395 1
      val gc_array = Array.array(gc, MachSpec.global)
d1399 1
a1399 1
	 Array.update(gc_array, MirTypes.GC.unpack mir_reg, reg))
d1401 1
a1401 1
      val non_gc_array = Array.array(non_gc, MachSpec.global)
d1405 1
a1405 1
	 Array.update(non_gc_array, MirTypes.NonGC.unpack mir_reg, reg))
d1407 1
a1407 1
      val fp_array = Array.array(fp, MachSpec.global)
d1411 1
a1411 1
	 Array.update(fp_array, MirTypes.FP.unpack mir_reg, reg))
d1682 1
a1682 1
	      val mach_reg = Array.sub(table, reg)
d1712 1
a1712 1
	    Array.sub(fp_array, MirTypes.FP.unpack reg)
@


1.47
log
@Removing use of MLWorks.Integer
@
text
@d4 3
d264 1
a264 1
      aux (explode l,0)
d309 1
a309 1
      val exp_mant = explode mantissa
d317 1
a317 1
  fun binary_list_to_string(done, [], _, 128) = implode(rev done)
d323 1
a323 1
	val x = ord x - ord "0"
d326 1
a326 1
	  binary_list_to_string(chr(digit + x) :: done, xs, 0, 128)
d336 1
a336 1
	  val digit = chr(value mod 2 + ord"0")
d361 1
a361 1
	  if exponent < ~bits then (implode(n_zeroes([], bits)), 0)
d363 1
a363 1
	    (implode(n_zeroes([], abs exponent)) ^ mantissa, 0)
d372 1
a372 1
	   explode(String.substring(mantissa, 1, 23))
d384 1
a384 1
	   explode(String.substring(mantissa, 1, 52))
d398 1
a398 1
	   explode(String.substring(mantissa, 0, 64)) @@
d416 1
a416 1
	 Code_Module.REAL(i, implode (rev (explode (encoding_function(sign, mantissa, exponent)))))
d5594 1
a5594 1
                | generate_nulls n = chr(0) ^ generate_nulls (n-1)
d5598 1
a5598 1
              normalise_to_four_bytes(procedure_name ^ chr(0))
d5776 1
a5776 1
                       then implode (annotation_points (code,0,[]))
d5778 1
a5778 1
                       implode
d5789 1
a5789 1
		       implode(code :: make_nops(8 - size code mod 8, []))
d5814 1
a5814 1
	  output(std_out, "Normalised code size is " ^
@


1.46
log
@Removing error checks for FP operations
@
text
@d4 3
d163 2
d299 1
a299 1
		 MLWorks.Integer.makestring i,
d301 1
a301 1
		 MLWorks.Integer.makestring pos_limit]);
d317 1
a317 1
		       MLWorks.Integer.makestring l)
d814 1
a814 1
			  (fn (x, y) => Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ MLWorks.Integer.makestring y ^ "\n"))
d833 1
a833 1
	     (fn (x, y) => Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ MLWorks.Integer.makestring y ^ "\n"))
d877 1
a877 1
				    MLWorks.Integer.makestring disp ^ " out of range in " ^
d883 1
a883 1
				    MLWorks.Integer.makestring disp ^ 
d885 1
a885 1
				    MLWorks.Integer.makestring res ^
d887 1
a887 1
				    MLWorks.Integer.makestring i ^
d889 1
a889 1
				    MLWorks.Integer.makestring offset)
d962 1
a962 1
				    MLWorks.Integer.makestring disp ^ " out of range in " ^
d968 1
a968 1
				    MLWorks.Integer.makestring disp ^ 
d970 1
a970 1
				    MLWorks.Integer.makestring res ^
d972 1
a972 1
				    MLWorks.Integer.makestring i ^
d974 1
a974 1
				    MLWorks.Integer.makestring offset)
d998 1
a998 1
				    MLWorks.Integer.makestring disp ^ " out of range in " ^
d1004 1
a1004 1
				    MLWorks.Integer.makestring disp ^ 
d1006 1
a1006 1
				    MLWorks.Integer.makestring res ^
d1008 1
a1008 1
				    MLWorks.Integer.makestring i ^
d1010 1
a1010 1
				    MLWorks.Integer.makestring offset)
d1034 1
a1034 1
				    MLWorks.Integer.makestring disp ^ " out of range in " ^
d1040 1
a1040 1
				    MLWorks.Integer.makestring disp ^ 
d1042 1
a1042 1
				    MLWorks.Integer.makestring res ^
d1044 1
a1044 1
				    MLWorks.Integer.makestring i ^
d1046 1
a1046 1
				    MLWorks.Integer.makestring offset)
d1070 1
a1070 1
				    MLWorks.Integer.makestring disp ^ " out of range in " ^
d1076 1
a1076 1
				    MLWorks.Integer.makestring disp ^ 
d1078 1
a1078 1
				    MLWorks.Integer.makestring res ^
d1080 1
a1080 1
				    MLWorks.Integer.makestring i ^
d1082 1
a1082 1
				    MLWorks.Integer.makestring offset)
d1446 2
a1447 2
		     ("Spill slot " ^ MLWorks.Integer.makestring i ^
		      " requested, but only " ^ MLWorks.Integer.makestring gc_spill_size ^
d1470 1
a1470 1
		     raise bad_spill ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
d1472 1
a1472 1
				      MLWorks.Integer.makestring non_gc_spill_size ^
d1493 1
a1493 1
                     raise bad_spill ("fp spill slot " ^ MLWorks.Integer.makestring i ^
d1495 1
a1495 1
                                      MLWorks.Integer.makestring fp_spill_size ^
d3748 1
a3748 1
					 MLWorks.Integer.makestring alloc_size ^
d3750 1
a3750 1
					 MLWorks.Integer.makestring fp_offset ^
d3752 1
a3752 1
					 MLWorks.Integer.makestring
d5560 12
a5571 12
	  val _ = output(std_out, "non_gc_spill_size = " ^ MLWorks.Integer.makestring non_gc_spill_size ^ "\n")
	  val _ = output(std_out, "fp_spill_size = " ^ MLWorks.Integer.makestring fp_spill_size ^ "\n")
	  val _ = output(std_out, "fp_save_size = " ^ MLWorks.Integer.makestring fp_save_size ^ "\n")
	  val _ = output(std_out, "gc_spill_size = " ^ MLWorks.Integer.makestring gc_spill_size ^ "\n")
	  val _ = output(std_out, "gc_stack_alloc_size = " ^ MLWorks.Integer.makestring stack_extra ^ "\n")
	  val _ = output(std_out, "register_save_size = " ^ MLWorks.Integer.makestring register_save_size ^ "\n")
	  val _ = output(std_out, "non_gc_spill_offset = " ^ MLWorks.Integer.makestring frame_offset ^ "\n")
	  val _ = output(std_out, "fp_spill_offset = " ^ MLWorks.Integer.makestring fp_spill_offset ^ "\n")
	  val _ = output(std_out, "fp_save_offset = " ^ MLWorks.Integer.makestring fp_save_offset ^ "\n")
	  val _ = output(std_out, "gc_spill_offset = " ^ MLWorks.Integer.makestring gc_spill_offset ^ "\n")
	  val _ = output(std_out, "gc_stack_alloc_offset = " ^ MLWorks.Integer.makestring gc_stack_alloc_offset ^ "\n")
	  val _ = output(std_out, "register_save_offset = " ^ MLWorks.Integer.makestring register_save_offset ^ "\n")
d5812 1
a5812 1
		 MLWorks.Integer.makestring
@


1.45
log
@Allow offsets in mem_operands to be bigger than an int, to cope with words
@
text
@d4 3
d2727 1
d2786 20
d2807 18
a3529 16
                  (*
                   Here we translate:

                   ftest (cond,tag,op1,op2)

                   to:

                   fpush op1
                   fcomp op2
                   push ax
                   fstsw ax ; ax := fcc;
                   wait
                   sahf ; flags := ah
                   pop ax
                   jcc tag
                   *)
@


1.44
log
@Fix problems when doing fstref relative to frame
@
text
@d4 3
d1740 4
a1743 1
		  4*i+j (* Should never overflow! *)
d1782 1
a1782 1
                      offset=MLWorks.Option.SOME(fp_spill_value operand)})
d1915 1
a1915 1
				      offset=MLWorks.Option.SOME spill})),
d1929 1
a1929 1
					offset=MLWorks.Option.SOME spill})))
d2021 1
a2021 1
					offset=MLWorks.Option.SOME(reg_spill_value reg_operand)
d2104 1
a2104 1
				offset =
d2109 11
a2119 1
				  if invert_gp' then ~offset else offset
d2161 1
a2161 1
					 offset=MLWorks.Option.SOME(reg_spill_value reg_operand)})
d2256 1
a2256 1
				       offset=MLWorks.Option.SOME(reg_spill_value reg_operand)})
d2301 1
a2301 1
				       offset=MLWorks.Option.SOME(gp_spill_value gp_operand')})
d2330 1
a2330 1
				       offset=MLWorks.Option.SOME(reg_spill_value reg_operand)})
d2369 1
a2369 1
					offset=MLWorks.Option.SOME spill})),
d2383 1
a2383 1
					  offset=MLWorks.Option.SOME spill}))]
d2494 1
a2494 1
			      if spill = 0 then absent else MLWorks.Option.SOME spill
d2540 1
a2540 1
					MLWorks.Option.SOME spill
d2606 1
a2606 1
			       offset=MLWorks.Option.SOME(reg_spill_value reg_operand)})
d2632 1
a2632 1
			      offset=MLWorks.Option.SOME(reg_spill_value reg_operand)})),
d3181 1
a3181 1
                              offset=MLWorks.Option.SOME(gp_spill_value gp_operand)},[])
d3187 1
a3187 1
                                                 offset=MLWorks.Option.SOME(frame_size + stack_drop - fp_spare_offset)}
d3220 1
a3220 1
                                           offset=MLWorks.Option.SOME(frame_size + stack_drop - fp_spare_offset)}
d3231 1
a3231 1
                                 offset=MLWorks.Option.SOME(reg_spill_value reg_operand)}
d3377 1
a3377 1
				    offset=MLWorks.Option.SOME spill})),
d3403 1
a3403 1
				      offset=MLWorks.Option.SOME(gp_spill_value gp_op')})),
d3540 1
a3540 1
			      offset=MLWorks.Option.SOME Tags.CODE_OFFSET}))]),
d3569 1
a3569 1
				     offset=MLWorks.Option.SOME Tags.CODE_OFFSET}))]),
d3635 1
a3635 1
				       offset=MLWorks.Option.SOME(reg_spill_value reg_operand)})
d3670 1
a3670 1
				       offset=MLWorks.Option.SOME(reg_spill_value reg_operand)})
d3690 1
a3690 1
					offset=MLWorks.Option.SOME ~1}))]),
d3753 1
a3753 1
				  offset=MLWorks.Option.SOME offset}))]),
d3828 1
a3828 1
				       offset=MLWorks.Option.SOME(~primary)})),
d3842 1
a3842 1
				       offset=MLWorks.Option.SOME(bytes - primary - 4)})),
d3876 1
a3876 1
					offset=MLWorks.Option.SOME primary}))]),
d3893 1
a3893 1
					offset=MLWorks.Option.SOME bytes}))]),
d3902 1
a3902 1
					offset=MLWorks.Option.SOME gc_entry}))]),
d3922 1
a3922 1
				     offset=MLWorks.Option.SOME(4*Implicit_Vector.gc_base)})),
d3937 1
a3937 1
				     offset=MLWorks.Option.SOME(4*Implicit_Vector.gc_base)}))]),
d3948 1
a3948 1
				     offset=MLWorks.Option.SOME(4*Implicit_Vector.gc_limit)}))]),
d3959 1
a3959 1
				     offset=MLWorks.Option.SOME(primary-bytes)}))]),
d4005 1
a4005 1
				    offset=MLWorks.Option.SOME(reg_spill_value reg_operand)}),
d4011 1
a4011 1
				    (4+reg_spill_value reg_operand)}))
d4033 1
a4033 1
					      (gp_spill_value gp_operand)}))]),
d4057 1
a4057 1
					      offset=MLWorks.Option.SOME(4+7)}))]),
d4072 1
a4072 1
					     (gp_spill_value gp_operand)}))]),
d4089 1
a4089 1
						(gp_spill_value gp_operand)}))]),
d4120 1
a4120 1
					      (gp_spill_value gp_operand)}))]),
d4144 1
a4144 1
					      offset=MLWorks.Option.SOME(12+7)}))]),
d4158 1
a4158 1
					     (gp_spill_value gp_operand)}))]),
d4175 1
a4175 1
						(gp_spill_value gp_operand)}))]),
d4202 1
a4202 1
				     offset=MLWorks.Option.SOME(4*Implicit_Vector.gc_base)}))]),
d4213 1
a4213 1
				     offset=MLWorks.Option.SOME(4*Implicit_Vector.gc_limit)}))]),
d4236 1
a4236 1
				       (4*Implicit_Vector.gc_base)})),
d4250 1
a4250 1
				       (4*Implicit_Vector.gc_base)})),
d4285 1
a4285 1
				       offset=MLWorks.Option.SOME primary}))]),
d4300 1
a4300 1
				     offset=MLWorks.Option.SOME gc_entry}))]),
d4315 1
a4315 1
					 offset=MLWorks.Option.SOME primary}))]),
d4377 1
a4377 1
					     offset=MLWorks.Option.SOME offset})),
d4399 1
a4399 1
						 offset=MLWorks.Option.SOME spill_value}))]),
d4419 1
a4419 1
					     offset=MLWorks.Option.SOME(~primary)})),
d4468 1
a4468 1
					     offset=MLWorks.Option.SOME offset})),
d4490 1
a4490 1
						 offset=MLWorks.Option.SOME spill_value}))]),
d4510 1
a4510 1
					     offset=MLWorks.Option.SOME(~primary)})),
d4554 1
a4554 1
					     offset=MLWorks.Option.SOME(~primary)})),
d4586 1
a4586 1
				       (gp_spill_value gp_operand)})
d4636 1
a4636 1
				   offset=MLWorks.Option.SOME(reg_spill_value reg_operand)})
d4658 1
a4658 1
			       offset=MLWorks.Option.SOME(4*Implicit_Vector.register_stack_limit)})),
d4685 1
a4685 1
			      offset=MLWorks.Option.SOME(4 * check_offset)}))]),
d4724 1
a4724 1
				  offset=MLWorks.Option.SOME (~frame_size)}))]),
d4734 1
a4734 1
				  offset=MLWorks.Option.SOME(4*Implicit_Vector.register_stack_limit)}))]
d4747 1
a4747 1
				  offset=MLWorks.Option.SOME(4*Implicit_Vector.register_stack_limit)}))]
d4764 1
a4764 1
				 offset=MLWorks.Option.SOME(4*Implicit_Vector.extend)}))]),
d4820 1
a4820 1
				 offset=MLWorks.Option.SOME(frame_size-4)}))]),
d4904 1
a4904 1
			      offset=MLWorks.Option.SOME(4*Implicit_Vector.handler)})),
d4916 1
a4916 1
			      offset=MLWorks.Option.SOME(4*Implicit_Vector.handler)}))]),
d4925 1
a4925 1
			      offset=MLWorks.Option.SOME(~1)})),
d4942 1
a4942 1
				offset=MLWorks.Option.SOME(reg_spill_value frame + 4)}))]),
d4959 1
a4959 1
			    offset=MLWorks.Option.SOME(4*Implicit_Vector.handler)}))]),
d4969 1
a4969 1
			    offset=MLWorks.Option.SOME(~1)}))]),
d4978 1
a4978 1
			    offset=MLWorks.Option.SOME(4*Implicit_Vector.handler)})),
d4999 1
a4999 1
			       offset=MLWorks.Option.SOME spill}), true)
d5018 1
a5018 1
			       offset=MLWorks.Option.SOME vector}))]),
d5042 1
a5042 1
			    offset=MLWorks.Option.SOME(4*Implicit_Vector.external)}))]),
@


1.43
log
@Add implemetations of ADDW and SUBW
These are like ADDV and SUBV, except that
they cannot use exception trapping adds etc because they are untagged
and also when they detect overflow they must clean
all registers involved in the operation
Also fixed faulty string allocation size causing 16 bytes instead
of 8 to be allocated for 32 bit integers (with an inconsistent header)
@
text
@d4 9
d3114 1
d3130 11
a3140 3
                                 {base=MLWorks.Option.SOME rs1,
                                  index=absent,
                                  offset=MLWorks.Option.SOME(assemble_large_offset gp_operand)}))
d5682 2
d5723 1
a5723 1
                                              I386_Opcodes.output_opcode(I386_Assembly.assemble inst)::res))
d5731 1
a5731 1
                         I386_Opcodes.output_opcode(I386_Assembly.assemble x))
@


1.42
log
@Fixing problem with fp_spills and leafness
@
text
@d4 3
d1785 4
a1788 4
		      val opcode = case tagged_binary_op of
			MirTypes.ADDV => I386_Assembly.add
		      | MirTypes.SUBV => I386_Assembly.sub
		      | MirTypes.MULV => I386_Assembly.imul
d1791 5
d1797 42
d1970 5
d3764 1
a3764 1
				   (((size+12) div 8) * 8,
@


1.41
log
@Add extra field to procedure_parameters to contain old (pre register allocation)
spill sizes. This is for the i386, where spill assignment is done in the backend
@
text
@d4 4
a5169 1
	  val preserve_fps = fp_save_size <> 0
d5190 2
a5191 2
	  val stack_opt = stack_allocated
	  val stack_extra = case stack_opt of
d5314 13
d5332 2
a5333 2
	    (* Then see if any fps need perserving *)
	    preserve_fps orelse
a5386 11
	  (* Moved this from do_block as it's independent of block number *)
	  val spills_opt = spill_sizes

	  val (gc_spill_size, non_gc_spill_size, fp_spill_size) =
	    case spills_opt of
	      MLWorks.Option.SOME{gc = gc_spill_size,
			       non_gc = non_gc_spill_size,
			       fp = fp_spill_size} =>
	      (gc_spill_size, non_gc_spill_size, fp_spill_size)
	     | _ => Crash.impossible"Spill sizes missing to mach_cg"

a5390 4

	  val stack_extra = case stack_opt of
	    MLWorks.Option.SOME stack_extra => stack_extra
	  | _ =>  Crash.impossible"Stack size missing to mach_cg"
@


1.40
log
@Save argument register on stack when generating debug code.
@
text
@d4 3
a181 1
  sharing MirTables.MirTypes.Option = MirTables.MirTypes.Debugger_Types.RuntimeEnv.Option
a186 3
  sharing type I386_Schedule.I386_Assembly.opt = MirTables.MirTypes.Debugger_Types.RuntimeEnv.Option.opt
  sharing type I386_Schedule.I386_Assembly.option =
    MirTables.MirTypes.Debugger_Types.RuntimeEnv.Option.option
a201 1
  structure Option = RuntimeEnv.Option
d210 3
a212 3
    [(I386_Assembly.other_nop_code,Option.ABSENT,"Dummy instructions for tracing"),
     (I386_Assembly.other_nop_code,Option.ABSENT,"Dummy instructions for tracing"),
     (I386_Assembly.other_nop_code,Option.ABSENT,"Dummy instructions for tracing")]
d398 1
a398 1
  type half_op = I386_Assembly.opcode * MirTypes.tag Option.opt
d402 1
a402 1
  val absent = Option.ABSENT
d418 1
a418 1
	  ((_, Option.PRESENT tag, _), true) => (tag, true)
d618 1
a618 1
  MirTypes.tag * (I386_Assembly.opcode * MirTypes.tag Option.opt * string) list
d624 1
a624 1
       (I386_Assembly.BRANCH_ANNUL(I386_Assembly.BA, i), Option.PRESENT tag', comm),
d627 1
a627 1
       [(I386_Assembly.BRANCH(I386_Assembly.BA, i), Option.PRESENT tag', comm),
d710 1
a710 1
				       tag_opt as Option.PRESENT tag, comment), offset) =
d732 1
a732 1
				       tag_opt as Option.PRESENT tag, comment), offset) =
d823 1
a823 1
				   Option.PRESENT tag, comment), offset) =
d840 1
a840 1
				   Option.PRESENT tag, comment), offset) =
d876 1
a876 1
				   Option.PRESENT tag, comment), offset) =
d893 1
a893 1
				   Option.PRESENT tag, comment), offset) =
d909 1
a909 1
				   Option.PRESENT tag, comment), offset) =
d925 1
a925 1
				   Option.PRESENT tag, comment), offset) =
d961 1
a961 1
				   Option.PRESENT tag, comment), offset) =
d997 1
a997 1
				   Option.PRESENT tag, comment), offset) =
d1033 1
a1033 1
				   Option.PRESENT tag, comment), offset) =
d1069 1
a1069 1
				   Option.PRESENT tag, comment), offset) =
d1085 1
a1085 1
				   Option.PRESENT tag, comment), offset) =
d1102 1
a1102 1
				   Option.PRESENT tag, comment), offset) =
d1117 1
a1117 1
			       Option.PRESENT tag, comment), offset) =
d1130 1
a1130 1
			       Option.PRESENT tag, comment), offset) =
d1145 1
a1145 1
				   Option.PRESENT tag, comment), offset) =
d1172 1
a1172 1
				      Option.PRESENT tag, new_comment) ::
d1176 1
a1176 1
				      Option.PRESENT tag, new_comment) ::
d1180 1
a1180 1
				      Option.ABSENT, new_comment) :: tail
d1192 1
a1192 1
				   Option.PRESENT tag, comment), offset) =
d1208 1
a1208 1
				   Option.PRESENT tag, comment), _) =
d1232 1
a1232 1
				   Option.PRESENT tag, comment), offset) =
d1247 1
a1247 1
		      | do_opcode((opcode, Option.ABSENT, comment), offset) =
d1303 1
a1303 1
       I386_Assembly.r_m32(Option.SOME1 rs)]), absent, comment)
d1309 1
a1309 1
       I386_Assembly.r_m8(Option.SOME1 rs)]), absent, comment)
d1335 2
a1336 1
     float_value_size      : int  (* Number of bytes per float value *)
d1405 2
a1406 1
		      float_value_size
d1497 1
a1497 1
	       I386_Assembly.r_m32(Option.SOME1 I386Types.global)]),
d1514 1
a1514 1
	    I386_Assembly.r_m32(Option.SOME1 I386Types.global)]),
d1518 1
a1518 1
	   [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
d1526 1
a1526 1
	  Option.PRESENT loop_tag, "enter at head of initialisation loop") :: [],
d1532 1
a1532 1
	  Option.PRESENT loop_tag, "loop if not finished") :: []
d1567 5
a1571 1
		   float_value_size
a1578 1

d1594 1
a1594 1
				 Option.ABSENT,
d1601 1
a1601 1
		      (I386_Assembly.pop, [I386_Assembly.r32 gc]), Option.ABSENT,
d1613 1
a1613 1
                 Option.ABSENT,
d1737 1
a1737 1
		 (MirTypes.SIMPLE(MirTypes.GC.unpack reg - #gc(MirRegisters.pack_next))))
d1743 1
a1743 1
		 (MirTypes.SIMPLE(MirTypes.GC.unpack reg - #gc(MirRegisters.pack_next))))
d1749 1
a1749 1
		 (MirTypes.SIMPLE(MirTypes.FP.unpack reg - #fp(MirRegisters.pack_next))))
d1758 1
a1758 1
                     {base=Option.PRESENT I386Types.sp,
d1760 1
a1760 1
                      offset=Option.PRESENT(fp_spill_value operand)})
d1842 1
a1842 1
				   (Option.SOME2
d1844 1
a1844 1
				     {base=Option.PRESENT I386Types.sp,
d1846 1
a1846 1
				      offset=Option.PRESENT spill})),
d1856 1
a1856 1
				     (Option.SOME2
d1858 1
a1858 1
				       {base=Option.PRESENT I386Types.sp,
d1860 1
a1860 1
					offset=Option.PRESENT spill})))
d1872 1
a1872 1
				       (Option.SOME1
d1876 1
a1876 1
				       (Option.SOME1(lookup_reg_operand reg_operand)),
d1887 2
a1888 2
					I386_Assembly.r_m32(Option.SOME1 r)
				    | I386_Assembly.r_m32(Option.SOME1 r) =>
d1943 1
a1943 1
				      Option.SOME2
d1945 1
a1945 1
				       {base=Option.PRESENT I386Types.sp,
d1947 1
a1947 1
					offset=Option.PRESENT(reg_spill_value reg_operand)
d1950 1
a1950 1
				      Option.SOME1
d2018 1
a2018 1
			val base = Option.PRESENT(lookup_gp_operand gp_operand)
d2021 1
a2021 1
			  (Option.SOME2
d2025 1
a2025 1
				index=Option.PRESENT(lookup_gp_operand gp_operand', absent),
d2031 1
a2031 1
				Option.PRESENT
d2073 1
a2073 1
				       Option.SOME2
d2075 1
a2075 1
					{base=Option.PRESENT I386Types.sp,
d2077 1
a2077 1
					 offset=Option.PRESENT(reg_spill_value reg_operand)})
d2079 1
a2079 1
				       Option.SOME1(lookup_reg_operand reg_operand))
d2084 1
a2084 1
				      Option.PRESENT tag3, "continue")]
d2097 1
a2097 1
					      I386_Assembly.r_m32(Option.SOME1(lookup_reg_operand reg_operand))]),
d2110 1
a2110 1
					      I386_Assembly.r_m32(Option.SOME1(lookup_reg_operand reg_operand))]),
d2123 1
a2123 1
				      [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
d2129 1
a2129 1
				     Option.PRESENT tag2, "branch if ok") ::
d2141 1
a2141 1
					   I386_Assembly.r_m32(Option.SOME1 reg)]),
d2168 1
a2168 1
				     Option.SOME2
d2170 1
a2170 1
				      {base=Option.PRESENT I386Types.sp,
d2172 1
a2172 1
				       offset=Option.PRESENT(reg_spill_value reg_operand)})
d2174 1
a2174 1
				     Option.SOME1(lookup_reg_operand reg_operand))
d2213 1
a2213 1
				     Option.SOME2
d2215 1
a2215 1
				      {base=Option.PRESENT I386Types.sp,
d2217 1
a2217 1
				       offset=Option.PRESENT(gp_spill_value gp_operand')})
d2219 1
a2219 1
				     Option.SOME1(lookup_gp_operand gp_operand'))
d2227 1
a2227 1
				    [I386_Assembly.r_m32(Option.SOME1 I386Types.global)]),
d2242 1
a2242 1
				     Option.SOME2
d2244 1
a2244 1
				      {base=Option.PRESENT I386Types.sp,
d2246 1
a2246 1
				       offset=Option.PRESENT(reg_spill_value reg_operand)})
d2248 1
a2248 1
				     Option.SOME1(lookup_reg_operand reg_operand))
d2281 1
a2281 1
				     (Option.SOME2
d2283 1
a2283 1
				       {base=Option.PRESENT I386Types.sp,
d2285 1
a2285 1
					offset=Option.PRESENT spill})),
d2295 1
a2295 1
				       (Option.SOME2
d2297 1
a2297 1
					 {base=Option.PRESENT I386Types.sp,
d2299 1
a2299 1
					  offset=Option.PRESENT spill}))]
d2310 1
a2310 1
				       (Option.SOME1(lookup_reg_operand reg_operand)),
d2410 1
a2410 1
			      if spill = 0 then absent else Option.PRESENT spill
d2420 1
a2420 1
				      (Option.SOME2
d2422 1
a2422 1
					{base=Option.PRESENT I386Types.sp,
d2432 1
a2432 1
				    (Option.SOME2
d2434 1
a2434 1
				      {base=Option.PRESENT I386Types.sp,
d2456 1
a2456 1
					Option.PRESENT spill
d2462 1
a2462 1
					(Option.SOME2
d2464 1
a2464 1
					  {base=Option.PRESENT I386Types.sp,
d2480 1
a2480 1
					  (Option.SOME1 rs1)]),
d2490 1
a2490 1
					(Option.SOME1 rd)]),
d2518 1
a2518 1
			     Option.SOME2
d2520 1
a2520 1
			      {base=Option.PRESENT I386Types.sp,
d2522 1
a2522 1
			       offset=Option.PRESENT(reg_spill_value reg_operand)})
d2524 1
a2524 1
			     Option.SOME1(lookup_reg_operand reg_operand))
d2544 1
a2544 1
			   (Option.SOME2
d2546 1
a2546 1
			     {base=Option.PRESENT I386Types.sp,
d2548 1
a2548 1
			      offset=Option.PRESENT(reg_spill_value reg_operand)})),
d2555 1
a2555 1
			   (Option.SOME1(lookup_reg_operand reg_operand)),
d2622 1
a2622 1
                              (I386_Assembly.OPCODE (I386_Assembly.jmp, [I386_Assembly.rel32 0]), Option.PRESENT next_tag, "")])
d2631 1
a2631 1
                            (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.not_parity,[I386_Assembly.rel32 0]), Option.PRESENT end_tag,""),
d2634 1
a2634 1
                            (I386_Assembly.OPCODE (I386_Assembly.jmp, [I386_Assembly.rel32 0]), Option.PRESENT end_tag, "")],
d2661 1
a2661 1
                      (I386_Assembly.OPCODE (I386_Assembly.test, [I386_Assembly.r_m8 (Option.SOME1 I386Types.AL),
d2689 1
a2689 1
                        (I386_Assembly.OPCODE (I386_Assembly.test, [I386_Assembly.r_m8 (Option.SOME1 I386Types.AL),
d2700 1
a2700 1
				   Option.PRESENT offset) =>
d2702 1
a2702 1
		| MirTypes.STACKOP(stack_op, reg_operand, Option.ABSENT) =>
d2732 1
a2732 1
			     (Option.SOME2
d2735 2
a2736 2
				  {base = Option.PRESENT r1,
				   index = Option.PRESENT(lookup_gp_operand gp_operand', absent),
d2746 1
a2746 1
				    {base = Option.PRESENT r1,
d2748 1
a2748 1
				     offset = Option.PRESENT(assemble_large_offset gp_operand')}
d2930 1
a2930 1
			   Option.SOME2
d2933 2
a2934 2
			       {base=Option.PRESENT rs1,
				index=Option.PRESENT((lookup_gp_operand gp_operand), absent),
d2944 1
a2944 1
				 {base=Option.PRESENT rs1,
d2946 1
a2946 1
				  offset=Option.PRESENT(assemble_large_offset gp_operand)}
d3057 2
a3058 2
                                 {base=Option.PRESENT rs1,
                                  index=Option.PRESENT((lookup_gp_operand gp_operand), absent),
d3061 1
a3061 1
                                 {base=Option.PRESENT rs1,
d3063 1
a3063 1
                                  offset=Option.PRESENT(assemble_large_offset gp_operand)}))
d3086 1
a3086 1
                             {base=Option.PRESENT I386Types.sp,
d3088 1
a3088 1
                              offset=Option.PRESENT(gp_spill_value gp_operand)},[])
d3092 1
a3092 1
                              I386_Assembly.MEM {base=Option.PRESENT I386Types.sp,
d3094 1
a3094 1
                                                 offset=Option.PRESENT(frame_size + stack_drop - fp_spare_offset)}
d3105 1
a3105 1
                               (I386_Assembly.mov,[I386_Assembly.r_m32 (Option.SOME2 fp_spare_loc),
d3111 1
a3111 1
                       [(I386_Assembly.OPCODE (I386_Assembly.sar,[I386_Assembly.r_m32 (Option.SOME2 mem_operand),
d3125 1
a3125 1
                        I386_Assembly.MEM {base=Option.PRESENT I386Types.sp,
d3127 1
a3127 1
                                           offset=Option.PRESENT(frame_size + stack_drop - fp_spare_offset)}
d3136 1
a3136 1
                                {base=Option.PRESENT I386Types.sp,
d3138 1
a3138 1
                                 offset=Option.PRESENT(reg_spill_value reg_operand)}
d3140 1
a3140 1
                              (I386_Assembly.fp_mem result_operand,I386_Assembly.r_m32 (Option.SOME2 result_operand),[])
d3150 1
a3150 1
                             I386_Assembly.r_m32 (Option.SOME1 dest_operand_reg),
d3153 1
a3153 1
                                                   I386_Assembly.r_m32 (Option.SOME2 fp_spare_loc)]),
d3158 1
a3158 1
                        (I386_Assembly.OPCODE (I386_Assembly.mov, [I386_Assembly.r_m32 (Option.SOME2 (fp_spare_loc)),
d3171 1
a3171 1
                        (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.below_or_equal,[I386_Assembly.rel32 0]), Option.PRESENT tag,""),
d3180 1
a3180 1
                        (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.above,[I386_Assembly.rel32 0]), Option.PRESENT tag,""),
d3185 1
a3185 1
                                                I386_Assembly.r_m32 (Option.SOME2 (fp_spare_loc))]),
d3188 1
a3188 1
                                               [I386_Assembly.r_m16 (Option.SOME2 (fp_spare_loc)),
d3192 1
a3192 1
                                               [I386_Assembly.r_m16 (Option.SOME2 (fp_spare_loc)),
d3202 1
a3202 1
                                               [I386_Assembly.r_m32 (Option.SOME2 (fp_spare_loc)),
d3219 1
a3219 1
				(Option.SOME1(lookup_reg_operand reg))](*,
d3225 1
a3225 1
			    Option.PRESENT tag, "branch relative")]),
d3280 1
a3280 1
				 (Option.SOME2
d3282 1
a3282 1
				   {base=Option.PRESENT I386Types.sp,
d3284 1
a3284 1
				    offset=Option.PRESENT spill})),
d3306 1
a3306 1
				   (Option.SOME2
d3308 1
a3308 1
				     {base=Option.PRESENT I386Types.sp,
d3310 1
a3310 1
				      offset=Option.PRESENT(gp_spill_value gp_op')})),
d3316 1
a3316 1
				     (Option.SOME1 gp_r),
d3341 1
a3341 1
					  (I386_Assembly.r_m32(Option.SOME1 gp_r),
d3345 1
a3345 1
					   (I386_Assembly.r_m32(Option.SOME1 gp_r),
d3356 1
a3356 1
					     (Option.SOME1(I386Types.byte_reg_name gp_r)),
d3361 1
a3361 1
					     (Option.SOME1(I386Types.half_reg_name gp_r)),
d3379 1
a3379 1
			     Option.PRESENT test_tag, "do the branch")],
d3430 1
a3430 1
                      (I386_Assembly.OPCODE (I386_Assembly.jcc cond,[I386_Assembly.rel32 0]), Option.PRESENT tag,"")
d3443 1
a3443 1
			   (Option.SOME2
d3445 1
a3445 1
			     {base=Option.PRESENT(lookup_reg_operand reg_operand),
d3447 1
a3447 1
			      offset=Option.PRESENT Tags.CODE_OFFSET}))]),
d3451 1
a3451 1
			  [I386_Assembly.r_m32(Option.SOME1 I386Types.global)]),
d3457 1
a3457 1
		      Option.PRESENT tag, "call relative")],
d3472 1
a3472 1
				  (Option.SOME2
d3474 1
a3474 1
				    {base=Option.PRESENT(lookup_reg_operand reg),
d3476 1
a3476 1
				     offset=Option.PRESENT Tags.CODE_OFFSET}))]),
d3480 1
a3480 1
				 [I386_Assembly.r_m32(Option.SOME1(lookup_reg_operand reg))]),
d3486 1
a3486 1
			      Option.PRESENT tag, "branch relative(tail call)")]
d3496 1
a3496 1
				 [I386_Assembly.r_m32(Option.SOME1 I386Types.sp),
d3527 1
a3527 1
				 Option.PRESENT tag, "Unconditional branch")],
d3534 1
a3534 1
				    Option.PRESENT tag2, "Unconditional branch")]
d3538 1
a3538 1
				     Option.SOME2
d3540 1
a3540 1
				      {base=Option.PRESENT I386Types.sp,
d3542 1
a3542 1
				       offset=Option.PRESENT(reg_spill_value reg_operand)})
d3544 1
a3544 1
				     Option.SOME1(lookup_reg_operand reg_operand))
d3552 1
a3552 1
				  Option.PRESENT tag1, "branch if zero") ::
d3567 1
a3567 1
						   Option.PRESENT tag,
d3573 1
a3573 1
				     Option.SOME2
d3575 1
a3575 1
				      {base=Option.PRESENT I386Types.sp,
d3577 1
a3577 1
				       offset=Option.PRESENT(reg_spill_value reg_operand)})
d3579 1
a3579 1
				     Option.SOME1(lookup_reg_operand reg_operand))
d3585 1
a3585 1
				    [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
d3587 1
a3587 1
				   Option.PRESENT tag,
d3593 1
a3593 1
				     (Option.SOME2
d3595 1
a3595 1
				       {base=Option.PRESENT I386Types.callee_closure,
d3597 1
a3597 1
					offset=Option.PRESENT ~1}))]),
d3609 1
a3609 1
				   [I386_Assembly.r_m32(Option.SOME1 I386Types.global)]),
d3619 1
a3619 1
					  Option.PRESENT fp_offset) =>
d3656 1
a3656 1
			       (Option.SOME2
d3658 1
a3658 1
				 {base=Option.PRESENT I386Types.sp,
d3660 1
a3660 1
				  offset=Option.PRESENT offset}))]),
d3723 1
a3723 1
				 Option.PRESENT tag3, "jump to rest of code")]
d3731 1
a3731 1
				    (Option.SOME2
d3733 1
a3733 1
				      {base=Option.PRESENT rd,
d3735 1
a3735 1
				       offset=Option.PRESENT(~primary)})),
d3745 1
a3745 1
				    (Option.SOME2
d3747 1
a3747 1
				      {base=Option.PRESENT rd,
d3749 1
a3749 1
				       offset=Option.PRESENT(bytes - primary - 4)})),
d3766 1
a3766 1
				  Option.PRESENT tag2,
d3779 1
a3779 1
				     (Option.SOME2
d3781 1
a3781 1
				       {base=Option.PRESENT I386Types.global,
d3783 1
a3783 1
					offset=Option.PRESENT primary}))]),
d3796 1
a3796 1
				     (Option.SOME2
d3798 1
a3798 1
				       {base=Option.PRESENT rd,
d3800 1
a3800 1
					offset=Option.PRESENT bytes}))]),
d3805 1
a3805 1
				     (Option.SOME2
d3807 1
a3807 1
				       {base=Option.PRESENT I386Types.implicit,
d3809 1
a3809 1
					offset=Option.PRESENT gc_entry}))]),
d3818 1
a3818 1
				    I386_Assembly.r_m32(Option.SOME1 rd)]),
d3825 1
a3825 1
				  (Option.SOME2
d3827 1
a3827 1
				    {base=Option.PRESENT I386Types.implicit,
d3829 1
a3829 1
				     offset=Option.PRESENT(4*Implicit_Vector.gc_base)})),
d3840 1
a3840 1
				  (Option.SOME2
d3842 1
a3842 1
				    {base=Option.PRESENT I386Types.implicit,
d3844 1
a3844 1
				     offset=Option.PRESENT(4*Implicit_Vector.gc_base)}))]),
d3851 1
a3851 1
				  (Option.SOME2
d3853 1
a3853 1
				    {base=Option.PRESENT I386Types.implicit,
d3855 1
a3855 1
				     offset=Option.PRESENT(4*Implicit_Vector.gc_limit)}))]),
d3862 1
a3862 1
				  (Option.SOME2
d3864 1
a3864 1
				    {base=Option.PRESENT rd,
d3866 1
a3866 1
				     offset=Option.PRESENT(primary-bytes)}))]),
d3870 1
a3870 1
				 [I386_Assembly.rel32 0]), Option.PRESENT tag2,
d3876 1
a3876 1
				  [I386_Assembly.r_m32(Option.SOME1 rd),
d3882 1
a3882 1
				 Option.PRESENT tag2,
d3908 1
a3908 1
				 (Option.SOME2
d3910 1
a3910 1
				   {base=Option.PRESENT I386Types.sp,
d3912 2
a3913 2
				    offset=Option.PRESENT(reg_spill_value reg_operand)}),
				  Option.SOME2
d3915 1
a3915 1
				   {base=Option.PRESENT I386Types.sp,
d3917 1
a3917 1
				    offset=Option.PRESENT (* Offset changes from push *)
d3920 2
a3921 2
				 (Option.SOME1(lookup_reg_operand reg_operand),
				  Option.SOME1(lookup_reg_operand reg_operand))
d3935 1
a3935 1
					   (Option.SOME2
d3937 1
a3937 1
					     {base=Option.PRESENT I386Types.sp,
d3939 1
a3939 1
					      offset=Option.PRESENT
d3960 1
a3960 1
					   (Option.SOME2
d3962 1
a3962 1
					     {base=Option.PRESENT size_reg,
d3964 1
a3964 1
					      offset=Option.PRESENT(4+7)}))]),
d3974 1
a3974 1
					   (Option.SOME2
d3976 1
a3976 1
					     {base=Option.PRESENT I386Types.sp,
d3978 1
a3978 1
					      offset=Option.PRESENT
d3991 1
a3991 1
					     (Option.SOME2
d3993 1
a3993 1
					       {base=Option.PRESENT I386Types.sp,
d3995 1
a3995 1
						offset=Option.PRESENT
d4022 1
a4022 1
					   (Option.SOME2
d4024 1
a4024 1
					     {base=Option.PRESENT I386Types.sp,
d4026 1
a4026 1
					      offset=Option.PRESENT
d4047 1
a4047 1
					   (Option.SOME2
d4049 1
a4049 1
					     {base=Option.PRESENT size_reg,
d4051 1
a4051 1
					      offset=Option.PRESENT(12+7)}))]),
d4060 1
a4060 1
					   (Option.SOME2
d4062 1
a4062 1
					     {base=Option.PRESENT I386Types.sp,
d4064 1
a4064 1
					      offset=Option.PRESENT
d4077 1
a4077 1
					     (Option.SOME2
d4079 1
a4079 1
					       {base=Option.PRESENT I386Types.sp,
d4081 1
a4081 1
						offset=Option.PRESENT
d4105 1
a4105 1
				  (Option.SOME2
d4107 1
a4107 1
				    {base=Option.PRESENT I386Types.implicit,
d4109 1
a4109 1
				     offset=Option.PRESENT(4*Implicit_Vector.gc_base)}))]),
d4116 1
a4116 1
				  (Option.SOME2
d4118 1
a4118 1
				    {base=Option.PRESENT I386Types.implicit,
d4120 1
a4120 1
				     offset=Option.PRESENT(4*Implicit_Vector.gc_limit)}))]),
d4125 1
a4125 1
				 [I386_Assembly.rel32 0]), Option.PRESENT tag1,
d4138 1
a4138 1
				    (Option.SOME2
d4140 1
a4140 1
				      {base=Option.PRESENT I386Types.implicit,
d4142 1
a4142 1
				       offset=Option.PRESENT
d4152 1
a4152 1
				    (Option.SOME2
d4154 1
a4154 1
				      {base=Option.PRESENT I386Types.implicit,
d4156 1
a4156 1
				       offset=Option.PRESENT
d4170 1
a4170 1
				 Option.PRESENT tag2, "jump to continuation point")]
d4175 1
a4175 1
				   [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
d4188 1
a4188 1
				    (Option.SOME2
d4190 1
a4190 1
				      {base=Option.PRESENT I386Types.global,
d4192 1
a4192 1
				       offset=Option.PRESENT primary}))]),
d4203 1
a4203 1
				  (Option.SOME2
d4205 1
a4205 1
				    {base=Option.PRESENT I386Types.implicit,
d4207 1
a4207 1
				     offset=Option.PRESENT gc_entry}))]),
d4213 1
a4213 1
				 I386_Assembly.r_m32(Option.SOME1 reg) =>
d4218 1
a4218 1
				      (Option.SOME2
d4220 3
a4222 3
					{base=Option.PRESENT reg,
					 index=Option.PRESENT(I386Types.global, absent),
					 offset=Option.PRESENT primary}))]),
d4243 1
a4243 1
				 Option.PRESENT tag3, "branch to rest of code")]
d4274 1
a4274 1
					 [I386_Assembly.r_m32(Option.SOME1 index),
d4280 1
a4280 1
					  (Option.SOME2
d4282 3
a4284 3
					    {base=Option.PRESENT pointer,
					     index=Option.PRESENT(index, absent),
					     offset=Option.PRESENT offset})),
d4302 1
a4302 1
					      (Option.SOME2
d4304 1
a4304 1
						{base=Option.PRESENT I386Types.sp,
d4306 1
a4306 1
						 offset=Option.PRESENT spill_value}))]),
d4315 1
a4315 1
					    (Option.SOME1(lookup_gp_operand gp_operand))]),
d4322 1
a4322 1
					  (Option.SOME2
d4324 1
a4324 1
					    {base=Option.PRESENT pointer,
d4326 1
a4326 1
					     offset=Option.PRESENT(~primary)})),
d4365 1
a4365 1
					 [I386_Assembly.r_m32(Option.SOME1 index),
d4371 1
a4371 1
					  (Option.SOME2
d4373 3
a4375 3
					    {base=Option.PRESENT pointer,
					     index=Option.PRESENT(index, absent),
					     offset=Option.PRESENT offset})),
d4393 1
a4393 1
					      (Option.SOME2
d4395 1
a4395 1
						{base=Option.PRESENT I386Types.sp,
d4397 1
a4397 1
						 offset=Option.PRESENT spill_value}))]),
d4406 1
a4406 1
					    (Option.SOME1(lookup_gp_operand gp_operand))]),
d4413 1
a4413 1
					  (Option.SOME2
d4415 1
a4415 1
					    {base=Option.PRESENT pointer,
d4417 1
a4417 1
					     offset=Option.PRESENT(~primary)})),
d4457 1
a4457 1
					  (Option.SOME2
d4459 1
a4459 1
					    {base=Option.PRESENT pointer,
d4461 1
a4461 1
					     offset=Option.PRESENT(~primary)})),
d4488 1
a4488 1
				     Option.SOME2
d4490 1
a4490 1
				      {base=Option.PRESENT I386Types.sp,
d4492 1
a4492 1
				       offset=Option.PRESENT
d4495 1
a4495 1
				     Option.SOME1(lookup_gp_operand gp_operand))]),
d4499 1
a4499 1
				 [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
d4504 1
a4504 1
				 [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
d4527 1
a4527 1
			    Option.PRESENT tag, "Update gc pointer")]
d4539 1
a4539 1
				 Option.SOME2
d4541 1
a4541 1
				  {base=Option.PRESENT I386Types.sp,
d4543 1
a4543 1
				   offset=Option.PRESENT(reg_spill_value reg_operand)})
d4545 1
a4545 1
				 Option.SOME1(lookup_reg_operand reg_operand)),
d4547 1
a4547 1
			    Option.PRESENT tag,
d4561 1
a4561 1
			    (Option.SOME2
d4563 1
a4563 1
			      {base=Option.PRESENT I386Types.implicit,
d4565 1
a4565 1
			       offset=Option.PRESENT(4*Implicit_Vector.register_stack_limit)})),
d4571 1
a4571 1
			  Option.PRESENT continue_tag,
d4576 1
a4576 1
			  Option.PRESENT continue_tag, "continue after interrupt")]
d4588 1
a4588 1
			   (Option.SOME2
d4590 1
a4590 1
			     {base=Option.PRESENT I386Types.implicit,
d4592 1
a4592 1
			      offset=Option.PRESENT(4 * check_offset)}))]),
d4613 1
a4613 1
			    Option.PRESENT overflow_code_tag,
d4618 1
a4618 1
			    Option.PRESENT post_overflow_tag,
d4627 1
a4627 1
			       (Option.SOME2
d4629 1
a4629 1
				 {base=Option.PRESENT I386Types.sp,
d4631 1
a4631 1
				  offset=Option.PRESENT (~frame_size)}))]),
d4637 1
a4637 1
			       (Option.SOME2
d4639 1
a4639 1
				 {base=Option.PRESENT I386Types.implicit,
d4641 1
a4641 1
				  offset=Option.PRESENT(4*Implicit_Vector.register_stack_limit)}))]
d4650 1
a4650 1
			       (Option.SOME2
d4652 1
a4652 1
				 {base=Option.PRESENT I386Types.implicit,
d4654 1
a4654 1
				  offset=Option.PRESENT(4*Implicit_Vector.register_stack_limit)}))]
d4667 1
a4667 1
			      (Option.SOME2
d4669 1
a4669 1
				{base=Option.PRESENT I386Types.implicit,
d4671 1
a4671 1
				 offset=Option.PRESENT(4*Implicit_Vector.extend)}))]),
d4675 1
a4675 1
			    Option.PRESENT post_overflow_tag,
d4691 1
a4691 1
                                      [I386_Assembly.r_m32(Option.SOME1 I386Types.sp),
d4708 1
a4708 1
					 Option.PRESENT post_make_stack_tag,
d4723 1
a4723 1
			      (Option.SOME2
d4725 1
a4725 1
				{base=Option.PRESENT I386Types.sp,
d4727 1
a4727 1
				 offset=Option.PRESENT(frame_size-4)}))]),
d4737 1
a4737 1
			    Option.PRESENT real_proc_start_tag,
d4764 1
a4764 1
			       [I386_Assembly.r_m32(Option.SOME1 I386Types.sp),
d4807 1
a4807 1
			   (Option.SOME2
d4809 1
a4809 1
			     {base=Option.PRESENT I386Types.implicit,
d4811 1
a4811 1
			      offset=Option.PRESENT(4*Implicit_Vector.handler)})),
d4819 1
a4819 1
			   (Option.SOME2
d4821 1
a4821 1
			     {base=Option.PRESENT I386Types.implicit,
d4823 1
a4823 1
			      offset=Option.PRESENT(4*Implicit_Vector.handler)}))]),
d4828 1
a4828 1
			   (Option.SOME2
d4830 1
a4830 1
			     {base=Option.PRESENT rd,
d4832 1
a4832 1
			      offset=Option.PRESENT(~1)})),
d4845 1
a4845 1
			     (Option.SOME2
d4847 1
a4847 1
			       {base=Option.PRESENT I386Types.sp,
d4849 1
a4849 1
				offset=Option.PRESENT(reg_spill_value frame + 4)}))]),
d4862 1
a4862 1
			 (Option.SOME2
d4864 1
a4864 1
			   {base=Option.PRESENT I386Types.implicit,
d4866 1
a4866 1
			    offset=Option.PRESENT(4*Implicit_Vector.handler)}))]),
d4872 1
a4872 1
			 (Option.SOME2
d4874 1
a4874 1
			   {base=Option.PRESENT I386Types.global,
d4876 1
a4876 1
			    offset=Option.PRESENT(~1)}))]),
d4881 1
a4881 1
			 (Option.SOME2
d4883 1
a4883 1
			   {base=Option.PRESENT I386Types.implicit,
d4885 1
a4885 1
			    offset=Option.PRESENT(4*Implicit_Vector.handler)})),
d4902 1
a4902 1
			    (Option.SOME2
d4904 1
a4904 1
			      {base=Option.PRESENT I386Types.sp,
d4906 1
a4906 1
			       offset=Option.PRESENT spill}), true)
d4913 1
a4913 1
			      (Option.SOME1 arg, false)
d4915 1
a4915 1
			      (Option.SOME1 arg, true)
d4921 1
a4921 1
			    (Option.SOME2
d4923 1
a4923 1
			      {base=Option.PRESENT I386Types.implicit,
d4925 1
a4925 1
			       offset=Option.PRESENT vector}))]),
d4945 1
a4945 1
			 (Option.SOME2
d4947 1
a4947 1
			   {base=Option.PRESENT I386Types.implicit,
d4949 1
a4949 1
			    offset=Option.PRESENT(4*Implicit_Vector.external)}))]),
d4970 1
a4970 1
      fun exit_block [] = Option.ABSENT
d4975 1
a4975 1
	  then Option.PRESENT block
d5027 1
a5027 1
		   {spill_sizes, stack_allocated, ...},
d5034 2
a5035 2
	      Option.ABSENT => block_list
	    | Option.PRESENT exit_block =>
d5189 1
a5189 1
	    Option.PRESENT stack_extra => stack_extra
d5358 3
a5360 3
	      | opc_needs_fp_spare(MirTypes.REAL _ :: _) = true
	      | opc_needs_fp_spare(MirTypes.FLOOR _ :: _) = true
	      | opc_needs_fp_spare(_ :: rest) = opc_needs_fp_spare rest
d5366 2
a5367 2
	  | proc_needs_fp_spare(block :: block_list) =
	    block_needs_fp_spare block orelse proc_needs_fp_spare block_list
d5376 1
a5376 1
	      Option.PRESENT{gc = gc_spill_size,
d5388 1
a5388 1
	    Option.PRESENT stack_extra => stack_extra
d5431 4
a5434 1
	     float_value_size = float_value_size	
d5496 1
a5496 1
			    Option.PRESENT tag =>
d5498 1
a5498 1
			  | Option.ABSENT => " no tag") ^
d5568 1
a5568 1
				 Option.PRESENT tag =>
d5570 1
a5570 1
			       | Option.ABSENT => " no tag") ^
@


1.39
log
@Modification for improved runtime env spill offsets
to indicate the kind of data spilled
@
text
@d4 4
d1358 1
d1575 1
d1601 19
a1619 1
	  val do_save_gcs = fn x => do_save_gcs(x, [])
a1630 2
	  val gc_preserve_size = 4 * Lists.length gcs_to_preserve

a3486 1
			   val frame_left = frame_size - register_save_size
a4750 1
			 val frame_left = frame_size - register_save_size
d5399 3
a5401 1
	  val callee_save_area = Lists.length callee_saves
d5450 6
a5455 6
				     block_list,
				     stack_layout,
				     (*spills_need_init*)true,
				     (*stack_need_init*)true,
				     fps_to_preserve,
				     callee_saves))
d5477 1
a5477 1
	   callee_save_area)
@


1.38
log
@Fix local variable compilation problems
@
text
@d4 3
d1424 7
a1430 2
		    (fn value => (spill := RuntimeEnv.OFFSET2(value);value)) (symbolic_value i)
		  | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(i)),name) => i
d1448 7
a1454 2
		    (fn value => (spill := RuntimeEnv.OFFSET2(value);value)) (symbolic_value i)
		  | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(i)),name) => i
d1470 7
a1476 3
		    (fn value => (spill := RuntimeEnv.OFFSET2(value);value))
		    (symbolic_value i)
		  | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(i)),name) => i
@


1.37
log
@Fix bug in compiler crash when number of fp spill slots exceeded
@
text
@d4 3
a2659 22
(*
		  let
		    val opcode = case stack_op of
		      MirTypes.PUSH => MirTypes.STREF
		    | MirTypes.POP => MirTypes.LDREF
		  val _ =
		    if offset > gc_stack_alloc_size then
		      Crash.impossible("Stack access at offset " ^
				       MLWorks.Integer.makestring offset ^
				       " requested, in total area of only " ^
				       MLWorks.Integer.makestring gc_stack_alloc_size ^
				       "\n")
		    else()
		  in
		    ([],
		     MirTypes.STOREOP(opcode, reg_operand,
				      MirTypes.GC_REG MirRegisters.fp,
				      MirTypes.GP_IMM_ANY
				      (~(gc_stack_alloc_offset + 4 * (offset + 1)))) ::
		     opcode_list, block_list, final_result)
		  end
*)
d2692 4
a2695 4
			       {base=Option.PRESENT r1,
				index =
				if gp_is_reg then
				  Option.PRESENT(lookup_gp_operand gp_operand', absent)
d2697 12
a2708 6
				  absent,
				offset=
				if gp_is_reg then
				  absent
				else
				  Option.PRESENT(assemble_large_offset gp_operand')}))
d2876 94
a2969 84
		  let
		    val rd = lookup_reg_operand reg_operand
		    val rs1 = lookup_reg_operand reg_operand'
		    val (store_instr, word_size, load) = case store_op of
		      MirTypes.LD => (I386_Assembly.mov, true, true)
		    | MirTypes.ST => (I386_Assembly.mov, true, false)
		    | MirTypes.LDB => (I386_Assembly.movzx, false, true)
		    | MirTypes.STB => (I386_Assembly.mov, false, false)
		    | MirTypes.LDREF => (I386_Assembly.mov, true, true)
		    | MirTypes.STREF => (I386_Assembly.mov, true, false)
		    val r_m =
		      Option.SOME2
		      (I386_Assembly.MEM
		       (if is_reg gp_operand then
			  {base=Option.PRESENT rs1,
			   index=Option.PRESENT((lookup_gp_operand gp_operand), absent),
			   offset=absent}
			else
			  {base=Option.PRESENT rs1,
			   index=absent,
			   offset=Option.PRESENT(assemble_large_offset gp_operand)}))
		    val (con1, con2) =
		      if word_size then
			(I386_Assembly.r32, I386_Assembly.r_m32)
		      else
			if load then
			  (I386_Assembly.r32, I386_Assembly.r_m8)
			else
			  (I386_Assembly.r8, I386_Assembly.r_m8)
		  in
		    if word_size orelse I386Types.has_byte_name rd orelse load then
		      let
			val rd =
			  if word_size orelse load then
			    rd
			  else
			    I386Types.byte_reg_name rd
			val operands =
			  if load then
			    [con1 rd, con2 r_m]
			  else
			    [con2 r_m, con1 rd]
		      in
			([(I386_Assembly.OPCODE(store_instr, operands), absent, "")],
			 opcode_list, block_list, final_result, stack_drop)
		      end
		    else
		      (* Byte, no byte register name, store *)
		      (* Tricky, our destination may already be in global *)
		      if rs1 = I386Types.global orelse
			(is_reg gp_operand andalso lookup_gp_operand gp_operand = I386Types.global) then
			let
			  val operands =
			    if rs1 = I386Types.ESP orelse
			      (is_reg gp_operand andalso lookup_gp_operand gp_operand = I386Types.ESP) then
			      Crash.unimplemented"store byte relative to sp"
			    else
			      [I386_Assembly.r_m8 r_m,
			       I386_Assembly.r8(I386Types.byte_reg_name I386Types.EAX)]
			in
			  ([(I386_Assembly.OPCODE
			     (I386_Assembly.push, [I386_Assembly.r32 I386Types.EAX]),
			     absent, "create some workspace"),
			    move_reg(I386Types.EAX, rd, "can't store byte from " ^
				     I386Types.reg_to_string rd),
			    (I386_Assembly.OPCODE
			     (store_instr, operands), absent, ""),
			    (I386_Assembly.OPCODE
			     (I386_Assembly.pop, [I386_Assembly.r32 I386Types.EAX]),
			     absent, "restore EAX")],
			  opcode_list, block_list, final_result, stack_drop)
			end
		      else
			let
			  val operands =
			    [I386_Assembly.r_m8 r_m,
			     I386_Assembly.r8(I386Types.byte_reg_name I386Types.global)]
			in
			  ([move_reg(I386Types.global, rd, "can't store byte from " ^
				     I386Types.reg_to_string rd),
			    (I386_Assembly.OPCODE(store_instr, operands), absent, "")],
			   opcode_list, block_list, final_result, stack_drop)
			end
		  end)
d5160 3
d5308 4
@


1.36
log
@Fix problem whereby final word of vectors may be left uninitialised
@
text
@d4 3
d1426 5
a1430 5
                  (if i >= non_gc_spill_size 
                     then raise bad_spill ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
                                           " requested, but only " ^
                                           MLWorks.Integer.makestring non_gc_spill_size ^
                                           " allocated\n")
d1447 1
a1447 1
                                      MLWorks.Integer.makestring non_gc_spill_size ^
@


1.35
log
@Make intercept offset count bytes, not instructions.
@
text
@d4 3
d4214 1
d4218 2
a4219 1
					   (rd, I386Types.global)
d4235 1
a4235 1
					absent, "clamp index to avoid writing off end") ::
d4304 44
a4347 10
				 | _ =>
				     let
				       (* No initialisation for byte arrays *)
				       val (pointer, needs_push) =
					 if needs_temp then
					   (I386Types.EAX, true)
					 else
					   (rd, false)
				       val tag_jmp =
					 if needs_push then
d4349 81
a4429 6
					    (I386_Assembly.pop,
					     [I386_Assembly.r32 I386Types.EAX]),
					    absent, "restore EAX") :: tag3_jmp
					 else
					   tag3_jmp
				       val store_secondary =
d4432 8
a4439 25
					   [I386_Assembly.r_m32
					    (Option.SOME2
					     (I386_Assembly.MEM
					      {base=Option.PRESENT pointer,
					       index=absent,
					       offset=Option.PRESENT(~primary)})),
					    I386_Assembly.r32 I386Types.global]),
					  absent, "store the secondary tag") ::
					 tag_jmp
				       val get_pointer =
					 if needs_temp then
					   (I386_Assembly.OPCODE
					    (I386_Assembly.push,
					     [I386_Assembly.r32 I386Types.EAX]),
					    absent, "save EAX") ::
					   (I386_Assembly.OPCODE
					    (I386_Assembly.mov,
					     [I386_Assembly.r32 pointer, mod_rd_operand]),
					    absent, "get pointer to new store") ::
					   store_secondary
					 else
					   store_secondary
				     in
				       get_pointer
				     end
@


1.34
log
@Add WORD to value_cg
@
text
@d4 3
d243 1
a243 1
	find_nop_offsets(offset+1, rest)
@


1.33
log
@Add CHAR to value_cg
@
text
@d4 3
d377 1
@


1.32
log
@Fix problems in shift generation
@
text
@d4 3
d373 1
@


1.31
log
@Implement integer multiply
@
text
@d4 3
a1715 5
		      val _ =
			if tagged_binary_op = MirTypes.MULV then
			  output(std_out, "CG: " ^ MirPrint.opcode opcode ^ "\n")
			else
			  ()
d1726 1
a1726 1
			  (* Restricted for result in a register for imul *)
d2003 2
a2004 1
				(* Shift amount in ECX *)
a2005 1
				  val tag1 = MirTypes.new_tag()
d2018 1
a2018 1
				  val branch =
d2023 35
a2058 19
				    [(I386_Assembly.OPCODE
				      (I386_Assembly.cmp,
				       [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
					I386_Assembly.imm8 31]),
				      absent, "test for shift by > 31"),
				     (I386_Assembly.OPCODE
				      (I386_Assembly.jcc(I386_Assembly.less_or_equal),
				       [I386_Assembly.rel32 0]),
				      Option.PRESENT tag2, "branch if ok"),
				     (I386_Assembly.OPCODE
				      (I386_Assembly.mov,
				       [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
					I386_Assembly.imm8 31]),
				      absent, "treat as shift by 31"),
				     (I386_Assembly.OPCODE
				      (I386_Assembly.jmp,
				       [I386_Assembly.rel32 0]),
				      Option.PRESENT tag2, "continue")]
				  val block2 =
a2059 5
				     (i_opcode,
				      [operand, I386_Assembly.r8 I386Types.CL]),
				     absent, "do the actual shift") :: branch
				in
				  ([(I386_Assembly.OPCODE
d2062 2
a2063 2
				       I386_Assembly.imm8 0]),
				     absent, "test for shift by < 0"),
d2065 1
a2065 1
				     (I386_Assembly.jcc(I386_Assembly.greater_or_equal),
d2067 17
a2083 1
				     Option.PRESENT tag1, "branch if ok"),
d2085 9
a2093 13
				     (I386_Assembly.mov,
				      [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
				       I386_Assembly.imm8 0]),
				     absent, "treat as shift by 0"),
				    (I386_Assembly.OPCODE
				     (I386_Assembly.jmp,
				      [I386_Assembly.rel32 0]),
				     Option.PRESENT tag1, "continue")],
				  [],
				  MirTypes.BLOCK(tag3, opcode_list) :: block_list,
				  (tag1, block1) ::
				  (tag2, block2) ::
				  final_result, stack_drop)
d2099 2
a2100 2
				  if i < 0 then
				    Crash.impossible"shift by negative number"
d2102 1
a2102 1
				    if i >= 8 then 31 else 4*i+j
d2114 24
@


1.30
log
@Implement event checking in leaf case
@
text
@d4 3
d1713 5
d1721 1
a1721 1
		      | MirTypes.MULV => Crash.impossible"do_opcodes(TBINARY(MULV))"
a1723 1

d1727 12
a1738 6
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					MirTypes.GC_REG MirRegisters.global,
					gp_operand') ::
			 MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
					  gp_operand,
d1740 10
a1749 1
			 opcode_list, block_list, final_result, stack_drop)
d1751 22
a1772 21
			let
			  val operands =
			    if reg_operand_is_spill reg_operand then
			      let
				val spill = reg_spill_value reg_operand
				val op2 =
				  if is_reg gp_operand' then
				    I386_Assembly.r32(lookup_gp_operand gp_operand')
				  else
				    assemble_sized_gp_imm gp_operand'
			      in
				[I386_Assembly.r_m32
				 (Option.SOME2
				  (I386_Assembly.MEM
				   {base=Option.PRESENT I386Types.sp,
				    index=absent,
				    offset=Option.PRESENT spill})),
				 op2]
			      end
			    else
			      if gp_operand_is_spill gp_operand' then
d1774 6
a1779 1
				  val spill = gp_spill_value gp_operand'
d1781 1
a1781 2
				  [I386_Assembly.r32(lookup_reg_operand reg_operand),
				   I386_Assembly.r_m32
d1786 2
a1787 1
				      offset=Option.PRESENT spill}))]
d1790 16
a1805 2
				let
				  val op2 =
d1807 7
a1813 1
				      I386_Assembly.r32(lookup_gp_operand gp_operand')
d1815 31
a1845 16
				      assemble_sized_gp_imm gp_operand'
				in
				  [I386_Assembly.r_m32
				   (Option.SOME1(lookup_reg_operand reg_operand)),
				   op2]
				end
			in
			  ([(I386_Assembly.OPCODE(opcode, operands), absent, ""),
			    (I386_Assembly.OPCODE
			     (I386_Assembly.jcc(I386_Assembly.overflow),
			      [I386_Assembly.rel32 0]),
			     tag, "branch on numeric overflow")],
			   opcode_list,
			   block_list,
			   final_result, stack_drop)
			end
d1853 1
a1853 1
			| MirTypes.MULV => Crash.impossible"do_opcodes(TBINARY(MULV))"
d1910 28
a1937 8
		      ([],
		       MirTypes.UNARY(MirTypes.MOVE,
				      reg_operand,
				      gp_operand) ::
		       MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
					gp_from_reg reg_operand,
					gp_operand') ::
		       opcode_list, block_list, final_result, stack_drop)
@


1.29
log
@Fixed tagged pointer computation in variable sized allocations
@
text
@d4 3
d4300 1
a4300 1
		      val irupt_code =
d4303 1
a4303 9
			  (I386_Assembly.OPCODE
			   (I386_Assembly.call,
			    [I386_Assembly.r_m32
			     (Option.SOME2
			      (I386_Assembly.MEM
			       {base=Option.PRESENT I386Types.implicit,
				index=absent,
				offset=Option.PRESENT(4 * Implicit_Vector.event_check)}))]),
			   absent, "do event check") :: continue
d4306 11
a4316 14
(*
			  (I386_Assembly.LOAD_AND_STORE
			   (I386_Assembly.LD, I386Types.global,
			    I386Types.implicit,
			    I386_Assembly.IMM (4 * Implicit_Vector.event_check_leaf)),
			   absent, "Get address of event check") ::
			  (I386_Assembly.JUMP_AND_LINK
			   (I386_Assembly.JMPL, I386Types.global,
			    I386_Assembly.IMM 0, I386Types.global,
			    Debugger_Types.null_backend_annotation),
			   absent, "Do event_check_leaf") ::
			  I386_Assembly.nop :: continue
*)
			  Crash.impossible"Check_event in leaf case code"
@


1.28
log
@Change stack_limit to register_stack_limit
@
text
@d4 3
d4036 1
a4036 1
					 offset=Option.PRESENT 3}))]),
@


1.27
log
@Modifications for equality tests with zero
@
text
@d4 3
d4282 1
a4282 1
			       offset=Option.PRESENT(4*Implicit_Vector.stack_limit)})),
d4369 1
a4369 1
				  offset=Option.PRESENT(4*Implicit_Vector.stack_limit)}))]
d4382 1
a4382 1
				  offset=Option.PRESENT(4*Implicit_Vector.stack_limit)}))]
@


1.26
log
@Removing step and polyvariable options
@
text
@d4 3
d3081 1
a3081 1
			  val (rs1, reg_or_imm) =
d3102 2
a3103 1
				     assemble_sized_gp_imm gp_op')
d3117 2
a3118 1
				      offset=Option.PRESENT(gp_spill_value gp_op')})))
d3124 2
a3125 1
				     I386_Assembly.r32(lookup_gp_operand gp_op'))
d3133 1
a3133 1
				    (* We can shorten both the register and the immediate *)
d3135 3
d3139 17
a3155 3
				      (I386_Assembly.r_m32
				       (Option.SOME1 gp_r),
				       assemble_sized_gp_imm gp_op')
d3164 2
a3165 1
					     I386_Assembly.imm8 3)
d3169 2
a3170 1
					     I386_Assembly.imm16 3)
d3175 5
@


1.25
log
@Changes to Parser and Lexer structures
@
text
@d4 3
d1298 1
a1298 1
                      Options.COMPILEROPTIONS {generate_debug_info, debug_variables, debug_polyvariables, generate_moduler, opt_leaf_fns, ...},
d5018 1
a5018 1
            if generate_debug_info orelse debug_polyvariables orelse debug_variables orelse generate_moduler 
@


1.24
log
@Improvements to lineariser
@
text
@d4 3
d97 1
d120 1
d158 1
a158 2
  structure Options = Debugger_Types.Options
  structure NewMap = Debugger_Types.NewMap
d1295 1
a1295 1
                      Options.COMPILEROPTIONS {debug, debug_variables, debug_polyvariables, generate_moduler, opt_leaf_fns, ...},
d5015 1
a5015 1
            if debug orelse debug_polyvariables orelse debug_variables orelse generate_moduler 
d5330 1
a5330 1
                     if debug
@


1.23
log
@Tidy up, and implement some unimplemented opcodes
@
text
@d4 3
d396 5
a400 1
  fun find_dest_block(tag, [], [], x,y) = ((tag, []), false, x,y)
d402 3
a404 4
		      (block as (block_tag, opcode_list)) ::
		      rest,
		      other,
		      x , [] ) =
d406 3
a408 3
	(block, true, x @@ rest, other)
      else find_dest_block(dest_tag, rest, other, block :: x,[])

d411 2
a412 3
		      (block as (block_tag, opcode_list)) ::
		      rest,
		      x , y ) =
d414 3
a416 3
	(block, true, x , y @@ rest)
      else find_dest_block(dest_tag, [], rest, x, block :: y)

d425 1
a425 1
	    (t, code) :: (L @@ rest)
d462 7
a468 2
      fun do_fall_throughs_with_continuers_calculated(done, (block as (block_tag, opcode_list)),
                                                      continuers,non_continuers) =
a472 31
	  fun do_next() =
	    case continuers of
              (* CT this was rev(rev rest @@ (block :: done)), but
               rev(rev rest @@ (block::done)) = rev(block::done) @@ rest
               = rev( [block] @@ done) @@ rest = rev done @@ rev[block] @@ rest
               = rev done @@ (block :: rest)
               AND now rest = continuers @@ non-continuers *)
	      [] =>
		rev_app(done, (block :: non_continuers))
	    | _ =>
		let
		  val (next_block, continuers') =
		    (let
		       val (tag, _) = Lists.findp
			 (fn (x, _) =>
			  case tag_tree_map x of
			    MLWorks.Option.NONE => true
			  | _ => false)
			 continuers
		       val (others,value) =
			 Lists.assoc_returning_others(tag,continuers)
		     in
		       ((tag, value),others)
		     end) handle Lists.Find =>
		       (Lists.hd continuers, Lists.tl continuers)
		in
		  do_fall_throughs_with_continuers_calculated(block :: done,
							      next_block,
                                                              continuers',
							      non_continuers)
		end
d476 2
a477 2
	      val (dest_block, found_dest, non_continuers',continuers') =
		find_dest_block(dest_tag, non_continuers, continuers, [] , [])
d482 1
a482 1
		 dest_block, continuers', non_continuers')
d484 1
a484 1
		 do_next()
d487 1
a487 1
	     do_next()
d490 41
a530 13
      fun do_fall_throughs(done, block, []) = rev(block :: done)
	| do_fall_throughs(done, block,rest) =
	  let
	    fun continues(tag, _) =
	      case proc_info_map tag of
		MLWorks.Option.SOME(_, t) => t
	      | _ => false

	    val (continuers,non_continuers) =
	      Lists.partition continues rest
	  in
	    do_fall_throughs_with_continuers_calculated(done,block,continuers,non_continuers)
	  end
d536 5
a540 1
      (proc_tag, do_fall_throughs([], hd_block_list, tl_block_list))
@


1.22
log
@Debugger changes
@
text
@d4 3
a225 11
  fun make_imm_fault(i, signed, max_pos) =
(*
    let
      val _ = fault_range(i, signed, max_pos)
      val res = I386_Assembly.IMM i
    in
      res
    end
*)
    Crash.unimplemented"make_imm_fault"

a357 14
(*
    (* Computed GOTOS must be treated specially *)
    | last_opcode([(I386_Assembly.BRANCH_ANNUL(I386_Assembly.BA, _),
                            _, _),
                   elem as (I386_Assembly.BRANCH_ANNUL(I386_Assembly.BA, _),
                            _, _)]) =
     (elem, true)
    | last_opcode([elem as (I386_Assembly.BRANCH(I386_Assembly.BA, _), _, _),
                   _]) =
      (elem, true)
    | last_opcode([elem as (I386_Assembly.BRANCH_ANNUL(I386_Assembly.BA, _),
			    _, _), _]) =
      (elem, true)
*)
a1044 9
(*
			       val _ = output(std_out,
					      "fixup mov with i = " ^
					      MLWorks.Integer.makestring i ^
					      ", j = " ^
					      MLWorks.Integer.makestring j ^
					      ", res = " ^
					      MLWorks.Integer.makestring res ^ "\n")
*)
d1433 1
a1433 11
	((*(I386_Assembly.OPCODE
	  (I386_Assembly.lea,
	   [I386_Assembly.r32 I386Types.global,
	    I386_Assembly.r_m32
	    (Option.SOME2
	     (I386_Assembly.MEM
	      {base=Option.PRESENT I386Types.sp,
	       index=absent,
	       offset=Option.PRESENT((~size)*4)}))]),
	  absent, "get pointer to base of area to be initialised")*)
	 (I386_Assembly.OPCODE
d1450 1
a1450 1
	  (I386_Assembly.push, [(*I386_Assembly.imm32(0, 0)*)I386_Assembly.imm8 0]),
d1502 1
a1502 25
(*
	      case I386Types.fp_used of
		I386Types.single =>
		  (I386_Assembly.LOAD_AND_STORE_FLOAT
		   (I386_Assembly.STF, fp, I386Types.fp,
		    I386_Assembly.IMM offset), Option.ABSENT,
		   "save float") :: do_save_instrs(offset+4, rest)
	      | I386Types.double =>
		  (I386_Assembly.LOAD_AND_STORE_FLOAT
		   (I386_Assembly.STDF, fp, I386Types.fp,
		    I386_Assembly.IMM offset), Option.ABSENT,
		   "save float") :: do_save_instrs(offset+8, rest)
	      | I386Types.extended =>
		  (I386_Assembly.LOAD_AND_STORE_FLOAT
		   (I386_Assembly.STDF, fp, I386Types.fp,
		    I386_Assembly.IMM offset), Option.ABSENT,
		   "save float") ::
		  (I386_Assembly.LOAD_AND_STORE_FLOAT
		   (I386_Assembly.STDF,
		    I386Types.next_reg(I386Types.next_reg fp),
		    I386Types.fp, I386_Assembly.IMM (offset+8)), Option.ABSENT,
		   "save float") ::
		  do_save_instrs(offset+16, rest)
*)
	      Crash.unimplemented"do_save_instrs"
d1506 1
a1506 27
(*
	      case I386Types.fp_used of
		I386Types.single =>
		  (I386_Assembly.LOAD_AND_STORE_FLOAT
		   (I386_Assembly.LDF, fp, I386Types.fp,
		    I386_Assembly.IMM offset), Option.ABSENT,
		   "restore float") ::
		  do_restore_instrs(offset+4, rest)
	      | I386Types.double =>
		  (I386_Assembly.LOAD_AND_STORE_FLOAT
		   (I386_Assembly.LDDF, fp, I386Types.fp,
		    I386_Assembly.IMM offset), Option.ABSENT,
		   "restore float") ::
		  do_restore_instrs(offset+8, rest)
	      | I386Types.extended =>
		  (I386_Assembly.LOAD_AND_STORE_FLOAT
		   (I386_Assembly.LDDF, fp, I386Types.fp,
		    I386_Assembly.IMM offset), Option.ABSENT,
		   "restore float") ::
		  (I386_Assembly.LOAD_AND_STORE_FLOAT
		   (I386_Assembly.LDDF,
		    I386Types.next_reg(I386Types.next_reg fp),
		    I386Types.fp, I386_Assembly.IMM (offset+8)), Option.ABSENT,
		   "restore float") ::
		  do_restore_instrs(offset+16, rest)
*)
	      Crash.unimplemented"do_restore_instrs"
a2218 4
(*
			    val _ =
			      output(std_out, "Generated move to spill\n")
*)
a2231 4
(*
				    val _ =
				      output(std_out, "Generating move from spill\n")
*)
a3131 39
(*
			    if is_reg gp_op' then
			      let
				val _ =
				  if gp_operand_is_spill gp_op' then
				    Crash.unimplemented"Test:gp_operand 1 is spill"
				  else
				    ()
			      in
				(I386_Assembly.r_m32(Option.SOME1 rs1),
				 I386_Assembly.r_m32(Option.SOME1(lookup_gp_operand gp_op')))
			      end
			    else
			      let
				val imm as (i, j) = assemble_imm32 gp_op'
			      in
				if test_instr = I386_Assembly.cmp then
				  if i <= 31 andalso i > ~32 then
				    (I386_Assembly.r_m32(Option.SOME1 rs1),
				     I386_Assembly.imm8(i*4+j))
				  else
				    (I386_Assembly.r_m32(Option.SOME1 rs1),
				     I386_Assembly.imm32 imm)
				else
				  if i = 0 andalso j = 3 then
				    if I386Types.has_byte_name rs1 then
				      (* Testing for tagged *)
				      (I386_Assembly.r_m8
				       (Option.SOME1(I386Types.byte_reg_name rs1)),
				       I386_Assembly.imm8 j)
				    else
				      (I386_Assembly.r_m16
				       (Option.SOME1(I386Types.half_reg_name rs1)),
				       I386_Assembly.imm16 j)
				  else
				    (I386_Assembly.r_m32(Option.SOME1 rs1),
				     I386_Assembly.imm32 imm)
			      end
			    *)
a3403 10
(*
                          val _ = output(std_out,
					 ("Stack allocation of " ^
					  MLWorks.Integer.makestring alloc_size ^
					  " at offset " ^
					  MLWorks.Integer.makestring fp_offset ^
					  " requested, in area starting " ^
					  MLWorks.Integer.makestring
					  gc_stack_alloc_offset ^ "\n"))
*)
d3654 1
a3654 1
			      (*(tag1, opcodes2) :: *)(tag2, opcodes3) :: final_result,
a4220 2
		    Crash.impossible"do_everything:MirTypes.INTERRUPT"
(*
d4224 15
a4238 7
			[(I386_Assembly.ARITHMETIC_AND_LOGICAL
			  (I386_Assembly.ADDCC, I386Types.G0,
			   I386_Assembly.IMM 1, I386Types.stack_limit),
			  Option.ABSENT, "check for interrupt"),
			 (I386_Assembly.BRANCH_ANNUL(I386_Assembly.BNE, 0),
			  Option.PRESENT continue_tag, "branch if no interrupt"),
			 I386_Assembly.nop]
d4240 3
a4242 3
			[(I386_Assembly.BRANCH_ANNUL(I386_Assembly.BA, 0),
			  Option.PRESENT continue_tag, "branch if no interrupt"),
			 I386_Assembly.nop]
d4246 9
a4254 11
			  (I386_Assembly.LOAD_AND_STORE
			   (I386_Assembly.LD, I386Types.global,
			    I386Types.implicit,
			    I386_Assembly.IMM (4 * Implicit_Vector.event_check)),
			   absent, "Get address of event check") ::
			  (I386_Assembly.JUMP_AND_LINK
			   (I386_Assembly.JMPL, I386Types.lr,
			    I386_Assembly.IMM 0, I386Types.global,
			    Debugger_Types.null_backend_annotation),
			   absent, "Do event_check") ::
			  I386_Assembly.nop :: continue
d4257 1
d4269 2
d4274 1
a4274 1
		       final_result)
a4275 1
*)
a4279 10
(*
			  (if stack_need_init then
			    gc_stack_alloc_size
			  else
			    0) +
			     (if spills_need_init then
				gc_spill_size
			      else
				0)
*)
a5151 26
      fun remove_redundant_loads(acc, []) = rev acc
	| remove_redundant_loads(acc, arg as [x]) = rev(x :: acc)
(*
	| remove_redundant_loads(acc, (ins1 as (I386_Assembly.LOAD_AND_STORE
						(I386_Assembly.ST, rd1, rs11, rs12),
						tag1, comment1)) ::
				 (ins2 as (I386_Assembly.LOAD_AND_STORE
					   (I386_Assembly.LD, rd2, rs21, rs22),
					   tag2, comment2)) :: rest) =
	  if rs11 = rs21 andalso rs12 = rs22 andalso rd1 = rd2 then
	    (diagnostic_output 3
	     (fn _ => ["Removing redundant load after store\n"]);
	     remove_redundant_loads(acc, ins1 :: rest))
	  else
	    remove_redundant_loads(ins2 :: ins1 :: acc, rest)
*)
	| remove_redundant_loads(acc, x :: rest) = remove_redundant_loads(x :: acc, rest)

      val remove_redundant_loads = fn x => remove_redundant_loads([], x)

      fun remove_redundant_loads_from_block(tag, opcode_list) =
	(tag, remove_redundant_loads opcode_list)

      fun remove_redundant_loads_from_proc(tag, block_list) =
	(tag, map remove_redundant_loads_from_block block_list)

d5182 2
a5183 2
	  val code_list =
            map (fn tuple=>remove_redundant_loads_from_proc (#1(tuple))) temp_code_list
@


1.21
log
@More work on fp stuff.
@
text
@d4 3
d5152 6
a5157 16
            if debug orelse debug_polyvariables orelse debug_variables orelse generate_moduler then
            let
              val Debugger_Types.INFO i = !debug_map
            in
              (case NewMap.tryApply' (i, procedure_name) of
                 MLWorks.Option.SOME((a, b, c),_, is_exn) =>
                   debug_map :=
                   (Debugger_Types.INFO (NewMap.define(i,
                         procedure_name,((a,if needs_preserve then b
                                            else true,c),runtime_env, is_exn))))
               | _ =>
                   debug_map :=
                   (Debugger_Types.INFO (NewMap.define(i,
                         procedure_name,((Debugger_Types.null_type,false,nil),
                                         runtime_env, false)))))
            end
@


1.20
log
@Floating point code generation
,
@
text
@d4 4
d165 19
d2414 1
d2435 1
d2458 57
a2514 2
                      (* This should probably do some checking for the transcendental functions *)
		      val mnemonics =
a2515 23
			case unary_fp_op of
			  MirTypes.FSQRT => [I386_Assembly.fsqrt]
			| MirTypes.FMOVE => []
			| MirTypes.FABS => [I386_Assembly.fabs]
			| MirTypes.FNEG => [I386_Assembly.fchs]
			| MirTypes.FSIN => [I386_Assembly.fsin]
			| MirTypes.FCOS => [I386_Assembly.fcos]
			| MirTypes.FTAN => [I386_Assembly.fptan]
                        (* fpatan is actually atan2 *)
			| MirTypes.FATAN => [I386_Assembly.fld1,I386_Assembly.fpatan]
                        | _ => Crash.impossible"Bad unary fp generated"
		    in
		      ([(I386_Assembly.OPCODE (I386_Assembly.fld, [rs]), absent, "Get unary fp arg")] @@
                       (map (fn m => (I386_Assembly.OPCODE (m, []), absent, "")) mnemonics) @@
                       [(I386_Assembly.OPCODE (I386_Assembly.fstp, [rd]), absent, "Write it back")],
                       opcode_list, block_list,
		       final_result,stack_drop)
		    end

                (* The following check for an incorrect result by storing out the answer, and *)
                (* reading back in again.  This is because overflows can happen on storing *)
                (* as well as during computation.  Checking the flags might be faster, though *)
                (* probably have a bigger instruction count *)
d2530 1
d2533 1
a2533 2
                      (I386_Assembly.OPCODE (I386_Assembly.fld, [rd]),absent,"And read back for rounding check"),
                      (I386_Assembly.OPCODE (I386_Assembly.fxam, []),absent,"Check result"),
d2535 5
a2539 2
                      (I386_Assembly.OPCODE (I386_Assembly.fstsw_ax,[]), absent,""),
                      (I386_Assembly.OPCODE (I386_Assembly.sahf,[]), absent,"Status to flags"),
d2541 1
a2541 2
                      (I386_Assembly.OPCODE (I386_Assembly.fstp, [I386_Assembly.fp_reg 0]),absent,"Pop checked result"),
                      (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.below,[I386_Assembly.rel32 0]), tag,"")
d2558 2
a2559 1
		      ([(I386_Assembly.OPCODE (I386_Assembly.fld, [rs]), absent, "")] @@
a2561 2
                        (I386_Assembly.OPCODE (I386_Assembly.fld, [rd]),absent,"And read back for rounding check"),
                        (I386_Assembly.OPCODE (I386_Assembly.fxam, []),absent,"Check result"),
d2563 5
a2567 2
                        (I386_Assembly.OPCODE (I386_Assembly.fstsw_ax,[]), absent,""),
                        (I386_Assembly.OPCODE (I386_Assembly.sahf,[]), absent,"Status to flags"),
d2569 1
a2569 2
                        (I386_Assembly.OPCODE (I386_Assembly.fstp, [I386_Assembly.fp_reg 0]),absent,"Pop checked result"),
                        (I386_Assembly.OPCODE (I386_Assembly.jcc I386_Assembly.below,[I386_Assembly.rel32 0]), tag,"")
a3037 14
                      fun B l =
                        let
                          fun aux ([],acc) = acc
                            | aux ("0"::rest,acc) =
                              aux (rest,acc+acc)
                            | aux ("1"::rest,acc) =
                              aux (rest,acc+acc+1)
                            | aux (" "::rest,acc) =
                              aux (rest,acc)
                            | aux (d::rest,acc) =
                              Crash.impossible "bad binary number"
                        in
                          aux (explode l,0)
                        end
d3071 1
a3071 1
                                                I386_Assembly.imm16 (B"1111 0011 1111 1111")]),
d3075 1
a3075 1
                                                I386_Assembly.imm16 (B"0000 0100 0000 0000")]),
d4509 17
a4525 6
                        (* Change this so we don't explicitly push stuff *)
                        val fp_slots_needed =
                          case I386Types.fp_used of
                            I386Types.single => fp_spill_size
                          | I386Types.double => fp_spill_size * 2
                          | _ => Crash.impossible "Can't do float type yet"
d4527 2
a4528 2
                        val num_slots_needed = non_gc_spill_size + fp_slots_needed + gc_stack_slots
			val small_frame = num_slots_needed <= 9 (* Break even point *)
d4531 1
a4531 1
			    (store_seq(num_slots_needed-1,
d4538 2
a4539 1
			    store_loop(post_make_stack_tag, num_slots_needed)
d4569 1
a4569 1
			 (post_overflow_tag, frame_init_a) ::
@


1.19
log
@Handle BINARY a := b - a type stuff
Modify messages for unrepresentable reals
@
text
@d4 4
d159 1
d310 5
a314 4
	 val encoding_function = case I386Types.fp_used of
	   I386Types.single => to_single_string (error_info,x,location)
	 | I386Types.double => to_double_string (error_info,x,location)
	 | I386Types.extended => to_extended_string (error_info,x,location)
d316 2
a317 1
	 Code_Module.REAL(i, encoding_function(sign, mantissa, exponent))
d1353 1
a1353 2
	    | symbolic_value MirTypes.NON_GC_SPILL_SIZE =
	      non_gc_spill_size * 4
d1365 2
a1366 2
		     frame_size - (gc_spill_offset + 4 * (1 + i))
		     )
d1378 8
a1385 14
		  let
		    val offset = if allow_fp_spare_slot then 1 else 0
		  in
		    (if i >= non_gc_spill_size then
		       Crash.impossible
		       ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
			" requested, but only " ^
			MLWorks.Integer.makestring non_gc_spill_size ^
			" allocated\n")
		     else
		       ();
		       frame_size - (non_gc_spill_offset + 4 * (1 + offset + i))
		       )
		  end
a1394 1
		val spare_size = if float_value_size >= 8 then 8 else 4
d1396 7
a1402 15
		  let
		    val offset = if allow_fp_spare_slot then 1 else 0
		  in
		    (if i >= fp_spill_size then
		       Crash.impossible
		       ("fp spill slot " ^ MLWorks.Integer.makestring i ^
			" requested, but only " ^
			MLWorks.Integer.makestring non_gc_spill_size ^
			" allocated\n")
		     else
		       ();
		       frame_size - (fp_spill_offset + float_value_size * (1 + i) +
				     offset * spare_size)
		       )
		  end
d1514 3
a1516 2
	  fun do_save_instrs(_, []) = []
	    | do_save_instrs(offset, fp :: rest) =
d1543 2
a1544 2
	  fun do_restore_instrs(_, []) = []
	    | do_restore_instrs(offset, fp :: rest) =
d1591 1
a1591 1
	  val save_fps = do_save_instrs(~fp_save_start, fps_to_preserve)
d1593 1
a1593 1
	  val restore_fps = do_restore_instrs(~fp_save_start, fps_to_preserve)
d1718 12
d2404 1
a2404 1
			(I386_Assembly.OPCODE
d2411 1
a2411 4
		| MirTypes.BINARYFP(binary_fp_op, fp_operand, fp_operand',
				    fp_operand'') =>
		  Crash.impossible"do_everything:MirTypes.BINARYFP"
(*
d2413 9
a2421 20
		    val rd = lookup_fp_operand fp_operand
		    val rs1 = lookup_fp_operand fp_operand'
		    val rs2 = lookup_fp_operand fp_operand''
		    val operation = case (I386Types.fp_used, binary_fp_op) of
		      (I386Types.single, MirTypes.FADD) => I386_Assembly.FADDS
		    | (I386Types.single, MirTypes.FSUB) => I386_Assembly.FSUBS
		    | (I386Types.single, MirTypes.FMUL) => I386_Assembly.FMULS
		    | (I386Types.single, MirTypes.FDIV) => I386_Assembly.FDIVS
		    | (I386Types.double, MirTypes.FADD) => I386_Assembly.FADDD
		    | (I386Types.double, MirTypes.FSUB) => I386_Assembly.FSUBD
		    | (I386Types.double, MirTypes.FMUL) => I386_Assembly.FMULD
		    | (I386Types.double, MirTypes.FDIV) => I386_Assembly.FDIVD
		    | (I386Types.extended, MirTypes.FADD) =>
			I386_Assembly.FADDX
		    | (I386Types.extended, MirTypes.FSUB) =>
			I386_Assembly.FSUBX
		    | (I386Types.extended, MirTypes.FMUL) =>
			I386_Assembly.FMULX
		    | (I386Types.extended, MirTypes.FDIV) =>
			I386_Assembly.FDIVX
d2423 4
a2426 2
		    ([(I386_Assembly.FBINARY(operation, rd, rs1, rs2), absent,
		       "")], opcode_list, block_list, final_result)
d2428 1
a2428 1
*)
d2430 17
a2446 43
		    Crash.impossible"do_everything:MirTypes.UNARYFP"
(*
		    let
		      val rd = lookup_fp_operand fp_operand
		      val rs2 = lookup_fp_operand fp_operand'
		      val (operation, extra_moves) =
			case (I386Types.fp_used, unary_fp_op) of
			  (I386Types.single, MirTypes.FSQRT) =>
			    (I386_Assembly.FSQRTS, 0)
			| (I386Types.single, MirTypes.FMOVE) =>
			    (I386_Assembly.FMOV, 0)
			| (I386Types.single, MirTypes.FABS) =>
			    (I386_Assembly.FABS, 0)
			| (I386Types.single, MirTypes.FNEG) =>
			    (I386_Assembly.FNEG, 0)
			| (I386Types.double, MirTypes.FSQRT) =>
			    (I386_Assembly.FSQRTD, 0)
			| (I386Types.double, MirTypes.FMOVE) =>
			    (I386_Assembly.FMOV, 1)
			| (I386Types.double, MirTypes.FABS) =>
			    (I386_Assembly.FABS, 1)
			| (I386Types.double, MirTypes.FNEG) =>
			    (I386_Assembly.FNEG, 1)
			| (I386Types.extended, MirTypes.FSQRT) =>
			    (I386_Assembly.FSQRTX, 0)
			| (I386Types.extended, MirTypes.FMOVE) =>
			    (I386_Assembly.FMOV, 3)
			| (I386Types.extended, MirTypes.FABS) =>
			    (I386_Assembly.FABS, 3)
			| (I386Types.extended, MirTypes.FNEG) =>
			    (I386_Assembly.FNEG, 3)
			| _ =>
			    Crash.impossible"Bad unary fp generated"
		      fun add_moves(_, _, 0) = []
		      | add_moves(rd, rs2, moves) =
			let
			  val rd = I386Types.next_reg rd
			  val rs2 = I386Types.next_reg rs2
			in
			  (I386_Assembly.FUNARY(I386_Assembly.FMOV, rd, rs2),
			   absent, "") :: add_moves(rd, rs2, moves - 1)
			end
		      val extra_code = add_moves(rd, rs2, extra_moves)
d2448 5
a2452 3
		      ((I386_Assembly.FUNARY(operation, rd, rs2), absent,
			"") :: extra_code, opcode_list, block_list,
		       final_result)
d2454 5
a2458 1
*)
d2461 10
a2470 33
		  ([(I386_Assembly.nop_code, absent,
		     "Should be an fp binary operation")],
		   opcode_list, block_list, final_result, stack_drop)
(*		  let
		    val rd = lookup_fp_operand fp_operand
		    val rs1 = lookup_fp_operand fp_operand'
		    val rs2 = lookup_fp_operand fp_operand''
		    val operation =
                      case (I386Types.fp_used, tagged_binary_fp_op)
                      of (I386Types.single, MirTypes.FADDV) =>
			I386_Assembly.FADDS
                      |  (I386Types.single, MirTypes.FSUBV) =>
			I386_Assembly.FSUBS
                      |  (I386Types.single, MirTypes.FMULV) =>
			I386_Assembly.FMULS
                      |  (I386Types.single, MirTypes.FDIVV) =>
			I386_Assembly.FDIVS
                      |  (I386Types.double, MirTypes.FADDV) =>
			I386_Assembly.FADDD
                      |  (I386Types.double, MirTypes.FSUBV) =>
			I386_Assembly.FSUBD
                      |  (I386Types.double, MirTypes.FMULV) =>
			I386_Assembly.FMULD
                      |  (I386Types.double, MirTypes.FDIVV) =>
			I386_Assembly.FDIVD
                      |  (I386Types.extended, MirTypes.FADDV) =>
			I386_Assembly.FADDX
                      |  (I386Types.extended, MirTypes.FSUBV) =>
			I386_Assembly.FSUBX
                      |  (I386Types.extended, MirTypes.FMULV) =>
			I386_Assembly.FMULX
                      |  (I386Types.extended, MirTypes.FDIVV) =>
			I386_Assembly.FDIVX
d2472 13
a2484 3
		    ([(I386_Assembly.FBINARY(operation, rd, rs1, rs2),
		       absent, "")],
		     opcode_list, block_list, final_result)
d2486 1
a2486 1
*)
d2489 9
a2497 41
		  ([(I386_Assembly.nop_code, absent,
		     "Should be an fp unary operation")],
		   opcode_list, block_list, final_result, stack_drop)
(*
		    (* same as untagged case - overflows caught by hardware/OS
		       and handled in runtime system. *)
		    let
		      val rd = lookup_fp_operand fp_operand
		      val rs2 = lookup_fp_operand fp_operand'
		      val (operation, extra_moves) =
			case (I386Types.fp_used, tagged_unary_fp_op) of
			  (I386Types.single, MirTypes.FSQRTV) =>
			    (I386_Assembly.FSQRTS, 0)
			| (I386Types.single, MirTypes.FABSV) =>
			    (I386_Assembly.FABS, 0)
			| (I386Types.single, MirTypes.FNEGV) =>
			    (I386_Assembly.FNEG, 0)
			| (I386Types.double, MirTypes.FSQRTV) =>
			    (I386_Assembly.FSQRTD, 0)
			| (I386Types.double, MirTypes.FABSV) =>
			    (I386_Assembly.FABS, 1)
			| (I386Types.double, MirTypes.FNEGV) =>
			    (I386_Assembly.FNEG, 1)
			| (I386Types.extended, MirTypes.FSQRTV) =>
			    (I386_Assembly.FSQRTX, 0)
			| (I386Types.extended, MirTypes.FABSV) =>
			    (I386_Assembly.FABS, 3)
			| (I386Types.extended, MirTypes.FNEGV) =>
			    (I386_Assembly.FNEG, 3)
			| _ =>
			    Crash.impossible"Bad unary fp generated"
		      fun add_moves(_, _, 0) = []
		      | add_moves(rd, rs2, moves) =
			let
			  val rd = I386Types.next_reg rd
			  val rs2 = I386Types.next_reg rs2
			in
			  (I386_Assembly.FUNARY(I386_Assembly.FMOV, rd, rs2),
			   absent, "") :: add_moves(rd, rs2, moves - 1)
			end
		      val extra_code = add_moves(rd, rs2, extra_moves)
d2499 14
a2512 3
		      ((I386_Assembly.FUNARY(operation, rd, rs2), absent,
			"") :: extra_code, opcode_list, block_list,
		       final_result)
d2514 1
a2514 1
*)
d2834 65
a2898 109
		| MirTypes.STOREFPOP(store_fp_op, fp_operand, reg_operand,
				     gp_operand) =>
		  ([(I386_Assembly.nop_code, absent,
		     "Should be an fp store operation")],
		   opcode_list, block_list, final_result, stack_drop)
(*
		  let
		    val frd = lookup_fp_operand fp_operand
		    val rs1 = lookup_reg_operand reg_operand
		    val (store, repeat) =
		      case (I386Types.fp_used, store_fp_op) of
			(I386Types.single, MirTypes.FLD) =>
			  (I386_Assembly.LDF, false)
		      | (I386Types.single, MirTypes.FST) =>
			  (I386_Assembly.STF, false)
		      | (I386Types.single, MirTypes.FLDREF) =>
			  (I386_Assembly.LDF, false)
		      | (I386Types.single, MirTypes.FSTREF) =>
			  (I386_Assembly.STF, false)
		      | (I386Types.double, MirTypes.FLD) =>
			  (I386_Assembly.LDDF, false)
		      | (I386Types.double, MirTypes.FST) =>
			  (I386_Assembly.STDF, false)
		      | (I386Types.double, MirTypes.FLDREF) =>
			  (I386_Assembly.LDDF, false)
		      | (I386Types.double, MirTypes.FSTREF) =>
			  (I386_Assembly.STDF, false)
		      | (I386Types.extended, MirTypes.FLD) =>
			  (I386_Assembly.LDDF, true)
		      | (I386Types.extended, MirTypes.FST) =>
			  (I386_Assembly.STDF, true)
		      | (I386Types.extended, MirTypes.FLDREF) =>
			  (I386_Assembly.LDDF, true)
		      | (I386Types.extended, MirTypes.FSTREF) =>
			  (I386_Assembly.STDF, true)
		    val gp_op = case reg_operand of
		      MirTypes.GC_REG reg => MirTypes.GP_GC_REG reg
		    | MirTypes.NON_GC_REG reg => MirTypes.GP_NON_GC_REG reg
		    fun gp_op_is_large(arg as MirTypes.GP_IMM_ANY i) =
		      gp_check_range(arg, true, arith_imm_limit) andalso
		      gp_check_range(MirTypes.GP_IMM_INT(i+8), true,
				     arith_imm_limit)
		    | gp_op_is_large(MirTypes.GP_IMM_INT i) =
		      gp_op_is_large(MirTypes.GP_IMM_ANY(i*4))
		    | gp_op_is_large(arg as MirTypes.GP_IMM_SYMB symb) =
		      gp_op_is_large(MirTypes.GP_IMM_ANY(symbolic_value symb))
		    | gp_op_is_large(MirTypes.GP_GC_REG _) = true
		    | gp_op_is_large(MirTypes.GP_NON_GC_REG _) = true
		  in
		    if repeat then
		      if gp_op_is_large gp_operand then
			([],
			 MirTypes.BINARY(MirTypes.ADD,
					 MirTypes.GC_REG MirRegisters.global,
					 gp_op,
					 gp_operand) ::
			 MirTypes.STOREFPOP(store_fp_op, fp_operand,
					    MirTypes.GC_REG
					    MirRegisters.global,
					    MirTypes.GP_IMM_ANY 0) ::
			 opcode_list, block_list, final_result)
		      else
			let
			  val (imm, arg) =
			    case make_imm_for_store gp_operand of
			      imm as I386_Assembly.IMM arg => (imm, arg)
			    | _ => Crash.impossible
				"make_imm_for_store fails to return IMM"
			  val imm' = I386_Assembly.IMM(arg+8)
			in
			  ([(I386_Assembly.LOAD_AND_STORE_FLOAT
			     (store, frd, rs1, imm),
			     absent, ""),
			    (I386_Assembly.LOAD_AND_STORE_FLOAT
			     (store,
			      I386Types.next_reg(I386Types.next_reg frd),
			      I386Types.next_reg(I386Types.next_reg rs1),
			      imm'),
			     absent, "")],
			  opcode_list, block_list, final_result)
			end
		    else
		      if is_reg gp_operand orelse
			gp_check_range(gp_operand, true, arith_imm_limit) then
			let
			  val reg_or_imm =
			    if is_reg gp_operand then
			      I386_Assembly.REG(lookup_gp_operand gp_operand)
			    else make_imm_for_store gp_operand
			in
			  ([(I386_Assembly.LOAD_AND_STORE_FLOAT(store, frd,
								 rs1,
								 reg_or_imm),
			     absent, "")],
			   opcode_list, block_list, final_result)
			end
		      else
			([],
			 MirTypes.BINARY(MirTypes.ADD,
					 MirTypes.GC_REG MirRegisters.global,
					 gp_op,
					 gp_operand) ::
			 MirTypes.STOREFPOP(store_fp_op, fp_operand,
					    MirTypes.GC_REG
					    MirRegisters.global,
					    MirTypes.GP_IMM_ANY 0) ::
			 opcode_list, block_list, final_result)
		  end
*)
d2900 41
a2940 45
		    ([(I386_Assembly.nop_code, absent,
		     "Should be an int to float operation")],
		     opcode_list, block_list, final_result, stack_drop)
(*
		    let
		      val operation = case I386Types.fp_used of
			I386Types.single => I386_Assembly.FITOS
		      | I386Types.double => I386_Assembly.FITOD
		      | I386Types.extended => I386_Assembly.FITOX
		      val rd = lookup_fp_operand fp_operand
		      val rs2 =
			if is_reg gp_operand then
			  lookup_gp_operand gp_operand
			else
			  I386Types.global
		    in
		      if is_reg gp_operand then
			([(I386_Assembly.ARITHMETIC_AND_LOGICAL
			   (I386_Assembly.SRA, I386Types.global,
			    I386_Assembly.IMM 2, rs2), absent,
			   "Untag operand"),
			  (I386_Assembly.LOAD_AND_STORE(I386_Assembly.ST,
							 I386Types.global,
							 I386Types.fp,
							 I386_Assembly.IMM
							 ~4), absent,
			   "Store the value to be converted in spare slot"),
			  (I386_Assembly.LOAD_AND_STORE_FLOAT
			   (I386_Assembly.LDF, rd, I386Types.fp,
			    I386_Assembly.IMM ~4), absent,
			   "And reload to fp register"),
			  (I386_Assembly.CONV_OP(operation, rd, rd),
			   absent, "")],
			 opcode_list, block_list, final_result)
		      else
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					MirTypes.GC_REG MirRegisters.global,
					gp_operand) ::
			 MirTypes.REAL(int_to_float, fp_operand,
				       MirTypes.GP_GC_REG
				       MirRegisters.global) ::
			 opcode_list, block_list, final_result)
		    end
*)
d2942 103
a3044 13
		  ([(I386_Assembly.nop_code, absent,
		     "Should be a floor operation")],
		   opcode_list, block_list, final_result, stack_drop)
(*
		    let

		      val (operation,operation',test,subtract) =
                        case I386Types.fp_used of
                          I386Types.single => (I386_Assembly.FSTOI,I386_Assembly.FITOS,I386_Assembly.FCMPS,I386_Assembly.FSUBS)
                        | I386Types.double => (I386_Assembly.FDTOI,I386_Assembly.FITOD,I386_Assembly.FCMPD,I386_Assembly.FSUBD)
                        | I386Types.extended => (I386_Assembly.FXTOI,I386_Assembly.FITOX,I386_Assembly.FCMPX,I386_Assembly.FSUBX)
		      val rs2 = lookup_fp_operand fp_operand
		      val rd = lookup_reg_operand reg_operand
a3045 84
		    in
		      ([
                        (* Test for a possible overflow if the number is too
			   big in magnitude.  Can't rely on hardware trap,
			   because our ints are only 30 bits. *)
                        (I386_Assembly.ARITHMETIC_AND_LOGICAL
                         (I386_Assembly.OR,I386Types.global,
                          I386_Assembly.IMM 1,I386Types.G0),absent,""),
                        (I386_Assembly.ARITHMETIC_AND_LOGICAL
                         (I386_Assembly.SLL,I386Types.global,
                          I386_Assembly.IMM 29,I386Types.global),absent,""),
                        (I386_Assembly.ARITHMETIC_AND_LOGICAL
                         (I386_Assembly.SUB,I386Types.global,
                          I386_Assembly.IMM 1,I386Types.global),absent,""),
                        (I386_Assembly.LOAD_AND_STORE
                         (I386_Assembly.ST,
                          I386Types.global,
                          I386Types.fp,
                          I386_Assembly.IMM ~4), absent,""),
                        (I386_Assembly.LOAD_AND_STORE_FLOAT
                         (I386_Assembly.LDF, I386Types.fp_global,
                          I386Types.fp,
                          I386_Assembly.IMM ~4), absent,
                         "Save converted value"),
                        (I386_Assembly.CONV_OP(operation', I386Types.fp_global,
						I386Types.fp_global),
                         absent, ""),
                        (I386_Assembly.FUNARY(test, rs2, I386Types.fp_global), absent, ""),
                        I386_Assembly.nop,
                        (I386_Assembly.FBRANCH(I386_Assembly.FBG, 0), Option.PRESENT tag, ""),

                        (I386_Assembly.FUNARY(I386_Assembly.FNEG,
                                               I386Types.fp_global, I386Types.fp_global), absent, ""),
                        (I386_Assembly.FUNARY(test, rs2, I386Types.fp_global), absent, ""),
                        I386_Assembly.nop,
                        (I386_Assembly.FBRANCH(I386_Assembly.FBL, 0), Option.PRESENT tag, ""),

                        (* Test for a negative quantity *)
                        (I386_Assembly.FBINARY(subtract, I386Types.fp_global, I386Types.fp_global, I386Types.fp_global),
                         absent, ""),
                       (I386_Assembly.FUNARY(test, rs2, I386Types.fp_global), absent, ""),
                        I386_Assembly.nop,
                        (I386_Assembly.FBRANCH(I386_Assembly.FBGE, 6), Option.ABSENT, ""),

                        (* Negative so subtract one *)
                        (I386_Assembly.ARITHMETIC_AND_LOGICAL
                         (I386_Assembly.OR,I386Types.global,
                          I386_Assembly.IMM 1,I386Types.G0),absent,""),
                        (I386_Assembly.LOAD_AND_STORE
                         (I386_Assembly.ST,
                          I386Types.global,
                          I386Types.fp,
                          I386_Assembly.IMM ~4), absent,""),
                        (I386_Assembly.LOAD_AND_STORE_FLOAT
                         (I386_Assembly.LDF, I386Types.fp_global,
                          I386Types.fp,
                          I386_Assembly.IMM ~4), absent,
                         "Save converted value"),
                        (I386_Assembly.CONV_OP(operation', I386Types.fp_global,
						I386Types.fp_global),
                         absent, ""),
                        (I386_Assembly.FBINARY(subtract, rs2, rs2, I386Types.fp_global),
                         absent, ""),

                        (* Do the conversion operation *)
                        (I386_Assembly.CONV_OP(operation, I386Types.fp_global,
						rs2),
			  absent, ""),
                        (I386_Assembly.LOAD_AND_STORE_FLOAT
                         (I386_Assembly.STF, I386Types.fp_global,
                          I386Types.fp,
                          I386_Assembly.IMM ~4), absent,
                         "Save converted value"),
                        (I386_Assembly.LOAD_AND_STORE(I386_Assembly.LD,
                                                       rd, I386Types.fp,
                                                       I386_Assembly.IMM
                                                       ~4), absent,
                        "And reload into destination"),
			(I386_Assembly.ARITHMETIC_AND_LOGICAL
			 (I386_Assembly.SLL, rd, I386_Assembly.IMM 2, rd),
			 absent, "Tag the result")],
		      opcode_list, block_list, final_result)
		    end
*)
d3243 37
a3279 2
		    ([(I386_Assembly.nop_code, absent,
		     "Should be an FTEST operation")],
d3281 2
a3282 23
(*
		  let
		    val branch = case fcond_branch of
		      MirTypes.FBEQ => I386_Assembly.FBE
		    | MirTypes.FBNE => I386_Assembly.FBNE
		    | MirTypes.FBLE => I386_Assembly.FBLE
		    | MirTypes.FBLT => I386_Assembly.FBL
		    val rs1 = lookup_fp_operand fp_operand
		    val rs2 = lookup_fp_operand fp_operand'
		    val test_instr = case I386Types.fp_used of
		      I386Types.single => I386_Assembly.FCMPS
		    | I386Types.double => I386_Assembly.FCMPD
		    | I386Types.extended => I386_Assembly.FCMPX
		  in
		    ([(I386_Assembly.FUNARY(test_instr, rs1, rs2),
		       absent, "Do the test"),
		      I386_Assembly.nop,
		      (I386_Assembly.FBRANCH_ANNUL(branch, 0),
		       Option.PRESENT tag, "Do the branch"),
		      I386_Assembly.nop],
		    opcode_list, block_list, final_result)
		  end
*)
d4457 15
a4471 1
			val small_frame = gc_stack_slots <= 9 (* Break even point *)
d4474 1
a4474 1
			    (store_seq(gc_stack_slots-1,
d4481 1
a4481 1
			    store_loop(post_make_stack_tag, gc_stack_slots)
d5127 13
a5139 1
	  val needs_fp_spare = false
d5141 2
d5145 1
d5153 2
d5158 1
d5162 1
a5166 2
	  val total_fp_size = fp_spill_size + fp_save_size
	  val total_gc_size = gc_spill_size + stack_extra
d5169 1
a5169 1
	    non_gc_spill_size * 4 + float_value_size * total_fp_size
d5181 1
d5202 1
a5202 1
     }
@


1.18
log
@Adding ALLOC_VECTOR
Include variable length strings & vectors
@
text
@d4 4
d255 1
a255 1
           "Real number too big : " ^ x)
d314 1
a314 1
	 (Info.FATAL, location, "Real number too big : " ^ x)
a1475 10
(*
	 (I386_Assembly.OPCODE
	  (I386_Assembly.cmp,
	   [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
	    I386_Assembly.r32 I386Types.sp]),
	  absent, "finished yet?") ::
	 (I386_Assembly.OPCODE
	  (I386_Assembly.jcc(I386_Assembly.not_equal), [I386_Assembly.rel32 0]),
	  Option.PRESENT loop_tag, "branch if not finished") :: []
*)
d1477 1
a1477 1
	  (I386_Assembly.loopnz, [I386_Assembly.rel8 0]),
d1939 161
a2099 6
		  if reg_equals_gp(reg_operand, gp_operand) then
		    if is_shift orelse i_opcode = I386_Assembly.not then
		      if is_shift then
			if is_reg gp_operand' then
			  (* Nasty, all shifts controlled by CL, part of ECX *)
			  if gp_operand_is_spill gp_operand' then
d2101 5
a2105 4
			     (MirTypes.UNARY(MirTypes.MOVE,
					     MirTypes.GC_REG MirRegisters.global,
					     gp_operand')) ::
			     MirTypes.BINARY(binary_op, reg_operand, gp_operand,
d2109 1
a2109 1
			    (* Shift amount in ECX *)
d2111 43
a2153 42
			      val tag1 = MirTypes.new_tag()
			      val tag2 = MirTypes.new_tag()
			      val tag3 = MirTypes.new_tag()
			      val operand =
				I386_Assembly.r_m32
				(if reg_operand_is_spill reg_operand then
				   Option.SOME2
				   (I386_Assembly.MEM
				    {base=Option.PRESENT I386Types.sp,
				     index=absent,
				     offset=Option.PRESENT(reg_spill_value reg_operand)})
				 else
				   Option.SOME1(lookup_reg_operand reg_operand))
			      val branch =
				[(I386_Assembly.OPCODE
				  (I386_Assembly.jmp,
				   [I386_Assembly.rel32 0]),
				  Option.PRESENT tag3, "continue")]
			      val block1 =
				[(I386_Assembly.OPCODE
				  (I386_Assembly.cmp,
				   [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
				    I386_Assembly.imm8 31]),
				  absent, "test for shift by > 31"),
				 (I386_Assembly.OPCODE
				  (I386_Assembly.jcc(I386_Assembly.less_or_equal),
				   [I386_Assembly.rel32 0]),
				  Option.PRESENT tag2, "branch if ok"),
				 (I386_Assembly.OPCODE
				  (I386_Assembly.mov,
				   [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
				    I386_Assembly.imm8 31]),
				  absent, "treat as shift by 31"),
				 (I386_Assembly.OPCODE
				  (I386_Assembly.jmp,
				   [I386_Assembly.rel32 0]),
				  Option.PRESENT tag2, "continue")]
			      val block2 =
				(I386_Assembly.OPCODE
				 (i_opcode,
				  [operand, I386_Assembly.r8 I386Types.CL]),
				 absent, "do the actual shift") :: branch
d2155 3
a2157 23
			      ([(I386_Assembly.OPCODE
				 (I386_Assembly.cmp,
				  [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
				   I386_Assembly.imm8 0]),
				 absent, "test for shift by < 0"),
				(I386_Assembly.OPCODE
				 (I386_Assembly.jcc(I386_Assembly.greater_or_equal),
				  [I386_Assembly.rel32 0]),
				 Option.PRESENT tag1, "branch if ok"),
				(I386_Assembly.OPCODE
				 (I386_Assembly.mov,
				  [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
				   I386_Assembly.imm8 0]),
				 absent, "treat as shift by 0"),
				(I386_Assembly.OPCODE
				 (I386_Assembly.jmp,
				  [I386_Assembly.rel32 0]),
				 Option.PRESENT tag1, "continue")],
			      [],
			      MirTypes.BLOCK(tag3, opcode_list) :: block_list,
			      (tag1, block1) ::
			      (tag2, block2) ::
			      final_result, stack_drop)
a2158 25
			else
			  let
			    val shift as (i, j) = assemble_imm32 gp_operand'
			    val shift =
			      if i < 0 then
				Crash.impossible"shift by negative number"
			      else
				if i >= 8 then 31 else 4*i+j
			    val operand =
			      I386_Assembly.r_m32
			      (if reg_operand_is_spill reg_operand then
				 Option.SOME2
				 (I386_Assembly.MEM
				  {base=Option.PRESENT I386Types.sp,
				   index=absent,
				   offset=Option.PRESENT(reg_spill_value reg_operand)})
			       else
				 Option.SOME1(lookup_reg_operand reg_operand))
			  in
			    ((I386_Assembly.OPCODE
			      (i_opcode,
			       [operand, I386_Assembly.imm8 shift]),
			      absent, "shift by immediate value") :: [],
			     opcode_list, block_list, final_result, stack_drop)
			  end
d2160 1
a2160 2
			(* BIC *)
			if is_reg gp_operand' then
d2162 22
a2183 10
			    val operand =
			      I386_Assembly.r_m32
			      (if gp_operand_is_spill gp_operand' then
				 Option.SOME2
				 (I386_Assembly.MEM
				  {base=Option.PRESENT I386Types.sp,
				   index=absent,
				   offset=Option.PRESENT(gp_spill_value gp_operand')})
			       else
				 Option.SOME1(lookup_gp_operand gp_operand'))
d2185 7
a2191 51
			    ([(I386_Assembly.OPCODE
			       (I386_Assembly.mov,
				[I386_Assembly.r32 I386Types.global, operand]),
			       absent, "get BIC value into ECX"),
			      (I386_Assembly.OPCODE
			       (I386_Assembly.not,
				[I386_Assembly.r_m32(Option.SOME1 I386Types.global)]),
			       absent, "invert it")],
			    MirTypes.BINARY(MirTypes.AND, reg_operand, gp_operand,
					    MirTypes.GP_GC_REG MirRegisters.global) ::
			    opcode_list, block_list, final_result, stack_drop)
			  end
			else
			  let
			    val mask as (i, j) = assemble_imm32 gp_operand'
			    val new_mask as (i, j) =
			      (MLWorks.Bits.xorb(i, ~1),
			       MLWorks.Bits.xorb(j, 3))
			    val operand =
			      I386_Assembly.r_m32
			      (if reg_operand_is_spill reg_operand then
				 Option.SOME2
				 (I386_Assembly.MEM
				  {base=Option.PRESENT I386Types.sp,
				   index=absent,
				   offset=Option.PRESENT(reg_spill_value reg_operand)})
			       else
				 Option.SOME1(lookup_reg_operand reg_operand))
			  in
			    ([(I386_Assembly.OPCODE
			       (I386_Assembly.and_op,
				[operand, I386_Assembly.imm32 new_mask]),
			       absent, "BIC by immediate value")],
			     opcode_list, block_list, final_result, stack_drop)
			  end
		    else
		      if reg_operand_is_spill reg_operand andalso
			gp_operand_is_spill gp_operand' then
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					MirTypes.GC_REG MirRegisters.global,
					gp_operand') ::
			 MirTypes.BINARY(binary_op, reg_operand,
					 gp_operand,
					 MirTypes.GP_GC_REG MirRegisters.global) ::
			 opcode_list, block_list, final_result, stack_drop)
		      else
			(* Not a shift, and not both spills *)
			let
			  val operands =
			    if reg_operand_is_spill reg_operand then
d2193 18
a2210 4
				val spill = reg_spill_value reg_operand
				val op2 =
				  if is_reg gp_operand' then
				    I386_Assembly.r32(lookup_gp_operand gp_operand')
d2212 8
a2219 9
				    assemble_sized_gp_imm gp_operand'
			      in
				[I386_Assembly.r_m32
				 (Option.SOME2
				  (I386_Assembly.MEM
				   {base=Option.PRESENT I386Types.sp,
				    index=absent,
				    offset=Option.PRESENT spill})),
				 op2]
d2221 9
a2229 28
			    else
			      if gp_operand_is_spill gp_operand' then
				let
				  val spill = gp_spill_value gp_operand'
				in
				  [I386_Assembly.r32(lookup_reg_operand reg_operand),
				   I386_Assembly.r_m32
				   (Option.SOME2
				    (I386_Assembly.MEM
				     {base=Option.PRESENT I386Types.sp,
				      index=absent,
				      offset=Option.PRESENT spill}))]
				end
			      else
				let
				  val op2 =
				    if is_reg gp_operand' then
				      I386_Assembly.r32(lookup_gp_operand gp_operand')
				    else
				      assemble_sized_gp_imm gp_operand'
				in
				  [I386_Assembly.r_m32
				   (Option.SOME1(lookup_reg_operand reg_operand)),
				   op2]
				end
			in
			  ([(I386_Assembly.OPCODE(i_opcode, operands),
			     absent, "binary op")],
a2230 47
			end
		  else
		    if reg_equals_gp(reg_operand, gp_operand') then
		      let
			val can_reverse = case binary_op of
			  MirTypes.ADD => true
			| MirTypes.SUB => false
			| MirTypes.MULU =>
			    Crash.unimplemented"MirTypes.MULU"
			| MirTypes.MULS =>
			    Crash.unimplemented"MirTypes.MULS"
			| MirTypes.DIVU =>
			    Crash.unimplemented"MirTypes.DIVU"
			| MirTypes.DIVS =>
			    Crash.unimplemented"MirTypes.DIVS"
			| MirTypes.MODU =>
			    Crash.unimplemented"MirTypes.MODU"
			| MirTypes.MODS =>
			    Crash.unimplemented"MirTypes.MODS"
			| MirTypes.AND => true
			| MirTypes.OR => true
			| MirTypes.BIC => false
			| MirTypes.EOR => true
			| MirTypes.LSR => false
			| MirTypes.ASL => false
			| MirTypes.ASR => false

		      in
			if can_reverse then
			  ([],
			   MirTypes.BINARY(binary_op, reg_operand, gp_operand',
					   gp_operand) :: opcode_list,
			   block_list, final_result, stack_drop)
			else
			  Crash.unimplemented
			  ("BINARY:unreversible:reg_operand = gp_operand' in " ^
			   MirPrint.opcode opcode)
		      end
		    else
		      ([],
		       MirTypes.UNARY(MirTypes.MOVE,
				      reg_operand,
				      gp_operand) ::
		       MirTypes.BINARY(binary_op, reg_operand,
				       gp_from_reg reg_operand,
				       gp_operand') ::
		       opcode_list, block_list, final_result, stack_drop)
@


1.17
log
@Minor improvements to tail, rts
@
text
@d4 3
d3630 3
d3855 88
a3942 3
			       case allocate
				 of MirTypes.ALLOC        => Crash.unimplemented "ALLOC variable size"
			       | MirTypes.ALLOC_STRING => Crash.unimplemented "ALLOC_STRING variable size"
@


1.16
log
@Rework stack clearing using push
Modify constant loading in gc sequences
@
text
@d4 4
d3206 7
a3212 1
				   I386_Assembly.imm32(assemble_imm32 gp_op'))
d3216 47
a3262 16
			      if gp_operand_is_spill gp_op' then
				(I386_Assembly.r32(lookup_gp_operand gp_op),
				 I386_Assembly.r_m32
				 (Option.SOME2
				  (I386_Assembly.MEM
				   {base=Option.PRESENT I386Types.sp,
				    index=absent,
				    offset=Option.PRESENT(gp_spill_value gp_op')})))
			      else
				(* gp_op' is not a spill *)
				(I386_Assembly.r_m32(Option.SOME1(lookup_gp_operand gp_op)),
				 if is_reg gp_op' then
				   I386_Assembly.r32(lookup_gp_operand gp_op')
				 else
				   (* This case needs more work *)
				   I386_Assembly.imm32(assemble_imm32 gp_op'))
d3422 2
a3423 3
			    (I386_Assembly.add,
			     [I386_Assembly.r_m32(Option.SOME1 I386Types.sp),
			      I386_Assembly.imm8 4]),
d3511 1
a3511 3
				       {base=Option.PRESENT
					(lookup_reg_operand
					 (MirTypes.GC_REG MirRegisters.callee_closure)),
d4508 2
a4509 3
			  (I386_Assembly.add,
			   [I386_Assembly.r_m32(Option.SOME1 I386Types.sp),
			    I386_Assembly.imm8 4]),
@


1.15
log
@Add immediate store operations
@
text
@d4 3
a635 13
(*
				    output(std_out, "Shrinking jcc to " ^
					   MirTypes.print_tag tag ^
					   " disp = " ^
					   MLWorks.Integer.makestring disp ^
					   " res = " ^
					   MLWorks.Integer.makestring res ^
					   " i = " ^
					   MLWorks.Integer.makestring i ^
					   " offset " ^
					   MLWorks.Integer.makestring offset ^
					   "\n");
*)
a657 12
(*
				      output(std_out, "Shrinking jmp to " ^
					     MirTypes.print_tag tag ^
					     " disp = " ^
					     MLWorks.Integer.makestring disp ^ 
					     " res = " ^
					     MLWorks.Integer.makestring res ^
					     " i = " ^
					     MLWorks.Integer.makestring i ^
					     " offset " ^
					     MLWorks.Integer.makestring offset ^"\n");
*)
d876 108
d1425 2
a1426 8
	     (I386_Assembly.mov,
	      [I386_Assembly.r_m32
	       (Option.SOME2
		(I386_Assembly.MEM
		 {base=Option.PRESENT I386Types.sp,
		  index=absent,
		  offset=absent})),
	       I386_Assembly.r32 I386Types.global]),
d1431 2
a1432 8
		       (I386_Assembly.mov,
			[I386_Assembly.r_m32
			 (Option.SOME2
			  (I386_Assembly.MEM
			   {base=Option.PRESENT I386Types.sp,
			    index=absent,
			    offset=Option.PRESENT(~(size*4))})),
			 I386_Assembly.r32 I386Types.global]),
d1436 1
a1436 1
	((I386_Assembly.OPCODE
d1444 15
a1458 2
	       offset=Option.PRESENT((size-1)*4)}))]),
	  absent, "get pointer to start of area to be initialised") ::
d1463 1
a1463 8
	  (I386_Assembly.mov,
	   [I386_Assembly.r_m32
	    (Option.SOME2
	     (I386_Assembly.MEM
	      {base=Option.PRESENT I386Types.global,
	       index=absent,
	       offset=absent})),
	    I386_Assembly.imm32(0, 0)]),
d1465 1
a1465 4
	 (I386_Assembly.OPCODE
	  (I386_Assembly.sub,
	   [I386_Assembly.r_m32(Option.SOME1 I386Types.global), I386_Assembly.imm8 4]),
	  absent, "decrement pointer") ::
d1472 1
a1472 1
	  (I386_Assembly.jcc(I386_Assembly.above_or_equal), [I386_Assembly.rel32 0]),
d1474 4
d1698 10
d1768 1
a1768 8
				    let
				      val imm as (i, j) = assemble_imm32 gp_operand'
				    in
				      if i <= 31 andalso i >= ~32 then
					I386_Assembly.imm8(4*i+j)
				      else
					I386_Assembly.imm32 imm
				    end
d1797 1
a1797 8
				      let
					val imm as (i, j) = assemble_imm32 gp_operand'
				      in
					if i <= 31 andalso i >= ~32 then
					  I386_Assembly.imm8(4*i+j)
					else
					  I386_Assembly.imm32 imm
				      end
d2118 1
a2118 8
				    let
				      val imm as (i, j) = assemble_imm32 gp_operand'
				    in
				      if i <= 31 andalso i >= ~32 then
					I386_Assembly.imm8(4*i+j)
				      else
					I386_Assembly.imm32 imm
				    end
d2147 1
a2147 8
				      let
					val imm as (i, j) = assemble_imm32 gp_operand'
				      in
					if i <= 31 andalso i >= ~32 then
					  I386_Assembly.imm8(4*i+j)
					else
					  I386_Assembly.imm32 imm
				      end
d3671 25
a3695 10
			       move_imm(I386Types.global, bytes, "amount requested") ::
			       (I386_Assembly.OPCODE
				(I386_Assembly.call,
				 [I386_Assembly.r_m32
				  (Option.SOME2
				   (I386_Assembly.MEM
				    {base=Option.PRESENT I386Types.implicit,
				     index=absent,
				     offset=Option.PRESENT gc_entry}))]),
				absent, "call the gc") :: opcodes1
d4398 1
a4398 20
			val make_stack =
			  if frame_size > register_save_size then
			    let
			      val frame_sub = frame_size - register_save_size
			      val operand =
				if frame_sub <= 127 then
				  I386_Assembly.imm8 frame_sub
				else
				  I386_Assembly.imm32(frame_sub div 4, frame_sub mod 4)
			    in
			      [(I386_Assembly.OPCODE
				(I386_Assembly.sub,
				 [I386_Assembly.r_m32(Option.SOME1 I386Types.sp),
				  operand]), absent,
				"leave space on stack")]
			    end
			  else
			    (* Simple case *)
			    []
			val small_frame = gc_stack_slots <= 4
d4438 1
a4438 1
			 (post_overflow_tag, make_stack @@ frame_init_a) ::
@


1.14
log
@Recode binary add and sub using lea
@
text
@d4 3
d359 1
d556 38
d607 130
d738 1
a750 33
	  fun rev_map f arg =
	    let
	      fun map_sub([], acc) = acc
		| map_sub(x :: xs, acc) = map_sub(xs, f x :: acc)
	    in
	      map_sub arg
	    end

	  fun rev_app([], y) = y
	    | rev_app(x :: xs, y) = rev_app(xs, x :: y)

	  fun copy_n(n, from, acc, new_tail) =
	    if n < 0 then
	      Crash.impossible"copy_n negative arg"
	    else
	      if n = 0 then
		rev_app(acc, new_tail)
	      else
		case from of
		  (x :: xs) =>
		    copy_n(n-1, xs, x :: acc, new_tail)
		| _ => Crash.impossible"copy_n short list"

	  fun drop(n, the_list) =
	    if n < 0 then
	      Crash.impossible"drop negative arg"
	    else
	      if n = 0 then the_list
	      else
		case the_list of
		  [] => Crash.impossible"drop bad list"
		| _ :: rest => drop(n-1, rest)

d777 85
d863 36
d915 1
a915 1
							[I386_Assembly.rel32 i]),
d929 1
d2529 64
d3379 1
a3379 1
						    [I386_Assembly.rel32 0]),
d3585 33
a3617 25
			       [move_imm(I386Types.global, bytes, "amount requested"),
				(I386_Assembly.OPCODE
				 (I386_Assembly.call,
				  [I386_Assembly.r_m32
				   (Option.SOME2
				    (I386_Assembly.MEM
				     {base=Option.PRESENT I386Types.implicit,
				      index=absent,
				      offset=Option.PRESENT gc_entry}))]),
				 absent, "call the gc"),
				(I386_Assembly.OPCODE
				 (I386_Assembly.lea,
				  [I386_Assembly.r32 rd,
				   I386_Assembly.r_m32
				   (Option.SOME2
				    (I386_Assembly.MEM
				     {base=Option.PRESENT I386Types.global,
				      index=absent,
				      offset=Option.PRESENT primary}))]),
				 absent, "produce the answer"),
				(I386_Assembly.OPCODE
				 (I386_Assembly.jmp,
				  [I386_Assembly.rel32 0]),
				 Option.PRESENT tag2,
				 "branch to continuation sequence")]
d4738 2
d4889 1
a4889 1
	    | check_instr_regs(MirTypes.STOREOP(_, reg_op, reg_op', gp_op )) =
d4893 4
@


1.13
log
@Sort out small stack initialisation code
@
text
@d4 3
d1136 16
a1151 1
	
d1548 51
d1600 12
a1611 124
		    let
		      val (opcode, is_shift) =
			case binary_op of
			  MirTypes.ADD => (I386_Assembly.add, false)
			| MirTypes.SUB => (I386_Assembly.sub, false)
			| MirTypes.MULU =>
			    Crash.unimplemented"MirTypes.MULU"
			| MirTypes.MULS =>
			    Crash.unimplemented"MirTypes.MULS"
			| MirTypes.DIVU =>
			    Crash.unimplemented"MirTypes.DIVU"
			| MirTypes.DIVS =>
			    Crash.unimplemented"MirTypes.DIVS"
			| MirTypes.MODU =>
			    Crash.unimplemented"MirTypes.MODU"
			| MirTypes.MODS =>
			    Crash.unimplemented"MirTypes.MODS"
			| MirTypes.AND => (I386_Assembly.and_op, false)
			| MirTypes.OR => (I386_Assembly.or, false)
			| MirTypes.BIC => (I386_Assembly.not, false)
			| MirTypes.EOR => (I386_Assembly.xor, false)
			| MirTypes.LSR => (I386_Assembly.shr, true)
			| MirTypes.ASL => (I386_Assembly.sal, true)
			| MirTypes.ASR => (I386_Assembly.sar, true)

		    in
		      if is_shift orelse opcode = I386_Assembly.not then
			if is_shift then
			  if is_reg gp_operand' then
			    (* Nasty, all shifts controlled by CL, part of ECX *)
			    if gp_operand_is_spill gp_operand' then
			      ([],
			       (MirTypes.UNARY(MirTypes.MOVE,
					       MirTypes.GC_REG MirRegisters.global,
					       gp_operand')) ::
			       MirTypes.BINARY(binary_op, reg_operand, gp_operand,
					       MirTypes.GP_GC_REG MirRegisters.global) ::
			       opcode_list, block_list, final_result, stack_drop)
			    else
			      (* Shift amount in ECX *)
			      let
				val tag1 = MirTypes.new_tag()
				val tag2 = MirTypes.new_tag()
				val tag3 = MirTypes.new_tag()
				val operand =
				  I386_Assembly.r_m32
				  (if reg_operand_is_spill reg_operand then
				     Option.SOME2
				     (I386_Assembly.MEM
				      {base=Option.PRESENT I386Types.sp,
				       index=absent,
				       offset=Option.PRESENT(reg_spill_value reg_operand)})
				   else
				     Option.SOME1(lookup_reg_operand reg_operand))
(*
				val needs_clear =
				  opcode = I386_Assembly.shr orelse
				  opcode = I386_Assembly.sar
*)
				val branch =
				  [(I386_Assembly.OPCODE
				    (I386_Assembly.jmp,
				     [I386_Assembly.rel32 0]),
				    Option.PRESENT tag3, "continue")]
				val last = branch
(*
				  if needs_clear then
				    (I386_Assembly.OPCODE
				     (I386_Assembly.and_op,
				      [operand,
				       I386_Assembly.imm32(~1, 0)]),
				     absent, "clear bottom two bits") :: branch
				  else
				    branch
*)
				val block1 =
				  [(I386_Assembly.OPCODE
				   (I386_Assembly.cmp,
				    [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
				     I386_Assembly.imm8 31]),
				   absent, "test for shift by > 31"),
				  (I386_Assembly.OPCODE
				   (I386_Assembly.jcc(I386_Assembly.less_or_equal),
				    [I386_Assembly.rel32 0]),
				   Option.PRESENT tag2, "branch if ok"),
				  (I386_Assembly.OPCODE
				   (I386_Assembly.mov,
				    [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
				     I386_Assembly.imm8 31]),
				   absent, "treat as shift by 31"),
				  (I386_Assembly.OPCODE
				   (I386_Assembly.jmp,
				    [I386_Assembly.rel32 0]),
				   Option.PRESENT tag2, "continue")]
				val block2 =
				  (I386_Assembly.OPCODE
				   (opcode,
				    [operand, I386_Assembly.r8 I386Types.CL]),
				   absent, "do the actual shift") :: last
			      in
				([(I386_Assembly.OPCODE
				   (I386_Assembly.cmp,
				    [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
				     I386_Assembly.imm8 0]),
				   absent, "test for shift by < 0"),
				  (I386_Assembly.OPCODE
				   (I386_Assembly.jcc(I386_Assembly.greater_or_equal),
				    [I386_Assembly.rel32 0]),
				   Option.PRESENT tag1, "branch if ok"),
				  (I386_Assembly.OPCODE
				   (I386_Assembly.mov,
				    [I386_Assembly.r_m32(Option.SOME1 I386Types.global),
				     I386_Assembly.imm8 0]),
				   absent, "treat as shift by 0"),
				  (I386_Assembly.OPCODE
				   (I386_Assembly.jmp,
				    [I386_Assembly.rel32 0]),
				   Option.PRESENT tag1, "continue")],
				 [],
				 MirTypes.BLOCK(tag3, opcode_list) :: block_list,
				 (tag1, block1) ::
				 (tag2, block2) ::
				 final_result, stack_drop)
			      end
d1613 1
d1615 3
a1617 6
			      val shift as (i, j) = assemble_imm32 gp_operand'
			      val shift =
				if i < 0 then
				  Crash.impossible"shift by negative number"
				else
				  if i >= 8 then 31 else 4*i+j
d1628 29
a1656 37
(*
			      val needs_clear =
				opcode = I386_Assembly.shr orelse
				opcode = I386_Assembly.sar
*)
			      val last =
(*
				if needs_clear then
				  [(I386_Assembly.OPCODE
				    (I386_Assembly.and_op,
				     [operand,
				      I386_Assembly.imm32(~1, 0)]),
				    absent, "clear bottom two bits")]
				else
*)
				  []
			    in
			      ((I386_Assembly.OPCODE
				(opcode,
				 [operand, I386_Assembly.imm8 shift]),
				absent, "shift by immediate value") :: last,
			       opcode_list, block_list, final_result, stack_drop)
			    end
			else
			  (* BIC *)
			  if is_reg gp_operand' then
			    let
			      val operand =
				I386_Assembly.r_m32
				(if gp_operand_is_spill gp_operand' then
				   Option.SOME2
				   (I386_Assembly.MEM
				    {base=Option.PRESENT I386Types.sp,
				     index=absent,
				     offset=Option.PRESENT(gp_spill_value gp_operand')})
				 else
				   Option.SOME1(lookup_gp_operand gp_operand'))
d1659 9
d1669 3
a1671 2
				  [I386_Assembly.r32 I386Types.global, operand]),
				 absent, "get BIC value into ECX"),
d1673 8
a1680 6
				 (I386_Assembly.not,
				  [I386_Assembly.r_m32(Option.SOME1 I386Types.global)]),
				 absent, "invert it")],
			       MirTypes.BINARY(MirTypes.AND, reg_operand, gp_operand,
					       MirTypes.GP_GC_REG MirRegisters.global) ::
			       opcode_list, block_list, final_result, stack_drop)
d1682 25
a1706 23
			  else
			    let
			      val mask as (i, j) = assemble_imm32 gp_operand'
			      val new_mask as (i, j) =
				(MLWorks.Bits.xorb(i, ~1),
				 MLWorks.Bits.xorb(j, 3))
			      val operand =
				I386_Assembly.r_m32
				(if reg_operand_is_spill reg_operand then
				   Option.SOME2
				   (I386_Assembly.MEM
				    {base=Option.PRESENT I386Types.sp,
				     index=absent,
				     offset=Option.PRESENT(reg_spill_value reg_operand)})
				 else
				   Option.SOME1(lookup_reg_operand reg_operand))
			    in
			      ([(I386_Assembly.OPCODE
				 (I386_Assembly.and_op,
				  [operand, I386_Assembly.imm32 new_mask]),
				 absent, "BIC by immediate value")],
			       opcode_list, block_list, final_result, stack_drop)
			    end
d1708 26
a1733 10
			if reg_operand_is_spill reg_operand andalso
			  gp_operand_is_spill gp_operand' then
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  MirTypes.GC_REG MirRegisters.global,
					  gp_operand') ::
			   MirTypes.BINARY(binary_op, reg_operand,
					   gp_operand,
					   MirTypes.GP_GC_REG MirRegisters.global) ::
			   opcode_list, block_list, final_result, stack_drop)
a1734 1
			  (* Not a shift, and not both spills *)
d1736 74
a1809 2
			    val operands =
			      if reg_operand_is_spill reg_operand then
a1810 1
				  val spill = reg_spill_value reg_operand
d1825 1
a1825 5
				   (Option.SOME2
				    (I386_Assembly.MEM
				     {base=Option.PRESENT I386Types.sp,
				      index=absent,
				      offset=Option.PRESENT spill})),
d1828 5
a1832 38
			      else
				if gp_operand_is_spill gp_operand' then
				  let
				    val spill = gp_spill_value gp_operand'
				  in
				    [I386_Assembly.r32(lookup_reg_operand reg_operand),
				     I386_Assembly.r_m32
				     (Option.SOME2
				      (I386_Assembly.MEM
				       {base=Option.PRESENT I386Types.sp,
					index=absent,
					offset=Option.PRESENT spill}))]
				  end
				else
				  let
				    val op2 =
				      if is_reg gp_operand' then
					I386_Assembly.r32(lookup_gp_operand gp_operand')
				      else
					let
					  val imm as (i, j) = assemble_imm32 gp_operand'
					in
					  if i <= 31 andalso i >= ~32 then
					    I386_Assembly.imm8(4*i+j)
					  else
					    I386_Assembly.imm32 imm
					end
				  in
				    [I386_Assembly.r_m32
				     (Option.SOME1(lookup_reg_operand reg_operand)),
				     op2]
				  end
			  in
			    ([(I386_Assembly.OPCODE(opcode, operands),
			       absent, "binary op")],
			     opcode_list, block_list, final_result, stack_drop)
			  end
		    end
d1879 1
d2411 1
a2411 2
			   index=Option.PRESENT((lookup_gp_operand gp_operand),
						Option.ABSENT),
@


1.12
log
@Fix new_handler code when handler frame pointer is spilled
Sort out some stack size and initialisation problems
Fix bug in array allocation when both size and destination are spills
@
text
@d4 5
d1075 1
a1075 2
	      [I386_Assembly.r32 I386Types.global,
	       I386_Assembly.r_m32
d1080 2
a1081 1
		  offset=absent}))]),
d1087 1
a1087 2
			[I386_Assembly.r32 I386Types.global,
			 I386_Assembly.r_m32
d1092 2
a1093 1
			    offset=Option.PRESENT(~(size*4))}))]),
d3059 1
@


1.11
log
@Fix problems with overloaded use of ECX during store byte
@
text
@d4 3
d129 1
d956 3
d976 1
a976 1
	  val frame_size = register_save_offset + register_save_size
d992 1
a992 1
		     frame_size - 4 - (gc_spill_offset + 4 * (1 + i))
d1016 1
a1016 1
		       frame_size - 4 - (non_gc_spill_offset + 4 * (1 + offset + i))
d1041 1
a1041 1
		       frame_size - 4 - (fp_spill_offset + float_value_size * (1 + i) +
d1059 2
a1060 16
	if size = 0 then
	  (I386_Assembly.OPCODE
	   (I386_Assembly.xor,
	    [I386_Assembly.r32 I386Types.global,
	     I386_Assembly.r_m32(Option.SOME1 I386Types.global)]),
	   absent, "clear global prior to storing") ::
	  (I386_Assembly.OPCODE
	   (I386_Assembly.mov,
	    [I386_Assembly.r32 I386Types.global,
	     I386_Assembly.r_m32
	     (Option.SOME2
	      (I386_Assembly.MEM
	       {base=Option.PRESENT I386Types.sp,
		index=absent,
		offset=absent}))]),
	   absent, "initialise final store") :: so_far
d1062 28
a1089 11
	  store_seq(size-1,
		    (I386_Assembly.OPCODE
		     (I386_Assembly.mov,
		      [I386_Assembly.r32 I386Types.global,
		       I386_Assembly.r_m32
		       (Option.SOME2
			(I386_Assembly.MEM
			 {base=Option.PRESENT I386Types.sp,
			  index=absent,
			  offset=Option.PRESENT(~(size*4))}))]),
		     absent, "initialise final store") :: so_far)
d1100 1
a1100 1
	       offset=Option.PRESENT(size*4)}))]),
d1125 1
a1125 1
	  (I386_Assembly.jcc(I386_Assembly.not_equal), [I386_Assembly.rel32 0]),
d1154 1
a1154 2
	  val frame_size = register_save_offset + register_save_size
	  val non_save_frame_size = register_save_offset
d3128 1
a3128 1
			    frame_size + stack_drop - 4 + Tags.PAIRPTR -
d3133 1
d3584 24
d3611 1
a3611 10
				absent, "negate size computed earlier") ::
			       (I386_Assembly.OPCODE
				(I386_Assembly.add,
				 [rd_operand, I386_Assembly.r32 I386Types.global]),
				absent, "add in pointer") ::
			       (I386_Assembly.OPCODE
				(I386_Assembly.add,
				 [rd_operand, I386_Assembly.imm8 primary]),
				absent, "add in primary tag") ::
			       tag2_jmp
d3623 1
a3623 1
				     val (pointer, index, needs_push) =
d3625 1
a3625 1
					 (I386Types.EAX, I386Types.global, true)
d3628 1
a3628 1
					   (rd, I386Types.global, false)
d3630 1
a3630 1
					   (rd, I386Types.global, false)
d3633 1
a3633 1
				       if needs_push then
d3660 20
a3679 12
					 (I386_Assembly.OPCODE
					  (I386_Assembly.mov,
					   [I386_Assembly.r32 index,
					    I386_Assembly.r_m32
					    (Option.SOME2
					     (I386_Assembly.MEM
					      {base=Option.PRESENT I386Types.sp,
					       index=absent,
					       offset=Option.PRESENT
					       (gp_spill_value gp_operand)}))]),
					  absent, "get pointer to new store") ::
					 initialise_last
d3686 1
a3686 1
					  absent, "get offset in new store") ::
d3992 1
a3992 1
			    (store_seq(gc_stack_slots,
a4033 221
(*
		      let
			val gc_stack_slots =
			  (if stack_need_init then
			    gc_stack_alloc_size
			  else
			    0) +
			     (if spills_need_init then
				gc_spill_size
			      else
				0)
			val top_tag = MirTypes.new_tag()
			val end_tag = MirTypes.new_tag()
			val clean_start =
			  if stack_need_init then
			    register_save_size
			  else
			    register_save_size + 4 * gc_stack_alloc_size
			val (clean_stack, opcodes, block) =
			  if gc_stack_slots <= 10 then
			    if gc_stack_slots = 0 then
			      (false,
			       [(I386_Assembly.BRANCH_ANNUL
				 (I386_Assembly.BA, 0),
				 Option.PRESENT end_tag,
				 "Finish cleaning stack"),
				I386_Assembly.nop],
			       (* The linearisation process will remove *)
			       (* this irrelevant block *)
			       (top_tag, []))
			    else
			      (false,
			       n_stores(clean_start, gc_stack_slots, end_tag),
			       (top_tag, []))
			  else
			    let
			      val branch_out =
				[(I386_Assembly.BRANCH_ANNUL
				  (I386_Assembly.BA, 0),
				  Option.PRESENT top_tag,
				  "")]
			      val (clean_start, extra) =
				if clean_start mod 8 = 4 then
				  (clean_start - 4, 4)
				  (* Start one earlier if not aligned *)
				else
				  (clean_start, 0)
			      val load_limit =
				let
				  val the_limit =
				    let
				      val gc_stack_size =
					4 * gc_stack_slots + extra
				    in
				      if gc_stack_size mod 8 = 0 then
					gc_stack_size
				      else
					gc_stack_size+4
				    end
(* If not 0 mod 8, we just uselessly initialise an fp or non_gc slot *)
				in
				  if check_range(the_limit, true,
						 arith_imm_limit) then
				    move_imm(I386Types.global,
					     the_limit) :: branch_out
				  else
				    load_large_number_into_register
				    (I386Types.global, MirTypes.GP_IMM_ANY the_limit) @@
				    branch_out
				end
			      val load_start =
				(I386_Assembly.ARITHMETIC_AND_LOGICAL
				 (I386_Assembly.ADD, I386Types.I2,
				  I386_Assembly.IMM clean_start,
				  I386Types.sp), absent,
				 "") ::
				load_limit
			      val store_loop =
				[(I386_Assembly.ARITHMETIC_AND_LOGICAL
				  (I386_Assembly.SUBCC, I386Types.global,
				   I386_Assembly.IMM 8,
				   I386Types.global),
				  absent, "Update counter"),
				 (I386_Assembly.BRANCH_ANNUL
				  (I386_Assembly.BGE, 0),
				  Option.PRESENT top_tag,
				  "Branch if not finished"),
				 (I386_Assembly.LOAD_AND_STORE
				  (I386_Assembly.STD, I386Types.G0,
				   I386Types.global,
				   I386_Assembly.REG I386Types.I2),
				  absent,
				  "Initialise a stack slot (delay slot)"),
				 (I386_Assembly.BRANCH_ANNUL
				  (I386_Assembly.BA, 0),
				  Option.PRESENT end_tag, ""),
				 I386_Assembly.nop]
			    in
			      (true, load_start, (top_tag, store_loop))
			    end
			val (opcode_list, block_list, final_result) =
			  if clean_stack then
			    ([],
			     (MirTypes.BLOCK(end_tag, opcode_list)) ::
			     block_list,
			     block :: final_result)
			  else (opcode_list, block_list, final_result)

			val ov_tag = MirTypes.new_tag()  (* Overflow case *)
			val non_ov_tag = MirTypes.new_tag()
			(* Non overflow case *)

			val join_tag = MirTypes.new_tag()
			val final_result = (join_tag, opcodes) :: final_result
			val immediate_size =
			  check_range(frame_size, true, arith_imm_limit)
			val test_opcodes =
			  [(I386_Assembly.BRANCH_ANNUL
			    (I386_Assembly.BLEU, 0),
			    Option.PRESENT non_ov_tag,
			    "Unsigned stack overflow test"),
			   I386_Assembly.nop,
			   (I386_Assembly.BRANCH_ANNUL
			    (I386_Assembly.BA, 0),
			    Option.PRESENT ov_tag, ""),
			   I386_Assembly.nop]
			val check_and_test_opcodes =
			  if non_save_frame_size = 0 then
			    (I386_Assembly.ARITHMETIC_AND_LOGICAL
			     (I386_Assembly.SUBCC, I386Types.G0,
			      I386_Assembly.REG(I386Types.sp), I386Types.stack_limit),
			     absent,
			     "Compare the required stack size with the calculated") ::
			    test_opcodes
			  else
			    (I386_Assembly.ARITHMETIC_AND_LOGICAL
			     (I386_Assembly.SUB, I386Types.global,
			      if immediate_size then
				I386_Assembly.IMM frame_size
			      else
				I386_Assembly.REG I386Types.O3,
				I386Types.sp),
			     absent, "Check the stack for underflow") ::
			    (I386_Assembly.ARITHMETIC_AND_LOGICAL
			     (I386_Assembly.SUBCC, I386Types.G0,
			      I386_Assembly.REG(I386Types.global),
			      I386Types.stack_limit),
			     absent,
			     "Compare the required stack size with the calculated") ::
			    test_opcodes
			val check_for_stack_overflow_wrap =
			  if immediate_size then
			    check_and_test_opcodes
			  else
			    load_large_number_into_register
			    (I386Types.O3, MirTypes.GP_IMM_ANY frame_size) @@
			    check_and_test_opcodes
			val post_ov_code =
			  [(I386_Assembly.BRANCH_ANNUL
			    (I386_Assembly.BA, 0),
			    Option.PRESENT non_ov_tag, ""),
			   I386_Assembly.nop]
			val post_ov_code =
			  if immediate_size then
			    post_ov_code
			  else
			    load_large_number_into_register
			    (I386Types.O3, MirTypes.GP_IMM_ANY frame_size) @@
			    post_ov_code
			val post_ov_code =
			     (I386_Assembly.LOAD_AND_STORE
			      (I386_Assembly.LD, I386Types.global,
			       I386Types.implicit,
			       I386_Assembly.IMM (4 * Implicit_Vector.extend)),
			      absent, "Get address of stack_overflow") ::
			     (I386_Assembly.JUMP_AND_LINK
			      (I386_Assembly.JMPL, I386Types.O4,
			       I386_Assembly.IMM 0, I386Types.global,
			       Debugger_Types.null_backend_annotation),
			      absent, "Do stack_overflow") ::
			     I386_Assembly.nop ::
			     post_ov_code
			val ov_tag_code =
			  if immediate_size then
			    (I386_Assembly.ARITHMETIC_AND_LOGICAL
			     (I386_Assembly.OR, I386Types.O3,
			      I386_Assembly.IMM frame_size, I386Types.G0),
			     absent, "Set the required size in O3") :: post_ov_code
			  else
			    post_ov_code
		      in
			(check_for_stack_overflow_wrap,
			 [],
			 (case opcode_list of
			    [] => block_list
			  | _ =>
			      MirTypes.BLOCK(end_tag,opcode_list) ::
			      block_list),
			    (non_ov_tag,
			     (if immediate_size
				then []
			      else
				[(I386_Assembly.ARITHMETIC_AND_LOGICAL
				  (I386_Assembly.SUB, I386Types.O3,
				   I386_Assembly.REG(I386Types.O3), I386Types.G0),
				  absent, "Negate the frame size")]) @@
				((I386_Assembly.SAVE_AND_RESTORE
				  (I386_Assembly.SAVE, I386Types.sp,
				   if immediate_size
				     then I386_Assembly.IMM(~frame_size)
				   else I386_Assembly.REG I386Types.O3,
				     I386Types.sp), absent, "New frame") ::
				(save_fps @@
				 [(I386_Assembly.BRANCH_ANNUL
				   (I386_Assembly.BA, 0),
				   Option.PRESENT join_tag, ""),
				  I386_Assembly.nop]))) ::
			    (ov_tag,ov_tag_code)  ::
			    final_result)
		      end
*)
d4137 1
a4137 1
				offset=Option.PRESENT(reg_spill_value frame)}))]),
d4185 1
a4185 1
		      val arg =
d4190 5
a4194 5
			    Option.SOME2
			    (I386_Assembly.MEM
			     {base=Option.PRESENT I386Types.sp,
			      index=absent,
			      offset=Option.PRESENT spill})
d4197 8
a4204 1
			  Option.SOME1(lookup_reg_operand reg)
a4206 5
			  (I386_Assembly.mov,
			   [I386_Assembly.r32 I386Types.caller_arg,
			    I386_Assembly.r_m32 arg]),
			  absent, "get raise argument"),
			 (I386_Assembly.OPCODE
d4215 9
d4465 3
a4467 1
            | check_instr (MirTypes.STACKOP _) = true
a4671 1
	  val frame_offset = 4 (* Leave room for return address on stack *)
d4680 1
d4688 2
a4689 2
	     register_save_size = 4 * (linkage_size + callee_save_area),
	     non_gc_spill_offset = 0,
d4700 1
d4705 3
a4707 3
	  val _ = output(std_out, "stack_extra = " ^ MLWorks.Integer.makestring stack_extra ^ "\n")
	  val _ = output(std_out, "register_save_size = " ^ MLWorks.Integer.makestring 64 ^ "\n")
	  val _ = output(std_out, "non_gc_spill_offset = " ^ MLWorks.Integer.makestring 0 ^ "\n")
a4714 87
(*
	  val block_tree =
	    Lists.reducel
	    (fn (map, MirTypes.BLOCK x) => MirTypes.Map.define'(map, x))
	    (MirTypes.Map.empty, block_list)

	  val spill_array = Array.array(gc_spill_size, true)
	  val stack_array = Array.array(stack_extra, true)

	  fun ok_store MirTypes.ST = true
	    | ok_store MirTypes.STREF = true
	    | ok_store _ = false

	  fun analyse_instr(_, MirTypes.TBINARY _) = ([], true)
	    | analyse_instr(_, MirTypes.TBINARYFP _) = ([], true)
	    | analyse_instr(_, MirTypes.TUNARYFP _) = ([], true)
	    | analyse_instr(_, MirTypes.REAL _) = ([], true)
	    | analyse_instr(_, MirTypes.FLOOR _) = ([], true)
	    | analyse_instr(_, MirTypes.BRANCH_AND_LINK _) = ([], true)
	    | analyse_instr(_, MirTypes.TAIL_CALL _) = ([], true)
	    | analyse_instr(_, MirTypes.CALL_C) = ([], true)
	    | analyse_instr(_, MirTypes.SWITCH _) = ([], true)
	    | analyse_instr(_, MirTypes.RAISE _) = ([], true)
	    | analyse_instr(_, MirTypes.INTERCEPT) = ([], true)
	    | analyse_instr(_, MirTypes.INTERRUPT) = ([], true)
	    | analyse_instr(_, MirTypes.BRANCH _) = ([], true)
	    | analyse_instr(_, MirTypes.TEST _) = ([], true)
	    | analyse_instr(_, MirTypes.FTEST _) = ([], true)
	    | analyse_instr(_, MirTypes.ALLOCATE _) = ([], true)
	    | analyse_instr(a as (list, x),
			    MirTypes.ALLOCATE_STACK(MirTypes.ALLOC, r, size, offset)) =
	      if x then a else
		let
		  val offset = case offset of
		    Option.PRESENT x => x
		  | _ => Crash.impossible"offset missing from stack allocation"
		in
		  ((r, stack_extra - offset - size) :: list, false)
		end

	    | analyse_instr(a as (list, x), MirTypes.STOREOP(store, _, r2, g)) =
	      if x orelse not(ok_store store) then a else
		(case g of
		   MirTypes.GP_IMM_SYMB symb =>
		     (case symb of
			MirTypes.GC_SPILL_SLOT _ =>
			  let
			    val offset = symb_value stack_layout symb
			    val i = gc_spill_size + (offset + gc_spill_offset) div 4
			    (* Offset in words from top of the relevant region *)
			    val _ = Array.update(spill_array, gc_spill_size -1 - i, false)
			  in
			    a
			  end
		      | _ => a)
		 | MirTypes.GP_IMM_ANY i =>
		     (let
		       val start = Lists.assoc(r2, list)
		       val offset = (i + 1) div 4
		       val _ = Array.update(stack_array, offset+start, false)
		      in
			a
		      end
			handle Lists.Assoc => a)
		 | _ => a)
	    | analyse_instr(x, _) = x

	  fun analyse_block block_tag =
	    let
	      val instrs = MirTypes.Map.tryApply'(block_tree, block_tag)
	    in
	      case instrs of
		MLWorks.Option.SOME instrs =>
		  Lists.reducel analyse_instr (([], false), instrs)
	      | _ => ([], false)
	    end

	  val _ = analyse_block proc_tag

	  fun needs_init(a, b) = a orelse b

	  val spills_need_init =
	    MLWorks.ExtendedArray.reducel needs_init (false, spill_array)

	  val stack_need_init =
	    MLWorks.ExtendedArray.reducel needs_init (false, stack_array)
*)
@


1.10
log
@Get offsets right in stack allocations
@
text
@d4 3
d438 1
a438 1
			    Map.NO => true
d475 1
a475 1
		Map.YES(_, t) => t
d612 1
a612 1
			 Map.YES res =>
d620 1
a620 1
		       | Map.NO =>
d629 1
a629 1
			   Map.YES res =>
d637 1
a637 1
			 | Map.NO =>
d645 1
a645 1
			   Map.YES res =>
d653 1
a653 1
			 | Map.NO =>
d661 1
a661 1
			   Map.YES res =>
d679 1
a679 1
			 | Map.NO => Crash.impossible "Assoc do_opcode: LEO")
d685 1
a685 1
			   Map.YES res =>
d693 1
a693 1
			 | Map.NO =>
d698 1
a698 1
			   Map.YES res =>
d706 1
a706 1
			 | Map.NO =>
d713 1
a713 1
			   Map.YES res =>
d753 1
a753 1
			 | Map.NO =>
d760 1
a760 1
			   Map.YES res =>
d771 1
a771 1
			 | Map.NO =>
d776 1
a776 1
			   Map.YES res =>
d794 1
a794 1
			 | Map.NO =>
d800 1
a800 1
			   Map.YES res =>
d809 1
a809 1
			 | Map.NO =>
d2388 1
a2388 1
			   offset=Option.PRESENT(assemble_large_offset gp_operand)}
d2391 1
a2391 1
			   index=Option.ABSENT,
d2420 35
a2454 10
		      let
			val operands =
			  [I386_Assembly.r_m8 r_m,
			   I386_Assembly.r8(I386Types.byte_reg_name I386Types.global)]
		      in
			([move_reg(I386Types.global, rd, "can't store byte from " ^
				   I386Types.reg_to_string rd),
			  (I386_Assembly.OPCODE(store_instr, operands), absent, "")],
			 opcode_list, block_list, final_result, stack_drop)
		      end
d3233 3
a3235 2
			       [(I386_Assembly.OPCODE
				 (I386_Assembly.add,
d3241 42
a3282 7
				      offset=Option.PRESENT(4*Implicit_Vector.gc_base)})),
				   if bytes <= 127 then
				     I386_Assembly.imm8 bytes
				   else
				     I386_Assembly.imm32(bytes div 4, bytes mod 4)]),
				 absent,
				 "increment base pointer"),
d3293 1
a3293 1
				"acquire base pointer for result"),
d3304 1
a3304 15
				"check for run out of store"),
			       (I386_Assembly.OPCODE
				(I386_Assembly.jcc I386_Assembly.below,
				 [I386_Assembly.rel32 0]), Option.PRESENT tag1,
				"branch if not run out of heap"),
			       move_imm(I386Types.global, bytes, "amount requested"),
			       (I386_Assembly.OPCODE
				(I386_Assembly.call,
				 [I386_Assembly.r_m32
				  (Option.SOME2
				   (I386_Assembly.MEM
				    {base=Option.PRESENT I386Types.implicit,
				     index=absent,
				     offset=Option.PRESENT gc_entry}))]),
				absent, "call the gc"),
d3311 1
a3311 1
				    {base=Option.PRESENT I386Types.global,
d3313 2
a3314 2
				     offset=Option.PRESENT primary}))]),
				absent, "produce the answer"),
d3316 4
a3319 4
				(I386_Assembly.jmp,
				 [I386_Assembly.rel32 0]),
				Option.PRESENT tag2,
				"branch to continuation sequence")]
d3341 1
a3341 1
			      (tag1, opcodes2) :: (tag2, opcodes3) :: final_result,
d4508 1
a4508 1
	      MirTypes.FP.Map.NO => MirTypes.FP.Map.define(map, fp, true)
d4536 1
a4536 1
	       MirTypes.GC.Map.NO => MirTypes.GC.Map.define(map, r, true)
d4542 1
a4542 1
	       MirTypes.GC.Map.NO => MirTypes.GC.Map.define(map, r, true)
d4609 1
a4609 1
	       MirTypes.FP.Map.YES x => x :: acc
d4617 1
a4617 1
	       MirTypes.GC.Map.YES x => x :: acc
d4666 1
a4666 1
	      MirTypes.GC.Map.YES x => check_reg x
d4671 1
a4671 1
	      MirTypes.NonGC.Map.YES x => check_reg x
d4784 1
a4784 1
                 NewMap.YES((a, b, c),_, is_exn) =>
d4961 1
a4961 1
		MirTypes.Map.YES instrs =>
d5187 1
a5187 1
				 NewMap.YES((ty,leaf,annotations),runtime_env) =>
@


1.9
log
@Fix various bugs, particularly in gc sequences
@
text
@d4 3
d8 1
a8 1
Get branch offsets right for corss procedure calls and tails
d1202 6
a1207 5
	  fun do_save_gcs [] = []
	    | do_save_gcs(gc :: rest) =
		  (I386_Assembly.OPCODE
		   (I386_Assembly.push, [I386_Assembly.r32 gc]), Option.ABSENT,
		   "save gcs") :: do_save_gcs rest
d1209 1
a1209 1
	  fun do_restore_gcs([], done) = done
d1216 1
d1218 1
d3091 1
a3091 1
			    frame_size + Tags.PAIRPTR -
d3094 2
d4752 1
a4752 2
	  fun compare_reg(r, s) =
	    I386Types.register_value r < I386Types.register_value s
d4955 2
a4956 1
	   not needs_preserve)
d5109 1
a5109 1
	     (fn ((tag, code),(_,spills,_,padded_name,_)) =>
d5112 1
a5112 1
		 c_saves=0,
@


1.8
log
@Get branch offsets right for corss procedure calls and tails
@
text
@d4 3
a118 8
(*
  val arith_imm_limit = 4096 (* 2 ** 12 *)
  val branch_disp_limit = 512 * 4096 (* 2 ** 21 *)
  val call_disp_limit = 16 * 256 * 256 * 256 (* 2 ** 28 *)
  (* Note that this has been reduced in order to stay positive within *)
  (* our system, which allows30 bit signed integers *)
*)

d291 2
d657 9
d827 3
a829 5
		  offset' + 4 (* Back-pointer *) + 4 (* Procedure number within set *)
		val offset''' =
		  if offset'' mod 8 = 4
		    then offset'' + 4
		  else offset''
d831 1
a831 1
		(tag, done') :: do_linearise_sub(offset''', rest)
d1045 68
a1112 50
      fun do_store(_, _, 0, done) = done
(*
	| do_store(reg, offset, 1, done) =
	  (I386_Assembly.LOAD_AND_STORE
	   (I386_Assembly.ST, I386Types.G0,
	    reg,
	    I386_Assembly.IMM offset), absent,
	   "Initialise a stack slot") :: done
	| do_store(reg, offset, n, done) =
	  if n < 0 then Crash.impossible"Do_store"
	  else
	    if offset mod 8 = 4 then
	      do_store(reg, offset+4, n-1,
		     (I386_Assembly.LOAD_AND_STORE
		      (I386_Assembly.ST, I386Types.G0,
		       reg,
		       I386_Assembly.IMM offset), absent,
		      "Initialise one misaligned stack slot") :: done)
	    else
	      do_store(reg, offset+8, n-2,
		       (I386_Assembly.LOAD_AND_STORE
			(I386_Assembly.STD, I386Types.G0,
			 reg,
			 I386_Assembly.IMM offset), absent,
			"Initialise two stack slots") :: done)
*)
	| do_store _ = Crash.unimplemented"do_store"

      (* revised version of n_stores running off sp *)
      fun n_stores(from, no_of_stores, end_tag) =
(*
	let
	  val end_limit = from + (no_of_stores-1)*4
	  val end_instrs =
	    [(I386_Assembly.BRANCH_ANNUL
	      (I386_Assembly.BA, 0),
	      Option.PRESENT end_tag,
	      "Finish cleaning stack"),
	     I386_Assembly.nop]
	in
	  if check_range(end_limit, true,
			 arith_imm_limit) then
	    do_store(I386Types.sp, from, no_of_stores, end_instrs)
	  else
	    Crash.impossible
	    ("n_stores end_limit = " ^
	     MLWorks.Integer.makestring end_limit)
	end
*)
	Crash.unimplemented"n_stores"
d1562 1
d1566 1
d1572 2
a1573 1
				val last =
d1582 1
d1650 1
d1654 1
d1656 1
d1664 1
d1849 9
a1857 9
			((*output(std_out, "Handling two spill move\n");*)
			
			 ([], MirTypes.UNARY(MirTypes.MOVE,
					     MirTypes.GC_REG MirRegisters.global,
					     gp_operand) ::
			  MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					 MirTypes.GP_GC_REG MirRegisters.global) ::
			  opcode_list, block_list, final_result, stack_drop)
			 )
a1861 4
(*
			    val _ =
			      output(std_out, "Generating move to spill\n")
*)
d2103 1
a2103 1
		  ([(I386_Assembly.OPCODE(I386_Assembly.nop, []), absent,
d2144 1
a2144 1
		  ([(I386_Assembly.OPCODE(I386_Assembly.nop, []), absent,
d2424 1
a2424 1
		  ([(I386_Assembly.OPCODE(I386_Assembly.nop, []), absent,
d2532 1
a2532 1
		    ([(I386_Assembly.OPCODE(I386_Assembly.nop, []), absent,
d2578 1
a2578 1
		  ([(I386_Assembly.OPCODE(I386_Assembly.nop, []), absent,
d2836 1
a2836 1
		    ([(I386_Assembly.OPCODE(I386_Assembly.nop, []), absent,
d2913 1
a2913 1
			      absent, "branch relative(tail call)")]
d2924 1
a2924 1
				 [I386_Assembly.r32 I386Types.sp,
d2949 99
a3047 49
		    Crash.impossible"do_everything:MirTypes.SWITCH"
(*
		    ((if Lists.length tag_list <= 2 then
			let
			  val reg = lookup_reg_operand reg_operand
			  val (numbered_tag_list, _) =
			    Lists.number_from(tag_list, 0, 4, fn x=> x)
			  fun do_tests(done, []) = rev done
			  | do_tests(done, (tag, imm) :: (rest as _ :: _)) =
			    do_tests((I386_Assembly.BRANCH
				      (I386_Assembly.BE, 0),
				      Option.PRESENT tag, "Do the branch") ::
				     (I386_Assembly.ARITHMETIC_AND_LOGICAL
				      (I386_Assembly.SUBCC, I386Types.G0,
				       I386_Assembly.IMM imm, reg),
				      absent, "Do the test") :: done, rest)
			  | do_tests(done, (tag, imm) :: rest) =
			    do_tests((I386_Assembly.BRANCH_ANNUL
				      (I386_Assembly.BA, 0),
				      Option.PRESENT tag, "Do the branch") ::
				     (I386_Assembly.nop_code, absent,
				      "No test required in final case") ::
				     done, rest)
			in
			  do_tests([], numbered_tag_list)
			end
		      else
			(I386_Assembly.Call
			 (I386_Assembly.CALL, 2),
			 absent, "Call self") ::
			(I386_Assembly.ARITHMETIC_AND_LOGICAL
			 (I386_Assembly.ADD, I386Types.lr,
			  I386_Assembly.IMM(4*4),
			  I386Types.lr), absent,
			 "Offset to start of table") ::
			(I386_Assembly.JUMP_AND_LINK
			 (I386_Assembly.JMPL, I386Types.G0,
			  I386_Assembly.REG I386Types.lr,
			  lookup_reg_operand reg_operand,
                          Debugger_Types.null_backend_annotation), absent,
			 "Branch into table") ::
			I386_Assembly.nop ::
			map
			(fn tag =>
			 (I386_Assembly.BRANCH_ANNUL
			  (I386_Assembly.BA, 0), Option.PRESENT tag, ""))
			tag_list),
			opcode_list, block_list, final_result)
*)
d3059 1
a3059 2
					 gc_stack_alloc_size ^
					 "\n")
d3074 10
d3125 1
d3157 1
a3157 1
				 Option.PRESENT tag2, "jump to rest of code")]
d3187 1
a3187 1
			     val (decrement_imm, dec_imm_size) =
d3192 1
a3192 1
				   (I386_Assembly.imm8 size, 3+3)
d3194 1
a3194 1
				   (I386_Assembly.imm32(size div 4, size mod 4), 3+6)
d3259 2
a3260 2
				 [I386_Assembly.rel32 dec_imm_size]),
				Option.PRESENT tag1,
d3263 11
a3273 6
			       (I386_Assembly.OPCODE
				(I386_Assembly.sub,
				 [I386_Assembly.r_m32(Option.SOME1 rd),
				  decrement_imm]),
				absent, "tag pointer correctly") ::
			       header_code
d3282 3
a3284 2
			     (opcodes1, [], MirTypes.BLOCK(tag2, opcode_list) :: block_list,
			      (tag1, opcodes2) :: final_result, stack_drop)
d3295 7
a3301 10
(*
			     val _ =
			       output(std_out, "handling variable sized alloc, size in " ^
				      (if size_is_spill then "spill" else "reg") ^
				      ", dest in " ^
				      (if needs_temp then "spill" else "register") ^ "\n")
*)
			     val rd_operand =
			       I386_Assembly.r_m32
			       (if needs_temp then
d3306 4
a3309 2
				    offset=Option.PRESENT(reg_spill_value reg_operand)})
				else
d3311 3
d3337 1
a3337 1
					 (I386_Assembly.add,
d3340 1
a3340 1
					 absent, "add in requested length"),
d3429 1
a3429 1
				 [I386_Assembly.rel32 0]), Option.PRESENT tag2,
a3528 1
			     val tag3 = MirTypes.new_tag()
d3532 4
a3535 1
				 absent, "branch to rest of code")]
d3547 1
a3547 1
					   (rd, lookup_gp_operand gp_operand, false)
d3560 5
d3590 6
d3616 1
a3616 1
					   [I386_Assembly.r32 pointer, rd_operand]),
d3660 1
a3660 1
					     [I386_Assembly.r32 pointer, rd_operand]),
d3795 1
d3804 2
a3805 1
			(* No stack checking yet *)
d3810 1
d3893 1
a3893 1
				"leave space on stack (no initialisation/stack overflow check yet)")]
d3898 11
d3938 2
a3939 1
			 (post_overflow_tag, make_stack @@ save_gcs @@ opcodes) ::
d4790 2
a4791 1
	  val fp_spill_offset = non_gc_spill_size * 4
d4793 1
a4793 1
	  val gc_spill_offset  = non_gc_stack_size
d4832 1
d4918 1
d4924 2
a4925 2
				     spills_need_init,
				     stack_need_init,
d5098 1
a5098 1
		
@


1.7
log
@Sort out load/store code
Fix minor problems in tail
@
text
@d4 4
d493 2
d506 2
a507 5
	  next_offset + 4 (* Back-pointer *) + 4 (* Procedure number within set *)
	val next_offset'' =
	  if next_offset' mod 8 = 4
	    then next_offset'+4
	  else next_offset'
d509 1
a509 1
	tag_offsets_for_list(next_offset'', rest, env)
d2871 1
a2871 1
				 [I386_Assembly.r32(Option.SOME1 I386Types.global),
d5024 3
d5028 4
a5031 3
                     if size code mod 8 = 4
                       then code ^ nop_instruction
                     else code
@


1.6
log
@Do more opcodes
@
text
@d4 3
d2248 2
a2249 2
					   MirTypes.GC_REG MirRegisters.global,
					   gp_from_reg reg_operand) ::
d2866 14
a2879 4
			      (I386_Assembly.OPCODE
			       (I386_Assembly.jmp,
				[I386_Assembly.r_m32(Option.SOME1(lookup_reg_operand reg))]),
			       absent, "branch indirect(tail call)")
d2881 4
a2884 4
			    (I386_Assembly.OPCODE
			     (I386_Assembly.jmp,
			      [I386_Assembly.rel32 0]),
			     absent, "branch relative(tail call)")
d2891 1
a2891 1
			       [jump]
d2902 1
a2902 1
			       [jump]
d2916 1
a2916 1
			 [jump],
@


1.5
log
@Add stack initialisation and overflow checking, and variable size allocation
Stack initialisation not in yet
@
text
@d4 4
d36 1
d57 1
d66 1
a66 1
  sharing MirTables.MirTypes = MirRegisters.MirTypes
d109 1
d115 3
d647 3
a649 3
		
(*
				  ((I386_Assembly.BRANCH(branch, i),
a650 14
		      (case lookup_env tag of
			 Map.YES res =>
			   let
			     val disp =
			       fault_range(( res - offset) div 4,
					   true, branch_disp_limit)
			   in
			     (I386_Assembly.BRANCH(branch, disp), comment)
			   end
		       | Map.NO =>
			   Crash.impossible"Assoc do_opcode branch")

		      | do_opcode((I386_Assembly.BRANCH_ANNUL(branch, i),
			       Option.PRESENT tag, comment), offset) =
d654 2
a655 3
			       val disp =
				 fault_range((res - offset) div 4,
					     true, branch_disp_limit)
d657 3
a659 1
                           (I386_Assembly.BRANCH_ANNUL(branch, disp), comment)
d661 3
a663 2
			 | Map.NO =>
			     (Crash.impossible"Assoc do_opcode branch_annul"))
a689 48
		      | do_opcode((I386_Assembly.Call(I386_Assembly.CALL, i),
				   Option.PRESENT tag, comment), offset) =
			(case lookup_env tag of
			   Map.YES res =>
			     let
			       val disp =
				 fault_range(( res + i - offset) div 4,
					     true, call_disp_limit)
			     in
			       (I386_Assembly.Call(I386_Assembly.CALL, disp), comment)
			     end
			 | Map.NO => Crash.impossible "Assoc do_opcode Call")
		      | do_opcode((I386_Assembly.LOAD_OFFSET(I386_Assembly.LEO, rd, i),
				   Option.PRESENT tag, comment), offset) =
			(* This will probably suffer the same problems as adr did *)
			(case lookup_env tag of
			   Map.YES res =>
			     let
			       val disp = (res + i) - proc_offset
			     (* Must work relative to start of current proc in set *)
			     in
			       if check_range(disp, true, arith_imm_limit) then
				 (I386_Assembly.ARITHMETIC_AND_LOGICAL
				  (I386_Assembly.OR, rd, I386_Assembly.IMM disp, I386Types.G0),
				  comment)
			       else
				 let
				   val _ =
				     diagnostic_output 3
				     (fn _ => ["Found bad LEO, substituting\n"])
				   val head_size = (offset - block_start) div 4
				   val tail = drop(1 + head_size, opcode_list)
				   (* get the opcodes after this one *)
				   val new_comment = comment ^ " (expanded adr)"
				   val new_tail =
				     (I386_Assembly.SPECIAL_LOAD_OFFSET
				      (I386_Assembly.LOAD_OFFSET_HIGH, rd, I386Types.G0, i),
				      Option.PRESENT tag, new_comment) ::
				     (I386_Assembly.SPECIAL_LOAD_OFFSET
				      (I386_Assembly.LOAD_OFFSET_AND_MASK, rd, rd, i),
				      Option.PRESENT tag, new_comment) :: tail
				 in
				   raise bad_offset
				     (block_tag,
				      copy_n(head_size, opcode_list, [], new_tail))
				 end
			     end
			 | Map.NO => Crash.impossible "Assoc do_opcode LEO")
d934 2
d963 1
a963 1
		     Crash.impossible
d969 1
a969 1
		     frame_size - (gc_spill_offset + 4 * (1 + i))
d993 1
a993 1
		       frame_size - (non_gc_spill_offset + 4 * (1 + offset + i))
d1012 1
a1012 1
		       ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
d1018 1
a1018 1
		       frame_size - (fp_spill_offset + float_value_size * (1 + i) +
d1289 1
a1289 1
		 (MirTypes.SIMPLE(#gc(MirRegisters.pack_next) - MirTypes.GC.unpack reg)))
d1295 1
a1295 1
		 (MirTypes.SIMPLE(#gc(MirRegisters.pack_next) - MirTypes.GC.unpack reg)))
d1301 1
a1301 1
		 (MirTypes.SIMPLE(#fp(MirRegisters.pack_next) - MirTypes.FP.unpack reg)))
d1313 1
a1313 1
		case opcode of
d1408 60
a1467 1
		      Crash.unimplemented"BINARY:reg_operand = gp_operand'"
d1507 180
a1686 2
			Crash.unimplemented"BINARY:shift or BIC"
		      (* Nasty, all shifts controlled by CL, part of ECX *)
d1766 35
a1800 1
		      Crash.unimplemented"BINARY:reg_operand = gp_operand'"
d1933 48
a1980 16
		  | MirTypes.UNARY(MirTypes.NOT, reg_operand, gp_operand) =>
		      Crash.impossible"do_everything:MirTypes.UNARY"
(*
		    let
		      val rd = lookup_reg_operand reg_operand
		      val opcode = I386_Assembly.XORN
		      val simple_imm = I386_Assembly.IMM 3
		    in
		      if is_reg gp_operand then
			let
			  val rs1 = lookup_gp_operand gp_operand
			in
			  ([(I386_Assembly.ARITHMETIC_AND_LOGICAL
			     (opcode, rd, simple_imm, rs1), absent, "")],
			   opcode_list, block_list, final_result)
			end
d1982 7
a1988 14
			([], MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					    gp_operand) :: opcode_list,
			 block_list, final_result)
		    end
*)
		| MirTypes.NULLARY(MirTypes.CLEAN, reg_operand) =>
		    Crash.impossible"do_everything:MirTypes.NULLARY"
(*
                    ([(I386_Assembly.ARITHMETIC_AND_LOGICAL
                       (I386_Assembly.OR, lookup_reg_operand reg_operand,
                        I386_Assembly.REG I386Types.G0, I386Types.G0),
                       absent, "Clean")],
                    opcode_list, block_list, final_result)
*)
d2071 3
a2073 1
		  Crash.impossible"do_everything:MirTypes.TBINARYFP"
d2112 3
a2114 1
		  Crash.impossible"do_everything:MirTypes.TUNARYFP"
d2500 3
a2502 1
		    Crash.impossible"do_everything:MirTypes.REAL"
d2546 3
a2548 1
		    Crash.impossible"do_everything:MirTypes.FLOOR"
d2804 3
a2806 1
		  Crash.impossible"do_everything:MirTypes.FTEST"
d2875 1
a2875 5
			   val frame_left =
			     frame_size -
			     4(* return address *) -
			     8(* fp and callee_closure *) -
			     gc_preserve_size
d2958 44
a3001 23
		  Crash.impossible"do_everything:MirTypes.ALLOCATE_STACK"
(*
		  (if alloc_size + fp_offset > gc_stack_alloc_size then
		     Crash.impossible("Stack allocation of " ^
				      MLWorks.Integer.makestring alloc_size ^
				      " at offset " ^
				      MLWorks.Integer.makestring fp_offset ^
				      " requested, in total area of only " ^
				      MLWorks.Integer.makestring
				      gc_stack_alloc_size ^
				      "\n")
		   else();
		   case allocate of
		     MirTypes.ALLOC =>
		       ([],
			MirTypes.BINARY(MirTypes.SUB, reg_operand,
					MirTypes.GP_GC_REG MirRegisters.fp,
					MirTypes.GP_IMM_ANY
					(gc_stack_alloc_offset +
					 4 * (fp_offset + alloc_size) - Tags.PAIRPTR)) ::
			(* Note tagging on pointer *)
			opcode_list, block_list, final_result)
		   | _ => Crash.impossible"ALLOCATE_STACK strange allocate")
d3003 1
a3003 2
		     Crash.impossible"ALLOCATE_STACK with no offset from fp"
*)
d3187 7
d3266 1
a3266 8
				       if needs_temp then
					 [(I386_Assembly.OPCODE
					   (I386_Assembly.mov,
					    [rd_operand,
					     I386_Assembly.r32
					     (lookup_gp_operand gp_operand)]),
					   absent, "get size in rd")]
				       else
d3278 7
d3525 2
a3526 1
					       offset=Option.PRESENT(~primary)}))]),
a3581 2
		     Crash.impossible"do_everything:MirTypes.ADR"
(*
d3584 1
d3592 2
d3599 12
a3610 2
			  [(I386_Assembly.LOAD_OFFSET
			    (I386_Assembly.LEO, lookup_reg_operand reg_operand, 0),
d3612 2
a3613 3
			    "Get offset of tag from procedure start")]
			  ), opcode_list, block_list, final_result)
*)
a3614 4
(* Warning. If we ever make a leaf adr, we must ensure *)
(* handler continuations are done safely. This is not currently *)
(* true since they use o1 as the address. *)
(* But since handlers generate stack allocated stuff, they're unlikely to be leaf *)
d3705 1
a3705 1
				 {base=Option.PRESENT I386Types.global,
d3707 1
a3707 1
				  offset=Option.PRESENT frame_size}))]),
d3754 1
a3754 1
			  if frame_size > 16 + gc_preserve_size then
d3756 1
a3756 1
			      val frame_sub = frame_size - 16 - gc_preserve_size
d3785 1
a3785 1
				 offset=Option.PRESENT(~(frame_size-4))}))]),
d4032 1
a4032 5
			 val frame_left =
			   frame_size -
			   4(* return address *) -
			   8(* fp and callee_closure *) -
			   gc_preserve_size
d4043 1
a4043 1
			       [I386_Assembly.r32 I386Types.sp,
d4067 70
a4136 2
		| MirTypes.NEW_HANDLER tag =>
		    ([], opcode_list, block_list, final_result, stack_drop)
d4138 31
a4168 8
		    Crash.impossible"do_everything:MirTypes.OLD_HANDLER"
(*
		    ([(I386_Assembly.LOAD_AND_STORE
		       (I386_Assembly.LD, I386Types.handler, I386Types.handler,
			I386_Assembly.IMM(~1)),
		       absent,
		       "Restore old handler")], opcode_list, block_list, final_result)
*)
d4221 4
a4224 1
		| _ => Crash.unimplemented"do_everything"
d4465 2
a4466 1
	    | check_reg _ = Crash.impossible"check_reg:bad register"
d4617 2
a4618 1
	    | check_reg _ = Crash.impossible"check_reg:bad register"
a4650 2

	  val linkage_size = 3
@


1.4
log
@Add more opcodes and deal with spills
First version to complete __builtin_library
No stak overflow check or initialisation
@
text
@d4 5
d65 1
a65 1
  sharing type I386_Schedule.I386_Assembly.I386_Opcodes.I386Types.I386_Reg 
d137 1
a137 1
    else 
d205 1
a205 1
	  Info.error' 
d248 1
a248 1
	   n_zeroes([], 32)	   
d265 1
a265 1
	 Info.error' 
d350 1
a350 1
            
d405 1
a405 1
               rev(rev rest @@ (block::done)) = rev(block::done) @@ rest 
d407 1
a407 1
               = rev done @@ (block :: rest) 
d429 1
a429 1
							      next_block, 
d459 1
a459 1
	      Lists.partition continues rest 
d463 1
a463 1
      
d593 1
a593 1
			 Map.YES res => 
d604 1
a604 1
			   
d610 1
a610 1
			   Map.YES res => 
d626 1
a626 1
			   Map.YES res => 
d637 1
a637 1
		      
d642 1
a642 1
			 Map.YES res => 
d656 1
a656 1
			   Map.YES res => 
d669 1
a669 1
			   Map.YES res => 
d682 1
a682 1
			   Map.YES res => 
d695 1
a695 1
			   Map.YES res => 
d832 1
a832 1
			   Map.YES res => 
d849 1
a849 1
		    val (opcodes_and_offsets, next) = 
d938 1
a938 1
  fun mach_cg 
d940 1
a940 1
    (Options.OPTIONS {compiler_options = 
d1007 3
a1009 3
	      let 
		val symbolic_value = 
		  fn i => 
d1021 1
a1021 1
		  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1(i)),name) => 
d1027 3
a1029 3
	      let 
		val symbolic_value = 
		  fn i => 
d1045 2
a1046 2
		case i of 
		  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1(i)),name) => 
d1052 1
a1052 1
	      let 
d1071 3
a1073 3
		case i of 
		  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1(i)),name) => 
		    (fn value => (spill := RuntimeEnv.OFFSET2(value);value)) 
d1221 1
a1221 1
		  (I386_Assembly.OPCODE 
d1241 1
a1241 1
	  
d1351 9
a1359 1
	      val (result_list, opcode_list, new_blocks, new_final_result, done, tag,
d1364 8
a1371 20
		  Crash.impossible"do_everything:MirTypes.TBINARY"
(*
		  let
		    val rd = lookup_reg_operand reg_operand
		    val opcode = case tagged_binary_op of
		      MirTypes.ADDV =>
			I386_Assembly.TADDCCTV
		    | MirTypes.SUBV =>
			I386_Assembly.TSUBCCTV
		    | MirTypes.MULV =>
			Crash.impossible"do_opcodes(TBINARY(MULV))"
		    | MirTypes.DIVV =>
			Crash.impossible"do_opcodes(TBINARY(DIVV))"
		    | MirTypes.MODV =>
			Crash.impossible"do_opcodes(TBINARY(MODV))"

		    fun preserve_order MirTypes.SUBV = true
		    | preserve_order MirTypes.DIVV = true
		    | preserve_order MirTypes.MODV = true
		    | preserve_order _ = false
d1373 11
a1383 3
		    val (gp_operand, gp_operand', redo) =
		      if is_reg gp_operand then
			(gp_operand, gp_operand', false)
d1385 73
a1457 12
                        if is_reg gp_operand'
                          then
                            if preserve_order tagged_binary_op 
                              then 
                                (gp_operand, gp_operand', true)
                            else 
                              (gp_operand', gp_operand, false)
                        else
                          (* Both are immediate so no problem *)
                          (gp_operand, gp_operand', false)
		  in
		    if redo then
d1460 1
a1460 1
				      MirTypes.GC_REG MirRegisters.global,
d1463 1
a1463 1
					MirTypes.GP_GC_REG MirRegisters.global,
d1465 28
a1492 94
		       opcode_list, block_list, final_result)
		    else
		      if is_reg gp_operand then
			let
			  val rs1 = lookup_gp_operand gp_operand
			in
			  if is_reg gp_operand' orelse
			    gp_check_range(gp_operand', true,
					   arith_imm_limit) then
			    (* Actually making some code here *)
			    let
			      val reg_or_imm =
				if is_reg gp_operand' then
				  I386_Assembly.REG(lookup_gp_operand
						     gp_operand')
				else make_imm_format3 gp_operand'
			    in
			      ([(I386_Assembly.TAGGED_ARITHMETIC
				 (opcode, rd, reg_or_imm, rs1), absent, "")],
			       opcode_list,
			       block_list,
			       final_result)
			    end
			  else (* not (is_reg gp_operand') andalso
				  not (gp_check_range
				        (gp_operand', true, arith_imm_limit)) *)
			    ([],
			     (* Ok to use the global register here *)
			     (* Because it won't be the result *)
			     MirTypes.UNARY(MirTypes.MOVE,
					    MirTypes.GC_REG
					    MirRegisters.global,
					    gp_operand') ::
			     MirTypes.TBINARY(tagged_binary_op, tag,
					      reg_operand,
					      gp_operand,
					      MirTypes.GP_GC_REG
					      MirRegisters.global) ::
			     opcode_list, block_list, final_result)
			end
		      else (* not (is_reg gp_operand) *)
			(* Oh dear, both operands gp *)
			(diagnostic_output 3
			  (fn _ => ["Mach_Cg(TBINARY) first arg not reg\n"]);
			 ([],
			  MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					 gp_operand) ::
			  MirTypes.TBINARY(tagged_binary_op, tag,
					   reg_operand,
					   gp_from_reg reg_operand,
					   gp_operand') ::
			  opcode_list, block_list, final_result))
		  end
*)
	    | MirTypes.BINARY(binary_op, reg_operand, gp_operand,
			      gp_operand') =>
		  Crash.impossible"do_everything:MirTypes.BINARY"
(*
		  let
		    val rd = lookup_reg_operand reg_operand
		    val opcode =
		      case binary_op of
			MirTypes.ADD => I386_Assembly.ADD
		      | MirTypes.SUB => I386_Assembly.SUB
		      | MirTypes.MULU =>
			  Crash.unimplemented"MirTypes.MULU"
		      | MirTypes.MULS =>
			  Crash.unimplemented"MirTypes.MULS"
		      | MirTypes.DIVU =>
			  Crash.unimplemented"MirTypes.DIVU"
		      | MirTypes.DIVS =>
			  Crash.unimplemented"MirTypes.DIVS"
		      | MirTypes.MODU =>
			  Crash.unimplemented"MirTypes.MODU"
		      | MirTypes.MODS =>
			  Crash.unimplemented"MirTypes.MODS"
		      | MirTypes.AND => I386_Assembly.AND
		      | MirTypes.OR => I386_Assembly.OR
		      | MirTypes.BIC => I386_Assembly.ANDN
		      | MirTypes.EOR => I386_Assembly.XOR
		      | MirTypes.LSR => I386_Assembly.SRL
		      (* Temporary conversion into SRA from SRL *)
		      (* And back again *)
		      | MirTypes.ASL => I386_Assembly.SLL
		      | MirTypes.ASR => I386_Assembly.SRA

		    fun needs_reverse I386_Assembly.SUB = true
		    | needs_reverse I386_Assembly.SUBCC = true
		    | needs_reverse I386_Assembly.SUBX = true
		    | needs_reverse I386_Assembly.SUBXCC = true
		    | needs_reverse I386_Assembly.SRL = true
		    | needs_reverse I386_Assembly.SLL = true
		    | needs_reverse I386_Assembly.SRA = true
		    | needs_reverse _ = false
d1494 4
a1497 3
		    val (gp_operand, gp_operand', redo) =
		      if is_reg gp_operand then
			(gp_operand, gp_operand', false)
d1499 56
a1554 22
                        if is_reg gp_operand'
                          then
                            if needs_reverse opcode then
                              (gp_operand, gp_operand', true)
                            else 
                              (gp_operand', gp_operand, false)
                        else 
                          (* Both immediate so no problem *)
                          (gp_operand, gp_operand', false)
		  in
		    if redo then
		      let
			val inter_reg =
			  case gp_operand' of
			    MirTypes.GP_GC_REG r =>
			      (if r = MirRegisters.global then
				 (* The nasty case *)
				 (case reg_operand of
				    MirTypes.GC_REG r' =>
				      if r = r' then
					Crash.impossible
					"source and dest global with large int"
d1556 22
a1577 16
					r'
				  | MirTypes.NON_GC_REG _ =>
				      Crash.impossible"BINARY doesn't deliver GC")
			       else
				 MirRegisters.global)
			  | _ => Crash.impossible "BINARY has non-gc register"
		      in
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					MirTypes.GC_REG inter_reg,
					gp_operand) ::
			 MirTypes.BINARY(binary_op, reg_operand,
					 MirTypes.GP_GC_REG inter_reg,
					 gp_operand') ::
			 opcode_list, block_list, final_result)
		      end
d1579 9
a1587 52
		      if is_reg gp_operand then
			let
			  val rs1 = lookup_gp_operand gp_operand
			in
			  if is_reg gp_operand' orelse
			    gp_check_range(gp_operand', true,
					   arith_imm_limit) then
			    let
			      val reg_or_imm =
				if is_reg gp_operand' then
				  I386_Assembly.REG(lookup_gp_operand
						     gp_operand')
				else make_imm_format3 gp_operand'
			    in
			      ([(I386_Assembly.ARITHMETIC_AND_LOGICAL
				 (opcode, rd, reg_or_imm, rs1), absent, "")],
			       opcode_list, block_list, final_result)
			    end
			  else
			    let
			      val inter_reg =
				case gp_operand of
				  MirTypes.GP_GC_REG r =>
				    (if r = MirRegisters.global then
				       (* The nasty case *)
				       (case reg_operand of
					  MirTypes.GC_REG r' =>
					    if r = r' then
					      Crash.impossible
					      "source and dest global with large int"
					    else
					      r'
					| MirTypes.NON_GC_REG _ =>
					    Crash.impossible"BINARY doesn't deliver GC")
				     else
				       MirRegisters.global)
				| _ => Crash.impossible "BINARY has non-gc register"
			    in
			      ([],
			       MirTypes.UNARY(MirTypes.MOVE,
					      MirTypes.GC_REG inter_reg,
					      gp_operand') ::
			       MirTypes.BINARY(binary_op, reg_operand,
					       gp_operand,
					       MirTypes.GP_GC_REG inter_reg) ::
			       opcode_list, block_list, final_result)
			    end
			end
		      else Crash.impossible"Mach_Cg(BINARY) first arg not reg"
		  end
*)
		  | MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand) =>
d1590 2
a1591 2
			(output(std_out, "Handling two spill move\n");
			 
d1597 1
a1597 1
			  opcode_list, block_list, final_result, done, tag, stack_drop)
d1603 1
d1606 1
d1639 1
d1642 1
d1644 1
a1644 2
			    (code_list, opcode_list, block_list, final_result, done,
			     tag, stack_drop)
d1656 1
d1659 1
d1707 2
a1708 2
			    (code_list, opcode_list, block_list, final_result, done,
			     tag, stack_drop)
d1947 1
a1947 2
		       opcode_list, block_list, final_result, done,
		       tag, stack_drop + stack_inc)
d1960 1
a1960 1
			opcode_list, block_list, final_result, done, tag, stack_drop)
d1968 1
a1968 1
			opcode_list, block_list, final_result, done, tag, stack_drop)
d1980 1
a1980 1
			opcode_list, block_list, final_result, done, tag, stack_drop)
d1996 1
a1996 1
			    opcode_list, block_list, final_result, done, tag, stack_drop)
d2008 1
a2008 1
			    opcode_list, block_list, final_result, done, tag, stack_drop)
d2030 1
a2030 1
			    opcode_list, block_list, final_result, done, tag, stack_drop)
d2055 1
a2055 1
			    opcode_list, block_list, final_result, done, tag, stack_drop)
d2073 1
a2073 2
			    opcode_list, block_list, final_result, done, tag,
			    stack_drop)
d2123 1
a2123 1
			 opcode_list, block_list, final_result, done, tag, stack_drop)
d2135 1
a2135 1
			 opcode_list, block_list, final_result, done, tag, stack_drop)
d2140 3
a2142 1
		  Crash.impossible"do_everything:MirTypes.STOREFPOP"
d2264 1
a2264 1
			   (I386_Assembly.SRA, I386Types.global, 
d2296 1
a2296 1
		      val (operation,operation',test,subtract) = 
d2322 1
a2322 1
                          I386_Assembly.IMM ~4), absent,""),                   
d2335 1
a2335 1
                        (I386_Assembly.FUNARY(I386_Assembly.FNEG, 
d2342 1
a2342 1
                        (I386_Assembly.FBINARY(subtract, I386Types.fp_global, I386Types.fp_global, I386Types.fp_global), 
d2356 1
a2356 1
                          I386_Assembly.IMM ~4), absent,""),                   
d2365 1
a2365 1
                        (I386_Assembly.FBINARY(subtract, rs2, rs2, I386Types.fp_global), 
d2404 1
a2404 1
			opcode_list, block_list, final_result, done, tag, stack_drop)
d2417 1
a2417 1
		     opcode_list, block_list, final_result, done, tag, stack_drop)
d2533 1
a2533 1
			  opcode_list, block_list, final_result, done, tag, stack_drop)
d2543 1
a2543 1
			 opcode_list, block_list, final_result, done, tag, stack_drop)
d2590 1
a2590 1
		      opcode_list, block_list, final_result, done, tag, stack_drop)
d2595 1
a2595 1
		    opcode_list, block_list, final_result, done, tag, stack_drop)
d2650 1
a2650 1
			 opcode_list, block_list, final_result, done, tag, stack_drop)
d2731 1
a2731 1
		     ([], opcode_list, block_list, final_result, done, tag, stack_drop)
d2748 11
a2758 65
                       val (opcodes1, opcodes2, tag1) =
                         case gp_operand of
                           MirTypes.GP_IMM_INT size =>
			     let
			       val tag1 = MirTypes.new_tag()
			       val tag2 = MirTypes.new_tag()
			       val (bytes, primary, aligned, header) =
				 case allocate of
				   MirTypes.ALLOC =>
				     if size = 2 then
				       (8, Tags.PAIRPTR, true, 0)
				     else
				       (8 * ((size+2) div 2), Tags.POINTER,
					size mod 2 <> 0, 64*size+Tags.RECORD)
				 | MirTypes.ALLOC_STRING =>
				     (((size+12) div 8) * 8,
				      Tags.POINTER, true, 64*size+Tags.STRING)
				 | MirTypes.ALLOC_REAL =>
				     (case I386Types.fp_used
					of I386Types.single   => Crash.unimplemented "ALLOC_REAL single"
				      | I386Types.extended => Crash.unimplemented "ALLOC_REAL extended"
				      | I386Types.double   =>
					  (16, Tags.POINTER, true,
					   64*(16 - 4) + Tags.BYTEARRAY))
				 | MirTypes.ALLOC_REF  =>
				     (8 + 8*((size+2) div 2),
				      Tags.REFPTR, size mod 2 <> 0, 64*size+Tags.ARRAY)
				 | MirTypes.ALLOC_BYTEARRAY =>
				     (((size+12) div 8) * 8, Tags.REFPTR, true,
				      64*size+Tags.BYTEARRAY)
			       val header_code =
				 if header = 0 then
				   []
				 else
				   [(I386_Assembly.OPCODE
				     (I386_Assembly.mov,
				      [I386_Assembly.r_m32
				       (Option.SOME2
					(I386_Assembly.MEM
					 {base=Option.PRESENT rd,
					  index=absent,
					  offset=Option.PRESENT(~primary)})),
				       I386_Assembly.imm32(header div 4, header mod 4)]),
				     absent, "initialise header")]
			       val header_code =
				 if aligned then
				   header_code
				 else
				   (I386_Assembly.OPCODE
				    (I386_Assembly.mov,
				     [I386_Assembly.r_m32
				      (Option.SOME2
				       (I386_Assembly.MEM
					{base=Option.PRESENT rd,
					 index=absent,
					 offset=Option.PRESENT(bytes - primary - 4)})),
				      I386_Assembly.imm32(0, 0)]),
				    absent, "zero unaligned extra word") :: header_code

			       val decrement_imm =
				 let
				   val size = bytes-primary
				 in
				   if size <= 127 then
				     I386_Assembly.imm8 size
d2760 28
a2787 5
				     I386_Assembly.imm32(size div 4, size mod 4)
				 end
			     in
			       ([(I386_Assembly.OPCODE
				  (I386_Assembly.add,
d2791 1
a2791 1
				      {base=Option.PRESENT I386Types.implicit,
d2793 8
a2800 8
				       offset=Option.PRESENT(4*Implicit_Vector.gc_base)})),
				    if bytes <= 127 then
				      I386_Assembly.imm8 bytes
				    else
				      I386_Assembly.imm32(bytes div 4, bytes mod 4)]),
				  absent,
				  "increment base pointer"),
			         (I386_Assembly.OPCODE
d2802 1
a2802 2
				   [I386_Assembly.r32 rd, 
				    I386_Assembly.r_m32
d2805 1
a2805 1
				      {base=Option.PRESENT I386Types.implicit,
d2807 241
a3047 3
				       offset=Option.PRESENT(4*Implicit_Vector.gc_base)}))]),
				  absent,
				  "acquire base pointer for result"),
d3049 2
a3050 3
				  (I386_Assembly.cmp,
				   [I386_Assembly.r32 rd, 
				    I386_Assembly.r_m32
d3055 3
a3057 1
				       offset=Option.PRESENT(4*Implicit_Vector.gc_limit)}))]),
d3059 3
a3061 1
				  "check for run out of store"),
d3063 1
a3063 6
				  (I386_Assembly.jcc I386_Assembly.below,
				   [I386_Assembly.rel32 0]), Option.PRESENT tag1,
				  "branch if not run out of heap"),
				 move_imm(I386Types.global, bytes, "amount requested"),
				 (I386_Assembly.OPCODE
				  (I386_Assembly.call,
d3069 28
a3096 2
				       offset=Option.PRESENT gc_entry}))]),
				  absent, "call the gc"),
d3106 192
a3297 128
				  absent, "produce the answer"),
				 (I386_Assembly.OPCODE
				  (I386_Assembly.jmp,
				   [I386_Assembly.rel32 6]), Option.PRESENT tag1,
				  "branch to continuation sequence")],
			        (I386_Assembly.OPCODE
				 (I386_Assembly.sub,
				  [I386_Assembly.r_m32(Option.SOME1 rd),
				   decrement_imm]),
				 absent, "tag pointer correctly") ::
				header_code,
				tag1)
(*
				 (I386_Assembly.ARITHMETIC_AND_LOGICAL
				  (I386_Assembly.ADD, I386Types.gc1, I386_Assembly.IMM bytes, I386Types.gc1),
				  absent, "Attempt to allocate some heap") ::
				 (I386_Assembly.ARITHMETIC_AND_LOGICAL
				  (I386_Assembly.SUBCC, I386Types.G0, I386_Assembly.REG I386Types.gc2, I386Types.gc1),
				  absent, "Is a GC required?") ::
				 (I386_Assembly.BRANCH_ANNUL
				  (I386_Assembly.BL, 6),
				  absent, "Skip call to GC if not") ::
				 (I386_Assembly.ARITHMETIC_AND_LOGICAL
				  (I386_Assembly.ADD, rd, I386_Assembly.IMM (primary - bytes), I386Types.gc1),
				  absent, "Tag result with primary") ::
				 (I386_Assembly.LOAD_AND_STORE
				  (I386_Assembly.LD, I386Types.global, I386Types.implicit, gc_entry),
				  absent, "Fetch entry point of GC") ::
				 (I386_Assembly.JUMP_AND_LINK
				  (I386_Assembly.JMPL, link, I386_Assembly.IMM 0, I386Types.global,
				   Debugger_Types.null_backend_annotation),
				  absent, "Call GC") ::
				 (I386_Assembly.ARITHMETIC_AND_LOGICAL
				  (I386_Assembly.OR, I386Types.global, I386_Assembly.IMM bytes, I386Types.G0),
				  absent, "Size argument for GC") ::
				 (I386_Assembly.ARITHMETIC_AND_LOGICAL
				  (I386_Assembly.ADD, rd, I386_Assembly.IMM primary, I386Types.global),
				  absent, "Tag result with primary") ::
				 (if aligned then
				    header_code
				  else
				    (I386_Assembly.LOAD_AND_STORE
				     (I386_Assembly.ST, I386Types.G0, rd, I386_Assembly.IMM (bytes - primary - 4)),
				     absent, "Zero unaligned extra word") :: header_code)
*)
			     end
			 | MirTypes.GP_GC_REG reg =>
			     (*
			     let
			       val (primary, secondary, length_code) =
				 case allocate
				   of MirTypes.ALLOC        => Crash.unimplemented "ALLOC variable size"
				 | MirTypes.ALLOC_STRING => Crash.unimplemented "ALLOC_STRING variable size"
				 | MirTypes.ALLOC_REAL   => Crash.unimplemented "ALLOC_REAL variable size"
				 | MirTypes.ALLOC_REF    =>
				     (Tags.REFPTR, Tags.ARRAY,
				      [(I386_Assembly.ARITHMETIC_AND_LOGICAL
					(I386_Assembly.ADD, rd, I386_Assembly.IMM (12+7), lookup_reg(MirTypes.GC.unpack reg, gc_array)),
					absent, "Calculate length of Array")])                                
				 | MirTypes.ALLOC_BYTEARRAY =>
				     (Tags.REFPTR, Tags.BYTEARRAY,
				      [(I386_Assembly.ARITHMETIC_AND_LOGICAL
					(I386_Assembly.SRL, rd, I386_Assembly.IMM 2, lookup_reg(MirTypes.GC.unpack reg, gc_array)),
					absent, "Calculate length of ByteArray"),
				      (I386_Assembly.ARITHMETIC_AND_LOGICAL
				       (I386_Assembly.ADD, rd, I386_Assembly.IMM (4+7), lookup_reg(MirTypes.GC.unpack reg, gc_array)),
				       absent, "")])
			     in
			       length_code @@
			       ((I386_Assembly.ARITHMETIC_AND_LOGICAL
				 (I386_Assembly.ANDN, rd, I386_Assembly.IMM 7, rd),
				 absent, "Calculate aligned size in bytes") ::
				(I386_Assembly.ARITHMETIC_AND_LOGICAL
				 (I386_Assembly.ADD, I386Types.gc1, I386_Assembly.REG rd, I386Types.gc1),
				 absent, "Attempt to allocate some heap") ::
				(I386_Assembly.ARITHMETIC_AND_LOGICAL
				 (I386_Assembly.SUBCC, I386Types.G0, I386_Assembly.REG I386Types.gc2, I386Types.gc1),
				 absent, "Is a GC required?") ::
				(I386_Assembly.BRANCH_ANNUL
				 (I386_Assembly.BL, 5),
				 absent, "Skip call to GC if not") ::
				(I386_Assembly.ARITHMETIC_AND_LOGICAL
				 (I386_Assembly.SUB, I386Types.global, I386_Assembly.REG rd, I386Types.gc1),
				 absent, "Calculate address of new object") ::
				(I386_Assembly.LOAD_AND_STORE
				 (I386_Assembly.LD, I386Types.global, I386Types.implicit, gc_entry),
				 absent, "Fetch entry point of GC") ::
				(I386_Assembly.JUMP_AND_LINK
				 (I386_Assembly.JMPL, link, I386_Assembly.IMM 0, I386Types.global,
				  Debugger_Types.null_backend_annotation),
				 absent, "Call GC") ::
				(I386_Assembly.ARITHMETIC_AND_LOGICAL
				 (I386_Assembly.OR, I386Types.global, I386_Assembly.REG rd, I386Types.G0),
				 absent, "Size argument for GC") ::
				(I386_Assembly.ARITHMETIC_AND_LOGICAL
				 (I386_Assembly.ADD, rd, I386_Assembly.REG rd, I386Types.global),
				 absent, "Calculate end of object") ::
				(I386_Assembly.LOAD_AND_STORE
				 (I386_Assembly.ST, I386Types.G0, rd, I386_Assembly.IMM (~4)),
				 absent, "Zero last word in case it's unaligned") ::
				(I386_Assembly.ARITHMETIC_AND_LOGICAL
				 (I386_Assembly.ADD, rd, I386_Assembly.IMM primary, I386Types.global),
				 absent, "Tag object with primary") ::
				(I386_Assembly.ARITHMETIC_AND_LOGICAL
				 (I386_Assembly.SLL, I386Types.global, I386_Assembly.IMM 4, lookup_reg(MirTypes.GC.unpack reg, gc_array)),
				 absent, "") ::
				(I386_Assembly.ARITHMETIC_AND_LOGICAL
				 (I386_Assembly.ADD, I386Types.global, I386_Assembly.IMM secondary, I386Types.global),
				 absent, "Calculate header tag") ::
				(I386_Assembly.LOAD_AND_STORE
				 (I386_Assembly.ST, I386Types.global, rd, I386_Assembly.IMM (~primary)),
				 absent, "Initialise header tag") :: nil)
			     end
			   *)
			     Crash.unimplemented"ALLOCATE variable size"
			 | _ => Crash.impossible "Strange parameter to ALLOCATE"
		       val opcode_list =
			 if needs_temp then
			   MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					  MirTypes.GP_GC_REG MirRegisters.global) ::
			   opcode_list
			 else
			   opcode_list
                     in
                       (opcodes2, opcode_list, block_list,
			(tag, contract_sexpr(Sexpr.CONS(done, Sexpr.ATOM opcodes1))) ::
			(*(tag1, opcodes2) :: *)final_result,
			Sexpr.NIL, tag1, stack_drop)
d3328 1
a3328 1
		    (trace_dummy_instructions, opcode_list, block_list, final_result, done, tag, stack_drop)
d3394 71
d3504 5
a3508 1
				    I386Types.caller_closure, "set up closure")]
d3510 6
a3515 1
			(make_stack @@ save_gcs @@ opcodes, opcode_list, block_list, final_result, done, tag, stack_drop)
d3646 2
a3647 2
			     (I386_Assembly.SUBCC, I386Types.G0, 
			      I386_Assembly.REG(I386Types.sp), I386Types.stack_limit), 
d3653 1
a3653 1
			     (I386_Assembly.SUB, I386Types.global, 
d3655 1
a3655 1
				I386_Assembly.IMM frame_size 
d3657 1
a3657 1
				I386_Assembly.REG I386Types.O3, 
d3702 2
a3703 2
			     (I386_Assembly.OR, I386Types.O3, 
			      I386_Assembly.IMM frame_size, I386Types.G0), 
d3712 1
a3712 1
			  | _ => 
d3718 1
a3718 1
			      else 
d3721 1
a3721 1
				   I386_Assembly.REG(I386Types.O3), I386Types.G0), 
d3739 1
a3739 1
		      ([], opcode_list, block_list, final_result, done, tag, stack_drop)
d3782 1
a3782 1
		       opcode_list, block_list, final_result, done, tag, stack_drop)
d3784 1
a3784 1
		    ([], opcode_list, block_list, final_result, done, tag, stack_drop)
d3831 1
a3831 1
		       (code, opcode_list, block_list, final_result, done, tag, stack_drop)
d3845 1
a3845 1
		    opcode_list, block_list, final_result, done, tag, stack_drop)
d3871 2
a3872 2
          fun less_than_three_opcodes_that_are_not_comments([],occ) = true 
            | less_than_three_opcodes_that_are_not_comments(MirTypes.COMMENT _ :: rest,occ) = 
d3875 1
a3875 1
            | less_than_three_opcodes_that_are_not_comments(h::t,occ) = 
d4053 1
a4053 1
	    
a4202 3
	  val _ = output(std_out, "Worked out needs_preserve to be " ^
			 (if needs_preserve then "true" else "false") ^ "\n")

d4210 2
a4211 2
                   debug_map := 
                   (Debugger_Types.INFO (NewMap.define(i, 
d4214 3
a4216 3
               | _ => 
                   debug_map := 
                   (Debugger_Types.INFO (NewMap.define(i, 
d4403 1
a4403 1
				     block_list, 
d4418 1
a4418 1
              fun normalise_to_four_bytes (x) = 
d4425 1
a4425 1
	  ((proc_tag, code), 
d4483 1
a4483 1
	  val temp_code_list = 
d4488 1
a4488 1
	  val code_list = 
d4499 1
a4499 1
	    (fn _ => (map print_unscheduled_code 
d4579 1
a4579 1
		    
d4590 1
a4590 1
                       (case inst of 
d4592 2
a4593 2
                          I386_Assembly.JUMP_AND_LINK (_,_,_,_,Debugger_Types.Nop) => ()        
                        | I386_Assembly.JUMP_AND_LINK (_,_,_,_,debug) =>        
d4599 1
a4599 1
                                    if String.ordof(padded_name,to) = 0 
d4603 1
a4603 1
                                  check_index (s-1) 
d4613 1
a4613 1
                                     (NewMap.define(i, unpadded_name, 
d4620 1
a4620 1
                   val code = 
d4655 1
a4655 1
        if ! print_code_size then 
@


1.3
log
@More opcodes
@
text
@d4 3
d56 1
a56 1
  sharing MirTables.MirTypes.Option = MirTables.MirTypes.RuntimeEnv.Option
d62 1
a62 3
  sharing type MirTables.MirTypes.RuntimeEnv.debugger_env = 
    MirTables.MirTypes.Debugger_Types.Debugger_Env.debugger_env
  sharing type I386_Schedule.I386_Assembly.opt = MirTables.MirTypes.RuntimeEnv.Option.opt
d64 1
a64 1
    MirTables.MirTypes.RuntimeEnv.Option.option
d79 1
a79 1
  structure RuntimeEnv = MirTypes.RuntimeEnv
d900 6
d996 1
d1012 1
a1012 1
		     ~(gc_spill_offset + 4 * (1 + i))
d1016 4
a1019 4
		  Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
		    (fn value => (spill := Option.SOME2(value);value)) (symbolic_value i)
		  | Option.SOME1(ref(Option.SOME2(i)),name) => i
		  | Option.SOME2(i) => symbolic_value i
d1036 1
a1036 1
		       ~(non_gc_spill_offset + 4 * (1 + offset + i))
d1041 4
a1044 4
		  Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
		    (fn value => (spill := Option.SOME2(value);value)) (symbolic_value i)
		  | Option.SOME1(ref(Option.SOME2(i)),name) => i
		  | Option.SOME2(i) => symbolic_value i
d1047 26
a1072 6
	      (case i of 
		 Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
		   (fn value => (spill := Option.SOME2(value);value)) 
		   (~4 * (1 + non_gc_spill_size + i))
		 | Option.SOME1(ref(Option.SOME2(i)),name) => i
		 | Option.SOME2(i) => ~(fp_spill_offset + 4 * (1 + i)))
a1155 20
	  val symbolic_value = symb_value stack_layout

	  fun assemble_imm32(MirTypes.GP_IMM_INT i) = (i, 0)
	    | assemble_imm32(MirTypes.GP_IMM_ANY i) = (i div 4, i mod 4)
	    | assemble_imm32(MirTypes.GP_IMM_SYMB symb) =
	      let
		val i = symbolic_value symb
	      in
		(i div 4, i mod 4)
	      end
	    | assemble_imm32 _ =
	      Crash.impossible"assemble_imm32:non-immediate"

	  fun assemble_large_offset gp_operand =
	    let
	      val (i, j) = assemble_imm32 gp_operand
	    in
	      4*i+j (* Should never overflow! *)
	    end

d1242 45
a1286 2
	  fun do_everything
	    (_, tag, [], done, [], final_result) =
d1289 1
a1289 1
	    (needs_preserve, tag, [], done,
d1292 11
a1302 3
	    do_everything
	    (needs_preserve, tag', Lists.filter_outp is_comment opcodes, Sexpr.NIL, blocks,
	     (tag, contract_sexpr done) :: final_result)
d1304 1
a1304 1
	    (needs_preserve, tag, opcode :: opcode_list, done,
d1307 16
a1322 1
	      fun lookup_reg(reg, table) =
d1324 1
a1324 1
		  val mach_reg = Array.sub(table, reg)
d1326 1
a1326 5
		  if needs_preserve orelse
		    reg <> MirTypes.GC.unpack MirRegisters.callee_closure then
		    mach_reg
		  else
		    I386Types.caller_closure
d1329 19
a1347 16
	      fun lookup_reg_operand(MirTypes.GC_REG reg) =
	        lookup_reg(MirTypes.GC.unpack reg, gc_array)
	      | lookup_reg_operand(MirTypes.NON_GC_REG reg) =
		lookup_reg(MirTypes.NonGC.unpack reg, non_gc_array)
		
	      fun lookup_gp_operand(MirTypes.GP_GC_REG reg) =
	        lookup_reg(MirTypes.GC.unpack reg, gc_array)
	      | lookup_gp_operand(MirTypes.GP_NON_GC_REG reg) =
		lookup_reg(MirTypes.NonGC.unpack reg, non_gc_array)
	      | lookup_gp_operand _ =
		Crash.impossible"lookup_gp_operand(constant)"

	      fun lookup_fp_operand(MirTypes.FP_REG reg) =
		Array.sub(fp_array, MirTypes.FP.unpack reg)
		
	      val (result_list, opcode_list, new_blocks, new_final_result, done, tag) =
d1586 14
a1599 5
		    let
		      val rd = lookup_reg_operand reg_operand
		      val opcode = I386_Assembly.mov
		      val code_list =
			if is_reg gp_operand then
d1601 36
a1636 1
			    val rs1 = lookup_gp_operand gp_operand
d1638 2
a1639 9
			    if rd = rs1 then
			      [] (* Null move rn -> rn *)
			    else
			      [(I386_Assembly.OPCODE
				(opcode,
				 [I386_Assembly.r32 rd,
				  I386_Assembly.r_m32
				  (Option.SOME1 rs1)]),
				absent, "")]
d1642 63
a1704 19
			  case assemble_imm32 gp_operand of
			    (0, 0) =>
			      [(I386_Assembly.OPCODE
				(I386_Assembly.xor,
				 [I386_Assembly.r32 rd,
				  I386_Assembly.r_m32
				  (Option.SOME1 rd)]),
				absent, "")]
			  | x =>
			      [(I386_Assembly.OPCODE
				(opcode,
				 [I386_Assembly.r32 rd,
				  I386_Assembly.imm32 x]),
				absent, "")]
		    in
		      (code_list, opcode_list, block_list, final_result, done, tag)
		    end
		| MirTypes.UNARY(MirTypes.NOT, reg_operand, gp_operand) =>
		    Crash.impossible"do_everything:MirTypes.UNARY"
a1923 2
		| MirTypes.STACKOP _ =>
		    Crash.impossible"Offset missing on STACK_OP"
d1925 18
d1945 128
d2076 1
a2076 1
		    val (store, store_word, load) = case store_op of
d2079 1
a2079 1
		    | MirTypes.LDB => (I386_Assembly.mov, false, true)
d2096 1
a2096 1
		      if store_word then
d2099 4
a2102 1
			(I386_Assembly.r8, I386_Assembly.r_m8)
d2104 1
a2104 1
		    if store_word orelse I386Types.has_byte_name rd then
d2106 5
a2110 1
			val rd = if store_word then rd else I386Types.byte_reg_name rd
d2117 2
a2118 2
			([(I386_Assembly.OPCODE(store, operands), absent, "")],
			 opcode_list, block_list, final_result, done, tag)
d2121 1
d2124 2
a2125 4
			  if load then
			    [con1 I386Types.global, con2 r_m]
			  else
			    [con2 r_m, con1 I386Types.global]
d2127 4
a2130 10
			if load then
			  ([(I386_Assembly.OPCODE(store, operands), absent, ""),
			    move_reg(rd, I386Types.global, "can't load byte into " ^
				     I386Types.reg_to_string rd)],
			   opcode_list, block_list, final_result, done, tag)
			else
			  ([move_reg(I386Types.global, rd, "can't store byte from " ^
				     I386Types.reg_to_string rd),
			    (I386_Assembly.OPCODE(store, operands), absent, "")],
			   opcode_list, block_list, final_result, done, tag)
d2132 1
a2132 1
		  end
d2384 7
a2390 4
			  [(I386_Assembly.OPCODE
			    (I386_Assembly.jmp,
			     [I386_Assembly.r_m32
			      (Option.SOME1(lookup_reg_operand reg))](*,
d2392 1
a2392 1
			    absent, "branch indirect")]
d2397 1
a2397 1
			opcode_list, block_list, final_result, done, tag)
d2400 72
a2471 43
		  let
		    val branch = case cond_branch of
		      MirTypes.BNT => I386_Assembly.jcc I386_Assembly.equal
		    | MirTypes.BTA => I386_Assembly.jcc I386_Assembly.not_equal
		    | MirTypes.BEQ => I386_Assembly.jcc I386_Assembly.equal
		    | MirTypes.BNE => I386_Assembly.jcc I386_Assembly.not_equal
		    | MirTypes.BHI => I386_Assembly.jcc I386_Assembly.above
		    | MirTypes.BLS => I386_Assembly.jcc I386_Assembly.below_or_equal
		    | MirTypes.BHS => I386_Assembly.jcc I386_Assembly.above_or_equal
		    | MirTypes.BLO => I386_Assembly.jcc I386_Assembly.below
		    | MirTypes.BGT => I386_Assembly.jcc I386_Assembly.greater
		    | MirTypes.BLE => I386_Assembly.jcc I386_Assembly.less_or_equal
		    | MirTypes.BGE => I386_Assembly.jcc I386_Assembly.greater_or_equal
		    | MirTypes.BLT => I386_Assembly.jcc I386_Assembly.less
		    val test_instr = case cond_branch of
		      MirTypes.BTA => I386_Assembly.test
		    | MirTypes.BNT => I386_Assembly.test
		    | _ => I386_Assembly.cmp
		  in
		    if is_reg gp_operand orelse is_reg gp_operand' then
		      let
			val (branch, gp_op, gp_op') =
			  if is_reg gp_operand then
			    (branch, gp_operand, gp_operand')
			  else
			    (I386_Assembly.reverse_branch branch,
			     gp_operand', gp_operand)
			val rs1 = lookup_gp_operand gp_op
			val (rs1, reg_or_imm) =
			  if is_reg gp_op' then
			    (I386_Assembly.r_m32(Option.SOME1 rs1),
			     I386_Assembly.r_m32(Option.SOME1(lookup_gp_operand gp_op')))
			  else
			    let
			      val imm as (i, j) = assemble_imm32 gp_op'
			    in
			      if test_instr = I386_Assembly.cmp then
				if i <= 31 andalso i > ~32 then
				  (I386_Assembly.r_m32(Option.SOME1 rs1),
				   I386_Assembly.imm8(i*4+j))
				else
				  (I386_Assembly.r_m32(Option.SOME1 rs1),
				   I386_Assembly.imm32 imm)
d2473 27
a2499 6
				if i = 0 andalso j = 3 then
				  if I386Types.has_byte_name rs1 then
				    (* Testing for tagged *)
				    (I386_Assembly.r_m8
				     (Option.SOME1(I386Types.byte_reg_name rs1)),
				     I386_Assembly.imm8 j)
d2501 2
a2502 3
				    (I386_Assembly.r_m16
				     (Option.SOME1(I386Types.half_reg_name rs1)),
				      I386_Assembly.imm16 j)
d2504 34
a2537 22
				  (I386_Assembly.r_m32(Option.SOME1 rs1),
				   I386_Assembly.imm32 imm)
			    end
		      in
			([(I386_Assembly.OPCODE
			   (test_instr,
			    [rs1, reg_or_imm]),
			   absent, "do the test"),
			  (I386_Assembly.OPCODE(branch, [I386_Assembly.rel32 0]),
			   Option.PRESENT test_tag, "do the branch")],
			opcode_list, block_list, final_result, done, tag)
		      end
		    else
		      ([],
		       MirTypes.UNARY(MirTypes.MOVE,
				      MirTypes.GC_REG
				      MirRegisters.global,
				      gp_operand') ::
		       MirTypes.TEST(cond_branch, test_tag, gp_operand,
				     MirTypes.GP_GC_REG MirRegisters.global) ::
		       opcode_list, block_list, final_result, done, tag)
		  end
d2566 18
a2583 10
		    Crash.impossible"do_everything:MirTypes.BRANCH_AND_LINK"
(*
		    ([(I386_Assembly.JUMP_AND_LINK
		      (I386_Assembly.JMPL, I386Types.lr,  
		       I386_Assembly.IMM Tags.CODE_OFFSET, lookup_reg_operand reg_operand,
                       debug_information),
		      absent, "Call to tagged value"),
		     I386_Assembly.nop],
		    opcode_list, block_list, final_result) 
*)
d2585 4
a2588 8
		    Crash.impossible"do_everything:MirTypes.BRANCH_AND_LINK"
(*
		    ([(I386_Assembly.Call
		      (I386_Assembly.CALL, 0),
		      Option.PRESENT tag, "Call"),
		     I386_Assembly.nop],
		    opcode_list, block_list, final_result)
*)
d2594 8
a2601 4
			    (I386_Assembly.OPCODE
			     (I386_Assembly.jmp,
			      [I386_Assembly.r_m32(Option.SOME1(lookup_reg_operand reg))]),
			     absent, "branch indirect(tail call)")
d2643 1
a2643 1
			 opcode_list, block_list, final_result, done, tag)
d2724 1
a2724 1
		     ([], opcode_list, block_list, final_result, done, tag)
d2728 6
a2733 1
                       val rd = lookup_reg_operand reg_operand
a2754 1
(*
a2770 2
*)
				 | _ => Crash.unimplemented"Other ALLOCATEs"
a2913 41
(*
			       else
				 (load_large_number_into_register
				  (rd, MirTypes.GP_IMM_ANY bytes)) @@
				 ((I386_Assembly.ARITHMETIC_AND_LOGICAL
                                   (I386_Assembly.ADD, I386Types.gc1, I386_Assembly.REG rd, I386Types.gc1),
                                   absent, "Attempt to allocate some heap") ::
				 (I386_Assembly.ARITHMETIC_AND_LOGICAL
				  (I386_Assembly.SUBCC, I386Types.G0, I386_Assembly.REG I386Types.gc2, I386Types.gc1),
				  absent, "Is a GC required?") ::
				 (I386_Assembly.BRANCH_ANNUL
				  (I386_Assembly.BL, 5),
				  absent, "Skip call to GC if not") ::
				 (I386_Assembly.ARITHMETIC_AND_LOGICAL
				  (I386_Assembly.SUB, I386Types.global, I386_Assembly.REG rd, I386Types.gc1),
				  absent, "Calculate address of new object") ::
				 (I386_Assembly.LOAD_AND_STORE
				  (I386_Assembly.LD, I386Types.global, I386Types.implicit, gc_entry),
				  absent, "Fetch entry point of GC") ::
				 (I386_Assembly.JUMP_AND_LINK
				  (I386_Assembly.JMPL, link, I386_Assembly.IMM 0, I386Types.global,
				   Debugger_Types.null_backend_annotation),
				  absent, "Call GC") ::
				 (I386_Assembly.ARITHMETIC_AND_LOGICAL
				  (I386_Assembly.OR, I386Types.global, I386_Assembly.REG rd, I386Types.G0),
				  absent, "Size argument for GC") ::
				 (if aligned then
				    (I386_Assembly.ARITHMETIC_AND_LOGICAL
				     (I386_Assembly.ADD, rd, I386_Assembly.IMM primary, I386Types.global),
				     absent, "Tag object with primary") :: header_code
				  else
				    (I386_Assembly.ARITHMETIC_AND_LOGICAL
				     (I386_Assembly.ADD, rd, I386_Assembly.REG rd, I386Types.global),
				     absent, "Calculate end of object") ::
				    (I386_Assembly.LOAD_AND_STORE
				     (I386_Assembly.ST, I386Types.G0, rd, I386_Assembly.IMM (~4)),
				     absent, "Zero unaligned extra word") ::
				    (I386_Assembly.ARITHMETIC_AND_LOGICAL
				     (I386_Assembly.ADD, rd, I386_Assembly.IMM primary, I386Types.global),
				     absent, "Tag object with primary") :: header_code))
				 *)
d2985 7
d2996 1
a2996 1
			Sexpr.NIL, tag1)
d3027 1
a3027 1
		    (trace_dummy_instructions, opcode_list, block_list, final_result, done, tag)
a3090 1
		      in
d3093 10
a3102 6
			if gc_stack_slots <> 0 then
			  Crash.unimplemented"do_everything:non-leaf procedeure with spills"
			else
			  (* Simple case *)
			  let
			    val opcodes =
d3104 31
a3134 22
				(I386_Assembly.push,
				 [I386_Assembly.r32 I386Types.callee_closure]),
				absent, "save caller's closure"),
			       (I386_Assembly.OPCODE
				(I386_Assembly.lea,
				 [I386_Assembly.r32 I386Types.global,
				  I386_Assembly.r_m32
				  (Option.SOME2
				   (I386_Assembly.MEM
				    {base=Option.PRESENT I386Types.sp,
				     index=absent,
				     offset=Option.PRESENT(~(frame_size-4))}))]),
				absent, "calculate old sp"),
			       (I386_Assembly.OPCODE
				(I386_Assembly.push,
				 [I386_Assembly.r32 I386Types.global]),
				absent, "save old sp"),
			       move_reg(I386Types.callee_closure,
					I386Types.caller_closure, "set up closure")]
			  in
			    (save_gcs @@ opcodes, opcode_list, block_list, final_result, done, tag)
			  end
d3358 1
a3358 1
		      ([], opcode_list, block_list, final_result, done, tag)
d3401 1
a3401 1
		       opcode_list, block_list, final_result, done, tag)
d3403 1
a3403 1
		    ([], opcode_list, block_list, final_result, done, tag)
a3413 2
		    Crash.impossible"do_everything:MirTypes.RAISE"
(*
d3415 19
d3435 14
a3448 32
			if needs_preserve then
			  [(I386_Assembly.LOAD_AND_STORE
			    (I386_Assembly.LD, I386Types.global,
			     I386Types.implicit,
			     I386_Assembly.IMM (4 * Implicit_Vector.raise_code)),
			    absent, "Do all the work of getting to the handler"),
			  (I386_Assembly.JUMP_AND_LINK
			   (I386_Assembly.JMPL, I386Types.lr,
			    I386_Assembly.REG I386Types.global, I386Types.G0,
			    Debugger_Types.null_backend_annotation),
			   absent, "Raise"),
			  (I386_Assembly.ARITHMETIC_AND_LOGICAL
			   (I386_Assembly.OR, I386Types.caller_arg,
			    I386_Assembly.REG I386Types.G0,
			    lookup_reg_operand reg),
			   absent, "Move arg to raise into arg reg")]
			else
			  [(I386_Assembly.LOAD_AND_STORE
			    (I386_Assembly.LD, I386Types.global,
			     I386Types.implicit,
			     I386_Assembly.IMM (4 * Implicit_Vector.leaf_raise_code)),
			    absent, "Do all the work of getting to the handler"),
			  (I386_Assembly.JUMP_AND_LINK
			   (I386_Assembly.JMPL, I386Types.G0,
			    I386_Assembly.REG I386Types.global, I386Types.G0,
			    Debugger_Types.null_backend_annotation),
			   absent, "Raise"),
			  (I386_Assembly.ARITHMETIC_AND_LOGICAL
			   (I386_Assembly.OR, I386Types.caller_arg,
			    I386_Assembly.REG I386Types.G0,
			    lookup_reg_operand reg),
			   absent,"Move arg to raise into arg reg")]
d3450 1
a3450 1
		       (code, opcode_list, block_list, final_result)
a3451 1
*)
d3455 10
a3464 12
		    Crash.impossible"do_everything:MirTypes.CALL_C"
(*
		    ([(I386_Assembly.LOAD_AND_STORE
		       (I386_Assembly.LD, I386Types.global,
			I386Types.implicit, I386_Assembly.IMM (4 * Implicit_Vector.external)),
		       absent, "Get address of callc"),
		    (I386_Assembly.JUMP_AND_LINK
		     (I386_Assembly.JMPL, I386Types.lr,
		      I386_Assembly.IMM 0, I386Types.global,Debugger_Types.null_backend_annotation),
		     absent, "Do call_c"), I386_Assembly.nop],
		    opcode_list, block_list, final_result)
*)
d3468 1
a3468 1
	      (needs_preserve, tag, opcode_list,
d3474 1
a3474 1
	  do_everything(needs_preserve, tag, Lists.filter_outp is_comment opcodes,
d3650 19
a3668 2
	  val fps = Set.list_to_set(map (fn r => MirTypes.FP.Map.apply'(fp_map, r)) fp)
	  val gcs = Set.list_to_set(map (fn r => MirTypes.GC.Map.apply'(gc_map, r)) gc)
d3708 10
d3719 1
a3719 1
	    check_reg(MirTypes.GC.Map.apply'(gc_map, r))
d3721 1
a3721 1
	      check_reg(MirTypes.NonGC.Map.apply'(non_gc_map, r))
d3724 1
a3724 1
	    check_reg(MirTypes.GC.Map.apply'(gc_map, r))
d3726 1
a3726 1
	      check_reg(MirTypes.NonGC.Map.apply'(non_gc_map, r))
d3821 3
@


1.2
log
@Compiled move, load/store, enter and rts (leaf only) and started on alloc
@
text
@d4 6
a9 3
# Revision 1.1  1994/09/15  17:07:14  jont
# new file
#
d275 1
a275 2
(*
    | last_opcode [elem as (I386_Assembly.BRANCH_ANNUL(I386_Assembly.BA, _),
d278 1
d317 3
a319 5
(*	  (I386_Assembly.BRANCH_ANNUL _, _, _) :: rest => rest
	| (operation, opt, comment) :: (I386_Assembly.BRANCH _, _, _) :: rest =>
	    (operation, opt, comment ^ " preceding BA removed") :: rest
	| _ :: (I386_Assembly.BRANCH_ANNUL(I386_Assembly.BA, _), _, _) :: rest => rest
	| *)_ =>
d348 12
d381 2
d445 12
a456 12
      | do_fall_throughs(done, block,rest) =
	let
	  fun continues(tag, _) =
	    case proc_info_map tag of
	      Map.YES(_, t) => t
	    | _ => false

	  val (continuers,non_continuers) =
	    Lists.partition continues rest 
        in
          do_fall_throughs_with_continuers_calculated(done,block,continuers,non_continuers)
        end
d458 1
a458 1
      val (hd_block_list, tl_block_list) = case block_list of
d465 5
d472 1
a472 1
      tag_offsets(rest, disp + 4 * (Lists.length ho_list),
d507 8
d582 51
a632 1
		    fun do_opcode(*
d838 2
a839 1
		      | do_opcode*)((opcode, Option.ABSENT, comment), offset) =
d843 2
a844 3
		    val (opcodes_and_offsets, next) =
		      Lists.number_from(opcode_list, block_start, 4, fn x => x)

d854 1
a854 1
	    | do_linearise_sub(offset, ((tag, proc)(*,padded_name*)) :: rest) =
d893 11
a903 14
  fun move_reg(rd, rs) =
(*
    (I386_Assembly.ARITHMETIC_AND_LOGICAL
     (I386_Assembly.OR, rd, I386_Assembly.REG I386Types.G0, rs), absent, "")
*)
    Crash.unimplemented"move_reg"

  fun move_imm(rd, imm) =
(*
    (I386_Assembly.ARITHMETIC_AND_LOGICAL
     (I386_Assembly.OR, rd, I386_Assembly.IMM imm, I386Types.G0),
     absent, "")
*)
    Crash.unimplemented"move_imm"
d922 2
a923 1
     allow_fp_spare_slot   : bool (* Do we need a slot for float to int conversion? *)
d985 2
a986 1
		      allow_fp_spare_slot
d1101 1
a1101 1
      fun do_blocks(_, [], _, _, _, (*_, _, _, _,*) _) = []
d1116 2
a1117 1
		   allow_fp_spare_slot
d1121 2
a1122 1
		  fps_to_preserve
d1130 3
a1132 25
	  fun gp_check_range(MirTypes.GP_IMM_INT i, signed, pos_limit) =
	    check_range(i, signed, pos_limit div 4)
	    | gp_check_range(MirTypes.GP_IMM_ANY i, signed, pos_limit) =
	      check_range(i, signed, pos_limit)
	    | gp_check_range(MirTypes.GP_IMM_SYMB symb, signed, pos_limit) =
	      check_range(symbolic_value symb, signed, pos_limit)
	    | gp_check_range _ =
	      Crash.impossible"gp_check_range of non-immediate" 

	  fun split_int(MirTypes.GP_IMM_INT i) =
	    (((i div (4096 div 4)) mod (256 * 256 * 16))*4,
	     (i mod (4096 div 4))*4)
	    | split_int(MirTypes.GP_IMM_ANY i) =
	      (((i div 4096) mod (256 * 256 * 16))*4, i mod 4096)
	    | split_int(MirTypes.GP_IMM_SYMB symb) =
	      let
		val i = symbolic_value symb
	      in
		(((i div 4096) mod (256 * 256 * 16))*4, i mod 4096)
	      end
	    | split_int _ = Crash.impossible"split_int of non-immediate" 

	  fun assemble_large_number(MirTypes.GP_IMM_INT i) = (i, 0)
	    | assemble_large_number(MirTypes.GP_IMM_ANY i) = (i div 4, i mod 4)
	    | assemble_large_number(MirTypes.GP_IMM_SYMB symb) =
d1138 2
a1139 2
	    | assemble_large_number _ =
	      Crash.impossible"assemble_large_number:non-immediate"
d1143 1
a1143 1
	      val (i, j) = assemble_large_number gp_operand
a1147 43
	  fun load_large_number_into_register (reg, gp_operand) =
	    case split_int gp_operand of
(*
	      (0, 0) =>
                [(I386_Assembly.ARITHMETIC_AND_LOGICAL
                  (I386_Assembly.OR, reg,
                   I386_Assembly.REG I386Types.G0, I386Types.G0),
                  absent, "")]
	    | (0, lo) =>
                [(I386_Assembly.ARITHMETIC_AND_LOGICAL
                  (I386_Assembly.OR, reg,
                   I386_Assembly.IMM lo, I386Types.G0),
                  absent, "")]
	    | (hi, 0) =>
                [(I386_Assembly.SetHI
                  (I386_Assembly.SETHI, reg, hi),
                  absent, "Get high part")]
	    | (hi, lo) =>
                [(I386_Assembly.SetHI
                  (I386_Assembly.SETHI, reg, hi),
                  absent, "Get high part"),
                 (I386_Assembly.ARITHMETIC_AND_LOGICAL
                  (I386_Assembly.ADD, reg,
                   I386_Assembly.IMM lo, reg),
                  absent, "Add in low part")]
*)
	      _ => Crash.unimplemented"load_large_number_into_register"

	  fun make_imm_format3(MirTypes.GP_IMM_INT i) =
	    make_imm_fault(4 * i, true, arith_imm_limit)
	    | make_imm_format3(MirTypes.GP_IMM_ANY i) =
	      make_imm_fault(i, true, arith_imm_limit)
	    | make_imm_format3(MirTypes.GP_IMM_SYMB symb) =
	      make_imm_fault(symbolic_value symb, true, arith_imm_limit)
	    | make_imm_format3 _ = Crash.impossible"make_imm of non-immediate"

	  fun make_imm_for_store(MirTypes.GP_IMM_ANY i) =
	    make_imm_fault(i, true, arith_imm_limit)
	    | make_imm_for_store(MirTypes.GP_IMM_SYMB symb) =
	      make_imm_fault(symbolic_value symb, true, arith_imm_limit)
	    | make_imm_for_store _ =
	      Crash.impossible"make_imm_for_store(bad value)"

d1206 14
d1225 6
d1274 1
a1274 1
	      val (result_list, opcode_list, new_blocks, new_final_result) =
a1275 1
(*
d1278 2
d1375 5
a1379 2
		| MirTypes.BINARY(binary_op, reg_operand, gp_operand,
				  gp_operand') =>
d1512 1
a1512 1
		  MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand) =>
d1525 4
a1528 1
				(opcode, [I386_Assembly.r32 rd, I386_Assembly.r32 rs1]),
d1532 14
a1545 4
			  [(I386_Assembly.OPCODE
			    (opcode, [I386_Assembly.r32 rd,
				      I386_Assembly.imm32(assemble_large_number gp_operand)]),
			    absent, "")]
d1547 1
a1547 1
		      (code_list, opcode_list, block_list, final_result)
d1549 2
a1551 1
		| MirTypes.UNARY(MirTypes.NOT, reg_operand, gp_operand) =>
d1570 1
d1572 2
d1579 1
d1582 2
d1609 1
d1611 2
d1659 1
d1662 2
a1663 1
		  let
d1698 1
d1701 2
d1745 1
d1748 2
a1801 6
		    val rd = if store_word then rd else I386Types.byte_reg_name rd
		    val operands =
		      if load then
			[con1 rd, con2 r_m]
		      else
			[con2 r_m, con1 rd]
d1803 31
a1833 2
		    ([(I386_Assembly.OPCODE(store, operands), absent, "")],
		     opcode_list, block_list, final_result)
a1834 1
(*
d1837 2
d1941 1
d1943 2
d1985 1
d1987 2
d2082 1
d2085 13
a2097 13
		      MirTypes.REG reg =>
			[(I386_Assembly.JUMP_AND_LINK
			  (I386_Assembly.JMPL, I386Types.G0,
			   I386_Assembly.IMM 0, lookup_reg_operand reg,
                           Debugger_Types.null_backend_annotation),
			  absent, "Branch indirect"),
			 I386_Assembly.nop]
		    | MirTypes.TAG tag =>
			[(I386_Assembly.BRANCH_ANNUL(I386_Assembly.BA, 0),
			  Option.PRESENT tag, "Branch relative"),
			 I386_Assembly.nop]),
			opcode_list, block_list, final_result)
		| MirTypes.TEST(cond_branch, tag, gp_operand,
d2101 12
a2112 25
		      MirTypes.BNT => I386_Assembly.BE
		    | MirTypes.BTA => I386_Assembly.BNE
		    | MirTypes.BEQ => I386_Assembly.BE
		    | MirTypes.BNE => I386_Assembly.BNE
		    | MirTypes.BHI => I386_Assembly.BGU
		    | MirTypes.BLS => I386_Assembly.BLEU
		    | MirTypes.BHS => I386_Assembly.BCC
		    | MirTypes.BLO => I386_Assembly.BCS
		    | MirTypes.BGT => I386_Assembly.BG
		    | MirTypes.BLE => I386_Assembly.BLE
		    | MirTypes.BGE => I386_Assembly.BGE
		    | MirTypes.BLT => I386_Assembly.BL
		    val (branch, gp_op, gp_op') =
		      case gp_operand of
			MirTypes.GP_GC_REG _ =>
			  (branch, gp_operand, gp_operand')
		      | MirTypes.GP_NON_GC_REG _ =>
			  (branch, gp_operand, gp_operand')
		      | _ => (I386_Assembly.reverse_branch branch,
			      gp_operand', gp_operand)
		    val _ = case gp_op of
		      MirTypes.GP_GC_REG _ => ()
		    | MirTypes.GP_NON_GC_REG _ => ()
		    | _ => Crash.impossible"Two constant operands to test"
		    val rs1 = lookup_gp_operand gp_op
d2114 3
a2116 3
		      MirTypes.BTA => I386_Assembly.ANDCC
		    | MirTypes.BNT => I386_Assembly.ANDCC
		    | _ => I386_Assembly.SUBCC
d2118 1
a2118 2
		    if is_reg gp_op' orelse
		      gp_check_range(gp_op', true, arith_imm_limit) then
d2120 8
a2127 1
			val reg_or_imm =
d2129 2
a2130 1
			    I386_Assembly.REG(lookup_gp_operand gp_op')
d2132 25
a2156 1
			    make_imm_format3 gp_op'
d2158 7
a2164 8
			([(I386_Assembly.ARITHMETIC_AND_LOGICAL
			   (test_instr, I386Types.G0,
			    reg_or_imm, rs1),
			   absent, "Do the test"),
			  (I386_Assembly.BRANCH_ANNUL(branch, 0),
			   Option.PRESENT tag, "Do the branch"),
			  I386_Assembly.nop],
			opcode_list, block_list, final_result)
d2171 2
a2172 2
				      gp_op') ::
		       MirTypes.TEST(cond_branch, tag, gp_op,
d2174 1
a2174 1
		       opcode_list, block_list, final_result)
d2176 1
d2179 2
d2202 4
a2205 1
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.REG reg_operand,debug_information) =>
d2213 4
a2216 1
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.TAG tag,_) =>
d2222 1
d2225 12
a2236 9
		      val restore =
			if needs_preserve then
			  (I386_Assembly.SAVE_AND_RESTORE
			   (I386_Assembly.RESTORE, I386Types.G0,
			    I386_Assembly.IMM 0, I386Types.G0),
			   absent,
			   "Restore in delay slot")
			else
			  I386_Assembly.nop
d2238 36
a2273 12
		      ([(case bl_dest of
			   MirTypes.REG reg =>
			     (I386_Assembly.JUMP_AND_LINK
			      (I386_Assembly.JMPL, I386Types.G0,
			       I386_Assembly.IMM Tags.CODE_OFFSET, lookup_reg_operand reg,
                               Debugger_Types.null_backend_annotation),
			      absent, "Branch indirect")
			 | MirTypes.TAG tag =>
			     (I386_Assembly.BRANCH(I386_Assembly.BA, 0),
			      Option.PRESENT tag, "Branch relative (tail call)")
			     ), restore],
		      opcode_list, block_list, final_result)
d2276 2
d2324 1
d2327 2
d2352 1
d2354 1
a2354 2
		     ([], opcode_list, block_list, final_result)
*)
d2359 6
a2364 8

(*
                       val (link, gc_entry) =
                         if needs_preserve then
                           (I386Types.lr, I386_Assembly.IMM (4 * Implicit_Vector.gc))
                         else
                           (I386Types.gc2, I386_Assembly.IMM (4 * Implicit_Vector.gc_leaf))
*)
d2366 1
a2366 1
                       val allocation =
d2370 2
a2377 1
(*
a2379 2
*)
				       Crash.unimplemented"ALLOCATE not pair"
d2400 37
a2436 11
(*
				 if header = 0 then [] else
				   load_large_number_into_register
				   (I386Types.global, MirTypes.GP_IMM_ANY header) @@
				   [(I386_Assembly.LOAD_AND_STORE
				     (I386_Assembly.ST, I386Types.global, rd,
				      I386_Assembly.IMM (~primary)),
				     absent, "Initialise header")]
*)
				 []
			       val (high, low) = split_int (MirTypes.GP_IMM_ANY bytes)
d2438 71
a2508 1
			       if high = 0 then
d2542 1
a2542 2
				 [(I386_Assembly.OPCODE(I386_Assembly.nop, []), absent,
				   "Will be allocate code")]
a2543 1
(*
a2582 1
				 Crash.unimplemented"ALLOCATE not pair"
d2655 4
a2658 1
                       (allocation, opcode_list, block_list, final_result)
d2660 2
a2662 1
		 | MirTypes.ADR(adr, reg_operand, tag) =>
d2682 1
d2689 1
a2689 1
		    (trace_dummy_instructions, opcode_list, block_list, final_result)
d2692 2
d2743 43
a2785 1
		      Crash.unimplemented"do_everything:non-leaf procedeure"
d3008 1
a3008 1
		      ([], opcode_list, block_list, final_result)
d3012 36
a3047 14
		       Crash.unimplemented"do_everything:non-leaf procedeure"
(*
		       restore_fps @@
		       [(I386_Assembly.JUMP_AND_LINK
			 (I386_Assembly.JMPL, I386Types.G0,
			  I386_Assembly.IMM 8,
			  I386Types.after_preserve I386Types.lr,
			  Debugger_Types.null_backend_annotation),
			 absent, "Scheduled return"),
		       (I386_Assembly.SAVE_AND_RESTORE
			(I386_Assembly.RESTORE, I386Types.G0,
			 I386_Assembly.IMM 0,
			 I386Types.G0), absent, "Restore in the delay slot")]
*)
a3048 8
(*
		       [(I386_Assembly.JUMP_AND_LINK
			 (I386_Assembly.JMPL, I386Types.G0,
			  I386_Assembly.IMM 8, I386Types.lr,
			  Debugger_Types.null_backend_annotation),
			 absent, "Ordinary return"),
			I386_Assembly.nop]
*)
d3051 1
a3051 2
		       opcode_list, block_list, final_result)
(*
d3053 1
a3053 1
		    ([], opcode_list, block_list, final_result)
d3055 2
d3062 1
d3064 2
d3103 1
d3107 2
d3233 71
d3305 1
a3312 5
(*
	  fun ch f s =
	    (Set.map f s; false) handle I386Types.NeedsPreserve => true
*)

d3323 1
a3323 3
            (* These need the extra slot for fp moves *)
            | check_instr (MirTypes.REAL _) = true
            | check_instr (MirTypes.FLOOR _) = true
d3473 2
a3474 5
	  fun move_first (_, []) =
	      Crash.impossible "move_first"
	    | move_first (L, (t, code) :: rest) =
	      if t = proc_tag then (t, code) :: (L @@ rest)
	      else move_first ((t, code) :: L, rest)
d3476 9
a3484 13
	  fun block_needs_fp_spare(MirTypes.BLOCK(_, opc_list)) =
	    let
	      fun opc_needs_fp_spare [] = false
		| opc_needs_fp_spare(MirTypes.REAL _ :: _) = true
		| opc_needs_fp_spare(MirTypes.FLOOR _ :: _) = true
		| opc_needs_fp_spare(_ :: rest) = opc_needs_fp_spare rest
	    in
	      opc_needs_fp_spare opc_list
	    end

	  fun proc_needs_fp_spare [] = false
	    | proc_needs_fp_spare(block :: block_list) =
	      block_needs_fp_spare block orelse proc_needs_fp_spare block_list
d3486 1
a3486 1
	  val needs_fp_spare = proc_needs_fp_spare block_list
d3500 4
a3503 1
	  val float_spill_size = case I386Types.fp_used of
d3510 2
a3511 9
	  val non_gc_spill_size =
	    if total_fp_size <> 0 andalso float_spill_size <> 4 andalso
	      non_gc_spill_size mod 2 <> 0 then
	      non_gc_spill_size + 1
	    (* Allow an extra word to get alignment for floats *)
	    else
	      non_gc_spill_size
	  (* non_gc_spill_size * 4 is now *)
	  (* double aligned ready for floats if necessary *)
d3513 2
a3514 1
	  val needs_preserve = needs_preserve orelse needs_fp_spare
d3516 1
a3516 2
	  val non_gc_stack_size =
	    non_gc_spill_size * 4 + float_spill_size * total_fp_size
d3518 1
a3518 4
	  val total = non_gc_stack_size + total_gc_size * 4
	  val non_gc_stack_size =
	    if total mod 8 = 0 then non_gc_stack_size else non_gc_stack_size + 4
	  (* Allow more non-gc space to get overall double alignment *)
d3521 1
a3521 1
	  val fp_save_offset = fp_spill_offset + fp_spill_size * float_spill_size
d3527 1
d3535 1
a3535 1
	     register_save_size = 64,
d3542 3
a3544 2
	     allow_fp_spare_slot = needs_fp_spare
	     }
d3648 1
a3648 1
	    move_first([], do_blocks(needs_preserve,
d3653 2
a3654 1
				     fps_to_preserve))
@


1.1
log
@new file
@
text
@d3 4
a6 1
$Log$
d59 2
d1073 18
d1216 1
a1216 1
		  val reg = Array.sub(table, reg)
d1218 5
a1222 5
(*
		  if needs_preserve then reg
		  else I386Types.after_restore reg
*)
		  reg
a1241 1
		  _ => Crash.unimplemented"do_everything"
d1473 2
a1474 1
		| MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand) =>
d1477 1
a1477 2
		      val opcode = I386_Assembly.OR
		      val imm = I386_Assembly.REG I386Types.G0
d1483 2
a1484 1
			    if rd = rs1 then [] (* Null move rn -> rn *)
d1486 3
a1488 2
			      [(I386_Assembly.ARITHMETIC_AND_LOGICAL
				(opcode, rd, imm, rs1), absent, "")]
d1491 4
a1494 12
			  if gp_check_range(gp_operand, true,
					    arith_imm_limit) then
			    let
			      val imm = case make_imm_format3 gp_operand of
				I386_Assembly.IMM 0 => imm (* MOVE 0 case *)
			      | non_zero_imm => non_zero_imm
			    in
			      [(I386_Assembly.ARITHMETIC_AND_LOGICAL
				(opcode, rd, imm, I386Types.G0), absent, "")]
			    end
			  else
			    load_large_number_into_register(rd, gp_operand)
d1498 1
d1703 1
d1707 30
a1736 65
		    val (shuffle, new_opcode_list) =
		      if is_reg gp_operand orelse
			gp_check_range(gp_operand, true, arith_imm_limit) then
			(
			 case opcode_list of
			   (store_op as MirTypes.STOREOP(MirTypes.LD, MirTypes.GC_REG g,
							 c_reg as MirTypes.GC_REG c,
							 MirTypes.GP_IMM_ANY ~1)) ::
			   (tail as (MirTypes.BRANCH_AND_LINK _ :: _)) =>
			     if g = MirRegisters.global andalso c = MirRegisters.caller_closure
			       andalso reg_operand' <> c_reg andalso reg_operand <> c_reg then
				 (true, store_op :: opcode :: tail)
			     else
			       (false, [])
			 | (store_op as MirTypes.STOREOP(MirTypes.LD, MirTypes.GC_REG g,
							 c_reg as MirTypes.GC_REG c,
							 MirTypes.GP_IMM_ANY ~1)) ::
			   (tail as (MirTypes.TAIL_CALL _ :: _)) =>
			     if (not needs_preserve) andalso
			       g = MirRegisters.global andalso c = MirRegisters.callee_closure
			       andalso reg_operand' <> c_reg andalso reg_operand <> c_reg then
			       (true, store_op :: opcode :: tail)
			     else
			       (false, [])
		         | (move_op as MirTypes.UNARY(MirTypes.MOVE, c_reg as MirTypes.GC_REG c,
						      MirTypes.GP_GC_REG r)) ::
			   (store_op as MirTypes.STOREOP(MirTypes.LD, MirTypes.GC_REG g,
							 MirTypes.GC_REG c',
							 MirTypes.GP_IMM_ANY ~1)) ::
			   (tail as (MirTypes.BRANCH_AND_LINK _ :: _)) =>
			     let
			       val r_reg = MirTypes.GC_REG r
			     in
			       if g = MirRegisters.global andalso c = MirRegisters.caller_closure
				 andalso c' = c
				 andalso reg_operand' <> c_reg
				 andalso reg_operand' <> r_reg
				 andalso reg_operand <> c_reg
				 andalso reg_operand <> r_reg then
				 (true, move_op :: store_op :: opcode :: tail)
			       else
				 (false, [])
			     end
		         | (move_op as MirTypes.UNARY(MirTypes.MOVE, c_reg as MirTypes.GC_REG c,
						      MirTypes.GP_GC_REG r)) ::
			   (store_op as MirTypes.STOREOP(MirTypes.LD, MirTypes.GC_REG g,
							 MirTypes.GC_REG c',
							 MirTypes.GP_IMM_ANY ~1)) ::
			   (tail as (MirTypes.TAIL_CALL _ :: _)) =>
			     let
			       val r_reg = MirTypes.GC_REG r
			     in
			       if (not needs_preserve) andalso
				 g = MirRegisters.global andalso c = MirRegisters.callee_closure
				 andalso c' = c
				 andalso reg_operand' <> c_reg
				 andalso reg_operand' <> r_reg
				 andalso reg_operand <> c_reg
				 andalso reg_operand <> r_reg then
				 (true, move_op :: store_op :: opcode :: tail)
			       else
				 (false, [])
			     end
			 | _ => (false, [])
			     )
d1738 1
a1738 2
			(false, [])
		    (* Don't bother if the store will use global, cos it won't work *)
d1740 2
a1741 37
		    if shuffle then
		      ([], new_opcode_list, block_list, final_result)
		    else
		      let
			val rd = lookup_reg_operand reg_operand
			val rs1 = lookup_reg_operand reg_operand'
			val store = case store_op of
			  MirTypes.LD => I386_Assembly.LD
			| MirTypes.ST => I386_Assembly.ST
			| MirTypes.LDB => I386_Assembly.LDUB
			| MirTypes.STB => I386_Assembly.STB
			| MirTypes.LDREF => I386_Assembly.LD
			| MirTypes.STREF => I386_Assembly.ST
		      in
			if is_reg gp_operand orelse
			  gp_check_range(gp_operand, true, arith_imm_limit) then
			  let
			    val reg_or_imm =
			      if is_reg gp_operand then
				I386_Assembly.REG(lookup_gp_operand gp_operand)
			      else make_imm_for_store gp_operand
			  in
			    ([(I386_Assembly.LOAD_AND_STORE(store, rd, rs1,
							     reg_or_imm), absent, "")],
			     opcode_list, block_list, final_result)
			  end
			else
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  MirTypes.GC_REG MirRegisters.global,
					  gp_operand) ::
			   MirTypes.STOREOP(store_op, reg_operand,
					    reg_operand',
					    MirTypes.GP_GC_REG
					    MirRegisters.global) ::
			   opcode_list, block_list, final_result)
		      end
d1743 1
d2195 1
d2201 1
d2207 1
d2210 87
a2296 76
                         case gp_operand

                           of MirTypes.GP_IMM_INT size =>
                              let
                                val (bytes, primary, aligned, header) =
                                  case allocate
                                    of MirTypes.ALLOC =>
                                       if size = 2 then
                                         (8, Tags.PAIRPTR, true, 0)
                                       else
                                         (8 * ((size+2) div 2), Tags.POINTER,
					  size mod 2 <> 0, 64*size+Tags.RECORD)
                                     | MirTypes.ALLOC_STRING =>
					 (((size+12) div 8) * 8,
					  Tags.POINTER, true, 64*size+Tags.STRING)
                                     | MirTypes.ALLOC_REAL =>
                                       (case I386Types.fp_used
                                          of I386Types.single   => Crash.unimplemented "ALLOC_REAL single"
                                           | I386Types.extended => Crash.unimplemented "ALLOC_REAL extended"
                                           | I386Types.double   =>
					       (16, Tags.POINTER, true,
						64*(16 - 4) + Tags.BYTEARRAY))
                                     | MirTypes.ALLOC_REF  =>
					 (8 + 8*((size+2) div 2),
					  Tags.REFPTR, size mod 2 <> 0, 64*size+Tags.ARRAY)
                                     | MirTypes.ALLOC_BYTEARRAY =>
					 (((size+12) div 8) * 8, Tags.REFPTR, true,
					  64*size+Tags.BYTEARRAY)

                                val header_code =
                                  if header = 0 then [] else
				    load_large_number_into_register
				    (I386Types.global, MirTypes.GP_IMM_ANY header) @@
                                        [(I386_Assembly.LOAD_AND_STORE
                                          (I386_Assembly.ST, I386Types.global, rd,
					   I386_Assembly.IMM (~primary)),
                                          absent, "Initialise header")]

                                val (high, low) = split_int (MirTypes.GP_IMM_ANY bytes)
                              in
                                if high = 0 then
                                  (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                   (I386_Assembly.ADD, I386Types.gc1, I386_Assembly.IMM bytes, I386Types.gc1),
                                   absent, "Attempt to allocate some heap") ::
                                  (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                   (I386_Assembly.SUBCC, I386Types.G0, I386_Assembly.REG I386Types.gc2, I386Types.gc1),
                                   absent, "Is a GC required?") ::
                                  (I386_Assembly.BRANCH_ANNUL
                                   (I386_Assembly.BL, 6),
                                   absent, "Skip call to GC if not") ::
                                  (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                   (I386_Assembly.ADD, rd, I386_Assembly.IMM (primary - bytes), I386Types.gc1),
                                   absent, "Tag result with primary") ::
                                  (I386_Assembly.LOAD_AND_STORE
                                   (I386_Assembly.LD, I386Types.global, I386Types.implicit, gc_entry),
                                   absent, "Fetch entry point of GC") ::
                                  (I386_Assembly.JUMP_AND_LINK
                                   (I386_Assembly.JMPL, link, I386_Assembly.IMM 0, I386Types.global,
                                    Debugger_Types.null_backend_annotation),
                                   absent, "Call GC") ::
                                  (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                   (I386_Assembly.OR, I386Types.global, I386_Assembly.IMM bytes, I386Types.G0),
                                   absent, "Size argument for GC") ::
                                  (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                   (I386_Assembly.ADD, rd, I386_Assembly.IMM primary, I386Types.global),
                                   absent, "Tag result with primary") ::
                                  (if aligned then
                                     header_code
                                   else
                                     (I386_Assembly.LOAD_AND_STORE
                                      (I386_Assembly.ST, I386Types.G0, rd, I386_Assembly.IMM (bytes - primary - 4)),
                                      absent, "Zero unaligned extra word") :: header_code)
                                else
				  (load_large_number_into_register
				   (rd, MirTypes.GP_IMM_ANY bytes)) @@
                                  ((I386_Assembly.ARITHMETIC_AND_LOGICAL
d2299 106
a2404 102
                                  (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                   (I386_Assembly.SUBCC, I386Types.G0, I386_Assembly.REG I386Types.gc2, I386Types.gc1),
                                   absent, "Is a GC required?") ::
                                  (I386_Assembly.BRANCH_ANNUL
                                   (I386_Assembly.BL, 5),
                                   absent, "Skip call to GC if not") ::
                                  (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                   (I386_Assembly.SUB, I386Types.global, I386_Assembly.REG rd, I386Types.gc1),
                                   absent, "Calculate address of new object") ::
                                  (I386_Assembly.LOAD_AND_STORE
                                   (I386_Assembly.LD, I386Types.global, I386Types.implicit, gc_entry),
                                   absent, "Fetch entry point of GC") ::
                                  (I386_Assembly.JUMP_AND_LINK
                                   (I386_Assembly.JMPL, link, I386_Assembly.IMM 0, I386Types.global,
                                    Debugger_Types.null_backend_annotation),
                                   absent, "Call GC") ::
                                  (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                   (I386_Assembly.OR, I386Types.global, I386_Assembly.REG rd, I386Types.G0),
                                   absent, "Size argument for GC") ::
                                  (if aligned then
                                     (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                      (I386_Assembly.ADD, rd, I386_Assembly.IMM primary, I386Types.global),
                                      absent, "Tag object with primary") :: header_code
                                   else
                                     (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                      (I386_Assembly.ADD, rd, I386_Assembly.REG rd, I386Types.global),
                                      absent, "Calculate end of object") ::
                                     (I386_Assembly.LOAD_AND_STORE
                                      (I386_Assembly.ST, I386Types.G0, rd, I386_Assembly.IMM (~4)),
                                      absent, "Zero unaligned extra word") ::
                                     (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                      (I386_Assembly.ADD, rd, I386_Assembly.IMM primary, I386Types.global),
                                      absent, "Tag object with primary") :: header_code))
                              end

                            | MirTypes.GP_GC_REG reg =>
                                let
                                  val (primary, secondary, length_code) =
                                    case allocate
                                      of MirTypes.ALLOC        => Crash.unimplemented "ALLOC variable size"
                                       | MirTypes.ALLOC_STRING => Crash.unimplemented "ALLOC_STRING variable size"
                                       | MirTypes.ALLOC_REAL   => Crash.unimplemented "ALLOC_REAL variable size"
                                       | MirTypes.ALLOC_REF    =>
                                         (Tags.REFPTR, Tags.ARRAY,
                                          [(I386_Assembly.ARITHMETIC_AND_LOGICAL
                                            (I386_Assembly.ADD, rd, I386_Assembly.IMM (12+7), lookup_reg(MirTypes.GC.unpack reg, gc_array)),
                                            absent, "Calculate length of Array")])                                
                                       | MirTypes.ALLOC_BYTEARRAY =>
                                         (Tags.REFPTR, Tags.BYTEARRAY,
                                          [(I386_Assembly.ARITHMETIC_AND_LOGICAL
                                            (I386_Assembly.SRL, rd, I386_Assembly.IMM 2, lookup_reg(MirTypes.GC.unpack reg, gc_array)),
                                            absent, "Calculate length of ByteArray"),
                                           (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                            (I386_Assembly.ADD, rd, I386_Assembly.IMM (4+7), lookup_reg(MirTypes.GC.unpack reg, gc_array)),
                                            absent, "")])
                                in
                                  length_code @@
                                  ((I386_Assembly.ARITHMETIC_AND_LOGICAL
                                     (I386_Assembly.ANDN, rd, I386_Assembly.IMM 7, rd),
                                     absent, "Calculate aligned size in bytes") ::
                                    (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                     (I386_Assembly.ADD, I386Types.gc1, I386_Assembly.REG rd, I386Types.gc1),
                                     absent, "Attempt to allocate some heap") ::
                                    (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                     (I386_Assembly.SUBCC, I386Types.G0, I386_Assembly.REG I386Types.gc2, I386Types.gc1),
                                     absent, "Is a GC required?") ::
                                    (I386_Assembly.BRANCH_ANNUL
                                     (I386_Assembly.BL, 5),
                                     absent, "Skip call to GC if not") ::
                                    (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                     (I386_Assembly.SUB, I386Types.global, I386_Assembly.REG rd, I386Types.gc1),
                                     absent, "Calculate address of new object") ::
                                    (I386_Assembly.LOAD_AND_STORE
                                     (I386_Assembly.LD, I386Types.global, I386Types.implicit, gc_entry),
                                     absent, "Fetch entry point of GC") ::
                                    (I386_Assembly.JUMP_AND_LINK
                                     (I386_Assembly.JMPL, link, I386_Assembly.IMM 0, I386Types.global,
                                      Debugger_Types.null_backend_annotation),
                                     absent, "Call GC") ::
                                    (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                     (I386_Assembly.OR, I386Types.global, I386_Assembly.REG rd, I386Types.G0),
                                     absent, "Size argument for GC") ::
                                    (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                     (I386_Assembly.ADD, rd, I386_Assembly.REG rd, I386Types.global),
                                     absent, "Calculate end of object") ::
                                    (I386_Assembly.LOAD_AND_STORE
                                     (I386_Assembly.ST, I386Types.G0, rd, I386_Assembly.IMM (~4)),
                                     absent, "Zero last word in case it's unaligned") ::
                                    (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                     (I386_Assembly.ADD, rd, I386_Assembly.IMM primary, I386Types.global),
                                     absent, "Tag object with primary") ::
                                    (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                     (I386_Assembly.SLL, I386Types.global, I386_Assembly.IMM 4, lookup_reg(MirTypes.GC.unpack reg, gc_array)),
                                     absent, "") ::
                                    (I386_Assembly.ARITHMETIC_AND_LOGICAL
                                     (I386_Assembly.ADD, I386Types.global, I386_Assembly.IMM secondary, I386Types.global),
                                     absent, "Calculate header tag") ::
                                    (I386_Assembly.LOAD_AND_STORE
                                     (I386_Assembly.ST, I386Types.global, rd, I386_Assembly.IMM (~primary)),
                                     absent, "Initialise header tag") :: nil)
                                end
                            | _ => Crash.impossible "Strange parameter to ALLOCATE"
d2408 1
d2484 1
d2487 2
d2708 1
d2714 2
d2727 1
d2729 1
d2735 4
a2738 1
			I386_Assembly.nop],
d2740 1
d2800 1
@
