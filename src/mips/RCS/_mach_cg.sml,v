head	1.121;
access;
symbols
	MLW_daveb_inline_1_4_99:1.121.1
	MLWorks_21c0_1999_03_25:1.121
	MLWorks_20c1_1998_08_20:1.121
	MLWorks_20c0_1998_08_04:1.121
	MLWorks_20b2c2_1998_06_19:1.121
	MLWorks_20b2_Windows_1998_06_12:1.121
	MLWorks_20b1c1_1998_05_07:1.121
	MLWorks_20b0_1998_04_07:1.120
	MLWorks_20b0_1998_03_20:1.120
	MLWorks_20m2_1998_02_16:1.119
	MLWorks_20m1_1997_10_23:1.117
	MLWorks_11r1:1.109.1.1.1.1.1
	MLWorks_workspace_97:1.117.2
	MLWorks_dt_wizard:1.117.1
	MLWorks_11c0_1997_09_09:1.109.1.1.1.1
	MLWorks_10r3:1.109.1.1.3
	MLWorks_10r2_551:1.109.1.1.2
	MLWorks_11:1.109.1.1.1
	MLWorks_1_0_r2c2_1997_07_28:1.109.1.1
	MLWorks_20m0_1997_06_20:1.115
	MLWorks_1_0_r2c2_1997_06_14:1.109.1.1
	MLWorks_1_0_r2c1_released_1997_05_23:1.109.1.1
	MLWorks_1_0_r2c1_1997_05_12:1.109.1
	MLWorks_BugFix_1997_04_24:1.109
	MLWorks_1_0_r2_Win32_1997_04_11:1.109
	MLWorks_1_0_r2_Unix_1997_04_04:1.109
	MLWorks_1_0_1_ULTRASPARC_1997_02_24:1.104.1.1.1
	MLWorks_gui_1996_12_18:1.104.2
	MLWorks_1_0_Win32_1996_12_17:1.104.1
	MLWorks_1_0_Irix_1996_11_28_released_1996_12_17:1.103.1.1.1.2
	MLWorks_1_0_Unix_1996_11_14_released_1996_12_17:1.103.1.1
	MLWorks_1_0_Irix_1996_11_28:1.103.1.1.1
	MLWorks_1_0_Win32_1996_11_22:1.103.2
	MLWorks_1_0_Unix_1996_11_14:1.103.1
	MLWorks_Open_Beta2_1996_10_11:1.100.2
	MLWorks_License_dev:1.100.1
	MLWorks_1_open_beta_1996_09_13:1.99.1
	MLWorks_Open_Beta_1996_08_22:1.99
	MLWorks_Beta_1996_07_02:1.95
	MLWorks_Beta_1996_06_07:1.95
	MLWorks_Beta_1996_06_06:1.95
	MLWorks_Beta_1996_06_05:1.95
	MLWorks_Beta_1996_06_03:1.95
	MLWorks_Beta_1996_05_31:1.95
	MLWorks_Beta_1996_05_30:1.94
	ML_beta_release_12/08/94:1.36
	ML_beta_release_03/08/94:1.36
	ML_revised_beta_release_25/05/94:1.17
	ML_final_beta_release_02/03/94:1.8
	mlworks-28-01-1994:1.3;
locks; strict;
comment	@ * @;


1.121
date	98.04.23.10.54.57;	author mitchell;	state Exp;
branches
	1.121.1.1;
next	1.120;

1.120
date	98.02.13.15.35.20;	author jont;	state Exp;
branches;
next	1.119;

1.119
date	98.01.30.09.48.00;	author johnh;	state Exp;
branches;
next	1.118;

1.118
date	97.11.13.11.19.32;	author jont;	state Exp;
branches;
next	1.117;

1.117
date	97.08.08.09.49.42;	author jont;	state Exp;
branches
	1.117.1.1
	1.117.2.1;
next	1.116;

1.116
date	97.08.01.14.02.13;	author jont;	state Exp;
branches;
next	1.115;

1.115
date	97.06.12.14.46.46;	author matthew;	state Exp;
branches;
next	1.114;

1.114
date	97.06.12.14.34.12;	author matthew;	state Exp;
branches;
next	1.113;

1.113
date	97.05.30.11.56.48;	author jont;	state Exp;
branches;
next	1.112;

1.112
date	97.05.27.11.16.53;	author daveb;	state Exp;
branches;
next	1.111;

1.111
date	97.05.22.13.37.02;	author matthew;	state Exp;
branches;
next	1.110;

1.110
date	97.05.06.09.51.40;	author jont;	state Exp;
branches;
next	1.109;

1.109
date	97.04.01.12.23.59;	author daveb;	state Exp;
branches
	1.109.1.1;
next	1.108;

1.108
date	97.03.25.11.28.45;	author matthew;	state Exp;
branches;
next	1.107;

1.107
date	97.01.29.10.47.47;	author matthew;	state Exp;
branches;
next	1.106;

1.106
date	97.01.24.14.46.13;	author matthew;	state Exp;
branches;
next	1.105;

1.105
date	97.01.16.16.34.18;	author matthew;	state Exp;
branches;
next	1.104;

1.104
date	96.12.05.09.29.02;	author stephenb;	state Exp;
branches
	1.104.1.1
	1.104.2.1;
next	1.103;

1.103
date	96.11.06.11.11.08;	author matthew;	state Exp;
branches
	1.103.1.1
	1.103.2.1;
next	1.102;

1.102
date	96.11.04.15.28.00;	author jont;	state Exp;
branches;
next	1.101;

1.101
date	96.10.23.10.36.25;	author jont;	state Exp;
branches;
next	1.100;

1.100
date	96.09.27.12.33.59;	author matthew;	state Exp;
branches
	1.100.1.1
	1.100.2.1;
next	1.99;

1.99
date	96.08.16.17.57.49;	author io;	state Exp;
branches
	1.99.1.1;
next	1.98;

1.98
date	96.08.08.16.58.40;	author jont;	state Exp;
branches;
next	1.97;

1.97
date	96.08.01.16.40.33;	author jont;	state Exp;
branches;
next	1.96;

1.96
date	96.08.01.12.59.07;	author jont;	state Exp;
branches;
next	1.95;

1.95
date	96.05.30.12.43.18;	author daveb;	state Exp;
branches;
next	1.94;

1.94
date	96.05.17.09.41.03;	author matthew;	state Exp;
branches;
next	1.93;

1.93
date	96.05.14.10.41.14;	author matthew;	state Exp;
branches;
next	1.92;

1.92
date	96.05.08.14.32.24;	author matthew;	state Exp;
branches;
next	1.91;

1.91
date	96.05.07.16.54.14;	author jont;	state Exp;
branches;
next	1.90;

1.90
date	96.05.01.12.07.50;	author jont;	state Exp;
branches;
next	1.89;

1.89
date	96.04.29.14.51.39;	author matthew;	state Exp;
branches;
next	1.88;

1.88
date	96.03.28.18.16.14;	author jont;	state Exp;
branches;
next	1.87;

1.87
date	96.03.21.15.22.25;	author matthew;	state Exp;
branches;
next	1.86;

1.86
date	96.02.05.11.38.32;	author jont;	state Exp;
branches;
next	1.85;

1.85
date	96.01.30.14.26.59;	author jont;	state Exp;
branches;
next	1.84;

1.84
date	96.01.29.18.12.43;	author jont;	state Exp;
branches;
next	1.83;

1.83
date	95.12.22.13.26.43;	author jont;	state Exp;
branches;
next	1.82;

1.82
date	95.11.22.10.56.12;	author jont;	state Exp;
branches;
next	1.81;

1.81
date	95.11.21.15.53.53;	author jont;	state Exp;
branches;
next	1.80;

1.80
date	95.11.21.12.05.32;	author jont;	state Exp;
branches;
next	1.79;

1.79
date	95.09.22.15.59.50;	author jont;	state Exp;
branches;
next	1.78;

1.78
date	95.09.15.13.49.34;	author io;	state Exp;
branches;
next	1.77;

1.77
date	95.09.08.16.31.48;	author jont;	state Exp;
branches;
next	1.76;

1.76
date	95.09.08.13.30.20;	author io;	state Exp;
branches;
next	1.75;

1.75
date	95.08.18.13.32.43;	author io;	state Exp;
branches;
next	1.74;

1.74
date	95.08.10.16.00.10;	author io;	state Exp;
branches;
next	1.73;

1.73
date	95.08.09.20.03.22;	author io;	state Exp;
branches;
next	1.72;

1.72
date	95.07.28.15.14.10;	author io;	state Exp;
branches;
next	1.71;

1.71
date	95.07.25.15.50.23;	author jont;	state Exp;
branches;
next	1.70;

1.70
date	95.07.19.14.22.18;	author jont;	state Exp;
branches;
next	1.69;

1.69
date	95.07.10.15.57.19;	author jont;	state Exp;
branches;
next	1.68;

1.68
date	95.06.20.12.49.48;	author matthew;	state Exp;
branches;
next	1.67;

1.67
date	95.06.19.16.19.37;	author jont;	state Exp;
branches;
next	1.66;

1.66
date	95.06.15.15.03.09;	author jont;	state Exp;
branches;
next	1.65;

1.65
date	95.05.31.15.21.37;	author nickb;	state Exp;
branches;
next	1.64;

1.64
date	95.05.09.15.39.29;	author nickb;	state Exp;
branches;
next	1.63;

1.63
date	95.05.04.14.41.52;	author matthew;	state Exp;
branches;
next	1.62;

1.62
date	95.05.02.15.31.39;	author matthew;	state Exp;
branches;
next	1.61;

1.61
date	95.04.27.15.59.26;	author nickb;	state Exp;
branches;
next	1.60;

1.60
date	95.04.20.10.52.30;	author nickb;	state Exp;
branches;
next	1.59;

1.59
date	95.04.12.14.57.07;	author nickb;	state Exp;
branches;
next	1.58;

1.58
date	95.03.20.12.37.49;	author matthew;	state Exp;
branches;
next	1.57;

1.57
date	95.03.07.16.17.48;	author matthew;	state Exp;
branches;
next	1.56;

1.56
date	95.03.01.17.20.21;	author matthew;	state Exp;
branches;
next	1.55;

1.55
date	95.02.02.15.27.08;	author nickb;	state Exp;
branches;
next	1.54;

1.54
date	95.01.30.14.54.25;	author matthew;	state Exp;
branches;
next	1.53;

1.53
date	95.01.10.18.06.51;	author nickb;	state Exp;
branches;
next	1.52;

1.52
date	95.01.10.14.09.27;	author nickb;	state Exp;
branches;
next	1.51;

1.51
date	94.12.09.12.00.14;	author nickb;	state Exp;
branches;
next	1.50;

1.50
date	94.11.28.16.43.10;	author matthew;	state Exp;
branches;
next	1.49;

1.49
date	94.11.25.17.59.46;	author nickb;	state Exp;
branches;
next	1.48;

1.48
date	94.11.24.14.44.35;	author matthew;	state Exp;
branches;
next	1.47;

1.47
date	94.11.22.17.08.52;	author io;	state Exp;
branches;
next	1.46;

1.46
date	94.11.16.12.28.31;	author jont;	state Exp;
branches;
next	1.45;

1.45
date	94.11.15.12.14.50;	author matthew;	state Exp;
branches;
next	1.44;

1.44
date	94.11.09.16.33.57;	author io;	state Exp;
branches;
next	1.43;

1.43
date	94.11.08.19.22.30;	author io;	state Exp;
branches;
next	1.42;

1.42
date	94.11.02.12.37.27;	author matthew;	state Exp;
branches;
next	1.41;

1.41
date	94.10.24.14.21.57;	author matthew;	state Exp;
branches;
next	1.40;

1.40
date	94.10.05.13.42.27;	author jont;	state Exp;
branches;
next	1.39;

1.39
date	94.09.23.13.00.18;	author matthew;	state Exp;
branches;
next	1.38;

1.38
date	94.08.25.13.39.49;	author matthew;	state Exp;
branches;
next	1.37;

1.37
date	94.08.25.10.41.10;	author jont;	state Exp;
branches;
next	1.36;

1.36
date	94.07.28.16.27.52;	author jont;	state Exp;
branches;
next	1.35;

1.35
date	94.07.27.16.15.48;	author jont;	state Exp;
branches;
next	1.34;

1.34
date	94.07.25.14.17.17;	author matthew;	state Exp;
branches;
next	1.33;

1.33
date	94.07.22.13.29.45;	author jont;	state Exp;
branches;
next	1.32;

1.32
date	94.07.15.16.30.07;	author jont;	state Exp;
branches;
next	1.31;

1.31
date	94.07.15.14.22.18;	author io;	state Exp;
branches;
next	1.30;

1.30
date	94.07.15.13.11.33;	author jont;	state Exp;
branches;
next	1.29;

1.29
date	94.07.14.12.28.14;	author jont;	state Exp;
branches;
next	1.28;

1.28
date	94.07.14.10.12.36;	author io;	state Exp;
branches;
next	1.27;

1.27
date	94.07.12.12.19.16;	author jont;	state Exp;
branches;
next	1.26;

1.26
date	94.07.12.11.52.48;	author jont;	state Exp;
branches;
next	1.25;

1.25
date	94.07.07.14.08.36;	author io;	state Exp;
branches;
next	1.24;

1.24
date	94.07.07.13.12.39;	author io;	state Exp;
branches;
next	1.23;

1.23
date	94.06.24.14.17.43;	author jont;	state Exp;
branches;
next	1.22;

1.22
date	94.06.16.18.36.03;	author sml;	state Exp;
branches;
next	1.21;

1.21
date	94.06.16.18.11.55;	author io;	state Exp;
branches;
next	1.20;

1.20
date	94.06.16.15.27.54;	author io;	state Exp;
branches;
next	1.19;

1.19
date	94.06.14.12.59.11;	author io;	state Exp;
branches;
next	1.18;

1.18
date	94.06.13.12.13.29;	author io;	state Exp;
branches;
next	1.17;

1.17
date	94.05.25.11.40.22;	author jont;	state Exp;
branches;
next	1.16;

1.16
date	94.05.25.10.23.24;	author jont;	state Exp;
branches;
next	1.15;

1.15
date	94.05.25.09.44.04;	author jont;	state Exp;
branches;
next	1.14;

1.14
date	94.03.18.18.18.42;	author jont;	state Exp;
branches;
next	1.13;

1.13
date	94.03.11.16.21.06;	author jont;	state Exp;
branches;
next	1.12;

1.12
date	94.03.10.12.53.19;	author jont;	state Exp;
branches;
next	1.11;

1.11
date	94.03.09.10.39.27;	author jont;	state Exp;
branches;
next	1.10;

1.10
date	94.03.04.12.40.46;	author jont;	state Exp;
branches;
next	1.9;

1.9
date	94.03.04.11.08.24;	author jont;	state Exp;
branches;
next	1.8;

1.8
date	94.03.01.17.56.52;	author jont;	state Exp;
branches;
next	1.7;

1.7
date	94.03.01.17.35.07;	author nickh;	state Exp;
branches;
next	1.6;

1.6
date	94.03.01.14.30.44;	author io;	state Exp;
branches;
next	1.5;

1.5
date	94.02.23.18.10.11;	author jont;	state Exp;
branches;
next	1.4;

1.4
date	94.02.22.12.43.53;	author io;	state Exp;
branches;
next	1.3;

1.3
date	93.12.20.14.53.36;	author io;	state Exp;
branches;
next	1.2;

1.2
date	93.11.17.13.42.01;	author io;	state Exp;
branches;
next	1.1;

1.1
date	93.10.28.14.31.01;	author simon;	state Exp;
branches;
next	;

1.99.1.1
date	96.09.13.11.19.32;	author hope;	state Exp;
branches;
next	;

1.100.1.1
date	96.10.07.16.09.25;	author hope;	state Exp;
branches;
next	;

1.100.2.1
date	96.10.17.11.27.41;	author hope;	state Exp;
branches;
next	;

1.103.1.1
date	96.11.14.12.53.17;	author hope;	state Exp;
branches
	1.103.1.1.1.1;
next	;

1.103.1.1.1.1
date	96.11.28.15.04.14;	author hope;	state Exp;
branches;
next	1.103.1.1.1.2;

1.103.1.1.1.2
date	96.12.05.13.39.42;	author stephenb;	state Exp;
branches;
next	;

1.103.2.1
date	96.11.22.18.12.16;	author hope;	state Exp;
branches;
next	;

1.104.1.1
date	96.12.17.17.50.46;	author hope;	state Exp;
branches
	1.104.1.1.1.1;
next	;

1.104.1.1.1.1
date	97.02.24.11.41.09;	author hope;	state Exp;
branches;
next	;

1.104.2.1
date	96.12.18.09.44.56;	author hope;	state Exp;
branches;
next	;

1.109.1.1
date	97.05.12.10.37.27;	author hope;	state Exp;
branches
	1.109.1.1.1.1
	1.109.1.1.2.1
	1.109.1.1.3.1;
next	;

1.109.1.1.1.1
date	97.07.28.18.22.40;	author daveb;	state Exp;
branches
	1.109.1.1.1.1.1.1;
next	;

1.109.1.1.1.1.1.1
date	97.10.07.11.48.19;	author jkbrook;	state Exp;
branches;
next	;

1.109.1.1.2.1
date	97.09.08.17.16.02;	author daveb;	state Exp;
branches;
next	;

1.109.1.1.3.1
date	97.09.09.14.11.58;	author daveb;	state Exp;
branches;
next	;

1.117.1.1
date	97.09.10.19.28.02;	author brucem;	state Exp;
branches;
next	;

1.117.2.1
date	97.09.11.20.57.59;	author daveb;	state Exp;
branches;
next	1.117.2.2;

1.117.2.2
date	97.11.20.17.09.08;	author daveb;	state Exp;
branches;
next	;

1.121.1.1
date	99.04.01.17.58.35;	author daveb;	state Exp;
branches;
next	;


desc
@Default RCS description
Copyright Harlequin Ltd., 1991
@


1.121
log
@[Bug #30349]
Fix non-unit non-final expression warnings
@
text
@(* mips Mach_Cg functor
 *
 * Copyright (c) 1993 Harlequin Ltd.
 *
 * Revison Log
 * $Log: _mach_cg.sml,v $
 * Revision 1.120  1998/02/13  15:35:20  jont
 * [Bug #70055]
 * Make sure argument saved whenever debugging or tracing are enabled
 *
 * Revision 1.119  1998/01/30  09:48:00  johnh
 * [Bug #30326]
 * Merge in change from branch MLWorks_workspace_97
 *
 * Revision 1.118  1997/11/13  11:19:32  jont
 * [Bug #30089]
 * Modify TIMER (from utils) to be INTERNAL_TIMER to keep bootstrap happy
 *
 * Revision 1.117.2.2  1997/11/20  17:09:08  daveb
 * [Bug #30326]
 *
 * Revision 1.117.2.1  1997/09/11  20:57:59  daveb
 * branched from trunk for label MLWorks_workspace_97
 *
 * Revision 1.117  1997/08/08  09:49:42  jont
 * [Bug #30243]
 * Remove tests for out of range shifts as we no longer generate them
 *
 * Revision 1.116  1997/08/01  14:02:13  jont
 * [Bug #30215]
 * Remove BIC, and replace by INTTAG instruction
 *
 * Revision 1.115  1997/06/12  14:46:46  matthew
 * [Bug #20071]
 *  Use 32 bit not for BIC
 *
 * Revision 1.114  1997/06/12  14:34:12  matthew
 * [Bug #20064]
 * Ensure r2 not overwritten in 32 bit int arithmetic.
 *
 * Revision 1.113  1997/05/30  11:56:48  jont
 * [Bug #30076]
 * Modifications to allow stack based parameter passing on the I386
 *
 * Revision 1.112  1997/05/27  11:16:53  daveb
 * [Bug #30136]
 * Removed early-mips-r4000 option.
 *
 * Revision 1.111  1997/05/22  13:37:02  matthew
 * Speeding up linearization
 *
 * Revision 1.110  1997/05/06  09:51:40  jont
 * [Bug #30088]
 * Get rid of MLWorks.Option
 *
 * Revision 1.109  1997/04/01  12:23:59  daveb
 * [Bug #1995]
 * Changed the definition of no_delay so that the mips_r4000 and early_mips_r4000
 * definitions are no longer linked.
 *
 * Revision 1.108  1997/03/25  11:28:45  matthew
 * Renamed R4000 option
 *
 * Revision 1.107  1997/01/29  10:47:47  matthew
 * Changing CGT code
 *
 * Revision 1.106  1997/01/24  14:46:13  matthew
 * Adding version options
 *
 * Revision 1.105  1997/01/16  16:34:18  matthew
 * Adding hardware multiply
 *
 * Revision 1.104  1996/12/05  09:29:02  stephenb
 * [Bug #1832]
 * event_check_code: add a couple of nops to avoid load hazzards
 * on an R3000.
 *
 * Revision 1.103  1996/11/06  11:11:08  matthew
 * [Bug #1728]
 * __integer becomes __int
 *
 * Revision 1.102  1996/11/04  15:28:00  jont
 * [Bug #1725]
 * Remove unsafe string operations introduced when String structure removed
 *
 * Revision 1.101  1996/10/23  10:36:25  jont
 * Remove basis.toplevel
 *
 * Revision 1.100  1996/09/27  12:33:59  matthew
 * Adding restore_fps in tail call code
 *
 * Revision 1.99  1996/08/16  17:57:49  io
 * basify mach_cg
 *
 * Revision 1.98  1996/08/08  16:58:40  jont
 * [bug 1535]
 * Ensure spill references are faulted if no stack specified
 *
 * Revision 1.97  1996/08/01  16:40:33  jont
 * Problems with parameters to set_proc_data being wrong order
 *
 * Revision 1.96  1996/08/01  12:59:07  jont
 * [Bug #1503]
 * Add field to FUNINFO to say if arg actually saved
 *
 * Revision 1.95  1996/05/30  12:43:18  daveb
 * The Ord exception is no longer at top level.
 *
 * Revision 1.94  1996/05/17  09:41:03  matthew
 * Moving Bits to Internal
 *
 * Revision 1.93  1996/05/14  10:41:14  matthew
 * Adding NOT32 MIR instruction
 *
 * Revision 1.92  1996/05/08  14:32:24  matthew
 * Fixing problem with untagged arithmetic.
 *
 * Revision 1.91  1996/05/07  16:54:14  jont
 * Array moving to MLWorks.Array
 *
 * Revision 1.90  1996/05/01  12:07:50  jont
 * String functions explode, implode, chr and ord now only available from String
 * io functions and types
 * instream, oustream, open_in, open_out, close_in, close_out, input, output and end_of_stream
 * now only available from MLWorks.IO
 *
 * Revision 1.89  1996/04/29  14:51:39  matthew
 * Removing checks for validity of FP results
 *
 * Revision 1.88  1996/03/28  18:16:14  jont
 * Fixing looping problems generating ADDW rn, rn, rm
 *
 * Revision 1.87  1996/03/21  15:22:25  matthew
 * Fixing problem with immediate shifts
 *
 * Revision 1.86  1996/02/05  11:38:32  jont
 * Add implemetations of ADDW and SUBW
 * These are like ADDV and SUBV, except that
 * they cannot use exception trapping adds etc because they are untagged
 * and also when they detect overflow they must clean
 * all registers involved in the operation
 *
 * Revision 1.85  1996/01/30  14:26:59  jont
 * Ensure that stack frame sizes are always double word aligned
 *
 * Revision 1.84  1996/01/29  18:12:43  jont
 * Fix bug in polymorphic equality sequence by decrementing instead
 *
 * Revision 1.83  1995/12/22  13:26:43  jont
 * Add extra field to procedure_parameters to contain old (pre register allocation)
 * spill sizes. This is for the i386, where spill assignment is done in the backend
 *
 * Revision 1.82  1995/11/22  10:56:12  jont
 * Tidy up some missing constructors in BINARY code generation
 *
 * Revision 1.81  1995/11/21  15:53:53  jont
 * Fix bugs in xor (and others) with immediate negative constants
 *
 * Revision 1.80  1995/11/21  12:05:32  jont
 * Modification for improved runtime env spill offsets
 * to indicate the kind of data spilled
 *
 * Revision 1.79  1995/09/22  15:59:50  jont
 * Fix bug in compiler crash when number of fp spill slots exceeded
 *
 * Revision 1.78  1995/09/15  13:49:34  io
 * fix MirTypes.TEST from overflowing ~1 on unsigned operations.
 *
 * Revision 1.77  1995/09/08  16:31:48  jont
 * Add a fixed branch type which can't be expanded beyond the 16 bit limit
 * This can be used to detect disastrous code generation in computed gotos
 * If this ever occurs, we can then fix the bug
 *
 * Revision 1.76  1995/09/08  13:30:20  io
 * ambiguity between const0 and reg0 in TEST
 *
 * Revision 1.75  1995/08/18  13:32:43  io
 * used slt/sltu in TEST, fixed bug introduced in BTA&BNT
 * sorted out overflow
 *
 * Revision 1.74  1995/08/10  16:00:10  io
 * implement jon's suggestion with imm32 cases in test and unsigned const comparisons
 *
 * Revision 1.73  1995/08/09  20:03:22  io
 * fix large imm problem, update mirtypes.test for unsigned code, shortcuts
 * eg [<u lhs zero] -> bnez lhs, optimize zero_reg tests
 *
 * Revision 1.72  1995/07/28  15:14:10  io
 * emit for BLO case (incomplete stub so that compiler can bootstrap)
 *
 * Revision 1.71  1995/07/25  15:50:23  jont
 * Add WORD to value_cg
 *
 * Revision 1.70  1995/07/19  14:22:18  jont
 * Add CHAR to value_cg
 *
 * Revision 1.69  1995/07/10  15:57:19  jont
 * Fix code generation problems with shifts
 *
 * Revision 1.68  1995/06/20  12:49:48  matthew
 * Fixing problem with not restoring fp registers
 *
 * Revision 1.67  1995/06/19  16:19:37  jont
 * Fix missing case in store floating point value
 *
 * Revision 1.66  1995/06/15  15:03:09  jont
 * Remove message about restarting linearise_sub
 *
 * Revision 1.65  1995/05/31  15:21:37  nickb
 * Rewrote the allocation code to get ml_gc_leaf to work.
 * Also tidied it up, and added a bunch of shorthand
 * names for registers &c.
 *
 * Revision 1.64  1995/05/09  15:39:29  nickb
 * Change stack overflow entry code; using fp as a temporary breaks
 * the profiler.
 *
 * Revision 1.63  1995/05/04  14:41:52  matthew
 * Partially fixing "restarting linearize_sub .." problem
 *
 * Revision 1.62  1995/05/02  15:31:39  matthew
 * Removing step and polyvariable options
 *
 * Revision 1.61  1995/04/27  15:59:26  nickb
 * Move the debugging argument save.
 * Plus a few general tidying changes.
 *
 * Revision 1.60  1995/04/20  10:52:30  nickb
 * Rearrange tail call instructions to make life easier for the profiler.
 *
 * Revision 1.59  1995/04/12  14:57:07  nickb
 * Turn on MIPS R4000 v 2.2 bug work-around
 *
 * Revision 1.58  1995/03/20  12:37:49  matthew
 * Disabling generation of "debugging" code
 *
 * Revision 1.57  1995/03/07  16:17:48  matthew
 * Fixing debugger stuff
 *
 * Revision 1.56  1995/03/01  17:20:21  matthew
 * Changes to Options structure/
 *
 * Revision 1.55  1995/02/02  15:27:08  nickb
 * Make arithmetic operations trap.
 * Also reduce code verbosity by adding some local names for things.
 *
 * Revision 1.54  1995/01/30  14:54:25  matthew
 * Debugger changes
 *
 * Revision 1.53  1995/01/10  18:06:51  nickb
 * Make the test for stack overflow unsigned so it catches the asynch events.
 *
 * Revision 1.52  1995/01/10  14:09:27  nickb
 * Add support for INTERRUPT.
 * Also extend INTERCEPT code.
 * Also allow functions which raise, or call real() or floor(), to be leaf.
 *
 * Revision 1.51  1994/12/09  12:00:14  nickb
 * Fix implicit entry points.
 *
 * Revision 1.50  1994/11/28  16:43:10  matthew
 * Fix for bytearray allocation length problem.
 * Changed real number unrepresentable message
 *
 * Revision 1.49  1994/11/25  17:59:46  nickb
 * Stack extension / function entry code changes.
 *
 * Revision 1.48  1994/11/24  14:44:35  matthew
 * Added code for ALLOC_VECTOR
 * Fixed problem with loop in initStackSlots
 *
 * Revision 1.47  1994/11/22  17:08:52  io
 * updating floor,
 * updating MirTypes.TEST for constant operands
 *
 * Revision 1.46  1994/11/16  12:28:31  jont
 * Add support for immediate store operation
 *
 * Revision 1.45  1994/11/15  12:14:50  matthew
 * Some changes for scheduling
 * Added elim_simple_branches functions
 *
 * Revision 1.44  1994/11/09  16:33:57  io
 * making stack initialisation shorter
 *
 * Revision 1.43  1994/11/08  19:22:30  io
 * rewriting real
 *
 * Revision 1.42  1994/11/02  12:37:27  matthew
 * Fixed problems with loading immediates:
 * use ADDUI for -2**15 .. 2**15-1
 * use ORI for 2**15 ..2**16-1
 * use LUI & ORI for other immediates
 * Fixed order of loading halves of double floats --
 * this may be endianness specific
 * Moved scheduling phase to during linearization.
 * Changed jumps in ALLOCATE to be to labels rather than by
 * fixed amounts.  This was confusing the scheduler.
 * Added removal of unreachable blocks before linearization.
 *
 * Revision 1.41  1994/10/24  14:21:57  matthew
 * Various things:
 * Fixed problems with pc-relative long branches
 * Rationalized some of the code comments
 * Reformatted a little
 * Commented out the "append_small_exit" part
 *
 * Revision 1.40  1994/10/05  13:42:27  jont
 * Changes for new NEW_HANDLER instruction
 *
 * Revision 1.39  1994/09/23  13:00:18  matthew
 * Abstraction of debug information
 *
 * Revision 1.38  1994/08/25  13:39:49  matthew
 * Changes to PROC_PARAMS
 *
 * Revision 1.37  1994/08/25  10:41:10  jont
 * Remove dependence on mir optimiser for fp registers used
 * Remove dependence on mir optimiser for gc registers used as well
 *
 * Revision 1.36  1994/07/28  16:27:52  jont
 * Use non-exception detecting arithmetic for the present
 *
 * Revision 1.35  1994/07/27  16:15:48  jont
 * Fix loading of large tagged integers
 *
 * Revision 1.34  1994/07/25  14:17:17  matthew
 * Added register lists to BRANCH_AND_LINK, TAIL_CALL and ENTER instructions.
 *
 * Revision 1.33  1994/07/22  13:29:45  jont
 * Modifications to include number of callee saves in wordsets
 * Fixed bugs in BIC, NOT and array length calculations
 *
 * Revision 1.32  1994/07/15  16:30:07  jont
 * Fix alignment and size calculation for arrays and bytearrays
 *
 * Revision 1.31  1994/07/15  14:22:18  io
 * fixed rest of ALLOCATE
 *
 * Revision 1.30  1994/07/15  13:11:33  jont
 * Fix restore fp not allowed in delay slot for the second time
 *
 * Revision 1.29  1994/07/14  12:28:14  jont
 * Fix problem with load_large_IMM_ANY_into_register
 *
 * Revision 1.28  1994/07/14  10:12:36  io
 * unifying jon's changes & revising ALLOCATE.
 *
 * Revision 1.25  1994/07/07  14:08:36  io
 * cleared up redundant match patterns
 *
 * Revision 1.24  1994/07/07  13:12:39  io
 * revised changes
 *
 * Revision 1.23  1994/06/24  14:17:43  jont
 * Update debugger information production
 *
 * Revision 1.22  1994/06/16  18:36:03  sml
 * Blotched checkin: redoing again
 *
 * Revision 1.21  1994/06/16  18:11:55  io
 * Blotched checkin: redoing
 *
 * Revision 1.20  1994/06/16  15:27:54  io
 * add new ENTER conventions
 *
 * Revision 1.19  1994/06/14  12:59:11  io
 * cleaning up caller_arg and callee_arg
 *
 * Revision 1.18  1994/06/13  12:13:29  io
 * added path change to accomodate new runtime structure
 *
 * Revision 1.14  1994/03/18  18:18:42  jont
 * Rationalise stack layout information
 * Fix bug whereby spills were written in the wrong place
 * Fix bug whereby gc initialisation was starting and finishing too low
 *
 * Revision 1.13  1994/03/11  16:21:06  jont
 * Fix code generation of LEO for mutually recursive function case
 *
 * Revision 1.12  1994/03/10  12:53:19  jont
 * Added code generation of load_offset.
 * Added handling of case where load_offset can't be one instruction
 * similar to case where adr expands to more than one
 *
 * Revision 1.11  1994/03/09  10:39:27  jont
 * Moved module types to separate file (code_module)
 * Fixed out of range branches and calls when compiling large functions
 * Recoded switch statements for semantic integrity
 * and to avoid long branch problems
 *
 * Revision 1.10  1994/03/04  12:40:46  jont
 * Moved machpsec from mips to main
 * Fixed problem where store offset zero was returned as register 0
 *
 * Revision 1.9  1994/03/04  11:08:24  jont
 * Fixing some store instruction problems
 *
 * Revision 1.8  1994/03/01  17:56:52  jont
 * Bring into line with debugger changes
 *
 * Revision 1.5  1994/02/23  18:10:11  jont
 * Updates to entry sequence
 *
 * Revision 1.3  1993/12/20  14:53:36  io
 * minor path change
 *
 * Revision 1.2  1993/11/17  13:42:01  io
 * Deleted old SPARC comments and fixed type errors
 *
 *)

require "../basis/__int";
require "../basis/__string";
require "../basis/__list";
require "../basis/__list_pair";
require "../utils/lists";
require "../utils/print";
require "../utils/mlworks_timer";
require "../utils/crash";
require "../utils/diagnostic";
require "../utils/sexpr";
require "../basics/ident";
require "../main/reals";
require "../main/options";
require "../mir/mirtables";
require "../mir/mirregisters";
require "../rts/gen/implicit";
require "../rts/gen/tags";
require "../main/info";
require "../main/machspec";
require "../main/code_module";
require "mips_schedule";
require "../main/mach_cg";

functor Mach_Cg(
  structure Tags : TAGS
  structure Print : PRINT
  structure Timer : INTERNAL_TIMER
  structure Lists : LISTS
  structure Crash : CRASH
  structure Info : INFO
  structure Sexpr : SEXPR
  structure Reals : REALS
  structure Ident : IDENT
  structure Options : OPTIONS
  structure MirTables : MIRTABLES
  structure MirRegisters : MIRREGISTERS
  structure MachSpec : MACHSPEC
  structure Mips_Schedule : MIPS_SCHEDULE
  structure Code_Module : CODE_MODULE
  structure Implicit_Vector : IMPLICIT_VECTOR
  structure Diagnostic : DIAGNOSTIC

  sharing Info.Location = Ident.Location
  sharing MirTables.MirTypes.Set = MachSpec.Set
  sharing MirTables.MirTypes = MirRegisters.MirTypes = Mips_Schedule.Mips_Assembly.MirTypes
  sharing type Ident.SCon = MirTables.MirTypes.SCon

  sharing type Mips_Schedule.Mips_Assembly.Mips_Opcodes.MachTypes.Mips_Reg
    = MachSpec.register
     ) : MACH_CG =
struct
  structure Mips_Assembly = Mips_Schedule.Mips_Assembly
  structure Mips_Opcodes = Mips_Assembly.Mips_Opcodes
  structure MirTypes = MirTables.MirTypes
  structure MachTypes = Mips_Opcodes.MachTypes
  structure MachSpec = MachSpec
  structure Diagnostic = Diagnostic
  structure Debugger_Types = MirTypes.Debugger_Types
  structure Map = MirTypes.Map
  structure Ident = Ident
  structure Set = MirTypes.Set
  structure Info = Info
  structure RuntimeEnv = MirTypes.Debugger_Types.RuntimeEnv
  structure Options = Options

  structure Bits = MLWorks.Internal.Bits

  type Module = Code_Module.Module
  type Opcode = Mips_Assembly.opcode

  val do_timings = ref false

  (* <URI:rts/gen/__tags.sml#MIPS_INTERCEPT_LENGTH>
   * <URI:rts/src/arch/MIPS/interface.S#ml_nop>
   *)
  val trace_dummy_instructions =
    [(Mips_Assembly.trace_nop_code,NONE,"Tracing nop"),
     (Mips_Assembly.trace_nop_code,NONE,"Tracing nop"),
     (Mips_Assembly.trace_nop_code,NONE,"Tracing nop"),
     (Mips_Assembly.trace_nop_code,NONE,"Tracing nop")]

  val do_diag = false

  val diagnostic_output =
    if do_diag
      then Diagnostic.output
    else fn _ => fn _ => ()

  val print_code_size = ref false

  (* Constant limits on aspects of the MIPS architecture *)

  val fifteen_bits = 32768 (* 2 ^ 15 *)
  val sixteen_bits = 65536 (* 2 ^ 16 *)

  val arith_imm_limit = fifteen_bits
  val unsigned_arith_imm_limit = sixteen_bits
  val branch_disp_limit = fifteen_bits
  val sethi_hisize = sixteen_bits
  val sethi_losize = sixteen_bits

  (* shorthand for commonly-used registers to make code sequences more legible *)

  val global_mir = MirRegisters.global
  val global = MachTypes.global
  val global_op = Mips_Assembly.REG global
  val global_reg = MirTypes.GC_REG global_mir
  val global_gp = MirTypes.GP_GC_REG global_mir
  val zero = MachTypes.zero_reg
  val zero_op = Mips_Assembly.REG zero
  val lr = MachTypes.lr
  val lr_op = Mips_Assembly.REG lr
  val nop = Mips_Assembly.nop
  val other_nop = (Mips_Assembly.other_nop_code,NONE,"Don't reschedule or eliminate this")
  val dummy = MachTypes.dummy_reg
  val dummy_op = Mips_Assembly.REG dummy

  (* This is used to store lr temporarily during calculation of long jumps *)
  val hacky_temporary_reg = MachTypes.R16

  (* find_nop_offsets: searches for tracing nops *)
  local
    fun find_nop_offsets(_, []) = ~1
      | find_nop_offsets(offset, (opcode, _) :: rest) =
	if opcode = Mips_Assembly.trace_nop_code then
	  offset
	else
	  find_nop_offsets(offset+1, rest)
  in
    val find_nop_offsets = fn (tag, code) => find_nop_offsets(0, code)
  end (* local *)

  fun check_range(i:int, signed, pos_limit) =
    if signed then
	(i >= 0 andalso i < pos_limit) orelse
	(i < 0 andalso i >= ~pos_limit)
    else i >= 0 andalso i < pos_limit

  (* fault_range: checks for branching outside offset limits *)
  fun fault_range(i, signed, pos_limit) =
    if check_range(i, signed, pos_limit)
      then i
    else
      (diagnostic_output 3
       (fn _ => ["fault_range called with value ",
		 Int.toString i,
		 " in positive range ",
		 Int.toString pos_limit]);
       Crash.impossible"Immediate constant out of range")

  (* make_imm_fault: puts arg into IMM form *)
  fun make_imm_fault(0, signed, max_pos) = zero_op
    | make_imm_fault(i, signed, max_pos) = let
	val _ = fault_range(i, signed, max_pos)
      in
	Mips_Assembly.IMM i
      end

  val absent = NONE

  (* copy: duplicates element N times tail-recursively *)
  fun copy n x =
    let
      fun copy' (0,acc) = acc
        | copy' (n,acc) = copy' (n-1,x :: acc)
    in
      if n < 0 then
	Crash.impossible "copy: negative"
      else
	copy' (n,[])
    end (* copy *)

  fun rev_fold_append([], acc) = acc
    | rev_fold_append(x :: xs, acc) = rev_fold_append(xs, x @@ acc)

  fun rev_map f arg =
    let
      fun map_sub([], acc) = acc
	| map_sub(x :: xs, acc) = map_sub(xs, f x :: acc)
    in
      map_sub arg
    end

  fun revapp ([],l) = l
    | revapp (a::b,c) = revapp (b,a::c)

  fun drop (0,l) = l
    | drop (n,[]) = Crash.impossible "drop ran out of items"
    | drop (n,a::b) = drop (n-1,b)

  fun move_regc(rd, rs, comment) =
    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
     (Mips_Assembly.OR, rd, rs, zero_op),
      absent, comment)

  (* move_reg: or rd, rs *)
  fun move_reg(rd, rs) =
    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
     (Mips_Assembly.OR, rd, rs, zero_op),
     absent, "")

  (* move_imm: addiu rd, $0 *)
  fun move_imm(rd, imm) =
    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
     (Mips_Assembly.ADDIU, rd, zero, Mips_Assembly.IMM imm),
     absent, "")

  (* move_immc :: addiu rd, $0 *)
  (* ORI zero extends the immediate so won't work *)
  fun move_immc(rd, imm, comment) =
    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
     (Mips_Assembly.ADDIU, rd, zero, Mips_Assembly.IMM imm),
     absent, comment)


  fun make_clean_code reg_list =
    let
      val regs_to_clean = Lists.rev_remove_dups reg_list
      val regs_to_clean =
        List.filter
        (fn reg => reg <> MachTypes.R0 andalso
         reg <> MachTypes.global)
        regs_to_clean
    in
      (* No point in cleaning global as it's non-gc *)
      (* R0 is already clean *)
      (map
       (fn reg => move_regc(reg, zero,"Clean register"))
       regs_to_clean)
    end

  fun binary_list_to_string(done, [], _, 128) = String.implode(rev done)
    | binary_list_to_string(_, [], _, l) =
      Crash.impossible("Binary_list_to_string length not 8, remainder length " ^
		       Int.toString l)
    | binary_list_to_string(done, x :: xs, digit, power) =
      let val x = ord x - ord #"0"
      in
	if power = 1 then
	  binary_list_to_string(chr(digit + x) :: done, xs, 0, 128)
	else
	  binary_list_to_string(done, xs, digit + x * power, power div 2)
      end


  (* to_binary converts 'value' into binary number stored in length 'digits' *)
  fun to_binary (digits:int, value:int) : char list =
    let
      fun to_sub(0, _, done) = done
	| to_sub(digs_to_go, value, done) =
	  let
	    val digit = chr (value mod 2 + ord #"0")
	  in
	    to_sub(digs_to_go - 1, value div 2, digit :: done)
	  end
    in
      to_sub(digits, value, [])
    end

  (* adjust: checks for overflow in expon notation *)
  local
    (* mantissa_is_zero: checks elements are all "0" *)
    fun mantissa_is_zero mantissa = List.all (fn x=> #"0" = x) (String.explode mantissa)
  in
    fun adjust (error_info,x,location) (mantissa, exponent, max_exponent, bits) =
      if mantissa_is_zero mantissa then
	(mantissa, 0)
      else
	if exponent > 0 andalso exponent < max_exponent then
	  (mantissa, exponent)
	else
	  (* Need to handle subnormal numbers *)
	  if exponent >= max_exponent then
	    Info.error'
	    error_info
	    (Info.FATAL,location,
	     "Real number unrepresentable: " ^ x)
	  else
	    if exponent < ~bits then (String.implode(copy bits #"0"), 0)
	    else
	      (String.implode(copy (abs exponent) #"0") ^ mantissa, 0)
  end (* adjust *)

  fun to_single_string args (sign, mantissa, exponent) =
    let
      val real_exponent = exponent + 127
      val (mantissa, real_exponent) = adjust args (mantissa, real_exponent, 255, 23)
	
      val binary_list =
	(if sign then #"1" else #"0") ::
	   to_binary(8, real_exponent) @@
	   String.explode (String.substring(mantissa, 1,23))
    in
      binary_list_to_string([], binary_list, 0, 128)
    end

  fun to_double_string args (sign, mantissa, exponent) =
    let
      val real_exponent = exponent + 1023
      val (mantissa, real_exponent) = adjust args (mantissa, real_exponent, 2047, 52)
      val binary_list =
	(if sign then #"1" else #"0") ::
	   to_binary(11, real_exponent) @@
	   String.explode(String.substring(mantissa, 1, 52))
    in
      binary_list_to_string([], binary_list, 0, 128)
    end

  fun to_extended_string args (sign, mantissa, exponent) =
    let
      val real_exponent = exponent + 16383
      val (mantissa, real_exponent) =
	adjust args (mantissa, real_exponent, 32767, 63)
      val binary_list =
	(if sign then #"1" else #"0") ::
	   to_binary(15, real_exponent) @@
	   copy 16 #"0" @@
	   String.explode(String.substring(mantissa, 0, 64)) @@
	   copy 32 #"0"
    in
      binary_list_to_string([], binary_list, 0, 128)
    end

  fun value_cg(i, MirTypes.SCON (Ident.STRING x),_) = Code_Module.STRING(i, x)
    | value_cg(i, MirTypes.SCON (Ident.REAL(x,location)),error_info) =
      (let
        val the_real = Reals.evaluate_real x
        val (sign, mantissa, exponent) = Reals.find_real_components the_real
        val encoding_function = case MachTypes.fp_used of
          MachTypes.single => to_single_string (error_info,x,location)
        | MachTypes.double => to_double_string (error_info,x,location)
        | MachTypes.extended => to_extended_string (error_info,x,location)
      in
        Code_Module.REAL(i, encoding_function(sign, mantissa, exponent))
      end handle MLWorks.Internal.StringToReal =>
	Info.error'
	error_info
	(Info.FATAL, location, "Real number unrepresentable: " ^ x)
      )
    | value_cg(_, MirTypes.SCON (Ident.INT _),_) = Crash.impossible"VALUE(INT)"
    | value_cg(_, MirTypes.SCON (Ident.CHAR _),_) = Crash.impossible"VALUE(CHAR)"
    | value_cg(_, MirTypes.SCON (Ident.WORD _),_) = Crash.impossible"VALUE(WORD)"
    | value_cg (i,MirTypes.MLVALUE value,_) =
      Code_Module.MLVALUE (i,value)

  (* last_opcode: return the external branch out of the block if one exists *)
  fun last_opcode [] = (nop, false)
    | last_opcode([elem as (Mips_Assembly.BRANCH(Mips_Assembly.BA, _, _, _), _, _), _])
      = (elem, true)
    | last_opcode([elem as (Mips_Assembly.FIXED_BRANCH(Mips_Assembly.BA, _, _, _), _, _), _])
      = (elem, true)
    | last_opcode(_ :: xs) = last_opcode xs

  fun make_proc_info(res as (main_tree, tag_tree), []) = res
    | make_proc_info((main_tree, tag_tree),
		     ((block_tag, opcode_list)) :: rest) =
      let
	val last_tag_exists as (tag, ok) = case last_opcode opcode_list of
	  ((_, SOME tag, _), true) => (tag, true)
	| _ => (block_tag, false)
      in
	make_proc_info
	((Map.define (main_tree, block_tag, last_tag_exists),
	  if ok then
	    Map.define (tag_tree, tag, 0)
	  else tag_tree), rest)
      end

  fun rev_app(     [], ys) = ys
    | rev_app(     xs, []) = xs
    | rev_app(x :: xs, ys) = rev_app(xs, x :: ys)


  (* remove_trailing_branch: deletes sll,ba,nop and stuffs comment into preceding opcode that it did so *)
  fun remove_trailing_branch(block_tag, opcode_list) =
    let
      val new_opc =
	case rev opcode_list of
	  (Mips_Assembly.ARITHMETIC_AND_LOGICAL  (* nop *)
	   (Mips_Assembly.SLL, MachTypes.R0, MachTypes.R0, _), _, _) ::
	  (Mips_Assembly.BRANCH _, _, _) :: rest => rest
	| (operation, opt, comment) :: (Mips_Assembly.BRANCH _, _, _) :: rest =>
	    (operation, opt, comment ^ " preceding BA removed") :: rest
	| (Mips_Assembly.ARITHMETIC_AND_LOGICAL  (* nop *)
	   (Mips_Assembly.SLL, MachTypes.R0, MachTypes.R0, _), _, _) ::
	  (Mips_Assembly.FIXED_BRANCH _, _, _) :: rest => rest
	| (operation, opt, comment) :: (Mips_Assembly.FIXED_BRANCH _, _, _) :: rest =>
	    (operation, opt, comment ^ " preceding BA removed") :: rest
	| _ => Crash.impossible"Remove trailing branch fails"
    in
      (block_tag, rev new_opc)
    end

  (* CT this now works on the continuer and non-continuer lists in turn *)
  fun find_dest_block(tag, [], [], x,y) = ((tag, []), false, x,y)
    | find_dest_block(dest_tag,
		      (block as (block_tag, opcode_list)) ::
		      rest,
		      other,
		      x , [] ) =
      if dest_tag = block_tag then
	(block, true, x @@ rest, other)
      else find_dest_block(dest_tag, rest, other, block :: x,[])

    | find_dest_block(dest_tag,
		      [],
		      (block as (block_tag, opcode_list)) ::
		      rest,
		      x , y ) =
      if dest_tag = block_tag then
	(block, true, x , y @@ rest)
      else find_dest_block(dest_tag, [], rest, x, block :: y)

    | find_dest_block _ =
      Crash.impossible "This should never happen in _mach_cg "

  (* Algorithm *)
  (* Start with the first block (entry block) *)
  (* Find the block it tails into, and append that *)
  (* Repeat until we end up with a block which either doesn't tail *)
  (* into an unused block (eg a loop), or doesn't tail at all (eg ret) *)
  (* Now find all blocks which tail into something *)
  (* and pick one from these which nothing tails into from these *)
  (* This is called a chain head *)
  (* Repeat as if we'd just started *)
  (* If no such block, pick one from the cycle and repeat as before *)
  (* If no blocks which tail at all, bung them on the end and finish *)
  (* A consequence of this algorithm is *)
  (* When searching for a new head of a chain, *)
  (* we need only check that a block which continues *)
  (* was never the target of another block (ie check at proc start) *)
  (* Because if it once was, and has now ceased to be *)
  (* Then it would have been processed already (reductio ad absurdum) *)

  fun reorder_blocks(proc as (proc_tag, block_list)) =
    (* Reorder the blocks for a proc so as to allow fall throughs *)
    (* Note that this will result in blocks with dangling ends *)
    (* So they must not be reordered again by any other means *)
    let
      val (proc_info, tag_tree) =
	make_proc_info((Map.empty , Map.empty), block_list)

      val proc_info_map = Map.tryApply proc_info
      val tag_tree_map = Map.tryApply tag_tree
      (* We don't have to repeatedly re-calculate the continuers lists *)
      fun do_fall_throughs_with_continuers_calculated(done, (block as (block_tag, opcode_list)),
                                                      continuers,non_continuers) =
        let
	  val (dest_tag, found_block) =
	    Map.apply_default'(proc_info, (block_tag, false), block_tag)

	  fun do_next() =
	    case continuers of
              (* CT this was rev(rev rest @@ (block :: done)), but
               rev(rev rest @@ (block::done)) = rev(block::done) @@ rest
               = rev( [block] @@ done) @@ rest = rev done @@ rev[block] @@ rest
               = rev done @@ (block :: rest)
               AND now rest = continuers @@ non-continuers *)
	      [] =>
		rev_app(done, (block :: non_continuers))
	    | _ =>
		let
		  val (next_block, continuers') =
		    (let
		       val (tag,_) =
			 valOf (List.find (fn (x,_)=>not(isSome(tag_tree_map x))) continuers)
		       val (others,value) =
			 Lists.assoc_returning_others(tag,continuers)
		     in
		       ((tag, value),others)
		     end) handle Option =>
		       (hd continuers, tl continuers)
		in
		  do_fall_throughs_with_continuers_calculated(block :: done,
							      next_block,
                                                              continuers',
							      non_continuers)
		end
	in
	  if found_block then
	    let
	      val (dest_block, found_dest, non_continuers',continuers') =
		find_dest_block(dest_tag, non_continuers, continuers, [] , [])
	    in
	      if found_dest then
		do_fall_throughs_with_continuers_calculated
		(remove_trailing_branch block :: done,
		 dest_block, continuers', non_continuers')
	      else
		 do_next()
	    end
	  else
	     do_next()
	end

      fun do_fall_throughs(done, block, []) = rev(block :: done)
      | do_fall_throughs(done, block,rest) =
	let
	  fun continues(tag, _) =
	    case proc_info_map tag of
	      SOME(_, t) => t
	    | _ => false

	  val (continuers,non_continuers) =
	    Lists.partition continues rest
        in
          do_fall_throughs_with_continuers_calculated(done,block,continuers,non_continuers)
        end

      val (hd_block_list, tl_block_list) = case block_list of
	x :: y => (x, y)
      | _ => Crash.impossible"Empty block list"
    in
      (proc_tag, do_fall_throughs([], hd_block_list, tl_block_list))
    end

  fun tag_offsets([], offset, tag_env) = (offset, tag_env)
    | tag_offsets((tag, ho_list) :: rest, disp, tag_env) =
      tag_offsets(rest, disp + 4 * (List.length ho_list),
		  Map.define (tag_env, tag, disp))


  fun tag_offsets_for_list(_, [], env) = env
    | tag_offsets_for_list(offset, (_, proc) :: rest, env) =
      let
	val (next_offset, env) = tag_offsets(proc, offset, env)
	val next_offset' =
	  next_offset + 4 (* Back-pointer *) + 4 (* Procedure number within set *)
	val next_offset'' =
	  if next_offset' mod 8 = 4
	    then next_offset'+4
	  else next_offset'
      in
	tag_offsets_for_list(next_offset'', rest, env)
      end

  fun do_little_block(block as (tag, opcode_list)) =
    case opcode_list of _ => block (* I see no annulled branches here *)

  fun reschedule_little_blocks(proc_tag, block_list) =
    (proc_tag, map do_little_block block_list)

  (* linearise_list takes a list of procedures which have been code
   * generated and figures out all the displacements for branches &c,
   * so that instructions can be output. It also inserts nops to align
   * branch instructions (see the long comment below). It is called by
   * list_proc_cg *)

  fun linearise_list (mips_r4000, proc_list) =
    let

      val no_delay = mips_r4000
      val _ = diagnostic_output 3 (fn _ => (["Rescheduling code\n"]))

      val new_proc_list =
	Timer.xtime
	("Instruction Scheduling", !do_timings,
	 fn () => map (Mips_Schedule.reschedule_proc no_delay) proc_list)

      val _ = diagnostic_output 3 (fn _ => ["Rescheduled code\n"])

      (* We'd now like to reschedule any small blocks that branch backwards *)

      val new_proc_list = map reschedule_little_blocks new_proc_list

      fun do_linearise' (proc_list,bad_branches) =
	let
          fun addBadOffset item =
            (bad_branches := item :: !bad_branches;
             (Mips_Assembly.nop_code, "ERROR -- Dummy instruction for bad offset -- shouldn't see this"))

	  val tag_env = tag_offsets_for_list(0, proc_list, Map.empty)

	  val _ = diagnostic_output 3 (fn _ => ["Tag_env ="])
	  val _ =
	    diagnostic_output 3
	    (fn _ =>
             (app
              (fn (x, y) => Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ Int.toString y ^ "\n"))
              (Map.to_list tag_env) ;
              []))

	  fun lookup_env tag = Map.tryApply'(tag_env,tag)

	  fun copy_n( limit, xs, ys) =
	    if limit < 0 orelse limit > length xs then
	      Crash.impossible "copy_n: failed"
	    else
	      let
		fun scan (0, _, acc) = acc
		  | scan (n, x::xs, acc) = scan (n-1, xs, x::acc)
		  | scan (_, _, _) = Crash.impossible "scan: warnings & mmaps hate each other"
	      in
		rev_app(scan (limit, xs, []), ys)
	      end (* copy_n *)

	  fun linearise_proc(proc_offset, offset, [], done) =
	    (offset, rev done)
	    | linearise_proc(proc_offset, start, blocks as (block :: block_list), done) =
	    let
	      (* Insert algorithm for optimal linearisation of blocks here *)
	      (* Present algorithm just uses the current order *)
	      (* Also assumes NOPs inserted after all control transfers *)
	      fun do_block(block_start, (block_tag, opcode_list), done) =
		let
		  val fault_range =
		    fn (x, y as (offset, _, _)) =>
		    ((fault_range y) handle exn =>
		      (print ("fault_range fails on " ^ x ^
			      " with offset " ^ Int.toString offset ^
			      "\n");
		       raise exn))

		  fun invert_call_to_branch Mips_Assembly.BGEZAL = Mips_Assembly.BLTZ
		    | invert_call_to_branch Mips_Assembly.BLTZAL = Mips_Assembly.BGEZ

		  fun do_opcode((Mips_Assembly.BRANCH(branch, r1, r2, i),
				 tag_opt as SOME tag, comment), offset) =
                    (case lookup_env tag of
                       SOME res =>
                         let
			   val disp = ( res - offset) div 4 - 1
                         in
			   if check_range(disp, true, branch_disp_limit) then
			     (* Branch ok in one instruction *)
			     (Mips_Assembly.BRANCH(branch, r1, r2, disp), comment)
			   else
			     (* Nasty case *)
                             let
                               val _ =
                                 diagnostic_output 3
                                 (fn _ => ["Found bad branch, substituting\n",
					   "Offset = ",
					   Int.toString disp,
					   "\ntag = ",
					   MirTypes.print_tag tag])
                               val head_size = (offset - block_start) div 4
                               val tail = drop(1 + head_size, opcode_list)
			       val (delay_instr, tail) = case tail of
				 (x :: y) => (x, y)
			       | _ => Crash.impossible "branch instruction has no delay"
                               (* get the opcodes after this one *)
                               val new_comment = comment ^ " (expanded branch)"
                               (* Save lr in temporary during calculation of offset *)
                               (* This should be safe even if r1 or r2 are spills as their values *)
                               (* will have already been used *)
                               (* WARNING: If cross block spill optimizations are done, this may change *)
			       val new_code =
				 delay_instr ::
                                 move_regc (hacky_temporary_reg,lr,"Save current lr") ::
				 (Mips_Assembly.CALL
				  (Mips_Assembly.BGEZAL,
				   zero, 1,
                                   Debugger_Types.null_backend_annotation),
                                  NONE,
				  "call .") ::
                                 (Mips_Assembly.SETHI
                                  (Mips_Assembly.LUI, global, i-4),
                                  SOME tag, new_comment) ::
                                 (Mips_Assembly.SPECIAL_ARITHMETIC
                                  (Mips_Assembly.ADD_AND_MASK, global,
                                   Mips_Assembly.IMM i, global),
                                  tag_opt, new_comment) ::
                                 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                                  (Mips_Assembly.ADD, global, lr, global_op),
                                  absent, new_comment) ::
                                 move_regc (lr,hacky_temporary_reg,"Restore current lr") ::
				 (Mips_Assembly.JUMP
				  (Mips_Assembly.JR, global_op,
				   dummy,
				   Debugger_Types.null_backend_annotation),
				  NONE, "jump to original destination") ::
				 nop :: []
                               val new_code = case branch of
				 Mips_Assembly.BA => new_code
			       | _ =>
				 (Mips_Assembly.BRANCH
				  (Mips_Assembly.inverse_branch branch,
				   r1, r2, 9), NONE,
				  "short inverted branch to skip over long jump") ::
				 new_code
                             in
                               addBadOffset(offset,2,new_code)
                             end
                         end
                     | NONE =>
                         Crash.impossible ("Assoc do_opcode branch: " ^ MirTypes.print_tag tag))
		    | do_opcode((Mips_Assembly.FIXED_BRANCH(branch, r1, r2, i),
				 tag_opt as SOME tag, comment), offset) =
		      (case lookup_env tag of
			 SOME res =>
			   let
			     val disp = ( res - offset) div 4 - 1
			   in
			     if check_range(disp, true, branch_disp_limit) then
			       (* Branch ok in one instruction *)
			       (Mips_Assembly.BRANCH(branch, r1, r2, disp), comment)
			     else
			       Crash.impossible"range failure on fixed branch within computed goto"
			   end
		       | NONE =>
			   Crash.impossible ("Assoc do_opcode branch: " ^ MirTypes.print_tag tag))
		    | do_opcode((Mips_Assembly.FBRANCH(branch, i),
				 SOME tag, comment), offset) =
		      (case lookup_env tag of
			 SOME res =>
			   let
			     val disp =
			       fault_range("fbranch", ((res - offset) div 4 - 1,
					   true, branch_disp_limit))
			   in
			     (Mips_Assembly.FBRANCH(branch, disp), comment)
			   end
		       | NONE =>
			   Crash.impossible ("Assoc do_opcode fbranch: " ^ MirTypes.print_tag tag))

		    | do_opcode((Mips_Assembly.CALL(call, r, i,debug_info),
				 tag_opt as SOME tag, comment), offset) =
		      (case lookup_env tag of
			 SOME res =>
			   let
			     val disp = ( res - offset) div 4 - 1
			   in
			     if check_range(disp, true, branch_disp_limit) then
			       (* Branch ok in one instruction *)
			       (Mips_Assembly.CALL(Mips_Assembly.BGEZAL, r, disp,debug_info),
                                comment)
			     else
			       (* Nasty case *)
                             let
                               val _ =
                                 diagnostic_output 3
                                 (fn _ => ["Found bad call, substituting\n",
					   "Offset = ",
					   Int.toString disp,
					   "\ntag = ",
					   MirTypes.print_tag tag])
                               val head_size = (offset - block_start) div 4
                               val tail = drop(1 + head_size, opcode_list)
			       val (delay_instr, tail) = case tail of
				 (x :: y) => (x, y)
			       | _ => Crash.impossible "call instruction has no delay"
                               (* get the opcodes after this one *)
                               val new_comment = comment ^ " (expanded call)"
			       val new_code =
				 delay_instr ::
				 (Mips_Assembly.CALL
				  (Mips_Assembly.BGEZAL,
				   zero, 1,
                                   Debugger_Types.null_backend_annotation),
                                  NONE,
				  "call .") ::
                                 (Mips_Assembly.SETHI
                                  (Mips_Assembly.LUI, global, i-4),
                                  tag_opt, new_comment) ::
                                 (Mips_Assembly.SPECIAL_ARITHMETIC
                                  (Mips_Assembly.ADD_AND_MASK, global,
                                   Mips_Assembly.IMM i, global),
                                  SOME tag, new_comment) ::
                                 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                                  (Mips_Assembly.ADD, global, lr,
                                   global_op),
                                  absent, new_comment) ::
                                 (* This overwrites lr so don't need to save *)
				 (Mips_Assembly.JUMP
				  (Mips_Assembly.JALR, lr_op, global,
				   Debugger_Types.null_backend_annotation),
				  NONE, "jump and link to original destination") ::
				 nop ::
				 []
			       val new_code = case (call, r) of
				 (Mips_Assembly.BGEZAL, MachTypes.R0) =>
				   new_code
				   (* Don't need the skip for always call *)
			       | _ =>
				 (Mips_Assembly.BRANCH
				  (invert_call_to_branch call,
				   r, zero, 7),
				  NONE,
				  "short inverted branch to skip over long jump") ::
				 new_code
                             in
                               addBadOffset(offset, 2, new_code)
                             end
			   end
		       | NONE => Crash.impossible "Assoc do_opcode call")
		    | do_opcode((Mips_Assembly.LOAD_OFFSET(Mips_Assembly.LEO, rd, i),
				 SOME tag, comment), offset) =
		      (* This will probably suffer the same problems as adr did *)
		      (case lookup_env tag of
			 SOME res =>
			   let
			     val disp = (res + i) - proc_offset
			   (* Must work relative to start of current proc in set *)
			   in
			     if check_range(disp, true, arith_imm_limit) then
			       (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                                (Mips_Assembly.ADD, rd, zero, Mips_Assembly.IMM disp),
                                comment)
			     else
			       let
				 val _ =
				   diagnostic_output 3
				   (fn _ => ["Found bad LEO, substituting\n"])
				 val head_size = (offset - block_start) div 4
				 val tail = drop(1 + head_size, opcode_list)
				 (* get the opcodes after this one *)
				 val new_comment = comment ^ " (expanded adr)"
				 val new_code =
				   (Mips_Assembly.SPECIAL_LOAD_OFFSET
				    (Mips_Assembly.LOAD_OFFSET_HIGH, rd,
				     zero, i),
				    SOME tag, new_comment) ::
				   (Mips_Assembly.SPECIAL_LOAD_OFFSET
				    (Mips_Assembly.LOAD_OFFSET_AND_MASK, rd, rd, i),
				    SOME tag, new_comment) :: []
			       in
				 addBadOffset (offset,1,new_code)
			       end
			   end
		       | NONE => Crash.impossible "Assoc do_opcode LEO")
		    | do_opcode((Mips_Assembly.ARITHMETIC_AND_LOGICAL
				 (Mips_Assembly.ADD, rd, rs1, Mips_Assembly.IMM i),
				 SOME tag, comment), offset) =
		      (case lookup_env tag of
			 SOME res =>
			   let
			     val disp = res + i - offset
			   in
			     if check_range(disp, true, arith_imm_limit) then
			       (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				(Mips_Assembly.ADD, rd, rs1, Mips_Assembly.IMM disp),
				comment)
			     else
			       let
				 val _ =
				   diagnostic_output 3
				   (fn _ => ["Found bad ADR, substituting\n"])
				 val head_size = (offset - block_start) div 4
				 val tail = drop(1 + head_size, opcode_list)
				 (* get the opcodes after this one *)
				 val _ =
				   if rs1 = rd then
				     Crash.impossible"ADR has dest in lr"
				   else ()
				 val new_comment = comment ^ " (expanded adr)"
				 val new_code =
				   (Mips_Assembly.SETHI
                                    (Mips_Assembly.LUI, rd, i),
				    SOME tag, new_comment) ::
				   (Mips_Assembly.SPECIAL_ARITHMETIC
				    (Mips_Assembly.ADD_AND_MASK, rd,
				     Mips_Assembly.IMM (i+4), rd),
				    SOME tag, new_comment) ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				    (Mips_Assembly.ADD, rd, rs1,
				     Mips_Assembly.REG rd),
				    absent, new_comment) :: []
			       in
				 addBadOffset(offset,1,new_code)
			       end
			   end
		       | NONE =>
			   Crash.impossible"Assoc do_opcode arith")

		    | do_opcode((Mips_Assembly.SPECIAL_ARITHMETIC
				 (_, rd, Mips_Assembly.IMM i,
				  rs1),
				 SOME tag, comment), offset) =
                      (* This needs to do an OR of the low part *)
                      (* ADD won't work here *)
		      (case lookup_env tag of
			 SOME res =>
			   let
			     val disp =
			       make_imm_fault
			       ((res + i - offset) mod sethi_losize,
				false, unsigned_arith_imm_limit)
			   in
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ORI, rd, rs1, disp),
			      comment)
			   end
		       | NONE =>
			   Crash.impossible"Assoc do_opcode arith")

		    | do_opcode((Mips_Assembly.SPECIAL_LOAD_OFFSET(load, rd, rn, i),
				 SOME tag, comment), _) =
		      (case lookup_env tag of
			 SOME res =>
			   let
			     val disp = res + i - proc_offset
			   (* Must work relative to start of current proc in set *)
			   in
			     case load of
			       Mips_Assembly.LOAD_OFFSET_HIGH =>
				 (Mips_Assembly.SETHI
				  (Mips_Assembly.LUI, rd,
				   (disp div sethi_losize) mod sethi_hisize),
				  comment)
			     | Mips_Assembly.LOAD_OFFSET_AND_MASK =>
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.ORI, rd, rn,
				   make_imm_fault (disp mod sethi_losize, false, unsigned_arith_imm_limit)),
				  comment)
			   end
		       | NONE =>
			   Crash.impossible"Assoc do_opcode SPECIAL_LOAD_OFFSET")

		    | do_opcode((Mips_Assembly.SETHI(_, rd, i),
				 SOME tag, comment), offset) =
		      (case lookup_env tag of
			 SOME res =>
			   let
			     val disp = res + i - offset
			     val disp = (disp div sethi_losize) mod sethi_hisize
			   (* Ensure positive *)
			   in
			     (Mips_Assembly.SETHI(Mips_Assembly.LUI, rd, disp),
			      comment)
			   end
		       | NONE =>
			   Crash.impossible"Assoc do_opcode sethi")

		    | do_opcode((Mips_Assembly.OFFSET i, SOME tag, comment),
				offset) =
		      (case lookup_env tag of
			 SOME res =>
			   let
			     val disp = res + i - offset
			   in
			     (Mips_Assembly.OFFSET disp, comment)
			   end
		       | NONE =>
			   Crash.impossible"Assoc do_opcode offset")

		    | do_opcode((opcode, NONE, comment), offset) =
		      (opcode, comment)
		    | do_opcode _ = Crash.impossible"Bad tagged instruction"

		  val (opcodes_and_offsets, next) =
		    Lists.number_from(opcode_list, block_start, 4, fn x => x)

		in
		  (rev_map do_opcode (opcodes_and_offsets, done), next)
		end
	      val (so_far, next) = do_block(start, block, done)
	    in
	      linearise_proc(proc_offset, next, block_list, so_far)
	    end

	  fun do_linearise_sub(_, []) = []
	    | do_linearise_sub(offset, ((tag, proc)) :: rest) =
	      let
		val (offset', done') = linearise_proc(offset, offset, proc, [])
		val offset'' =
		  offset' + 4 (* Back-pointer *) + 4 (* Procedure number within set *)
		val offset''' =
		  if offset'' mod 8 = 4
		    then offset'' + 4
		  else offset''
	      in
		(tag, done') :: do_linearise_sub(offset''', rest)
	      end

	in
	  do_linearise_sub(0, proc_list)
	end

(*
      fun subst_branches ([],offset,subst_list,acc) = raise Div
*)

      fun subst_branches (proclist,offset,subst_list) =
        let
(*
          val _ = print "Doing subst_branches..\n"
          val _ = map (fn (i,_,_) => print (Int.toString i ^ " ")) subst_list
          val _ = print "\n"
*)
          (* Now just iterate through the proclist, keeping track of the offset *)
          (* as used to insert entries in subst_list ie.  starting from zero, counting in *)
          (* bytes, and double-word aligning the start of procedures *)
          (* Note that subst_list is in offset order so we only need to look at the first *)
          (* item.  *)
          fun loop ([],offset,subst_list,acc)  = rev acc
            | loop ((tag,blocklist)::proclist,offset,subst_list,acc) =
            let
              fun subst_proc ([],offset,subst_list,acc) =
                (offset,subst_list,rev acc)
                | subst_proc ((tag,opcodelist)::rest,offset,subst_list,acc) =
                let
                  fun subst_block ([],offset,subst_list,acc) =
                    (offset,subst_list,rev acc)
                    | subst_block (opcodelist,offset,[],acc) =
                    (offset,[],revapp (acc,opcodelist))
                    | subst_block (opcode::rest,offset,
                                   subst_list as ((ix,count,newcode)::subst_list'),acc) =
                    if ix = offset
                      then ((* print ("Found a substitution " ^ Int.toString ix ^ " " ^ Int.toString count ^ " \n"); *)
                            subst_block (drop (count-1,rest),offset+(4 * count),
                                         subst_list',revapp (newcode,acc)))
                     else subst_block (rest,offset+4,subst_list,opcode::acc)
                  val (offset,subst_list,opcodelist) =
                    subst_block (opcodelist,offset,subst_list,[])
                in
                  subst_proc (rest,offset,subst_list,(tag,opcodelist)::acc)
                end

              val (offset,subst_list,blocklist) =
                subst_proc (blocklist,offset,subst_list,[])
              (* Calculate offset of next procedure *)
              (* see above for details *)
              val offset =
                let
                  val t = offset + 4 + 4 (* backptr and count *)
                in
                  if t mod 8 = 4 then t + 4 else t (* double word align *)
                end
            in
              loop (proclist,offset,subst_list,(tag,blocklist)::acc)
            end
        in
          loop (proclist,offset,subst_list,[])
        end

      fun do_linearise (proclist) =
        let
          val bad_branches = ref []
          val result = do_linearise' (proclist,bad_branches)
        in
          case !bad_branches of
            [] => result
          | subst_list =>
              ((* print "Restarting do_linearise\n"; *)
               do_linearise (subst_branches (proclist,0,rev subst_list)))
        end
    in
      do_linearise new_proc_list
    end

  fun is_reg(MirTypes.GP_GC_REG reg) = true
    | is_reg(MirTypes.GP_NON_GC_REG reg) = true
    | is_reg _ = false


  fun reg_from_gp(MirTypes.GP_GC_REG x)     = MirTypes.GC_REG x
    | reg_from_gp(MirTypes.GP_NON_GC_REG x) = MirTypes.NON_GC_REG x
    | reg_from_gp _ = Crash.impossible "reg_from_gp(IMM)"

  fun gp_from_reg(MirTypes.GC_REG reg) = MirTypes.GP_GC_REG reg
    | gp_from_reg(MirTypes.NON_GC_REG reg) = MirTypes.GP_NON_GC_REG reg

  (* check_reg: returns true for a callee_save register *)
  fun check_reg MachTypes.R0 = false
    | check_reg MachTypes.R1 = false
    | check_reg MachTypes.R2 = false
    | check_reg MachTypes.R3 = false
    | check_reg MachTypes.R4 = false
    | check_reg MachTypes.R5 = false
    | check_reg MachTypes.R6 = false
    | check_reg MachTypes.R7 = false
    | check_reg MachTypes.R8 = false
    | check_reg MachTypes.R9 = false
    | check_reg MachTypes.R10 = true
    | check_reg MachTypes.R11 = true
    | check_reg MachTypes.R12 = true
    | check_reg MachTypes.R13 = true
    | check_reg MachTypes.R14 = true
    | check_reg MachTypes.R15 = true
    | check_reg MachTypes.R16 = false
    | check_reg MachTypes.R17 = false
    | check_reg MachTypes.R18 = false
    | check_reg MachTypes.R19 = false
    | check_reg MachTypes.R20 = false
    | check_reg MachTypes.R21 = false
    | check_reg MachTypes.R22 = false
    | check_reg MachTypes.R23 = false
    | check_reg MachTypes.R24 = true
    | check_reg MachTypes.R25 = true
    | check_reg MachTypes.R26 = false
    | check_reg MachTypes.R27 = false
    | check_reg MachTypes.R28 = false
    | check_reg MachTypes.R29 = false
    | check_reg MachTypes.R30 = false
    | check_reg MachTypes.R31 = false
    | check_reg MachTypes.cond = Crash.impossible"check_reg: the condition codes"
    | check_reg MachTypes.heap = Crash.impossible"check_reg: the heap"
    | check_reg MachTypes.stack = Crash.impossible"check_reg: the stack"
    | check_reg MachTypes.mult_result = Crash.impossible"check_reg: mult_result"
    | check_reg MachTypes.nil_v = Crash.impossible"check_reg: the nil vector"
	
  fun compare_reg(r, s) = Mips_Opcodes.register_val r < Mips_Opcodes.register_val s

  datatype proc_stack =
    PROC_STACK of
    {non_gc_spill_size     : int, (* In words *)
     fp_spill_size         : int, (* In singles, doubles or extendeds *)
     fp_save_size          : int, (* As for fp_spill_size *)
     gc_spill_size         : int, (* In words *)
     gc_stack_alloc_size   : int, (* In words *)
     register_save_size    : int, (* In bytes *)
     non_gc_spill_offset   : int, (* In bytes *)
     fp_spill_offset       : int, (* In bytes *)
     fp_save_offset        : int, (* In bytes *)
     gc_spill_offset       : int, (* In bytes *)
     gc_stack_alloc_offset : int, (* In bytes *)
     register_save_offset  : int, (* In bytes *)
     allow_fp_spare_slot   : bool, (* slot needed for float/int conversion? *)
     float_value_size      : int  (* Number of bytes per float value *)
     }

  fun mach_cg
    error_info
    (Options.OPTIONS {compiler_options = Options.COMPILEROPTIONS {generate_debug_info, debug_variables, generate_moduler, opt_leaf_fns, intercept, mips_r4000, ...},
                      ...},
     MirTypes.CODE(MirTypes.REFS(loc_refs,
                                 {requires = ext_refs,
                                  vars = vars,
                                  exns = exns,
                                  strs = strs,
                                  funs = funs}),
                    value_list,
                    proc_list_list),
    (gc_map,
     non_gc_map,
     fp_map),
    debugging_map) =
    let
      val save_arg_for_debugging = generate_debug_info orelse debug_variables orelse intercept
      val {gc, non_gc, fp} = MirRegisters.pack_next
      val gc_array = MLWorks.Internal.Array.array(gc, global)
      val _ =
	MirTypes.GC.Map.iterate
	(fn (mir_reg, reg) =>
	 MLWorks.Internal.Array.update(gc_array, MirTypes.GC.unpack mir_reg, reg))
	gc_map
      val non_gc_array = MLWorks.Internal.Array.array(non_gc, global)
      val _ =
	MirTypes.NonGC.Map.iterate
	(fn (mir_reg, reg) =>
	 MLWorks.Internal.Array.update(non_gc_array, MirTypes.NonGC.unpack mir_reg, reg))
	non_gc_map
      val fp_array = MLWorks.Internal.Array.array(fp, global)
      val _ =
	MirTypes.FP.Map.iterate
	(fn (mir_reg, reg) =>
	 MLWorks.Internal.Array.update(fp_array, MirTypes.FP.unpack mir_reg, reg))
	fp_map

      val debug_map = ref debugging_map

      val value_elements =
	(map
	(fn(MirTypes.VALUE(tag, x)) =>
	 value_cg(Lists.assoc(tag, loc_refs), x,error_info))
	value_list) handle Lists.Assoc => Crash.impossible"Assoc value_elements"
	
	(* do_blocks is called by proc_cg (q.v.) to generate all the
         * code for a procedure. First it defines instruction
         * sequences for things like saving and restoring the
         * GC-saves, FP-saves and so forth, then it defines the big
         * do_everything function, which actually does the code
         * generation, and enters its complex recursion appropriately.
         * See the comment for that function. *)

      fun do_blocks(_, [], _, _, _) = []
      | do_blocks(needs_preserve, MirTypes.BLOCK(tag,opcodes) :: rest,
		  PROC_STACK
		  {non_gc_spill_size,
		   fp_spill_size,
		   fp_save_size,
		   gc_spill_size,
		   gc_stack_alloc_size,
		   register_save_size,
		   non_gc_spill_offset,
		   fp_spill_offset,
		   fp_save_offset,
		   gc_spill_offset,
		   gc_stack_alloc_offset,
		   register_save_offset,
		   allow_fp_spare_slot,
		   float_value_size
		   },
		  fps_to_preserve,
		  gcs_to_preserve
	          ) =
	let
	  val frame_size = register_save_offset + register_save_size
	  val _ =
	    if frame_size mod 8 <> 0 then
	      Info.error error_info (Info.WARNING, Info.Location.UNKNOWN,
				     "Warning: frame_size not a multiple of eight\n")
	    else
	      ()
	  val non_save_frame_size = frame_size - 44

	  fun symbolic_value MirTypes.GC_SPILL_SIZE = gc_spill_size * 4
	    | symbolic_value MirTypes.NON_GC_SPILL_SIZE =
	      non_gc_spill_size * 4
	    | symbolic_value(MirTypes.GC_SPILL_SLOT i) =
	      let
		val symbolic_value =
		  fn i =>
		  (if i >= gc_spill_size then
		     Crash.impossible
		     ("Spill slot " ^ Int.toString i ^
		      " requested, but only " ^ Int.toString gc_spill_size ^
		      " allocated\n")
		   else
		     ();
		     ~(gc_spill_offset + 4 * (1 + i))
		     )
	      in
                case i of
                  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1 i),name) =>
                    ((*output(std_out,"\n name = "^name^"\n");*)
		     let
		       val value = symbolic_value i
		     in
		       spill := RuntimeEnv.OFFSET2(RuntimeEnv.GC, value);
		       value
		     end)
                | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(_, i)),name) =>
                    ((*output(std_out,"\n name = "^name^"\n");*)
                     i)
                | MirTypes.SIMPLE i => symbolic_value i
	      end
	    | symbolic_value(MirTypes.NON_GC_SPILL_SLOT i) =
	      let
		fun symbolic_value i =
		  let
		    val offset = if allow_fp_spare_slot then 1 else 0
		  in
		    if i >= non_gc_spill_size then
		      Crash.impossible
		      ("non gc spill slot " ^ Int.toString i ^
		       " requested, but only " ^ Int.toString non_gc_spill_size ^
		       " allocated\n")
		    else
		      ();
		      ~(non_gc_spill_offset + 4 * (1 + offset + i))
		  end
	      in
                case i of
                  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1 i),name) =>
                    ((*output(std_out,"\n name = "^name^"\n");*)
		     let
		       val value = symbolic_value i
		     in
		       spill := RuntimeEnv.OFFSET2(RuntimeEnv.NONGC, value);
		       value
		     end)
                | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(_, i)),name) =>
                    ((*output(std_out,"\n name = "^name^"\n");*)
                     i)
                | MirTypes.SIMPLE i => symbolic_value i
	      end
	    | symbolic_value(MirTypes.FP_SPILL_SLOT i) =
	      let
		val spare_size = if float_value_size >= 8 then 8 else 4
		fun symbolic_value i =
		  let
		    val offset = if allow_fp_spare_slot then 1 else 0
		  in
		    (if i>= fp_spill_size then
		       Crash.impossible
		       ("fp spill slot " ^ Int.toString i ^
			" requested, but only " ^ Int.toString fp_spill_size ^
			" allocated\n")
		     else
		       ();
		       ~(fp_spill_offset + float_value_size * (1 + i) +
			 offset * spare_size)
		       )
		  end
	      in
		case i of
		  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1 i),name) =>
		    let
		      val value = symbolic_value i
		    in
		      spill := RuntimeEnv.OFFSET2(RuntimeEnv.FP, value);
		      value
		    end
		  | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(_, i)),name) => i
		  | MirTypes.SIMPLE i => symbolic_value i
	      end

	  fun gp_check_range(MirTypes.GP_IMM_INT i, signed, pos_limit) =
	    check_range(i, signed, pos_limit div 4)
	    | gp_check_range(MirTypes.GP_IMM_ANY i, signed, pos_limit) =
	      check_range(i, signed, pos_limit)
	    | gp_check_range(MirTypes.GP_IMM_SYMB symb, signed, pos_limit) =
	      check_range(symbolic_value symb, signed, pos_limit)
	    | gp_check_range _ =
	      Crash.impossible"gp_check_range of non-immediate"

	  fun is_imm32 mreg = not (is_reg mreg) andalso not (gp_check_range (mreg, true, arith_imm_limit))
	  fun is_imm16 mreg = not (is_reg mreg) andalso gp_check_range (mreg, true, arith_imm_limit)
	  fun is_imm mreg = not (is_reg mreg)

	  fun split_imm(MirTypes.GP_IMM_INT i) =
	    (i div (sethi_hisize div 4), 4*(i mod (sethi_losize div 4)))
	    | split_imm(MirTypes.GP_IMM_ANY i) =
	      (i div sethi_hisize, (i mod sethi_losize))
	    | split_imm(MirTypes.GP_IMM_SYMB symb) =
	      let
		val i = symbolic_value symb
	      in
		(i div sethi_hisize, (i mod sethi_losize))
	      end
	    | split_imm _ = Crash.impossible"split_imm of non-immediate"

          (* This should only be used for small immediates *)
          (* converts an mir immediate into an int *)
	  fun get_small_imm (MirTypes.GP_IMM_INT i) =
              fault_range (4*i, true, arith_imm_limit)
	    | get_small_imm (MirTypes.GP_IMM_ANY i) =
              fault_range (i, true, arith_imm_limit)
	    | get_small_imm (MirTypes.GP_IMM_SYMB symb) =
              fault_range (symbolic_value symb, true, arith_imm_limit)
	    | get_small_imm _ = Crash.impossible"get_small_imm of non-immediate"

	  fun load_imm_into_register (reg, imm) =
	    (* See if we can use an immediate value *)
            if gp_check_range (imm,true,arith_imm_limit)
              then
                case get_small_imm imm of
                  0 => [move_reg (reg, zero)]
                | i =>
                    [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                      (Mips_Assembly.ADDIU, reg, zero, Mips_Assembly.IMM i),
                      absent, "")]
            else
              case (split_imm imm) of
                (0,0) => Crash.impossible "zero not in range"
              | (0, low) =>
                  (* Need to ORI in the immediate *)
                  (* Don't use ADDI here as it sign extends *)
                  [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                      (Mips_Assembly.ORI, reg, zero,
                       Mips_Assembly.IMM low),
                      absent, "")]
              | (high, 0) =>
                  [(Mips_Assembly.SETHI
                    (Mips_Assembly.LUI, reg, high),
                    absent, MachTypes.reg_to_string reg ^ " := " ^ Int.toString high ^ ", load upper half")]
              | (high, low) =>
                  let
                    val comment = case imm of
                      MirTypes.GP_IMM_ANY x => "ANY(" ^ Int.toString x ^ ")"
                    | MirTypes.GP_IMM_INT x => "INT(" ^ Int.toString x ^ ")"
                    | MirTypes.GP_IMM_SYMB symb =>
                        "SYMB(" ^ Int.toString(symbolic_value symb) ^ ")"
                    | _ => Crash.impossible"load_imm_into_register bad value"
                  in
                    [(Mips_Assembly.SETHI
                      (Mips_Assembly.LUI, reg, high),
                      absent, MachTypes.reg_to_string reg ^ " := " ^ comment ^ ", loading large number"),
                     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                      (Mips_Assembly.ORI, reg, reg,
                       Mips_Assembly.IMM low),
                      absent, "")]
                  end

          (* This should only be used for small immediates *)
          (* converts an mir immediate into a machine immediate *)
	  fun convert_small_imm (MirTypes.GP_IMM_INT i) =
              make_imm_fault (4*i, true, arith_imm_limit)
	    | convert_small_imm (MirTypes.GP_IMM_ANY i) =
              make_imm_fault (i, true, arith_imm_limit)
	    | convert_small_imm (MirTypes.GP_IMM_SYMB symb) =
              make_imm_fault (symbolic_value symb, true, arith_imm_limit)
	    | convert_small_imm _ = Crash.impossible"convert_small_imm of non-immediate"

	  fun load_large_number_into_register (reg, num) =
	    load_imm_into_register (reg, MirTypes.GP_IMM_ANY num)

	  (* make_imm_for_store: restrict make_imm_fault on IMM_INT and converts R0 to #0 *)
	  (* what is an IMM_INT *)
	  (* redo in the future *)
	  local
	    fun make_imm_for_store(MirTypes.GP_IMM_ANY i) = make_imm_fault(i, true, arith_imm_limit)
	      | make_imm_for_store(MirTypes.GP_IMM_SYMB symb) = make_imm_fault(symbolic_value symb, true, arith_imm_limit)
	      | make_imm_for_store _ = Crash.impossible"make_imm_for_store(bad value)"
	  in
	    val make_imm_for_store =
	      fn x => case make_imm_for_store x of
	      x as Mips_Assembly.IMM _ => x
	    | Mips_Assembly.REG MachTypes.R0 => Mips_Assembly.IMM 0
	    | _ => Crash.impossible"make_imm_for_store produces bad register value"
	  end (* local *)

          (* NB. For double floats, the ith word goes to reg+1, the i+1th word to reg. *)
          (* This may be different of different ended machines *)
	  fun do_save_fps(_, []) = []
	    | do_save_fps(offset, fp :: rest) =
	      case MachTypes.fp_used of
		MachTypes.single =>
		  (Mips_Assembly.LOAD_AND_STORE_FLOAT
		   (Mips_Assembly.SWC1, fp, MachTypes.fp,
		    Mips_Assembly.IMM offset), NONE,
		   "save float") :: do_save_fps(offset+4, rest)
	      | MachTypes.double =>
		  (Mips_Assembly.LOAD_AND_STORE_FLOAT
		   (Mips_Assembly.SWC1, fp,
		    MachTypes.fp,
		    Mips_Assembly.IMM (offset+4)), NONE,
		   "save float") ::
		  (Mips_Assembly.LOAD_AND_STORE_FLOAT
		   (Mips_Assembly.SWC1,
		    MachTypes.next_reg fp,
		    MachTypes.fp,
		    Mips_Assembly.IMM (offset)), NONE,
		   "save float") ::
		  do_save_fps(offset+8, rest)
	      | MachTypes.extended => Crash.impossible "do_save_fps: Extended floats not supported"
	  local
	    fun really_do_restore_fps(_, []) = []
	      | really_do_restore_fps(offset, fp :: rest) =
		case MachTypes.fp_used of
		  MachTypes.single =>
		    (Mips_Assembly.LOAD_AND_STORE_FLOAT
		     (Mips_Assembly.LWC1, fp, MachTypes.fp,
		      Mips_Assembly.IMM offset), NONE,
		     "restore float") ::
		    nop ::
		    really_do_restore_fps(offset+4, rest)
		| MachTypes.double =>
		    (Mips_Assembly.LOAD_AND_STORE_FLOAT
		     (Mips_Assembly.LWC1, fp,
		      MachTypes.fp,
		      Mips_Assembly.IMM (offset+4)), NONE,
		     "restore float") ::
		    (Mips_Assembly.LOAD_AND_STORE_FLOAT
		     (Mips_Assembly.LWC1,
		      MachTypes.next_reg fp,
		      MachTypes.fp,
		      Mips_Assembly.IMM (offset)), NONE,
		     "restore float") ::
		    really_do_restore_fps(offset+8, rest)
		| MachTypes.extended => Crash.impossible "really_do_restore_fps: Extended floats not supported"
	  in
	    fun do_restore_fps(_, []) = []
	      | do_restore_fps a = really_do_restore_fps a
	  end

	  fun do_save_gcs(offset, []) =
	    if save_arg_for_debugging then
	      [(Mips_Assembly.LOAD_AND_STORE
		(Mips_Assembly.SW, MachTypes.arg, MachTypes.fp, offset),
		NONE, "save argument for debugging")]
	    else []
	    | do_save_gcs(offset, gc :: rest) =
	      (Mips_Assembly.LOAD_AND_STORE
	       (Mips_Assembly.SW, gc, MachTypes.fp,
		offset), NONE,
	       "save gcs") :: do_save_gcs(offset+4, rest)
	
	  fun do_restore_gcs(_, []) = []
	    | do_restore_gcs(offset, gc :: rest) =
		  (Mips_Assembly.LOAD_AND_STORE
		   (Mips_Assembly.LW, gc, MachTypes.fp,
		    offset), NONE,
		   "restore gcs") :: do_restore_gcs(offset+4, rest)

	  val fp_save_start = gc_spill_offset
	  val save_fps = do_save_fps(~fp_save_start, fps_to_preserve)
	  val restore_fps = do_restore_fps(~fp_save_start, fps_to_preserve)
	  (* Note that these work up from this slot *)

	  val callee_save_size =
	    List.length gcs_to_preserve +
	    (if save_arg_for_debugging then 1 else 0)

	  val callee_save_offset = register_save_offset + callee_save_size * 4

	  val save_gcs = do_save_gcs(~callee_save_offset, gcs_to_preserve)

	  val restore_gcs = do_restore_gcs(~callee_save_offset, gcs_to_preserve)
	
	  fun is_comment(MirTypes.COMMENT _) = true
	    | is_comment _ = false

(*

fun do_everything, called by fun do_blocks to actually generate
machine instructions for each MIR opcode, recurses through opcodes in
order within each block, and through the blocks in order.

do_everything takes 6 arguments:

needs_preserve
	a boolean, true if we are in a function which creates a stack
	frame, i.e. a non-leaf,
tag
	the tag of the current block,
opcode_list
	the MIR opcodes left to translate in the current block
done
	a Sexpr of lists of the MIPS instructions produced so far in this block
block_list
	blocks remaining to be translated
final_result
	a list of blocks (i.e. pairs of tags and instruction lists)
	produced so far.

The recursion is such that the translation of an individual
instruction can:

(1) generate finished blocks to add to the final_result (e.g. a loop),
    or remove finished blocks from the final_result.

(2) construct MIR blocks to push back onto the block_list (e.g. if
    code generating some instructions needs to be postponed, if a set
    of instructions needs to be tagged differently, a new MIR block can be
    made of them and pushed on the block_list)

(3) modify the opcode_list (e.g. delete all remaining opcodes from this block)

(4) add instructions to the done sexpr.

*)
	  fun do_everything(_, tag, [], done, [], final_result) = (tag, Sexpr.toList done) :: final_result
	    | do_everything
	    (needs_preserve, tag, [], done,
	     MirTypes.BLOCK(tag',opcodes) :: blocks,
	     final_result) =
	    do_everything
	    (needs_preserve, tag',
	     List.filter (fn x=>not(is_comment x)) opcodes,
	     Sexpr.NIL,
	     blocks,
	     (tag, Sexpr.toList done) :: final_result)

	  | do_everything
	    (needs_preserve, tag, opcode :: opcode_list, done,
	     block_list, final_result) =
	    let
	      fun lookup_reg(reg, table) =
		let
		  val reg = MLWorks.Internal.Array.sub(table, reg)
		in
		  if needs_preserve then reg
		  else MachTypes.after_restore reg
		end

	      fun lookup_reg_operand(MirTypes.GC_REG reg) =
	        lookup_reg(MirTypes.GC.unpack reg, gc_array)
	      | lookup_reg_operand(MirTypes.NON_GC_REG reg) =
		lookup_reg(MirTypes.NonGC.unpack reg, non_gc_array)
		
	      fun lookup_gp_operand(MirTypes.GP_GC_REG reg) =
	        lookup_reg(MirTypes.GC.unpack reg, gc_array)
	      | lookup_gp_operand(MirTypes.GP_NON_GC_REG reg) =
		lookup_reg(MirTypes.NonGC.unpack reg, non_gc_array)
	      | lookup_gp_operand _ =
		Crash.impossible"lookup_gp_operand(constant)"

	      fun lookup_fp_operand(MirTypes.FP_REG reg) =
		MLWorks.Internal.Array.sub(fp_array, MirTypes.FP.unpack reg)

              fun is_tagged_mult_op MirTypes.MULS = true
                | is_tagged_mult_op MirTypes.DIVS = true
                | is_tagged_mult_op MirTypes.MODS = true
                | is_tagged_mult_op MirTypes.MUL32S = true
                | is_tagged_mult_op MirTypes.DIV32S = true
                | is_tagged_mult_op MirTypes.MOD32S = true
                | is_tagged_mult_op MirTypes.DIVU = true
                | is_tagged_mult_op MirTypes.MODU = true
                | is_tagged_mult_op MirTypes.DIV32U = true
                | is_tagged_mult_op MirTypes.MOD32U = true
                | is_tagged_mult_op _ = false

              fun is_mult_op MirTypes.MULU = true
                | is_mult_op MirTypes.MUL32U = true
                | is_mult_op _ = false

	      val (result_list, opcode_list, new_blocks, new_final_result) =

		(* the case statement from hell!
		 * each case returns the above 4-tuple so that we can
		 * achieve the recursion result described in the big
		 * comment above. *)

		case opcode of
		  (* TBINARY rewritten by nickb 1995-01-19 *)
		  MirTypes.TBINARY(tagged_op, taglist, reg, gp, gp') =>
                    let
                      val preserve_order =
                        case tagged_op of
                          MirTypes.SUBS => true
                        | MirTypes.DIVS => true
                        | MirTypes.MODS => true
                        | MirTypes.SUB32S => true
                        | MirTypes.DIV32S => true
                        | MirTypes.MOD32S => true
                        | MirTypes.DIVU => true
                        | MirTypes.MODU => true
                        | MirTypes.DIV32U => true
                        | MirTypes.MOD32U => true
                        | _ => false
			
                      val error_tag = case taglist of [] => NONE | (a::b) => SOME a

                      val is_reg_gp = is_reg gp
                      val is_reg_gp' = is_reg gp'

                      val xchg = (not is_reg_gp) andalso is_reg_gp' andalso (not preserve_order)
                      val redo = (not is_reg_gp) andalso is_reg_gp' andalso preserve_order

                      val (gp,gp') = if xchg then (gp',gp) else (gp,gp')
                      val is_reg_gp = is_reg gp
                      val is_reg_gp' = is_reg gp'
                    in
                      if redo then
                        ([],
                         MirTypes.UNARY(MirTypes.MOVE, global_reg, gp) ::
                         MirTypes.TBINARY(tagged_op, taglist, reg, global_gp, gp') ::
                         opcode_list, block_list, final_result)
                      else if is_tagged_mult_op tagged_op
                        then
                          (* First rewrite case when either argument is non-register *)
                          if not is_reg_gp
                            then
                              ([],
                               MirTypes.UNARY (MirTypes.MOVE,reg,gp) ::
                               MirTypes.TBINARY (tagged_op, taglist, reg,gp_from_reg reg, gp') ::
                               opcode_list, block_list, final_result)
                          else if not is_reg_gp'
                             then
                               ([],
                                MirTypes.UNARY(MirTypes.MOVE,global_reg, gp') ::
                                MirTypes.TBINARY(tagged_op, taglist,reg, gp, global_gp) ::
                                opcode_list,
                                block_list, final_result)
                          else
                            (* its a mult_op and both operands are registers *)
                            (* r3 can't be the global reg *)
                            let
                              val r1 = lookup_gp_operand gp
                              val r2 = lookup_gp_operand gp'
                              val r3 = lookup_reg_operand reg (* This is the result register *)
                              val check =
                                if r3 = global
                                  then Crash.impossible "TBINARY, mult_op: r3 is global"
                                else ()
                              val check =
                                if r1 = r2 andalso r2 = global
                                  then Crash.impossible "TBINARY(multiply): both r1 & r2 are global"
                                else ()
                              fun make_clean_blocks (error_tag,true) =
                                (error_tag,[])
                                | make_clean_blocks (error_tag,false) =
                                let
                                  val tag = MirTypes.new_tag ()
                                in
                                  (SOME tag,
                                   [(tag,
                                     make_clean_code [r1,r2,r3] @@
                                     [(Mips_Assembly.BRANCH (Mips_Assembly.BA, zero, zero, 0),
                                       error_tag, ""),
                                      Mips_Assembly.nop])])
                                end

                              (* Test for exceptional conditions *)
                              (* These tests are done in between the multiplication and returning the result *)
                              fun mul_code (r1,r2,r3,tagged_calc) =
                                let
                                  val (overflow_tag,overflow_blocks) =
                                    make_clean_blocks (error_tag,tagged_calc)
                                in
                                  ([(Mips_Assembly.MULT_AND_DIV_RESULT (Mips_Assembly.MFHI, r3),
                                     absent,"get high word of result"),
                                    (Mips_Assembly.MULT_AND_DIV_RESULT (Mips_Assembly.MFLO, global),
                                     absent,"get low word of result"),
                                    (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SRA,
                                                                           global,
                                                                           global,
                                                                           Mips_Assembly.IMM 31),
                                     absent,"and sign extend"),
                                    (Mips_Assembly.BRANCH (Mips_Assembly.BNE, global, r3, 0),
                                     overflow_tag, "and check if they are the same"),
                                    (Mips_Assembly.MULT_AND_DIV_RESULT (Mips_Assembly.MFLO, r3),
                                     absent,"get answer in delay")],
                                  overflow_blocks,opcode_list, block_list)
                                end
                              fun adjust_code (r2,temp,r3,getcode,tag_result,cont_tag,adjust_op) =
                                let
                                  val adjust = MirTypes.new_tag ()
                                  val noadjust = MirTypes.new_tag ()
                                  val noadjust1 = MirTypes.new_tag ()
                                  val tag_op =
                                    if not tag_result
                                      then move_reg (r3,temp)
                                    else
                                      (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SLL,
                                                                             r3,
                                                                             temp,
                                                                             Mips_Assembly.IMM 2),
                                       absent, "Tag result in delay")
                                in
                                  ([(Mips_Assembly.MULT_AND_DIV_RESULT (Mips_Assembly.MFHI, temp),
                                     absent,""),
                                    (Mips_Assembly.BRANCH (Mips_Assembly.BEQ, temp, zero, 0),
                                     SOME noadjust1,""),
                                    (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.XOR,
                                                                           temp,
                                                                           r2,
                                                                           Mips_Assembly.REG temp),
                                     absent,"check remainder is same sign"),
                                    (Mips_Assembly.BRANCH (Mips_Assembly.BLTZ,temp,zero,0),
                                     SOME adjust, ""),
                                    (Mips_Assembly.MULT_AND_DIV_RESULT (getcode, temp),
                                     absent, "fetch actual result"),
                                    (Mips_Assembly.BRANCH (Mips_Assembly.BA,zero,zero,0),
                                     SOME noadjust,""),
                                    nop],
                                [(adjust,
                                  [(Mips_Assembly.BRANCH (Mips_Assembly.BA,zero,zero,0),
                                    SOME noadjust,""),
                                   (adjust_op,absent,"adjust result in delay")]),
                                 (noadjust1,
                                  [(Mips_Assembly.MULT_AND_DIV_RESULT (getcode, temp),
                                     absent, "fetch actual result"),
                                   (Mips_Assembly.BRANCH (Mips_Assembly.BA,zero,zero,0),
                                    SOME cont_tag,""),
                                   tag_op]),
                                 (noadjust,
                                  [(Mips_Assembly.BRANCH (Mips_Assembly.BA,zero,zero,0),
                                    SOME cont_tag,""),
                                   tag_op])])
                                end


                              fun div_code (r1,r2,r3,tagged_calc) =
                                let
                                  val (overflow_tag,div_tag) =
                                    case taglist of
                                      [a,b] => (a,b)
                                    | _ => Crash.impossible "Wrong tags for div"
                                  val (div_tag,div_blocks) =
                                    make_clean_blocks (SOME div_tag,tagged_calc)
                                  val (overflow_tag,overflow_blocks) =
                                    make_clean_blocks (SOME overflow_tag,tagged_calc)
                                  val cont_tag = MirTypes.new_tag ()
                                  val ok_tag = MirTypes.new_tag ()
                                  val temp = if r2 = global then r3 else global
                                  (* Note that temp could be the same as r1 *)
                                  val arg_test =
                                    [(Mips_Assembly.BRANCH (Mips_Assembly.BEQ,
                                                            r2,
                                                            zero,
                                                            0),
                                      div_tag, "branch on division by zero"),
                                     nop,
                                     (* Now see if we are dividing MININT by ~1 *)
                                     (* if r1 is non-negative then we are OK *)
                                     (Mips_Assembly.BRANCH (Mips_Assembly.BGEZ,
                                                            r1,
                                                            zero,
                                                            0),
                                      SOME ok_tag, ""),
                                     nop,
                                     (* else subtract one *)
                                     (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SUBU,
                                                                            r1,
                                                                            r1,
                                                                            Mips_Assembly.IMM 1),
                                      absent,""),
                                     (* its positive iff it was originally MININIT *)
                                     (Mips_Assembly.BRANCH (Mips_Assembly.BLTZ,
                                                            r1,
                                                            zero,
                                                            0),
                                      SOME ok_tag, ""),
                                     (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADDU,
                                                                            r1,
                                                                            r1,
                                                                            Mips_Assembly.IMM 1),
                                      absent,"Restore reg in delay"),
                                     (* Now check for (tagged) ~1 *)
                                     (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SUB,
                                                                            temp,
                                                                            zero,
                                                                            if tagged_calc
                                                                              then Mips_Assembly.IMM 4
                                                                            else Mips_Assembly.IMM 1),
                                      absent,""),
                                     (Mips_Assembly.BRANCH (Mips_Assembly.BEQ,
                                                            r2,
                                                            temp,
                                                            0),
                                      overflow_tag, ""),
                                     nop,
                                     (Mips_Assembly.BRANCH (Mips_Assembly.BA,
                                                            zero,
                                                            zero,
                                                            0),
                                      SOME ok_tag, ""),
                                     nop]

                                  val (rest,blocks) =
                                    adjust_code (r2,temp,r3,Mips_Assembly.MFLO,tagged_calc,cont_tag,
                                                 Mips_Assembly.ARITHMETIC_AND_LOGICAL
                                                 (Mips_Assembly.SUB,
                                                  temp,
                                                  temp,
                                                  Mips_Assembly.IMM 1))
                                in
                                  (arg_test,
                                   (ok_tag,rest) :: div_blocks @@ overflow_blocks @@ blocks,
                                   [],
                                   MirTypes.BLOCK (cont_tag,opcode_list) ::  block_list)
                                end
                              fun mod_code (r1,r2,r3,tagged_calc) =
                                let
                                  val (div_tag,div_blocks) =
                                    make_clean_blocks (error_tag,tagged_calc)
                                  val arg_test = [(Mips_Assembly.BRANCH (Mips_Assembly.BEQ, r2, zero, 0),
                                                   div_tag, "branch on division by zero")]
                                  val cont_tag = MirTypes.new_tag ()
                                  val temp = if r2 = global then r3 else global
                                  val (rest,blocks) =
                                    adjust_code (r2,temp,r3,Mips_Assembly.MFHI,false,cont_tag,
                                                 Mips_Assembly.ARITHMETIC_AND_LOGICAL
                                                 (Mips_Assembly.ADD,
                                                  temp,
                                                  temp,
                                                  Mips_Assembly.REG r2))
                                in
                                  (arg_test @@ rest,
                                   div_blocks @@ blocks,
                                   [],
                                   MirTypes.BLOCK (cont_tag,opcode_list) :: block_list)
                                end
                              fun modu_code (r1,r2,r3,tagged_calc) =
                                let
                                  val (div_tag,div_blocks) =
                                    make_clean_blocks (error_tag,tagged_calc)
                                  val code = [(Mips_Assembly.BRANCH (Mips_Assembly.BEQ, r2, zero, 0),
                                               div_tag, "branch on division by zero"),
                                              nop,
                                              (Mips_Assembly.MULT_AND_DIV_RESULT (Mips_Assembly.MFHI, r3),
                                               absent,"")]
                                in
                                  (code,
                                   div_blocks,
                                   opcode_list,
                                   block_list)
                                end
                              fun divu_code (r1,r2,r3,tagged_calc) =
                                let
                                  val (div_tag,div_blocks) =
                                    make_clean_blocks (error_tag,tagged_calc)
                                  val code = [(Mips_Assembly.BRANCH (Mips_Assembly.BEQ, r2, zero, 0),
                                               div_tag, "branch on division by zero"),
                                              nop,
                                              (Mips_Assembly.MULT_AND_DIV_RESULT (Mips_Assembly.MFLO, r3),
                                               absent,"")]
                                  val tag_result =
                                    if tagged_calc then
                                      [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                                        (Mips_Assembly.SLL,
                                         r3,
                                         r3,
                                         Mips_Assembly.IMM 2),
                                        absent, "Tag result")]
                                    else []
                                in
                                  (code @@ tag_result,
                                   div_blocks,
                                   opcode_list,
                                   block_list)
                                end
                              val (opcode, (result_code,extra,opcode_list,block_list), untag) =
                                case tagged_op of
                                  (* pass global as second parameter because of untagging *)
                                  MirTypes.MULS => (Mips_Assembly.MULT, mul_code (r1,global,r3,true), true)
                                | MirTypes.DIVS => (Mips_Assembly.DIV, div_code (r1,r2,r3,true), false)
                                | MirTypes.MODS => (Mips_Assembly.DIV, mod_code (r1,r2,r3,true), false)
                                | MirTypes.DIVU => (Mips_Assembly.DIVU, divu_code (r1,r2,r3,true),false)
                                | MirTypes.MODU => (Mips_Assembly.DIVU, modu_code (r1,r2,r3,true),false)
                                | MirTypes.MUL32S => (Mips_Assembly.MULT, mul_code (r1,r2,r3,false), false)
                                | MirTypes.DIV32S => (Mips_Assembly.DIV, div_code (r1,r2,r3,false), false)
                                | MirTypes.MOD32S => (Mips_Assembly.DIV, mod_code (r1,r2,r3,false), false)
                                | MirTypes.DIV32U => (Mips_Assembly.DIVU, divu_code (r1,r2,r3,false),false)
                                | MirTypes.MOD32U => (Mips_Assembly.DIVU, modu_code (r1,r2,r3,false),false)
                                | _ => Crash.impossible ("mult_op opcode")
                            in
                              (* Untag r2 into global -- r1 can't be the global register *)
                              ((if untag then
                                  if r1 = global
                                    then Crash.impossible "TBINARY (MULS) untagging into r1"
                                  else
                                    [(Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SRA,
                                                                            MachTypes.global, r2, Mips_Assembly.IMM 2),
                                      absent, "Untag arg")]
                                else []) @@
                               [(Mips_Assembly.MULT_AND_DIV (opcode,r1,if untag then MachTypes.global else r2),
                                 absent, "")] @@
                               result_code,
                               opcode_list, block_list, extra @@ final_result)
                            end (* of mult_op case *)
                      else if is_reg_gp then
                         if is_reg_gp' orelse
			  gp_check_range(gp', true, arith_imm_limit) then
			  let
			    val reg_or_imm =
			      if is_reg_gp' then
				Mips_Assembly.REG(lookup_gp_operand gp')
			      else convert_small_imm gp'
			      val use_traps = case tagged_op of
				MirTypes.ADDS => true
			      | MirTypes.SUBS => true
                              | _ => false
			      val rs1 = lookup_gp_operand gp
                              val rd = lookup_reg_operand reg
			  in
			    if use_traps then
			      let
				val opcode = case tagged_op of
				  MirTypes.ADDS => Mips_Assembly.ADD
				| MirTypes.SUBS => Mips_Assembly.SUB
				| _ => Crash.impossible"do_opcodes(TBINARY)"
			      in
				([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				   (opcode, rd, rs1, reg_or_imm), absent, "")],
				 opcode_list, block_list, final_result)
			      end
			    else
			      let
				val opcode = case tagged_op of
				  MirTypes.ADD32S => Mips_Assembly.ADDU
				| MirTypes.SUB32S => Mips_Assembly.SUBU
				| _ => Crash.impossible"do_opcodes(TBINARY)"
				val _ =
				  if rd = MachTypes.global then
				    Crash.impossible"TBINARY global destination"
				  else
				    ()
				val regs_to_clean = [rd, rs1]
				val regs_to_clean = case reg_or_imm of
				  Mips_Assembly.REG reg => reg :: regs_to_clean
				| _ => regs_to_clean
                                val clean_code =
                                  make_clean_code regs_to_clean @@
                                  [(Mips_Assembly.BRANCH
				    (Mips_Assembly.BA, zero, zero, 0),
				    error_tag, ""),
				   Mips_Assembly.nop]
				val exn_tag = MirTypes.new_tag()
				val exn_tag_opt = SOME exn_tag
			      in
				(* Tricky stuff here *)
				(* We must do manual overflow detection *)
				(* for x + y this is (x + y < x) <> (y < 0) *)
				(* for x - y this is (x - y > x) <> (y < 0) *)
				(* The general case can be improved *)
				(* if y is a constant as y < 0 is then also constant *)
				(* First deal with some silly cases *)
				case reg_or_imm of
				  Mips_Assembly.REG rs2 =>
				    (if rs1 = rs2 then
				       (* this is either double (ADDW) or *)
				       (* produce zero (SUBW) *)
				       case opcode of
					 Mips_Assembly.ADDU =>
					   (* What if rd = rs1? *)
					   let
					     val (extra, rs1) =
					       if rs1 = rd then
						 ([move_reg(MachTypes.global, rs1)], global)
					       else
						 ([], rs1)
					   in
					     ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
						(opcode, rd, rs1, reg_or_imm), absent, ""),
					       (Mips_Assembly.ARITHMETIC_AND_LOGICAL
						(Mips_Assembly.XOR, MachTypes.global,
						 rd, Mips_Assembly.REG MachTypes.global),
						absent, "Check for sign change across add"),
					       (Mips_Assembly.BRANCH
						(Mips_Assembly.BLTZ, MachTypes.global,
						 zero, 0), exn_tag_opt,
						"Branch on overflow"),
					       Mips_Assembly.nop],
					      opcode_list, block_list, final_result)
					   end
				       | Mips_Assembly.SUBU =>
					   ([move_regc(rd, zero, "sub rd, x, x!")],
					    opcode_list, block_list, final_result)
				       | _ => Crash.impossible"TBINARY failure"
				     else
				       (* All register args, sources distinct *)
				       (* Must now check if rs1 = rd *)
				       (* As this will mess up the first test *)
				       if rd = rs1 then
					 if opcode = Mips_Assembly.ADDU then
					   (* Just swap the operands in this case *)
					   (* as we already know rs2 <> rs1 *)
					   ([],
					    MirTypes.TBINARY(tagged_op, taglist, reg, gp', gp) :: opcode_list,
					    block_list, final_result)
					 else
					   (* Subtract case, can't swap operands *)
					   (* So put rs1 into global then repeat *)
					   if rs2 = MachTypes.global then
					     Crash.unimplemented"TBINARY SUB rd, rd, global"
					   else
					     ([],
					      MirTypes.UNARY(MirTypes.MOVE, MirTypes.GC_REG MirRegisters.global, gp) ::
					      MirTypes.TBINARY(tagged_op, taglist, reg, MirTypes.GP_GC_REG MirRegisters.global, gp') ::
					      opcode_list, block_list, final_result)
				       else
					 (* rs1 <> rd *)
					 let
                                           (* If rs2 = rd then we need to save its value in global *)
                                           (* If so, we should check that rs1 <> global and rd <> global *)
                                           (* And rs1 = global only if rs1 was originally rd, but rs2 and rs1 can't *) 
                                           (* be equal, so we should be OK *)
                                           (* Check anyway to make sure *)
                                           val (get_rs2,rs2_reg) =
                                             if rs2 = rd then
                                               (if rd = global 
                                                  then Crash.impossible ("rd = global in int 32 op")
                                                else if rs1 = global 
                                                  then Crash.impossible ("rs1 = global in int 32 op")
                                                else ();
                                                ([move_regc(global, rs2, "Save rs2 in global")],
                                                 global))
                                             else ([], rs2)
					   val swap_for_slt =
					     case opcode of
					       Mips_Assembly.ADDU => false
					     | Mips_Assembly.SUBU => true
					     | _ => Crash.impossible"TBINARY failure"
					   (* true if we test result < source *)
					   (* false if we test source < result *)

					   val slt =
					     if swap_for_slt then
					       Mips_Assembly.ARITHMETIC_AND_LOGICAL
					       (Mips_Assembly.SLT,
						MachTypes.global, rs1,
						Mips_Assembly.REG rd)
					     else
					       Mips_Assembly.ARITHMETIC_AND_LOGICAL
					       (Mips_Assembly.SLT,
						MachTypes.global, rd,
						Mips_Assembly.REG rs1)
					   val second_test_tag = MirTypes.new_tag()
					   val second_test_tag_opt =
					     SOME second_test_tag
					   val cont_tag = MirTypes.new_tag()
					   val cont_tag_opt =
					     SOME cont_tag
					 in
					   (get_rs2 @@
                                            [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					      (opcode, rd, rs1, reg_or_imm), absent, ""),
					     (Mips_Assembly.BRANCH
					      (Mips_Assembly.BLTZ, rs2_reg, zero, 0),
					      second_test_tag_opt,
					      "Branch on y < 0"),
					     (* y >= 0 case *)
					     (* Test rd < rs1 for ADD *)
					     (* Or rs1 < rd for SUB *)
					     (slt, absent, "binary operation overflow check"),
					     (Mips_Assembly.BRANCH
					      (Mips_Assembly.BGTZ, global, zero, 0),
					      exn_tag_opt,
					      "Branch on < for ADD and > for SUB"),
					     Mips_Assembly.nop,
					     (Mips_Assembly.BRANCH
					      (Mips_Assembly.BA, zero, zero, 0),
					      cont_tag_opt, "Continue normal flow"),
					     Mips_Assembly.nop],
					   [],
					   MirTypes.BLOCK(cont_tag, opcode_list) ::
					   block_list,
					   (second_test_tag,
					    (* Use the same test result, but *)
					    (* Take the opposite branch *)
					     [(Mips_Assembly.BRANCH
					       (Mips_Assembly.BEQZ, global, zero, 0),
					       exn_tag_opt,
					       "Branch on >= for ADD and <= for SUB"),
                                              Mips_Assembly.nop,
					      (Mips_Assembly.BRANCH
					       (Mips_Assembly.BA, zero, zero, 0),
					       cont_tag_opt, "Continue normal flow"),
					      Mips_Assembly.nop]) ::
					    (exn_tag, clean_code) :: final_result)
					 end)
				| Mips_Assembly.IMM imm =>
				    (* y is immediate here *)
				    let
				      val test =
					if imm < 0 then
					  Mips_Assembly.BEQZ
					else
					  Mips_Assembly.BGTZ
				      val swap_for_slt =
					case opcode of
					  Mips_Assembly.ADDU => false
					| Mips_Assembly.SUBU => true
					| _ => Crash.impossible"TBINARY failure"
				      (* true if we test result < source *)
				      (* false if we test source < result *)

				      (* Now check rd <> rs1, else we must use *)
				      (* global to hold one of them *)
				      val (extra, rs1) =
					if rs1 = rd then
					  ([move_reg(MachTypes.global, rs1)], global)
					else
					  ([], rs1)
				      val slt =
					if swap_for_slt then
					  Mips_Assembly.ARITHMETIC_AND_LOGICAL
					  (Mips_Assembly.SLT,
					   MachTypes.global, rs1,
					   Mips_Assembly.REG rd)
					else
					  Mips_Assembly.ARITHMETIC_AND_LOGICAL
					  (Mips_Assembly.SLT,
					   MachTypes.global, rd,
					   Mips_Assembly.REG rs1)
				    in
				      (extra @@
				       [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					 (opcode, rd, rs1, reg_or_imm), absent, ""),
					(slt, absent, "binary operation overflow check"),
					(Mips_Assembly.BRANCH
					 (test, global, zero, 0),
					 exn_tag_opt,
					 "Branch to clean before raising exception"),
					Mips_Assembly.nop],
				       opcode_list, block_list,
				       (exn_tag, clean_code) :: final_result)
				    end
			      end
			  end
			else
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  global_reg, gp') ::
			   MirTypes.TBINARY(tagged_op, taglist,
					    reg, gp, global_gp) ::
			   opcode_list, block_list, final_result)
		      else
			([],
			  MirTypes.UNARY(MirTypes.MOVE, reg, gp) ::
			  MirTypes.TBINARY(tagged_op, taglist, reg,
					   gp_from_reg reg, gp') ::
			  opcode_list, block_list, final_result)
		  end
		| MirTypes.BINARY(binary_op, reg_operand, gp_operand,
				  gp_operand') =>
		  if is_mult_op binary_op then
		    if not (is_reg gp_operand) then
		       ([],
			MirTypes.UNARY (MirTypes.MOVE, reg_operand, gp_operand) ::
			MirTypes.BINARY (binary_op, reg_operand,
					 gp_from_reg reg_operand, gp_operand') ::
			opcode_list, block_list, final_result)
		     else
		     if not (is_reg gp_operand') then
		       ([],
			MirTypes.UNARY(MirTypes.MOVE,
				       global_reg, gp_operand') ::
			MirTypes.BINARY(binary_op, reg_operand, gp_operand, global_gp) ::
			opcode_list,
			block_list, final_result)
		     else (* its a mult_op and both operands are registers *)
		       let
			 val r1 = lookup_gp_operand gp_operand
			 val r2 = lookup_gp_operand gp_operand'
			 val r3 = lookup_reg_operand reg_operand
			 val (opcode,result_opcode,untag) =
			   case binary_op of
			     MirTypes.MULU =>
			       (Mips_Assembly.MULTU,Mips_Assembly.MFLO,true)
			   | MirTypes.MUL32U =>
			       (Mips_Assembly.MULTU,Mips_Assembly.MFLO,false)
			   | _ => Crash.impossible ("mult_op opcode")
		       in
			 ((if untag then
			     [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (Mips_Assembly.SRA, MachTypes.global, r2,
				Mips_Assembly.IMM 2),
			       absent, "Untag arg")]
			   else []) @@
			     [(Mips_Assembly.MULT_AND_DIV
			       (opcode, r1,
				if untag then MachTypes.global else r2),
			       absent, "")] @@
			     [(Mips_Assembly.MULT_AND_DIV_RESULT (result_opcode,r3),
			       absent, "")],
			     opcode_list, block_list, final_result)
		       end (* of mult_op case *)
                  else
                    let
		      (* Shifts are difficult, we'll do them separately *)
		      fun is_shift MirTypes.ADDU = false
			| is_shift MirTypes.SUBU = false
			| is_shift MirTypes.MULU = false
			| is_shift MirTypes.MUL32U = false
			| is_shift MirTypes.AND = false
			| is_shift MirTypes.OR = false
			| is_shift MirTypes.EOR = false
			| is_shift MirTypes.LSR = true
			| is_shift MirTypes.ASL = true
			| is_shift MirTypes.ASR = true

		      val rd = lookup_reg_operand reg_operand
		      val opcode =
			case binary_op of
			  MirTypes.ADDU => Mips_Assembly.ADDU
			| MirTypes.SUBU => Mips_Assembly.SUBU
			| MirTypes.AND => Mips_Assembly.AND
			| MirTypes.OR => Mips_Assembly.OR
			| MirTypes.EOR => Mips_Assembly.XOR
			| MirTypes.LSR => Mips_Assembly.SRL
			| MirTypes.ASL => Mips_Assembly.SLL
			| MirTypes.ASR => Mips_Assembly.SRA
			| MirTypes.MULU => Crash.impossible"MirTypes.MULU"
			| MirTypes.MUL32U => Crash.impossible"MirTypes.MULS"

		      fun needs_reverse Mips_Assembly.SUB	= true
			| needs_reverse Mips_Assembly.SUBU	= true
			| needs_reverse Mips_Assembly.SRL	= true
			| needs_reverse Mips_Assembly.SLL	= true
			| needs_reverse Mips_Assembly.SRA	= true
			| needs_reverse _ 			= false

		      val (gp_operand, gp_operand', redo) =
			if is_reg gp_operand then
			  (gp_operand, gp_operand', false)
			else
			  if is_reg gp_operand' then
			    if needs_reverse opcode then
			      (gp_operand, gp_operand', true)
			    else
			      (gp_operand', gp_operand, false)
			  else (* Both immediate so no problem *)
			    (gp_operand, gp_operand', false)
		      val is_a_shift = is_shift binary_op
		    in
		      if redo andalso not is_a_shift then
			let
			  val inter_reg =
			    case gp_operand' of
			      MirTypes.GP_GC_REG r =>
				(if r = global_mir then
				   (* The nasty case *)
				   (case reg_operand of
				      MirTypes.GC_REG r' =>
					if r = r' then
					  Crash.impossible "source and dest global with large int"
					else
					  r'
				    | MirTypes.NON_GC_REG _ =>
					  Crash.impossible"BINARY doesn't deliver GC")
				 else
				   global_mir)
			    | _ => Crash.impossible "BINARY has non-gc register"
			in
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  MirTypes.GC_REG inter_reg,
					  gp_operand) ::
			   MirTypes.BINARY(binary_op, reg_operand,
					   MirTypes.GP_GC_REG inter_reg,
					   gp_operand') ::
			   opcode_list, block_list, final_result)
			end
		      else
			if is_a_shift then
			  (* Deal with possible out of range shifts *)
			  let
			    val const_shift = case gp_operand' of
			      MirTypes.GP_GC_REG _ => false
			    | MirTypes.GP_NON_GC_REG _ => false
			    | _ => true
			  in
			    if const_shift then
			      let
				val shift_size = convert_small_imm gp_operand'
				fun get_shift(Mips_Assembly.IMM i) = i
				  | get_shift(Mips_Assembly.REG (MachTypes.R0)) = 0
				  | get_shift _ =
				  Crash.impossible"mach_cg:non_constant in shift by constant"
				val shift_val = get_shift shift_size
			      in
				case binary_op of
				  MirTypes.LSR =>
				    (* Deal with possible immediate value here *)
				    if is_reg gp_operand then
				      let
					val rs1 = lookup_gp_operand gp_operand
				      in
					([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					   (opcode, rd, rs1, shift_size),
					   absent, "")],
					 opcode_list, block_list, final_result)
				      end
				    else
				      (* A rare case, just replace by move *)
				      (* and shift the result *)
				      ([],
				       MirTypes.UNARY(MirTypes.MOVE,
						      global_reg,
						      gp_operand) ::
				       MirTypes.BINARY(binary_op,
						       reg_operand,
						       global_gp,
						       gp_operand') ::
				       opcode_list,
				       block_list, final_result)
				| MirTypes.ASR =>
				  if is_reg gp_operand then
				    let
				      val rs1 = lookup_gp_operand gp_operand
				    in
				      ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					 (opcode, rd, rs1, shift_size),
					 absent, "")],
				       opcode_list, block_list, final_result)
				    end
				  else
				    (* A rare case, just replace by move *)
				    (* and shift the result *)
				    ([],
				     MirTypes.UNARY(MirTypes.MOVE,
						    global_reg,
						    gp_operand) ::
				     MirTypes.BINARY(binary_op,
						     reg_operand,
						     global_gp,
						     gp_operand') ::
				     opcode_list,
				     block_list, final_result)
				| MirTypes.ASL =>
				    (* Deal with possible immediate value here *)
				    if is_reg gp_operand then
				      let
					val rs1 = lookup_gp_operand gp_operand
				      in
					([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					   (opcode, rd, rs1, shift_size),
					   absent, "")],
					 opcode_list, block_list, final_result)
				      end
				    else
				      (* A rare case, just replace by move *)
				      (* and shift the result *)
				      ([],
				       MirTypes.UNARY(MirTypes.MOVE,
						      global_reg,
						      gp_operand) ::
				       MirTypes.BINARY(binary_op,
						       reg_operand,
						       global_gp,
						       gp_operand') ::
				       opcode_list,
				       block_list, final_result)
				| _ => Crash.impossible"mach_cg: non-shift in shift case"
			      end
			    else
			      (* Need a range test to sort out shifts by large amounts *)
			      (* This includes the case of a constant shifted by a variable amount *)
			      let
				val rs1 = lookup_gp_operand gp_operand'
				val cont_tag = MirTypes.new_tag()
				fun make_range_test limit =
				  let
				    val bad_tag = MirTypes.new_tag()
				  in
				    (bad_tag,
				     [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				       (Mips_Assembly.SLTIU,
					MachTypes.global, rs1,
					Mips_Assembly.IMM limit),
				       absent, "shift range test"),
				      (Mips_Assembly.BRANCH
				       (Mips_Assembly.BEQ, MachTypes.global,
					zero, 0),
				       SOME bad_tag, ""),
				      nop])
				  end

				val continue =
				  [(Mips_Assembly.BRANCH
				    (Mips_Assembly.BA, zero, zero, 0),
				    SOME cont_tag, ""),
				   nop]

				fun constant_out_of_range_shift gp_op =
				  case binary_op of
				    MirTypes.ASL => [move_imm(rd, 0)]
				  | MirTypes.ASR =>
				      if gp_check_range(gp_op, false, arith_imm_limit) then
					[move_imm(rd, 0)]
				      else
					(case gp_operand of
					   MirTypes.GP_IMM_INT i =>
					     [move_imm(rd, if i < 0 then ~4 else 0)]
					 | MirTypes.GP_IMM_ANY i =>
					     [move_imm(rd, 0)]
					 | _ => Crash.impossible"Mach_cg:shift:bad constant")
				  | MirTypes.LSR => [move_imm(rd, 0)]
				  | _ => Crash.impossible"mach_cg: non-shift in shift case"
				val shift_limit = case binary_op of
				  MirTypes.ASL => 32
				| MirTypes.ASR => 31
				| MirTypes.LSR => 32
				| _ => Crash.impossible"mach_cg: non-shift in shift case"

				fun variable_out_of_range_shift gp_op =
				  case binary_op of
				    MirTypes.ASL => [move_imm(rd, 0)]
				  | MirTypes.ASR =>
				      (* Shift by 31 and tag if necessary *)
				      [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					(opcode, rd, lookup_gp_operand gp_op,
					 Mips_Assembly.IMM 31),
					absent, "")]
				  | MirTypes.LSR => [move_imm(rd, 0)]
				  | _ => Crash.impossible"mach_cg: non-shift in shift case"

				val (bad_tag, range_test) =
				  make_range_test shift_limit
				val shift_op =
				  if is_reg gp_operand then
				    [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				      (opcode, rd,
				       lookup_gp_operand gp_operand,
				       Mips_Assembly.REG rs1),
				      absent, "")]
				  else
				    load_imm_into_register(rd, gp_operand) @@
				    [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				      (opcode, rd, rd, Mips_Assembly.REG rs1),
				      absent, "")]
			      in
				(range_test @@ shift_op @@ continue, [],
				 MirTypes.BLOCK(cont_tag, opcode_list) ::
				 block_list,
				 (bad_tag,
				  (if is_reg gp_operand then
				     variable_out_of_range_shift gp_operand
				   else
				     constant_out_of_range_shift gp_operand) @@
				     continue) :: final_result)
			      end
			  end
			else
			  (* Not a shift *)
			  let
			    fun cant_extend_negative_imm x =
			      case x of
				Mips_Assembly.ADD => false
			      | Mips_Assembly.ADDI => false
			      | Mips_Assembly.ADDIU => false
			      | Mips_Assembly.ADDU => false
			      | Mips_Assembly.SUB => false
			      | Mips_Assembly.SUBU => false
			      | Mips_Assembly.AND => true
			      | Mips_Assembly.ANDI => true
			      | Mips_Assembly.OR => true
			      | Mips_Assembly.ORI => true
			      | Mips_Assembly.XOR => true
			      | Mips_Assembly.XORI => true
			      | Mips_Assembly.NOR => true
			      | Mips_Assembly.SLT => false
			      | Mips_Assembly.SLTU => false
			      | Mips_Assembly.SLTI => false
			      | Mips_Assembly.SLTIU => false
			      | Mips_Assembly.SLL => false
			      | Mips_Assembly.SRL => false
			      | Mips_Assembly.SRA => false
			      | Mips_Assembly.SLLV => false
			      | Mips_Assembly.SRLV => false
			      | Mips_Assembly.SRAV => false
			    fun negative_imm(Mips_Assembly.IMM i) = i < 0
			      | negative_imm _ = false
			  in
			    if is_reg gp_operand then
			      let
				val rs1 = lookup_gp_operand gp_operand
			      in
				if is_reg gp_operand' orelse
				  gp_check_range(gp_operand', true,
						 arith_imm_limit) then
				  let
				    val reg_or_imm =
				      if is_reg gp_operand' then
					Mips_Assembly.REG(lookup_gp_operand
							  gp_operand')
				      else
					convert_small_imm gp_operand'
				  in
				    if negative_imm reg_or_imm andalso
				      cant_extend_negative_imm opcode then
				      let
					val inter_reg =
					  case gp_operand of
					    MirTypes.GP_GC_REG r =>
					      (if r = global_mir then
						 (* The nasty case *)
						 (case reg_operand of
						    MirTypes.GC_REG r' =>
						      if r = r' then
							Crash.impossible "source and dest global with large int"
						      else
							r'
						  | MirTypes.NON_GC_REG _ =>
							Crash.impossible"BINARY doesn't deliver GC")
					       else
						 global_mir)
					  | _ => Crash.impossible "BINARY has non-gc register"
				      in
					([],
					 MirTypes.UNARY(MirTypes.MOVE,
							MirTypes.GC_REG inter_reg,
							gp_operand') ::
					 MirTypes.BINARY(binary_op, reg_operand,
							 gp_operand,
							 MirTypes.GP_GC_REG inter_reg) ::
					 opcode_list, block_list, final_result)
				      end
				    else
				      ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					 (opcode, rd, rs1, reg_or_imm), absent, "")],
				       opcode_list, block_list, final_result)
				  end
				else
				  let
				    val inter_reg =
				      case gp_operand of
					MirTypes.GP_GC_REG r =>
					  (if r = global_mir then
					     (* The nasty case *)
					     (case reg_operand of
						MirTypes.GC_REG r' =>
						  if r = r' then
						    Crash.impossible
						    "source and dest global with large int"
						  else
						    r'
					      | MirTypes.NON_GC_REG _ =>
						    Crash.impossible"BINARY doesn't deliver GC")
					   else
					     global_mir)
				      | _ => Crash.impossible "BINARY has non-gc register"
				  in
				    ([],
				     MirTypes.UNARY(MirTypes.MOVE,
						    MirTypes.GC_REG inter_reg,
						    gp_operand') ::
				     MirTypes.BINARY(binary_op, reg_operand,
						     gp_operand,
						     MirTypes.GP_GC_REG inter_reg) ::
				     opcode_list, block_list, final_result)
				  end
			      end
			    else
			      (* gp_operand not a register *)
			      if is_reg gp_operand' then
				([],
				 MirTypes.UNARY(MirTypes.MOVE,
						global_reg,
						gp_operand) ::
				 MirTypes.BINARY(binary_op, reg_operand,
						 global_gp,
						 gp_operand') ::
				 opcode_list, block_list, final_result)
			      else
				(* gp_operand' also not a register *)
				([],
				 MirTypes.UNARY(MirTypes.MOVE,
						reg_operand,
						gp_operand) ::
				 MirTypes.BINARY(binary_op, reg_operand,
						 gp_from_reg reg_operand,
						 gp_operand') ::
				 opcode_list, block_list, final_result)
			  end
		    end
		| MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand) =>
		    let
		      val rd = lookup_reg_operand reg_operand (* dest reg *)
		    in
		      if is_reg gp_operand then
			let val rs1 = lookup_gp_operand gp_operand in
			  (if rd = rs1 then
			     []
			   else
			     [move_regc(rd, rs1, "")],
			     opcode_list, block_list, final_result)
			end
		      else
			(load_imm_into_register(rd, gp_operand), opcode_list, block_list, final_result)
		    end
                (* This one masks out bottom two bits *)
	        | MirTypes.UNARY(MirTypes.NOT, reg_operand, gp_operand) =>
		    let
		      val rd = lookup_reg_operand reg_operand
		      fun not_seq(rs1, imm) =
			[(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			  (Mips_Assembly.SUBU, rd, zero,
			   Mips_Assembly.REG rs1), absent, "negate"),
			 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			  (Mips_Assembly.ADDIU, rd, rd, Mips_Assembly.IMM imm),
			  absent, "and subtract")]
		    in
		      if is_reg gp_operand then
			let
			  val rs1 = lookup_gp_operand gp_operand
			  val imm = ~4
			in
			  (not_seq(rs1, imm),
			   opcode_list, block_list, final_result)
			end
		      else
                        ([],
                         MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand) ::
                         MirTypes.UNARY(MirTypes.NOT, reg_operand,
                                        gp_from_reg reg_operand)
                         :: opcode_list, block_list, final_result)
		    end

                (* No masking for this one *)
	        | MirTypes.UNARY(MirTypes.NOT32, reg_operand, gp_operand) =>
		    let
		      val rd = lookup_reg_operand reg_operand (* dest reg *)
		    in
		      if is_reg gp_operand then
			let
                          val rs1 = lookup_gp_operand gp_operand
                        in
			  ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.NOR, rd, rs1,Mips_Assembly.REG rs1),
                             absent, "")],
                           opcode_list, block_list, final_result)
			end
		      else
                        ([],
                         MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand) ::
                         MirTypes.UNARY(MirTypes.NOT32, reg_operand, gp_from_reg reg_operand)
                         :: opcode_list, block_list, final_result)
		    end
		| MirTypes.UNARY(MirTypes.INTTAG, reg_operand, gp_operand) =>
		    let
		      val rn = lookup_reg_operand reg_operand
		    in
		      if is_reg gp_operand then
			let
			  val gp = lookup_gp_operand gp_operand
			in
			  ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			     (Mips_Assembly.SRL, rn, gp,
			      Mips_Assembly.IMM 2),
			     absent, "move right 2"),
			    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			     (Mips_Assembly.SLL, rn, rn,
			      Mips_Assembly.IMM 2), absent, "then left 2 to tag as integer")],
			   opcode_list, block_list, final_result)
			end 
		      else
			([], MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					    gp_operand) ::
			 MirTypes.UNARY(MirTypes.INTTAG, reg_operand,
					gp_from_reg reg_operand) ::
			 opcode_list, block_list, final_result)
		    end
		| MirTypes.NULLARY(MirTypes.CLEAN, reg_operand) =>
		    ([move_regc(lookup_reg_operand reg_operand, zero, "clean")],
		     opcode_list, block_list, final_result)

		| MirTypes.BINARYFP(binary_fp_op, fp_operand, fp_operand',
				    fp_operand'') =>
		  let
		    val operation = case (MachTypes.fp_used, binary_fp_op) of
		      (MachTypes.single, MirTypes.FADD) => Mips_Assembly.ADD_S
		    | (MachTypes.single, MirTypes.FSUB) => Mips_Assembly.SUB_S
		    | (MachTypes.single, MirTypes.FMUL) => Mips_Assembly.MUL_S
		    | (MachTypes.single, MirTypes.FDIV) => Mips_Assembly.DIV_S
		    | (MachTypes.double, MirTypes.FADD) => Mips_Assembly.ADD_D
		    | (MachTypes.double, MirTypes.FSUB) => Mips_Assembly.SUB_D
		    | (MachTypes.double, MirTypes.FMUL) => Mips_Assembly.MUL_D
		    | (MachTypes.double, MirTypes.FDIV) => Mips_Assembly.DIV_D
		    | (MachTypes.extended, MirTypes.FADD) => Crash.impossible "Extended floats not supported"
		    | (MachTypes.extended, MirTypes.FSUB) => Crash.impossible "Extended floats not supported"
		    | (MachTypes.extended, MirTypes.FMUL) => Crash.impossible "Extended floats not supported"
		    | (MachTypes.extended, MirTypes.FDIV) => Crash.impossible "Extended floats not supported"
		  in
		    ([(Mips_Assembly.FBINARY
		       (operation,lookup_fp_operand fp_operand,
			lookup_fp_operand fp_operand',
			lookup_fp_operand fp_operand''),
		       absent, "")], opcode_list, block_list, final_result)
		  end

		| MirTypes.UNARYFP(unary_fp_op, fp_operand, fp_operand') =>
		    let
		      val rd = lookup_fp_operand fp_operand
		      val rs2 = lookup_fp_operand fp_operand'
		      val (operation, extra_moves) =
			case (MachTypes.fp_used, unary_fp_op) of
			  (MachTypes.single, MirTypes.FSQRT)	=> Crash.impossible "no hardware square root"
			| (MachTypes.single, MirTypes.FMOVE)	=> (Mips_Assembly.MOV_S, 0)
			| (MachTypes.single, MirTypes.FABS)	=> (Mips_Assembly.ABS_S, 0)
			| (MachTypes.single, MirTypes.FNEG)	=> (Mips_Assembly.NEG_S, 0)
			| (MachTypes.double, MirTypes.FSQRT)	=> Crash.impossible "no hardware square root"
			| (MachTypes.double, MirTypes.FMOVE)	=> (Mips_Assembly.MOV_D, 0)
			| (MachTypes.double, MirTypes.FABS)	=> (Mips_Assembly.ABS_D, 0)
			| (MachTypes.double, MirTypes.FNEG)	=> (Mips_Assembly.NEG_D, 0)
			| (MachTypes.extended, MirTypes.FSQRT)	=> Crash.impossible "Extended floats not supported"
			| (MachTypes.extended, MirTypes.FMOVE)	=> Crash.impossible "Extended floats not supported"
			| (MachTypes.extended, MirTypes.FABS)	=> Crash.impossible "Extended floats not supported"
			| (MachTypes.extended, MirTypes.FNEG)	=> Crash.impossible "Extended floats not supported"
			| _ 					=> Crash.impossible "Bad unary fp generated"
		      fun add_moves(_, _, 0) = []
		      | add_moves(rd, rs2, moves) = let
			  val rd = MachTypes.next_reg rd
			  val rs2 = MachTypes.next_reg rs2
			in
			  (Mips_Assembly.FUNARY(Mips_Assembly.MOV_D, rd, rs2),
			   absent, "") :: add_moves(rd, rs2, moves - 1)
			end
		      val extra_code = add_moves(rd, rs2, extra_moves)
		    in
		      ((Mips_Assembly.FUNARY(operation, rd, rs2), absent,
			"") :: extra_code, opcode_list, block_list,
		       final_result)
		    end
		| MirTypes.TBINARYFP(tagged_binary_fp_op, taglist, fp_operand,
				     fp_operand', fp_operand'') =>
		  let
		    val rd = lookup_fp_operand fp_operand
		    val rs1 = lookup_fp_operand fp_operand'
		    val rs2 = lookup_fp_operand fp_operand''
                    val tag = case taglist of [] => NONE | (a::b) => SOME a
		    val (operation, test) =
                      case (MachTypes.fp_used, tagged_binary_fp_op)
                        of (MachTypes.single,   MirTypes.FADDV) => (Mips_Assembly.ADD_S, Mips_Assembly.C_UN_S)
                         | (MachTypes.single,   MirTypes.FSUBV) => (Mips_Assembly.SUB_S, Mips_Assembly.C_UN_S)
                         | (MachTypes.single,   MirTypes.FMULV) => (Mips_Assembly.MUL_S, Mips_Assembly.C_UN_S)
                         | (MachTypes.single,   MirTypes.FDIVV) => (Mips_Assembly.DIV_S, Mips_Assembly.C_UN_S)
                         | (MachTypes.double,   MirTypes.FADDV) => (Mips_Assembly.ADD_D, Mips_Assembly.C_UN_D)
                         | (MachTypes.double,   MirTypes.FSUBV) => (Mips_Assembly.SUB_D, Mips_Assembly.C_UN_D)
                         | (MachTypes.double,   MirTypes.FMULV) => (Mips_Assembly.MUL_D, Mips_Assembly.C_UN_D)
                         | (MachTypes.double,   MirTypes.FDIVV) => (Mips_Assembly.DIV_D, Mips_Assembly.C_UN_D)
                         | (MachTypes.extended, MirTypes.FADDV) => Crash.impossible "Extended floats not supported"
                         | (MachTypes.extended, MirTypes.FSUBV) => Crash.impossible "Extended floats not supported"
                         | (MachTypes.extended, MirTypes.FMULV) => Crash.impossible "Extended floats not supported"
                         | (MachTypes.extended, MirTypes.FDIVV) => Crash.impossible "Extended floats not supported"
		  in
		    ([(Mips_Assembly.FBINARY(operation, rd, rs1, rs2), absent, "")],
                     opcode_list, block_list, final_result)
		  end
		| MirTypes.TUNARYFP(tagged_unary_fp_op, tag, fp_operand,
				    fp_operand') =>
		    let
		      val rd = lookup_fp_operand fp_operand
		      val rs2 = lookup_fp_operand fp_operand'
		      val (operation, test, extra_moves) =
			case (MachTypes.fp_used, tagged_unary_fp_op)
                          of (MachTypes.single,   MirTypes.FABSV)  => (Mips_Assembly.ABS_S,   Mips_Assembly.C_UN_S, 0)
                           | (MachTypes.single,   MirTypes.FNEGV)  => (Mips_Assembly.NEG_S,   Mips_Assembly.C_UN_S, 0)
                           | (MachTypes.single,   MirTypes.FSQRTV) => Crash.impossible "No hardware sqrt"
                           | (MachTypes.double,   MirTypes.FABSV)  => (Mips_Assembly.ABS_D,   Mips_Assembly.C_UN_D, 0)
                           | (MachTypes.double,   MirTypes.FNEGV)  => (Mips_Assembly.NEG_D,   Mips_Assembly.C_UN_D, 0)
                           | (MachTypes.double,   MirTypes.FSQRTV) => Crash.impossible "No hardware sqrt"
                           | (MachTypes.extended, MirTypes.FABSV)  => Crash.impossible "Extended floats not supported"
                           | (MachTypes.extended, MirTypes.FNEGV)  => Crash.impossible "Extended floats not supported"
                           | (MachTypes.extended, MirTypes.FSQRTV) => Crash.impossible "Extended floats not supported"
                           | _ => Crash.impossible "Bad tagged unary FP generated"
		      fun add_moves(_, _, 0) = []
                        | add_moves(rd, rs2, moves) =
                          let
                            val rd = MachTypes.next_reg rd
                            val rs2 = MachTypes.next_reg rs2
			    val mov_instr =
			      (case MachTypes.fp_used of
				MachTypes.single => Mips_Assembly.MOV_S
			      | MachTypes.double => Mips_Assembly.MOV_D
			      | MachTypes.extended => Crash.impossible "Extended floats not supported")
                          in
			    if rd=rs2 then [] else
			      (Mips_Assembly.FUNARY(mov_instr, rd, rs2),
			       absent, "") :: add_moves(rd, rs2, moves - 1)
                          end
		      val extra_code = add_moves(rd, rs2, extra_moves)
		    in
		      ((Mips_Assembly.FUNARY(operation, rd, rs2), absent, "") ::
                       extra_code, opcode_list, block_list, final_result)
		    end

		| MirTypes.STACKOP(stack_op, reg_operand,
				   SOME offset) =>
		  let
		    val opcode = case stack_op of
		      MirTypes.PUSH => MirTypes.STREF
		    | MirTypes.POP => MirTypes.LDREF
		    val _ =
		      if offset > gc_stack_alloc_size then
			Crash.impossible("Stack access at offset " ^
					 Int.toString offset ^
					 " requested, in total area of only " ^
					 Int.toString
					 gc_stack_alloc_size ^
					 "\n")
		      else()
		  in
		    ([],
		     MirTypes.STOREOP(opcode, reg_operand,
				      MirTypes.GC_REG MirRegisters.fp,
				      MirTypes.GP_IMM_ANY
				      (~(gc_stack_alloc_offset + 4 * (offset + 1)))) ::
		     opcode_list, block_list, final_result)
		  end
		| MirTypes.STACKOP _ => Crash.impossible"Offset missing on STACK_OP"
		| MirTypes.IMMSTOREOP _ =>
		    Crash.impossible"IMMSTOREOP not supported on mips"
		| opcode as MirTypes.STOREOP(store_op, reg_operand, reg_operand',
					     gp_operand) =>
		  let
		    val rd = lookup_reg_operand reg_operand
		    val rs1 = lookup_reg_operand reg_operand'
		    val (load_or_store, noop_if_needed) = case store_op of
		      MirTypes.LD => (Mips_Assembly.LW, [nop])
		    | MirTypes.ST => (Mips_Assembly.SW, [])
		    | MirTypes.LDB => (Mips_Assembly.LBU, [nop])
		    | MirTypes.STB => (Mips_Assembly.SB, [])
		    | MirTypes.LDREF => (Mips_Assembly.LW, [nop])
		    | MirTypes.STREF => (Mips_Assembly.SW, [])
		  in
		    if is_reg gp_operand then
		      (* Difficult case, we have two registers for the store *)
		      (* but the mips doesn't allow this *)
		      ([],
		       MirTypes.BINARY
		       (MirTypes.ADDU, global_reg,
			gp_from_reg reg_operand', gp_operand) ::
		       MirTypes.STOREOP(store_op, reg_operand,
					global_reg,
					MirTypes.GP_IMM_ANY 0) ::
		       opcode_list, block_list, final_result)
		    else
		      if gp_check_range(gp_operand, true, arith_imm_limit) then
			let
			  val imm = case make_imm_for_store gp_operand of
			    Mips_Assembly.IMM(n) => n
			  | _ => Crash.impossible "Store, expecting immediate offset"
			in
			  (((Mips_Assembly.LOAD_AND_STORE(load_or_store, rd, rs1,
							  imm)), absent, "")
			   :: noop_if_needed,
			   opcode_list, block_list, final_result)
			end
		      else
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					global_reg,
					gp_operand) ::
			 MirTypes.STOREOP(store_op, reg_operand,
					  reg_operand',
					  global_gp) ::
			 opcode_list, block_list, final_result)
		  end
		| MirTypes.STOREFPOP(store_fp_op, fp_operand, reg_operand,
				     gp_operand) =>
		  let
		    val frd = lookup_fp_operand fp_operand
		    val rs1 = lookup_reg_operand reg_operand
		    val (store, repeat, noop_if_required) =
		      case (MachTypes.fp_used, store_fp_op) of
			(MachTypes.single, MirTypes.FLD)    => (Mips_Assembly.LWC1, false, [nop])
		      | (MachTypes.single, MirTypes.FST)    => (Mips_Assembly.SWC1, false, [])
		      | (MachTypes.single, MirTypes.FLDREF) => (Mips_Assembly.LWC1, false, [nop])
		      | (MachTypes.single, MirTypes.FSTREF) => (Mips_Assembly.SWC1, false, [])
		      | (MachTypes.double, MirTypes.FLD)    => (Mips_Assembly.LWC1, false, [nop])
		      | (MachTypes.double, MirTypes.FST)    => (Mips_Assembly.SWC1, false, [])
		      | (MachTypes.double, MirTypes.FLDREF) => (Mips_Assembly.LWC1, false, [nop])
		      | (MachTypes.double, MirTypes.FSTREF) => (Mips_Assembly.SWC1, false, [])
		      | (MachTypes.extended, _)             => Crash.impossible "Extended floats not supported"
		    val gp_op = case reg_operand of
		      MirTypes.GC_REG reg => MirTypes.GP_GC_REG reg
		    | MirTypes.NON_GC_REG reg => MirTypes.GP_NON_GC_REG reg
		
		    fun gp_op_is_large arg =
		      case arg of
			MirTypes.GP_IMM_ANY i     => gp_check_range(arg, true, arith_imm_limit) andalso
			  gp_check_range(MirTypes.GP_IMM_INT(i+8), true, arith_imm_limit)
		      | MirTypes.GP_IMM_INT i     => gp_op_is_large( MirTypes.GP_IMM_ANY (i*4))
		      | MirTypes.GP_IMM_SYMB symb => gp_op_is_large( MirTypes.GP_IMM_ANY (symbolic_value symb))
		      | MirTypes.GP_GC_REG _      => true
		      | MirTypes.GP_NON_GC_REG _  => true
		  in
		    if repeat then
                      (* Since repeat is always false this lot isn't executed !? *)
		      if gp_op_is_large gp_operand then
			([],
			 MirTypes.BINARY(MirTypes.ADDU,
					 global_reg,
					 gp_op,
					 gp_operand) ::
			 MirTypes.STOREFPOP(store_fp_op, fp_operand,
					    global_reg,
					    MirTypes.GP_IMM_ANY 0) ::
			 opcode_list, block_list, final_result)
		      else
			let
			  val (imm, arg) =
			    case make_imm_for_store gp_operand of
			      imm as Mips_Assembly.IMM arg => (imm, arg)
			    | _ => Crash.impossible
				"make_imm_for_store fails to return IMM"
			  val imm' = Mips_Assembly.IMM(arg+8)
			in
			  ([(Mips_Assembly.LOAD_AND_STORE_FLOAT
			     (store, frd, rs1, imm),
			     absent, ""),
			    (Mips_Assembly.LOAD_AND_STORE_FLOAT
			     (store,
			      MachTypes.next_reg(MachTypes.next_reg frd),
			      MachTypes.next_reg(MachTypes.next_reg rs1),
			      imm'),
			     absent, "")],
			  opcode_list, block_list, final_result)
			end
		    else
		      if is_reg gp_operand orelse
			gp_check_range(gp_operand, true, arith_imm_limit) then
			let
			  val (reg_or_imm, reg_or_imm') =
			    if is_reg gp_operand then
                              (* This case doesn't look right *)
			      (Mips_Assembly.REG(lookup_gp_operand gp_operand),
			       Mips_Assembly.REG(lookup_gp_operand gp_operand))
			    else
			      let val i = case  gp_operand of
				MirTypes.GP_IMM_ANY i => i
			      | MirTypes.GP_IMM_INT i => i*4
			      | MirTypes.GP_IMM_SYMB symbolic =>
				  (case symbolic of
				     MirTypes.FP_SPILL_SLOT info =>
				       symbolic_value symbolic
				   | _ => Crash.impossible"Store FP Op bad symbolic")
			      | MirTypes.GP_GC_REG _ =>
				  Crash.impossible"Store FP Op GP_GC_REG"
			      | MirTypes.GP_NON_GC_REG _ =>
				  Crash.impossible"Store FP Op GP_NON_GC_REG"
			      in
				(make_imm_for_store gp_operand,
				 make_imm_for_store (MirTypes.GP_IMM_ANY (4+i)))
			      end
			in
                          (if MachTypes.fp_used = MachTypes.single
                             then
                               (Mips_Assembly.LOAD_AND_STORE_FLOAT(store, frd, rs1, reg_or_imm), absent, "") ::
                               noop_if_required
                           else
                             (Mips_Assembly.LOAD_AND_STORE_FLOAT
                              (store, frd, rs1, reg_or_imm'), absent, "") ::
                             (Mips_Assembly.LOAD_AND_STORE_FLOAT
                              (store, MachTypes.next_reg frd, rs1, reg_or_imm), absent, "") ::
                             noop_if_required,
                             opcode_list, block_list, final_result)
			end
		      else
			([],
			 MirTypes.BINARY(MirTypes.ADDU,
					 global_reg,
					 gp_op,
					 gp_operand) ::
			 MirTypes.STOREFPOP(store_fp_op, fp_operand,
					    global_reg,
					    MirTypes.GP_IMM_ANY 0) ::
			 opcode_list, block_list, final_result)
		  end
		| MirTypes.REAL(int_to_float, fp_operand, gp_operand) =>
		    let
		      val operation = case MachTypes.fp_used of
			MachTypes.single => Mips_Assembly.CVT_S_W
		      | MachTypes.double => Mips_Assembly.CVT_D_W
		      | _ => Crash.impossible "T[REAL] extended floats not supported"
		      val rd = lookup_fp_operand fp_operand
		      val rs2 =
			if is_reg gp_operand then
			  lookup_gp_operand gp_operand
			else
			  global
		    in
		      if is_reg gp_operand then
			([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			   (Mips_Assembly.SRA, global, lookup_gp_operand gp_operand, Mips_Assembly.IMM 2),
			   absent, "untag operand"),
			  (Mips_Assembly.LOAD_AND_STORE_FLOAT
			   (Mips_Assembly.MTC1, global, rd, dummy_op),
			   absent, ""),
			  nop,
			  (Mips_Assembly.CONV_OP
			   (operation, rd, rd), absent, "")
			  ], opcode_list, block_list, final_result)
		      else
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					global_reg, gp_operand) ::
			 MirTypes.REAL(int_to_float, fp_operand, global_gp) ::
			 opcode_list, block_list, final_result)
		    end



		(* T[FLOOR float_to_int tag rd rs2] =>

		   floor : real -> int

		   -----------------------------------------------------------
		   -2^29 <= x < 2^29
		
		   fp_global := 2^29
		   if rs2 >= fp_global then go tag
		   fp_global := negate fp_global
		   if rs2<fp_global go tag
		   calculate the result
		   box the result
		
		   tag: raise Floor
		   -----------------------------------------------------------
		   "overflow checking, use conversion to check avail precision"
		
		      saveRoundingMode rd global "save rounding mode"
		      changeRoundingMode rd global
		      li global 1
		      sll global global 29
		      mtc1 global fp_global
		      nop
		      operation' fp_global fp_global

		      test rs2 fp_global
		      nop
		      bc1f tag "branch on overflow, unable to tag"
		      nop

		      negate fp_global fp_global
		      test' fp_global rs2
		      nop
		      bc1f tag "branch on overflow, unable to tag"
		      nop

		      "do the conversion operation"
		      operation fp_global rs2
		      nop
		      restoreRoundingMode rd
		      mfc1 rd fp_global
		      nop
		      sll rd rd 2 "tag the result, no overflow"
		      where
		         (operation, operation', test, test', negate)
			    | fp_used == single =
			         (CVT_W_S, CVT_S_W, C_OLT_S, C_OLE_S, NEG_S)
			    | fp_used == double =
			         (CVT_W_D, CVT_D_W, C_OLT_D, C_OLE_D, NEG_D)
			    | _ = BANG! extended floats not supported
			 saveRoundingMode rd gl =
			    cfc1 rd $31 "get FPU status"
			    changeRoundingMode 3
			    where
			       changeRoundingMode bitseq =
			          | bitseq == 3 =
				       ori gl rd bitseq ""
				  | otherwise =
				       ori gl rd 0x3 "mask & reset rounding mode"
				       xori gl gl bitseq ""
				  ctc1 gl $31 ""
				  nop
		         restoreRoundingMode rd =
			    ctc1 rd $31 "restore FPU status"
			    nop
		 *)

		| MirTypes.FLOOR(float_to_int, tag, reg_operand, fp_operand) =>
		    let
		      val (operation, operation', test, test', negate) =
			case MachTypes.fp_used of
			  MachTypes.single =>
			    (Mips_Assembly.CVT_W_S, Mips_Assembly.CVT_S_W,
			     Mips_Assembly.C_OLT_S, Mips_Assembly.C_OLE_S,
			     Mips_Assembly.NEG_S)
                        | MachTypes.double =>
			    (Mips_Assembly.CVT_W_D, Mips_Assembly.CVT_D_W,
			     Mips_Assembly.C_OLT_D, Mips_Assembly.C_OLE_D,
			     Mips_Assembly.NEG_D)
                        | _ => Crash.impossible "extended floats not supported"
			
		      (*
		         fun changeRoundingMode bitseq =
			   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			   (Mips_Assembly.ORI, gl, rd, Mips_Assembly.IMM 3),
			   absent, "mask & reset rounding mode")
			   ::
			   (if bitseq = 3 then [] else
			      [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.XORI, gl, gl, Mips_Assembly.IMM bitseq),
			      absent, "")])
			      @@
			      [(Mips_Assembly.LOAD_AND_STORE_FLOAT
			      (Mips_Assembly.CTC1, gl, MachTypes.R31, dummy_op),
			      absent, ""),
			      nop]
		       *)
		      val rs2 = lookup_fp_operand fp_operand
		      val rd = lookup_reg_operand reg_operand

		      val restore_rounding_mode =
			(* fun restoreRoundingMode rd = *)
			[(Mips_Assembly.LOAD_AND_STORE_FLOAT
			  (Mips_Assembly.CTC1, rd, MachTypes.R31, dummy_op),
			  absent, "restore FPU status"),
			 nop]
		      val roundingmode_instrs =
			[(Mips_Assembly.LOAD_AND_STORE_FLOAT
			  (Mips_Assembly.CFC1, rd, MachTypes.R31, dummy_op),    (* special reg r31 here *)
			  absent, "get fpu status"),
			 nop,
			 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			  (Mips_Assembly.ORI, global, rd, Mips_Assembly.IMM 3),
			  absent, "mask& reset roundingmode"),
			 (Mips_Assembly.LOAD_AND_STORE_FLOAT
			  (Mips_Assembly.CTC1, global, MachTypes.R31, dummy_op), (* special reg r31 here *)
			  absent, "save rounding mode changes")]
		    in
		      (roundingmode_instrs
		       @@
		       [(* Test for a possible overflow if the number is too big in magnitude *)
			move_imm(global,1),
                        (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                         (Mips_Assembly.SLL,global,global, Mips_Assembly.IMM 29),
			 absent,""),
			(Mips_Assembly.LOAD_AND_STORE_FLOAT
			 (Mips_Assembly.MTC1, global, MachTypes.fp_global,
			  dummy_op),
			 absent,""),
			nop,
                        (Mips_Assembly.CONV_OP(operation', MachTypes.fp_global, MachTypes.fp_global),
			 absent, ""),
                        (Mips_Assembly.FCMP(test, rs2, MachTypes.fp_global), absent, ""),
			nop,
                        (Mips_Assembly.FBRANCH(Mips_Assembly.BC1F, 0),
			 SOME tag, "branch on overflow, unable to tag"),
                        nop,
                        (Mips_Assembly.FUNARY(negate, MachTypes.fp_global, MachTypes.fp_global), 			
			 absent, ""),
                        (Mips_Assembly.FCMP(test', MachTypes.fp_global, rs2), absent, ""),
			nop,
                        (Mips_Assembly.FBRANCH(Mips_Assembly.BC1F, 0),
			 SOME tag, "branch on overflow, unable to tag"),
                        nop,
                        (* Do the conversion operation *)
                        (Mips_Assembly.CONV_OP(operation, MachTypes.fp_global, rs2),
			 absent, ""),
			nop]
		       @@ restore_rounding_mode
		       @@
		       [(Mips_Assembly.LOAD_AND_STORE_FLOAT
			 (Mips_Assembly.MFC1, rd, MachTypes.fp_global, dummy_op),
			 absent,""),
			nop,
			(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			 (Mips_Assembly.SLL, rd, rd, Mips_Assembly.IMM 2),
			 absent, "Tag the result, no more overflow")],
		       opcode_list, block_list, final_result)
		    end
		
		| MirTypes.BRANCH(branch, bl_dest) =>
		    ((case bl_dest of
		      MirTypes.REG reg =>
			[(Mips_Assembly.JUMP
			  (Mips_Assembly.JR,
			   Mips_Assembly.REG (lookup_reg_operand reg), dummy,
                           Debugger_Types.null_backend_annotation),
			  absent, "Branch indirect"),
			 nop]
		    | MirTypes.TAG tag =>
			[(Mips_Assembly.BRANCH(Mips_Assembly.BA, dummy,dummy,0),
			  (* was annulled *)
			  SOME tag, "branch"),
			 nop]),
			opcode_list, block_list, final_result)

		| MirTypes.TEST (mn, tag, lhs, rhs) =>
		    let
		      (* is_zero identifies if is a 0 or zero_reg *)
		      val poly_test =
			(mn = MirTypes.BNE) andalso
			(((lhs = MirTypes.GP_GC_REG MirRegisters.global) andalso
			  (rhs = MirTypes.GP_IMM_ANY 1)) orelse
			 ((rhs = MirTypes.GP_GC_REG MirRegisters.global) andalso
			  (lhs = MirTypes.GP_IMM_ANY 1)))
		    in
		      if poly_test then
			(* We can't handle this normally as global gets overloaded *)
			(* But we can decrement and test for zero instead *)
			([],
			 MirTypes.BINARY(MirTypes.SUBU,
					 MirTypes.GC_REG MirRegisters.global,
					 MirTypes.GP_GC_REG MirRegisters.global,
					 MirTypes.GP_IMM_ANY 1) ::
			 MirTypes.TEST(MirTypes.BNE, tag,
				       MirTypes.GP_GC_REG MirRegisters.global,
				       MirTypes.GP_IMM_ANY 0) ::
			 opcode_list, block_list, final_result)
		      else
			let
			  local
			    val zero_virtual = case MirRegisters.zero of
			      SOME zero_virtual => MirTypes.GP_GC_REG zero_virtual
			    | _ => Crash.impossible "zero_virtual"
			  in
			    fun is_zero (MirTypes.GP_IMM_INT 0) = true
			      | is_zero (MirTypes.GP_IMM_ANY 0) = true
			      | is_zero x = x = zero_virtual
			    fun convert0 (MirTypes.GP_IMM_INT 0) = zero_virtual
			      | convert0 (MirTypes.GP_IMM_ANY 0) = zero_virtual
			      | convert0 e = e

			    fun convertImm0 e =
			      if e=zero_virtual then
				(MirTypes.GP_IMM_ANY 0)
			      else
				e
			  end
			  val imm_lhs = is_imm lhs
			  val imm_rhs = is_imm rhs

			  (* if lhs and rsh are constants or zero_regs then make both constants
			   otherwise convert Imm0s to zero_regs in both lhs and rhs *)
			  val (lhs, rhs) =
			    if (imm_lhs orelse is_zero lhs) andalso
			      (imm_rhs orelse is_zero rhs) then
			      (convertImm0 lhs, convertImm0 rhs)
			    else
			      (convert0 lhs, convert0 rhs)

			  val imm_lhs = is_imm lhs
			  val imm_rhs = is_imm rhs
			  val imm32_rhs = is_imm32 rhs
			  val imm32_lhs = is_imm32 lhs

			  val simpler = case mn of
			    MirTypes.BEQ => true
			  | MirTypes.BNE => true
			  | _ => false
			in
			  if imm_lhs andalso imm_rhs then
			    let
                              (* gp_value : ??? *)
                              fun gp_value gpmush = case gpmush of
                                MirTypes.GP_IMM_INT i  => (i,0)
                              | MirTypes.GP_IMM_ANY i  => (i div 4, i mod 4)
                              | MirTypes.GP_IMM_SYMB s => (symbolic_value s, 0)
                              | _             => Crash.impossible "gp_value: non constant operand"
			      val (gp1 as (gp11, gp12), gp2 as (gp21, gp22)) = (gp_value lhs, gp_value rhs)
                              (* synthesize unsigned comparisons *)
                              infix less greater lesseq greatereq
                              fun n less m =
                                if n >= 0
                                  then if m >=0 then n < m else true
                                else if m >= 0 then false else n > m
                              fun n lesseq m = n = m orelse n less m
                              fun n greater m = not (n lesseq m)
                              fun n greatereq m = not (n less m)
			      val branch =
				if mn = MirTypes.BGE then
                                  gp11 > gp21 orelse (gp11 = gp21 andalso gp12 >= gp22)
				else if mn = MirTypes.BLE then
				  gp11 < gp21 orelse (gp11 = gp21 andalso gp12 <= gp22)
				else if mn = MirTypes.BGT then
				  gp11 > gp21 orelse (gp11 = gp21 andalso gp12 > gp22)
				else if mn = MirTypes.BLT then
				  gp11 < gp21 orelse (gp11 = gp21 andalso gp12 < gp22)

                                else if mn = MirTypes.BHS then
                                  gp11 greater gp21 orelse (gp11 = gp21 andalso gp12 greatereq gp22)
				else if mn = MirTypes.BLS then
				  gp11 less gp21 orelse (gp11 = gp21 andalso gp12 lesseq gp22)
				else if mn = MirTypes.BHI then
				  gp11 greater gp21 orelse (gp11 = gp21 andalso gp12 greater gp22)
				else if mn = MirTypes.BLO then
				  gp11 less gp21 orelse (gp11 = gp21 andalso gp12 less gp22)
				else case mn of
				  MirTypes.BEQ => gp1 =  gp2
				| MirTypes.BNE => gp1 <> gp2
				| MirTypes.BNT => Bits.andb (gp12, gp22) =  0
				| MirTypes.BTA => Bits.andb (gp12, gp22) <> 0
				| _ => Crash.impossible "mir test const precalc failed"
			    in
			      if branch (* precalculated result *) then
				(* remainder of opcode_list irrelevant here *)
				([], [MirTypes.BRANCH (MirTypes.BRA, MirTypes.TAG tag)],
				 block_list, final_result)
			      else (* false, so fall through *)
				([], opcode_list, block_list, final_result)
			    end
			  else if imm32_lhs then
			    ([],
			     MirTypes.UNARY (MirTypes.MOVE, global_reg, lhs) ::
			     MirTypes.TEST (mn, tag, global_gp, rhs) ::
			     opcode_list, block_list, final_result)
			  else if imm32_rhs then
			    ([],
			     MirTypes.UNARY (MirTypes.MOVE, global_reg, rhs) ::
			     MirTypes.TEST (mn, tag, lhs, global_gp) ::
			     opcode_list, block_list, final_result)
			  else if simpler then
			    let
			      val branch = case mn of
				MirTypes.BEQ => Mips_Assembly.BEQ
			      | MirTypes.BNE => Mips_Assembly.BNE
			      | _ => Crash.impossible "simplebranch"
			      val (lhs, rhs) = if is_imm lhs then (rhs, lhs) else (lhs, rhs)
			    in
			      (if is_imm16 rhs then
				 (load_imm_into_register (MachTypes.global, rhs)
				  @@
				  [(Mips_Assembly.BRANCH
				    (branch, lookup_gp_operand lhs, MachTypes.global, 0),
				    SOME tag, ""),
				   nop])
			       else
				 [(Mips_Assembly.BRANCH
				   (branch, lookup_gp_operand lhs, lookup_gp_operand rhs, 0),
				   SOME tag, ""),
				  nop],
				 opcode_list, block_list, final_result)
			    end
			  else if is_zero lhs orelse is_imm16 lhs then
			    let
			      val mn' = case mn of
				MirTypes.BGT => MirTypes.BLT
			      | MirTypes.BLT => MirTypes.BGT
			      | MirTypes.BGE => MirTypes.BLE
			      | MirTypes.BLE => MirTypes.BGE
			      | MirTypes.BEQ => MirTypes.BEQ
			      | MirTypes.BNE => MirTypes.BNE
			      | MirTypes.BNT => MirTypes.BNT
			      | MirTypes.BTA => MirTypes.BTA
			      | MirTypes.BHS => MirTypes.BLS
			      | MirTypes.BLS => MirTypes.BHS
			      | MirTypes.BHI => MirTypes.BLO
			      | MirTypes.BLO => MirTypes.BHI
			    in
			      ([],
			       MirTypes.TEST (mn', tag, rhs, lhs)
			       :: opcode_list, block_list, final_result)
			    end
			  else if is_zero rhs then (* rhs is in focus *)
			    if mn = MirTypes.BNT orelse mn = MirTypes.BHS then (* shortcut branch-true *)
			      ([], [MirTypes.BRANCH (MirTypes.BRA, MirTypes.TAG tag)],
			       block_list, final_result)
			    else if mn = MirTypes.BTA orelse mn = MirTypes.BLO then (* shortcut branch-false *)
			      ([], opcode_list, block_list, final_result)
			    else
			      let
				val branch = case mn of
				  MirTypes.BGT => Mips_Assembly.BGTZ
				| MirTypes.BLT => Mips_Assembly.BLTZ
				| MirTypes.BGE => Mips_Assembly.BGEZ
				| MirTypes.BLE => Mips_Assembly.BLEZ
				| MirTypes.BEQ => Mips_Assembly.BEQZ
				| MirTypes.BNE => Mips_Assembly.BNEZ
				| MirTypes.BLS => Mips_Assembly.BEQZ
				| MirTypes.BHI => Mips_Assembly.BNEZ
				(* MirTypes.BNT => branch-true
				  * MirTypes.BTA => branch-false
				  * MirTypes.BHS => branch-true
				  * MirTypes.BLO => branch-false
				  *)
				| _ => Crash.impossible "shortbranch"
			      in
				if is_zero lhs then (* uncertain if imm and zero can exist at same time *)
				  ([(Mips_Assembly.BRANCH
				     (Mips_Assembly.reverse_branch branch, lookup_gp_operand rhs, zero, 0),
				     SOME tag, ""),
				    nop], opcode_list, block_list, final_result)
				else (* is_zero rhs *)
				  ([(Mips_Assembly.BRANCH
				     (branch, lookup_gp_operand lhs, zero, 0),
				     SOME tag, ""),
				    nop], opcode_list, block_list, final_result)
			      end

			    else (* rhs is in focus *)
			      let
				val andt = Mips_Assembly.AND
				val sltu = Mips_Assembly.SLTU
				val slt = Mips_Assembly.SLT
				val iftrue = Mips_Assembly.BNEZ
				val iffalse = Mips_Assembly.BEQ
				val (test, (lhs, rhs), branch) =
				  let
				    val swap = (rhs, lhs)
				    val usual = (lhs, rhs)
				    fun inc (MirTypes.GP_IMM_INT n) = MirTypes.GP_IMM_INT (n+1)
				      | inc (MirTypes.GP_IMM_ANY n) = MirTypes.GP_IMM_ANY (n+1)
				      | inc s = s
				    val rhs' = inc rhs
				    val imm16_rhs' = is_imm16 rhs'
				  in
				    case mn of
				      MirTypes.BNT => (andt, usual, iffalse)
				    | MirTypes.BTA => (andt, usual, iftrue)
				    | MirTypes.BLT => (slt,  usual, iftrue)
				    | MirTypes.BLO => (sltu, usual, iftrue)
				    | MirTypes.BGE => (slt,  usual, iffalse)
				    | MirTypes.BHS => (sltu, usual, iffalse)
				    | MirTypes.BGT =>
					if imm16_rhs' then
					  (slt, (lhs, rhs'), iffalse)
					else
					  (slt, swap, iftrue)
				    | MirTypes.BLE =>
					if imm16_rhs' then
					  (slt, (lhs, rhs'), iftrue)
					else
					  (slt, swap, iffalse)
				    | MirTypes.BLS =>
					if imm16_rhs' andalso not (is_zero rhs') then
					  (sltu, (lhs, rhs'), iftrue)
					else
					  (sltu, swap, iffalse)
				    | MirTypes.BHI =>
					if imm16_rhs' andalso not (is_zero rhs') then
					  (sltu, (lhs, rhs'), iffalse)
					else
					  (sltu, swap, iftrue)
				    | _ => Crash.impossible "mirtypes"
				  end
				val rhs' =
				  if is_imm16 rhs then convert_small_imm rhs
				  else Mips_Assembly.REG (lookup_gp_operand rhs)
			      in
				if is_imm lhs then
				  (* this is a hack to ensure
				   * when BHS ~1 r2
				   * => li global ~1; sltu global r2, global; beqz global
				   * optimised to
				   * => sltiu global r2 (~1+1); bnez global
				   * doesnt happen, as thats wrong
				   * ~1 unsigned is maxint
				   * maxint+1=0 is a problem
				   *)
				  (load_imm_into_register (MachTypes.global, lhs)
				   @@
				   [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				     (test, MachTypes.global, MachTypes.global, rhs'),
				     absent, ""),
				    (Mips_Assembly.BRANCH
				     (branch, MachTypes.global, zero, 0),
				     SOME tag, ""),
				    nop], opcode_list, block_list, final_result)
				else
				  ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				     (test, MachTypes.global, lookup_gp_operand lhs, rhs'),
				     absent, ""),
				    (Mips_Assembly.BRANCH
				     (branch, MachTypes.global, zero, 0),
				     SOME tag, ""),
				    nop], opcode_list, block_list, final_result)
			      end
			end
		    end
		| MirTypes.FTEST(fcond_branch, tag, fp_operand, fp_operand') => let
		    val (test_instr, branch) =
		      case (MachTypes.fp_used, fcond_branch) of
			(MachTypes.single, MirTypes.FBEQ) => (Mips_Assembly.C_EQ_S, Mips_Assembly.BC1T)
		      | (MachTypes.single, MirTypes.FBNE) => (Mips_Assembly.C_EQ_S, Mips_Assembly.BC1F)
		      | (MachTypes.single, MirTypes.FBLE) => (Mips_Assembly.C_OLE_S, Mips_Assembly.BC1T)
		      | (MachTypes.single, MirTypes.FBLT) => (Mips_Assembly.C_OLT_S, Mips_Assembly.BC1T)
		      | (MachTypes.double, MirTypes.FBEQ) => (Mips_Assembly.C_EQ_D, Mips_Assembly.BC1T)
		      | (MachTypes.double, MirTypes.FBNE) => (Mips_Assembly.C_EQ_D, Mips_Assembly.BC1F)
		      | (MachTypes.double, MirTypes.FBLE) => (Mips_Assembly.C_OLE_D, Mips_Assembly.BC1T)
		      | (MachTypes.double, MirTypes.FBLT) => (Mips_Assembly.C_OLT_D, Mips_Assembly.BC1T)
		      | (MachTypes.extended, _) 	  => Crash.impossible "Extended floats not supported"
		  in
		    ([(Mips_Assembly.FCMP
		       (test_instr,
			lookup_fp_operand fp_operand,
			lookup_fp_operand fp_operand'), absent, "fptest"),
		      nop,
		      (Mips_Assembly.FBRANCH(branch, 0),
		       SOME tag, "Do the branch"),
		      nop], opcode_list, block_list, final_result)
		  end

		| MirTypes.BRANCH_AND_LINK(_, MirTypes.REG reg_operand,debug_information,_) =>
		    ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
		       (Mips_Assembly.ADDU, global,
			lookup_reg_operand reg_operand, Mips_Assembly.IMM Tags.CODE_OFFSET),
		       absent, "address to jump to"),
		      (Mips_Assembly.JUMP
		       (Mips_Assembly.JALR, lr_op, global, debug_information),
		       absent, "Call to tagged value"),
		      nop],
		    opcode_list, block_list, final_result)
		
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.TAG tag,debug_info,_) =>
		    ([(Mips_Assembly.CALL
		      (Mips_Assembly.BGEZAL, zero, 0,debug_info),
		      SOME tag, "Call"),
		     nop],
		    opcode_list, block_list, final_result)

		| MirTypes.TAIL_CALL(_, target,_) => let
		    val restores =
                      if needs_preserve then
                         restore_fps @@
                         restore_gcs @@
                         [(Mips_Assembly.LOAD_AND_STORE
                           (Mips_Assembly.LW, lr, MachTypes.sp, 8),
                           absent, "reset link"),
			  (Mips_Assembly.LOAD_AND_STORE
                           (Mips_Assembly.LW, MachTypes.callee_closure, MachTypes.sp, 4),
                           absent, "restore our own caller's closure"),
                          move_reg(MachTypes.sp, MachTypes.fp)]
                      else
                        []
                    val reset =
                      if needs_preserve
                        then [(Mips_Assembly.LOAD_AND_STORE
                               (Mips_Assembly.LW, MachTypes.fp, MachTypes.sp, 0),
                               absent, "reset fp to old fp")]
                      else []
                    (* This sets the delay slot for the jump or branch *)
                    val postRestores =
                      if needs_preserve then
                        Mips_Assembly.nopc "delay slot unusable for fp"
                      else
                        nop
		  in
		    (case target of
		       MirTypes.REG reg =>
                         restores @@
                         [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                           (Mips_Assembly.ADDU, global, lookup_reg_operand reg, Mips_Assembly.IMM 3),
                           absent, "")] @@
                         reset @@
                         [(Mips_Assembly.JUMP
                           (Mips_Assembly.JR, global_op,
                            dummy,
                            Debugger_Types.null_backend_annotation),
                           absent, "tail call"),
                         postRestores]
		     | MirTypes.TAG tag =>
                         restores @@
                         reset @@
                         [(Mips_Assembly.BRANCH
                           (Mips_Assembly.BA, dummy, dummy, 0),
                           SOME tag, "branch"),
                          postRestores],
                      opcode_list, block_list, final_result)
		  end (* let *)

                (* There are some interesting interactions with load delays & branches here *)
                (* Note that both the old and the new versions have their branches with the *)
                (* same double word alignment.  We can save an instruction, but then we may *)
                (* gain one from the R4000 bug case, which is also the case if the load delay *)
                (* is eliminated for mips2.  Knowing how much code we have to jump over *)
                (* involves knowing if a nop has been inserted for double word alignment *)
                (* which is something we can't determine at this stage *)
		 | MirTypes.SWITCH(computed_goto, reg_operand, tag_list) =>
		     (let
			val reg = lookup_reg_operand reg_operand
		      in
			if List.length tag_list <= 2 then
			  let
			    fun do_test(done,[]) = []
			      | do_test(done, [tag]) =
				Mips_Assembly.nopc "table entry padding"
				:: (Mips_Assembly.BRANCH
				    (Mips_Assembly.BA, dummy, dummy, 0),
				    SOME tag, "branch to table entry")
				:: done
			      | do_test(done, tag :: rest) =
				   do_test(
					   Mips_Assembly.nopc "branch delay"
					   :: (Mips_Assembly.BRANCH
					       (Mips_Assembly.BEQ, global, zero, 0),
					       SOME tag, "")
					   :: (Mips_Assembly.ARITHMETIC_AND_LOGICAL
					       (Mips_Assembly.SUB, global, reg, Mips_Assembly.IMM 4),
					       absent, "do the test")
					   :: done,
					   rest)
			  in
			    rev (do_test([], tag_list))
			  end
			else if not needs_preserve andalso reg = global then
			  Crash.impossible "incorrect MIR SWITCH output"
			else if needs_preserve then
			  (Mips_Assembly.CALL (Mips_Assembly.BGEZAL, zero, 1,
                                               Debugger_Types.null_backend_annotation),
			   absent, "call self") ::
                          (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADDIU,
                                                                 lr,
                                                                 lr, Mips_Assembly.IMM (6 *4)),
                           absent, "offset to start of table") ::
                          (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADDU,
                                                                 global,
                                                                 lr, Mips_Assembly.REG reg ),
                           absent, "offset to entry") ::
                          (Mips_Assembly.LOAD_AND_STORE  (Mips_Assembly.LW,
                                                          global,
                                                          global, 0),
                           absent, "get table entry") ::
                          other_nop ::
			  (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADDU,
                                                                 lr,
                                                                 lr, global_op),
                           absent, "calculate destination") ::
			  (Mips_Assembly.JUMP (Mips_Assembly.JR,
                                               lr_op, dummy,
                                               Debugger_Types.null_backend_annotation),
                           absent, "jump to table entry") ::
			  nop ::
                          (rev (#1(foldl
                                   (fn (tag,(l,n)) =>
                                    ((Mips_Assembly.OFFSET n,SOME tag,"") :: l,n+4))
                                   ([],0)
                                   tag_list)))
			else Crash.impossible "unaccounted for MIR SWITCH case"
		      end,
		    opcode_list, block_list, final_result)
(*		
		 | MirTypes.SWITCH(computed_goto, reg_operand, tag_list) =>
		     (let
			val reg = lookup_reg_operand reg_operand
		      in
			if List.length tag_list <= 2 then
			  let
			    fun do_test(done,[]) = []
			      | do_test(done, [tag]) =
				Mips_Assembly.nopc "table entry padding"
				:: (Mips_Assembly.BRANCH
				    (Mips_Assembly.BA, dummy, dummy, 0),
				    SOME tag, "branch to table entry")
				:: done
			      | do_test(done, tag :: rest) =
				   do_test(
					   Mips_Assembly.nopc "branch delay"
					   :: (Mips_Assembly.BRANCH
					       (Mips_Assembly.BEQ, global, zero, 0),
					       SOME tag, "")
					   :: (Mips_Assembly.ARITHMETIC_AND_LOGICAL
					       (Mips_Assembly.SUB, global, reg, Mips_Assembly.IMM 4),
					       absent, "do the test")
					   :: done,
					   rest)
			  in
			    rev (do_test([], tag_list))
			  end
			else if not needs_preserve andalso reg = global then
			  Crash.impossible "incorrect MIR SWITCH output"
			else if needs_preserve then
			  (Mips_Assembly.CALL
			   (Mips_Assembly.BGEZAL, zero, 1,
                            Debugger_Types.null_backend_annotation),
			   absent, "call self")
			  :: (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADDIU, lr, lr, Mips_Assembly.IMM (4*4)),
			      absent, "point lr to start of table")
			  :: (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADDU, global, reg, Mips_Assembly.REG reg),
			      absent, "double index to get offset into table")
			  :: (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADDU, lr, lr, global_op),
			      absent, "calculate offset into table")
			  :: (Mips_Assembly.JUMP
			      (Mips_Assembly.JR, lr_op, dummy, Debugger_Types.null_backend_annotation),
			      absent, "jump to table offset")
			  :: nop
			  :: rev_fold_append
			  (rev_map
			   (fn t=>
			    (Mips_Assembly.FIXED_BRANCH
			     (Mips_Assembly.BA, dummy, dummy, 0),
			     SOME t, "branch to table entry")
			    :: Mips_Assembly.nopc "table entry padding"
			    :: []) (tag_list, []), [])
			else Crash.impossible "unaccounted for MIR SWITCH case"
		      end,
		    opcode_list, block_list, final_result)
*)		
		| MirTypes.ALLOCATE_STACK(allocate, reg_operand, alloc_size,
					  SOME fp_offset) =>
		  if alloc_size + fp_offset > gc_stack_alloc_size then
		    Crash.impossible("Stack allocation of "^Int.toString alloc_size
				     ^" at offset "
				     ^Int.toString fp_offset
				     ^"requested, in total area of only "
				     ^Int.toString gc_stack_alloc_size
				     ^"\n")
		  else (
			case allocate of
			  MirTypes.ALLOC =>
			    ([],
			     MirTypes.BINARY(MirTypes.SUBU, reg_operand,
					     MirTypes.GP_GC_REG MirRegisters.fp,
					     MirTypes.GP_IMM_ANY
					     (gc_stack_alloc_offset +
					      4 * (fp_offset + alloc_size) - Tags.PAIRPTR)) ::
			     (* Note tagging on pointer *)
			     opcode_list, block_list, final_result)
			| _ => Crash.impossible "ALLOCATE_STACK strange allocate")
		
		| MirTypes.ALLOCATE_STACK _ => Crash.impossible"ALLOCATE_STACK with no offset from fp"
		| MirTypes.DEALLOCATE_STACK _ => ([], opcode_list, block_list, final_result)
(*
                  ALLOCATE code rewritten by nickb, 1995-05-31
*)
		| MirTypes.ALLOCATE(allocate, reg_operand, gp_operand) =>
		    let			
		      val rd = lookup_reg_operand reg_operand
		      (* lift common registers out here to clarify things *)
		      val gc1 = MachTypes.gc1
		      val reg_gc2 = Mips_Assembly.REG MachTypes.gc2
		      val reg_rd = Mips_Assembly.REG rd

			(* leaf functions use gc2 as a link because lr is live *)
		      val (link, gc_entry) =
			if needs_preserve then
			  (lr, 4 * Implicit_Vector.gc)
			else
			  (MachTypes.gc2, 4 * Implicit_Vector.gc_leaf)

                      val end_gc_tag = MirTypes.new_tag ()
                      val finish_tag = MirTypes.new_tag ()

		(* lift common instructions out here to clarify the code *)
                      val branch_finish =
                        [(Mips_Assembly.BRANCH
                          (Mips_Assembly.BA, dummy, dummy, 0),
                          SOME finish_tag, ""),
                        nop]
		      val branch_end =
			(Mips_Assembly.BRANCH
			 (Mips_Assembly.BA, dummy, dummy, 0),
			 SOME end_gc_tag, "")
		      val gc_test =
			(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			 (Mips_Assembly.SUB, global, gc1, reg_gc2),
			 absent, "test for GC")
		      val gc_test_branch =
			(Mips_Assembly.BRANCH
			 (Mips_Assembly.BLTZ, global, dummy, 0),
			 SOME end_gc_tag, "branch if no GC required")
		      val get_gc_entry =
			(Mips_Assembly.LOAD_AND_STORE
			 (Mips_Assembly.LW, global, MachTypes.implicit, gc_entry),
			 absent, "get GC entry")
		      val call_gc =
			(Mips_Assembly.JUMP
			 (Mips_Assembly.JALR, Mips_Assembly.REG link, global,
			  Debugger_Types.null_backend_annotation),
			 absent, "call GC")
		      fun tag_result(primary) =
			(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			 (Mips_Assembly.ADD, rd, global, Mips_Assembly.IMM primary),
			 absent, "tag result")

		      val (allocation,finish_block) =
                       case gp_operand of
			MirTypes.GP_IMM_INT size =>
                         let
			  val (bytes, primary, pad, secondary) =
			    case allocate of
			      MirTypes.ALLOC =>
				if size = 2 then
				  (8, Tags.PAIRPTR, false, 0)
				else
				  (8 * ((size+2) div 2), Tags.POINTER,
				   size mod 2 = 0, 64*size+Tags.RECORD)
                            | MirTypes.ALLOC_VECTOR =>
                                (8 * ((size+2) div 2), Tags.POINTER,
                                 size mod 2 = 0, 64*size+Tags.RECORD)
			    | MirTypes.ALLOC_STRING =>
				(((size+11) div 8) * 8,
				 Tags.POINTER, false, 64*size+Tags.STRING)
			    | MirTypes.ALLOC_REAL =>
				(case MachTypes.fp_used
				   of MachTypes.single   => Crash.unimplemented "ALLOC_REAL single"
				    | MachTypes.extended => Crash.unimplemented "ALLOC_REAL extended"
				    | MachTypes.double   =>
					(16, Tags.POINTER, false,
					 64*(16 - 4) + Tags.BYTEARRAY))
			    | MirTypes.ALLOC_REF  =>
				(8 + 8*((size+2) div 2),
				 Tags.REFPTR, size mod 2 = 0, 64*size+Tags.ARRAY)
			    | MirTypes.ALLOC_BYTEARRAY =>
				(((size+11) div 8) * 8, Tags.REFPTR, false,
				 64*size+Tags.BYTEARRAY)

			  val write_header =
			    if secondary = 0 then
			      []
			    else
			      (load_large_number_into_register (global, secondary) @@
			       [(Mips_Assembly.LOAD_AND_STORE
                                 (Mips_Assembly.SW, global, rd, ~primary),
                                 absent, "write header word")])
			in
			  if check_range (bytes, true, arith_imm_limit) then
			   ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                              (Mips_Assembly.ADD, gc1, gc1, Mips_Assembly.IMM bytes),
                              absent, "advance alloc point"),
			     gc_test,
			     gc_test_branch,
                             (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                              (Mips_Assembly.ADD, rd, gc1, Mips_Assembly.IMM (primary - bytes)),
                              absent, "tag result in delay slot"),
                             get_gc_entry,
                             move_regc(rd,zero,"clear invalid register"),
			     call_gc,
                             move_immc(global, bytes, "pass size to gc"),
			     tag_result (primary),
                             branch_end,
                             nop],
                           (if pad then
                              (Mips_Assembly.LOAD_AND_STORE
                               (Mips_Assembly.SW, zero, rd, bytes - primary - 4),
			       absent, "clear unaligned padding") ::
                              write_header
                            else
                              write_header))
			  else
			    (load_large_number_into_register(rd, bytes) @@
                             [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                               (Mips_Assembly.ADD, gc1, gc1, Mips_Assembly.REG rd),
                               absent, "advance alloc point"),
			      gc_test,
                              gc_test_branch,
                              (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                               (Mips_Assembly.SUB, global, gc1, Mips_Assembly.REG rd),
                               absent, "point to new object in delay slot"),
                              get_gc_entry,
                              nop,
			      call_gc,
                              move_regc(global, rd, "pass size to gc"),
                             branch_end,
                             nop],
			     (if pad then
				tag_result (primary) ::
				write_header
			      else
				(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				 (Mips_Assembly.ADD, rd, global, Mips_Assembly.REG rd),
				 absent, "clear unaligned padding") ::
				(Mips_Assembly.LOAD_AND_STORE
				 (Mips_Assembly.SW, zero, rd, ~4), absent, "") ::
				tag_result (primary) ::
				write_header))
			end
		      | MirTypes.GP_GC_REG reg =>
			  let
			    val reg = lookup_reg(MirTypes.GC.unpack reg, gc_array)
			    val (primary, secondary, byte_length, header, padding, comment) =
			      case allocate
				of MirTypes.ALLOC        => Crash.unimplemented "ALLOC variable size"
				 | MirTypes.ALLOC_VECTOR =>
                                     (Tags.POINTER,Tags.RECORD, false, 4+7, true, "vector length")
				 | MirTypes.ALLOC_STRING =>
				     (Tags.POINTER, Tags.STRING, true, 4+7, false, "string length")
				 | MirTypes.ALLOC_REAL   => Crash.unimplemented "ALLOC_REAL variable size"
				 | MirTypes.ALLOC_REF    =>
				     (Tags.REFPTR, Tags.ARRAY, false, 12+7, true, "array length")
				 | MirTypes.ALLOC_BYTEARRAY =>
				     (Tags.REFPTR, Tags.BYTEARRAY, true, 4+7, false, "bytearray length")
			  in
			    (* get the length in bytes into rd *)
			    ((if byte_length then
				[(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.SRL, rd, reg, Mips_Assembly.IMM 2),
				  absent, "untag length")]
			      else
				[]) @@
				[(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.ADD, rd,
				   if byte_length then rd else reg,
				     Mips_Assembly.IMM header), absent, comment)] @@
				[(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.SRL, rd, rd, Mips_Assembly.IMM 3),
				  absent, "clear bottom bits"),
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.SLL, rd, rd, Mips_Assembly.IMM 3),
				  absent, "and realign"),
				 (* check for allocation overflow *)
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.ADDU, gc1, gc1, Mips_Assembly.REG rd),
				  absent, "advance alloc point"),
				 gc_test,
				 gc_test_branch,
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.SUBU, global, gc1, Mips_Assembly.REG rd),
				  absent, "point to new object in delay slot"),
				 get_gc_entry,
				 nop,
				 call_gc,
				 move_regc(global, rd, "pass size to gc"),
				 branch_end,
				 nop],
				(if padding then
				   [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				     (Mips_Assembly.ADD, rd, global, Mips_Assembly.REG rd),
				     absent, "clear unaligned padding"),
				    (Mips_Assembly.LOAD_AND_STORE
				     (Mips_Assembly.SW, zero, rd, ~4),
				     absent, "")]
				 else []) @@
				   [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				     (Mips_Assembly.ADD, rd, global, Mips_Assembly.IMM primary),
				     absent, "tag result"),
				     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				      (Mips_Assembly.SLL, global, reg,
				       Mips_Assembly.IMM 4),
				      absent, "make header word"),
				    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				     (Mips_Assembly.ADD, global, global, Mips_Assembly.IMM secondary),
				     absent, "with secondary tag"),
				    (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, global, rd, ~primary),
				     absent, "store header word")])
			  end
		      | _ => Crash.impossible "Strange parameter to ALLOCATE"
		    in
		      (allocation,
                       [],
                       MirTypes.BLOCK (finish_tag,opcode_list) :: block_list,
                       (end_gc_tag,finish_block @@ branch_finish) :: final_result)
		    end
		| MirTypes.ADR(adr, reg_operand, tag) =>
		    let
		      val reg = lookup_reg_operand reg_operand
		    in
		      ((case adr of
			  MirTypes.LEA =>
			    [(Mips_Assembly.CALL
			      (Mips_Assembly.BGEZAL, zero, 1,Debugger_Types.null_backend_annotation),
			      absent, "Call self"),
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADD, reg, lr,
			       Mips_Assembly.IMM 4),
			      SOME tag, "Update gc pointer")]
			| MirTypes.LEO =>
			    [(Mips_Assembly.LOAD_OFFSET
			      (Mips_Assembly.LEO, reg, 0),
			      SOME tag,
			      "Get offset of tag from procedure start")]),
			  opcode_list, block_list, final_result)
		     end
		(* Note that lr points to the call instruction *)
		(* Thus lr + 4, as computed by the ADD *)
		(* points to the ADD instruction, which is fixed *)
		(* up during linearisation *)

		(* Warning. If we ever make a leaf adr, we must ensure *)
		(* handler continuations are done safely. This is not currently *)
		(* true since they use o1 as the address. *)
	
		| MirTypes.INTERCEPT => (trace_dummy_instructions, opcode_list, block_list, final_result)
		(* T[INTERRUPT] =>
		   Written by nickb, 1995-01-05 *)
		| MirTypes.INTERRUPT =>
		    let
		      val continue_tag = MirTypes.new_tag()
			val block_list' =
			  MirTypes.BLOCK(continue_tag,opcode_list)::block_list
			val opcode_list' = []
			val (implicit_offset,link) =
			  if needs_preserve then
			    (4 * Implicit_Vector.event_check, lr)
			  else
			    (4*Implicit_Vector.event_check_leaf, MachTypes.gc2)
			val event_check_code =
			  [(Mips_Assembly.BRANCH
			    (Mips_Assembly.BGTZ, MachTypes.stack_limit,
			     dummy, 0),
			    SOME continue_tag,
			    "test for asynch event"),
                           nop, (* See bug report #1834 *)
			   (Mips_Assembly.LOAD_AND_STORE
			    (Mips_Assembly.LW, global,
			     MachTypes.implicit,
			     implicit_offset),
			    absent, ""),
                           nop,
			   (Mips_Assembly.JUMP
			    (Mips_Assembly.JALR,
			     Mips_Assembly.REG link,
			     global,
			     Debugger_Types.null_backend_annotation),
			    absent, "enter event check"),
			   Mips_Assembly.nopc "Can't fill this",
			   (Mips_Assembly.BRANCH
			    (Mips_Assembly.BA, dummy,
			     dummy, 0),
			    SOME continue_tag, "End of block"),
			   nop]
		    in
		      (event_check_code,
		       opcode_list', block_list', final_result)
		    end
		
		(* T[ENTER] =>
		  Rewritten by nickb, 1994-11-25 *)
		| MirTypes.ENTER _ =>
		    (* leaf case *)
		    if not needs_preserve then
		      ([], opcode_list, block_list, final_result)
		    else (* non-leaf case *)
		      let

                        (* There are three kinds of frame:

                         - Normal, which means it will fit in the leeway on the stack
                         (i.e. if sp >= stackLimit, we're OK)
                         - Medium, which means we can fit the frame size into an immediate
                         - Large, which means we can't
                         (so we put the frame size in 'global' and then keep it
                         there).
                         *)

			datatype frame =
			  Normal
			| Medium
			| Large
			val frame = if (non_save_frame_size <= 0) then Normal
				    else if (frame_size < arith_imm_limit)
					   then Medium
					 else Large
			val stackOKTag = MirTypes.new_tag()

			(* endTag tags the body of the function *)
			val endTag = MirTypes.new_tag()
			val block_list' =
			  MirTypes.BLOCK(endTag, opcode_list) :: block_list
			(* no more opcodes in this block *)
			val opcode_list' = []

                        (* there are five phases to the entry:

                         (0) saving the fp
                         (1) checking for stack overflow
                         .stackOK:
                         (2) making the stack frame and linkage,
                         (3) saving any GC & FP saves (already constructed as save_gcs and save_fps),
                         (4) initialising GC stack slots to zero. (can require a loop).
                         *)

                        (* (0) one instruction to save the fp *)
 			val save_the_fp =
			  (Mips_Assembly.LOAD_AND_STORE
			   (Mips_Assembly.SW, MachTypes.fp, MachTypes.sp, 0),
			   absent, "save fp")
                        (* (1) checking for stack overflow *)
			val check_for_stack_overflow =
			  let
                            (* first, get the value to check against the stack limit in a reg *)
			    val preCheck =
			      case frame of
				Normal => []
			      | Medium =>
				  [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				    (Mips_Assembly.ADDIU, global,
				     MachTypes.sp,
				     Mips_Assembly.IMM (~frame_size)),
				    absent, "new sp for checking")]
			    | Large =>
				load_large_number_into_register
				(global, frame_size)
				@@ [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				    (Mips_Assembly.SUBU, hacky_temporary_reg,
				     MachTypes.sp, global_op),
				    absent, "new sp for checking")]
                            (* next, compare it to the stack limit and skip to part (2) if OK *)
			    val stack_overflow_test =
			      let
				val stack_overflow_bool_reg =
				  case frame of
				    Large => hacky_temporary_reg
				  | _ => global
				val stack_overflow_test_reg =
				  case frame of
				    Normal => MachTypes.sp
				  | Medium => global
				  | Large => hacky_temporary_reg
			      in
				[(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.SLTU, stack_overflow_bool_reg,
				   MachTypes.stack_limit,
				   Mips_Assembly.REG stack_overflow_test_reg),
				  absent,"stack overflow test"),
				 (Mips_Assembly.BRANCH
				  (Mips_Assembly.BNE, stack_overflow_bool_reg,
				   zero,0),
				  SOME stackOKTag, "branch if OK"),
				 move_regc(MachTypes.fp, MachTypes.sp,
					   "update fp in delay slot")]
			      end
                            (* last, if the stack check failed, call the stack extension code *)
			    val stack_extension =
			      let
				val call_delay_slot_instr =
				  case frame of
				    Large =>
				      Mips_Assembly.nopc "Can't fill this"
				  | _ =>
				      move_imm(global, frame_size)
			      in
				[(Mips_Assembly.LOAD_AND_STORE
				  (Mips_Assembly.LW, hacky_temporary_reg,
				   MachTypes.implicit,
				   4 * Implicit_Vector.extend),
				  absent, ""),
				 Mips_Assembly.nopc "Can't fill this",
				 (Mips_Assembly.JUMP
				  (Mips_Assembly.JALR,
				   Mips_Assembly.REG MachTypes.gc2,
				   hacky_temporary_reg,
				   Debugger_Types.null_backend_annotation),
				  absent, ""),
				 call_delay_slot_instr,
				 (Mips_Assembly.BRANCH
				  (Mips_Assembly.BA, dummy,
				   dummy, 0),
				  SOME stackOKTag, "Do the branch"),
				 nop]
			      end
			  in
			    preCheck @@ stack_overflow_test @@ stack_extension
			  end

                        (* (2) making the stack frame and linkage *)			
			
			val make_frame =
			  let
			    val push_frame_instruction =
			      case frame of
				Large =>
				  (* we have the frame size in 'global' *)
				  (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				   (Mips_Assembly.SUBU, MachTypes.sp,
				    MachTypes.sp, global_op),
				   absent, "make the frame")
			      | _ =>
				  (* the frame size is immediate *)
				  (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				   (Mips_Assembly.ADDIU, MachTypes.sp,
				    MachTypes.sp,
				    Mips_Assembly.IMM (~frame_size)),
				   absent, "make the frame")
			  in
			    (* save values in the newly made slots *)
			      [push_frame_instruction,
			       (Mips_Assembly.LOAD_AND_STORE
				(Mips_Assembly.SW, MachTypes.callee_closure,
				 MachTypes.sp, 4), absent, "save closure"),
			       (Mips_Assembly.LOAD_AND_STORE
				(Mips_Assembly.SW, lr,
				 MachTypes.sp, 8), absent, "save link"),
			       (* set up our closure register *)
			       move_reg(MachTypes.callee_closure,
					MachTypes.caller_closure)]
			  end

                        (* (4) initialising  GC stack slots to zero *)

                        val (clear_frame_code,clear_frame_blocks) =
			  let
			    val gc_stack_slots =
			      (gc_spill_size + gc_stack_alloc_size)

			    (* Final branch to the end *)
			    val endInstrs =
			      [(Mips_Assembly.BRANCH
				(Mips_Assembly.BA, dummy,
				 dummy, 0),
				SOME endTag, "branch"),
			       nop]
			  in
			    if gc_stack_slots < 10 then
                              (* For small numbers of stack slots, initialize each one separately *)
			      let
				(* Clear a single stack slot *)
				fun saveInstr offset =
				  (Mips_Assembly.LOAD_AND_STORE
				   (Mips_Assembly.SW, zero,
				    MachTypes.sp, offset),
				   absent, "init stack slot")
				
				fun initStackSlots(offset, 0, done) = done
				  | initStackSlots(offset, n, done) =
				    initStackSlots(offset+4, n-1,
						   saveInstr offset :: done)
			      in
				(initStackSlots (register_save_size,
						 gc_stack_slots, endInstrs),[])
			      end
			    else
                              (* For larger numbers, we make a loop *)
			      let
				val loop_tag = MirTypes.new_tag ()
			      in
				([move_imm (hacky_temporary_reg,
					    gc_stack_slots),
				  (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				   (Mips_Assembly.ADDIU, global,
				    MachTypes.sp,
				    Mips_Assembly.IMM register_save_size),
				   absent, "global = first slot location"),
				  (Mips_Assembly.BRANCH
				   (Mips_Assembly.BA, dummy,
				    dummy, 0),
				   SOME loop_tag, ""),
				  nop],
				[(loop_tag,
				  [(Mips_Assembly.LOAD_AND_STORE
				    (Mips_Assembly.SW, zero,
				     global, 0),
				    absent, "clear stack slot"),
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				    (Mips_Assembly.ADDI, global,
				     global, Mips_Assembly.IMM 4),
				    absent, "increment pointer"),
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				    (Mips_Assembly.SUB, hacky_temporary_reg,
				     hacky_temporary_reg, Mips_Assembly.IMM 1),
				    absent, "decrement loop counter"),
				   (Mips_Assembly.BRANCH
				    (Mips_Assembly.BGTZ, hacky_temporary_reg,
				     dummy, 0),
				    SOME loop_tag, "and loop"),
				   nop] @@
				  endInstrs)])
			      (* temp is now zero so no need to clean *)
			      end
			  end

                        (* Now put it all together *)
                        (* phases 0 and 1 *)
                        val entry =
                          save_the_fp :: check_for_stack_overflow
                        (* phases 2, 3, and part of 4 *)			
                        val stackOKblock =
                          (stackOKTag,
                           make_frame @@ save_gcs @@ save_fps @@ clear_frame_code)
                      (* rest of 4 is in clear_frame_blocks *)
		      in
			(entry, opcode_list', block_list',
			 stackOKblock :: clear_frame_blocks @@ final_result)
		      end

		| MirTypes.RTS =>
		    if needs_preserve then
			(restore_fps @@
			 restore_gcs @@
			 [(Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, lr, MachTypes.sp, 8),
			   NONE, "restore lr"),
			  (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, MachTypes.callee_closure, MachTypes.sp, 4),
			   NONE, ""),
			  move_regc(MachTypes.sp, MachTypes.fp, "restore previous sp"),
			  (Mips_Assembly.LOAD_AND_STORE(Mips_Assembly.LW, MachTypes.fp, MachTypes.sp, 0),
			   NONE, "restore fp not in delay slot"),
			  (Mips_Assembly.JUMP (Mips_Assembly.JR, lr_op,dummy, Debugger_Types.null_backend_annotation),
			  NONE, "return"),
			  nop],
			 opcode_list, block_list, final_result)
		    else
		     ([(Mips_Assembly.JUMP
			(Mips_Assembly.JR, lr_op, dummy, Debugger_Types.null_backend_annotation),
			absent, "return"), nop],
			opcode_list, block_list, final_result)

		| MirTypes.NEW_HANDLER(handler_frame, tag) =>
		    ([(Mips_Assembly.LOAD_AND_STORE
		       (Mips_Assembly.SW, MachTypes.handler,
			lookup_reg_operand handler_frame, ~1),
		       absent, "Insert pointer to previous handler"),
		      move_reg(MachTypes.handler, lookup_reg_operand handler_frame)],
		     opcode_list, block_list, final_result)

		| MirTypes.OLD_HANDLER =>
		    ([(Mips_Assembly.LOAD_AND_STORE
		       (Mips_Assembly.LW, MachTypes.handler, MachTypes.handler,
			~1),
		       absent,
		       "Restore old handler"),
		      nop], opcode_list, block_list, final_result)

		| MirTypes.RAISE reg =>
		    ( (* #1 *)
		     (Mips_Assembly.LOAD_AND_STORE
		      (Mips_Assembly.LW, global, MachTypes.implicit, 4 *
		       (if needs_preserve then
			  Implicit_Vector.raise_code
			else
			  Implicit_Vector.leaf_raise_code)),
		      absent, "Find handler")
		     :: nop
		     :: (Mips_Assembly.JUMP
			 (Mips_Assembly.JALR, lr_op,
			  global,
			  Debugger_Types.null_backend_annotation), absent, "Raise")
		     :: move_regc(MachTypes.arg, lookup_reg_operand reg, "move arg to raise into arg reg")
		     :: [],
(*
                     handle MachTypes.OutOfScope r =>
		       Crash.impossible ("Raise parameter was in " ^ MachSpec.print_register r ^ " in a leaf procedure")
*)			
		     (* #2-4 *)
		     opcode_list, block_list, final_result)

		| MirTypes.COMMENT _ => Crash.impossible "MirTypes.COMMENT not filtered out"

		| MirTypes.CALL_C =>
		    ([(Mips_Assembly.LOAD_AND_STORE
		       (Mips_Assembly.LW, global,
			MachTypes.implicit, 4 * Implicit_Vector.external),
		       absent, "Get address of callc"),
		      nop,
		    (Mips_Assembly.JUMP
		     (Mips_Assembly.JALR,
		      lr_op, global,
		      Debugger_Types.null_backend_annotation),
		     absent, "Do call_c"), nop],
		    opcode_list, block_list, final_result)
	    in
	      do_everything
	      (needs_preserve, tag, opcode_list,
	       Sexpr.CONS(done, Sexpr.ATOM result_list), new_blocks,
	       new_final_result)
	    end

	in
	  do_everything(needs_preserve, tag, List.filter (fn x=>not(is_comment x)) opcodes,
			Sexpr.NIL, rest, [])
	end

      (* Some stuff to do with optimising unconditional branches to returns *)

      fun exit_block [] = NONE
      | exit_block((block as MirTypes.BLOCK(tag, opcode_list)) :: rest) =
	if List.exists
	  (fn MirTypes.RTS => true | _ => false)
	  opcode_list
	  then SOME block
	else exit_block rest

      fun small_exit_block(MirTypes.BLOCK(tag,opcode_list)) =
        let
          fun less_than_three_opcodes_that_are_not_comments([],occ) = true
            | less_than_three_opcodes_that_are_not_comments(MirTypes.COMMENT _ :: rest,occ) =
              less_than_three_opcodes_that_are_not_comments(rest,occ)
            | less_than_three_opcodes_that_are_not_comments(_,2) = false
            | less_than_three_opcodes_that_are_not_comments(h::t,occ) =
              less_than_three_opcodes_that_are_not_comments(t,occ+1)
        in
          less_than_three_opcodes_that_are_not_comments(opcode_list,0)
        end

      fun append_small_exit(MirTypes.BLOCK(tag, opcode_list), block_list) =
	let
	  fun do_block(block as MirTypes.BLOCK(tag', opc_list)) =
	    if List.exists
	      (fn (MirTypes.BRANCH(MirTypes.BRA, MirTypes.TAG t)) => tag = t
	      | _ => false) opc_list then
	      (* Difficult case. Append the exit block onto the block *)
	      (* branching to it, and remove the branch and tag *)
	      let
		val opc' = rev opc_list
		fun get_new_opc_list((comm as MirTypes.COMMENT _) :: rest) =
		  comm :: get_new_opc_list rest
		| get_new_opc_list(MirTypes.BRANCH(MirTypes.BRA,
						   MirTypes.TAG t) ::
				   rest) =
		  if t = tag then rest
		  else
		    Crash.impossible"get_new_opc fails to find proper branch"
		| get_new_opc_list _ = Crash.impossible"get_new_opc fails to find proper branch"
		val new_opc = get_new_opc_list opc'
	      in
		MirTypes.BLOCK(tag', rev_app(new_opc, opcode_list))
	      end
	    else
	      block
	in
	  map do_block block_list
	end

	(* proc_cg code generates for a single procedure. It
         * calculates all values concerned with a procedure's stack
         * frame (e.g. size of floating point save area, whether a
         * stack frame is required, etc.). Then it calls do_blocks
         * (see above) to actually generate the blocks of
         * instructions, moves the entry block to the start of the
         * list, and returns the result. *)

      fun proc_cg(MirTypes.PROC
		  (procedure_name,
                   tag, MirTypes.PROC_PARAMS
		   {spill_sizes, stack_allocated, ...},
		   block_list,runtime_env)) =
	let
          (*val _ = output(std_out,"\n proc_cg : "^procedure_name^"\n")*)
	  val exit_block = exit_block block_list

(* mips exit blocks can be quite long, even if they are < 3 _mir_ opcodes *)
(* So don't do this -- MLA *)
(*
	  val block_list =
	    case exit_block of
	      NONE => block_list
	    | SOME exit_block =>
		if small_exit_block exit_block then
		  append_small_exit(exit_block, block_list)
		else
		  block_list
*)

	  fun define_fp(map, MirTypes.FP_REG fp) =
	    case MirTypes.FP.Map.tryApply'(map, fp) of
	      NONE => MirTypes.FP.Map.define(map, fp, true)
	    | _ => map

	  fun get_fps_from_opcode(MirTypes.TBINARYFP(_, _, fp1, fp2, fp3), map) =
	    define_fp(define_fp(define_fp(map, fp1), fp2), fp3)
	    | get_fps_from_opcode(MirTypes.TUNARYFP(_, _, fp1, fp2),map) =
	      define_fp(define_fp(map, fp1), fp2)
	    | get_fps_from_opcode(MirTypes.BINARYFP(_, fp1, fp2, fp3),map) =
	      define_fp(define_fp(define_fp(map, fp1), fp2), fp3)
	    | get_fps_from_opcode(MirTypes.UNARYFP(_, fp1, fp2),map) =
	      define_fp(define_fp(map, fp1), fp2)
	    | get_fps_from_opcode(MirTypes.STOREFPOP(_, fp1, _, _),map) =
	      define_fp(map, fp1)
	    | get_fps_from_opcode(MirTypes.REAL(_, fp1, _), map) =
	      define_fp(map, fp1)
	    | get_fps_from_opcode(MirTypes.FLOOR(_, _, _, fp1),map) =
	      define_fp(map, fp1)
	    | get_fps_from_opcode(MirTypes.FTEST(_, _, fp1, fp2),map) =
	      define_fp(define_fp(map, fp1), fp2)
	    | get_fps_from_opcode(_, map) = map

	  fun get_fps_from_block(MirTypes.BLOCK(_, instr_list), map) =
	    List.foldl get_fps_from_opcode map instr_list

	  val fp = MirTypes.FP.Map.domain(List.foldl get_fps_from_block MirTypes.FP.Map.empty block_list)

	  fun define_gc(map, MirTypes.GC_REG r) =
	    (case MirTypes.GC.Map.tryApply'(map, r) of
	       NONE => MirTypes.GC.Map.define(map, r, true)
	     | _ => map)
	    | define_gc(map, _) = map

	  fun define_gp(map, MirTypes.GP_GC_REG r) =
	    (case MirTypes.GC.Map.tryApply'(map, r) of
               NONE => MirTypes.GC.Map.define(map, r, true)
	     | _ => map)
	    | define_gp(map, _) = map

	  fun define_bl_dest(map, MirTypes.REG r) = define_gc(map, r)
	    | define_bl_dest(map, _) = map

	  fun get_gcs_from_opcode(MirTypes.TBINARY(_, _, rd, g1, g2), map) =
	    define_gp(define_gp(define_gc(map, rd), g1), g2)
	    | get_gcs_from_opcode(MirTypes.BINARY(_, rd, g1, g2), map) =
	      define_gp(define_gp(define_gc(map, rd), g1), g2)
	    | get_gcs_from_opcode(MirTypes.UNARY(_, rd, g), map) =
	      define_gp(define_gc(map, rd), g)
	    | get_gcs_from_opcode(MirTypes.NULLARY(_, rd), map) =
	      define_gc(map, rd)
	    | get_gcs_from_opcode(MirTypes.TBINARYFP _, map) = map
	    | get_gcs_from_opcode(MirTypes.TUNARYFP _, map) = map
	    | get_gcs_from_opcode(MirTypes.BINARYFP _, map) = map
	    | get_gcs_from_opcode(MirTypes.UNARYFP _, map) = map
	    | get_gcs_from_opcode(MirTypes.STACKOP(_, rd, _), map) =
	      define_gc(map, rd)
	    | get_gcs_from_opcode(MirTypes.IMMSTOREOP _, map) =
	      Crash.impossible"IMMSTOREOP not supported on mips"
	    | get_gcs_from_opcode(MirTypes.STOREOP(_, rd, rs, g), map) =
	      define_gp(define_gc(define_gc(map, rd), rs), g)
	    | get_gcs_from_opcode(MirTypes.STOREFPOP(_, _, rs, g), map) =
	      define_gp(define_gc(map, rs), g)
	    | get_gcs_from_opcode(MirTypes.REAL(_, _, g), map) =
	      define_gp(map, g)
	    | get_gcs_from_opcode(MirTypes.FLOOR(_, _, rd, _), map) =
	      define_gc(map, rd)
	    | get_gcs_from_opcode(MirTypes.BRANCH(_, dest), map) =
	      define_bl_dest(map, dest)
	    | get_gcs_from_opcode(MirTypes.TEST(_, _, g1, g2), map) =
	      define_gp(define_gp(map, g1), g2)
	    | get_gcs_from_opcode(MirTypes.FTEST _, map) = map
	    | get_gcs_from_opcode(MirTypes.BRANCH_AND_LINK(_, dest, _, _), map) =
	      define_bl_dest(map, dest)
	    | get_gcs_from_opcode(MirTypes.TAIL_CALL(_, dest, _), map) =
	      define_bl_dest(map, dest)
	    | get_gcs_from_opcode(MirTypes.CALL_C, map) = map
	    | get_gcs_from_opcode(MirTypes.SWITCH(_, rs, _), map) =
	      define_gc(map, rs)
	    | get_gcs_from_opcode(MirTypes.ALLOCATE(_, rd, g), map) =
	      define_gp(define_gc(map, rd), g)
	    | get_gcs_from_opcode(MirTypes.ALLOCATE_STACK(_, rd, _, _), map) =
	      define_gc(map, rd)
	    | get_gcs_from_opcode(MirTypes.DEALLOCATE_STACK _, map) = map
	    | get_gcs_from_opcode(MirTypes.ADR(_, rd, _), map) =
	      define_gc(map, rd)
	    | get_gcs_from_opcode(MirTypes.INTERCEPT, map) = map
	    | get_gcs_from_opcode(MirTypes.INTERRUPT, map) = map
	    | get_gcs_from_opcode(MirTypes.ENTER _, map) = map
	    | get_gcs_from_opcode(MirTypes.RTS, map) = map
	    | get_gcs_from_opcode(MirTypes.NEW_HANDLER _, map) = map
	    | get_gcs_from_opcode(MirTypes.OLD_HANDLER, map) = map
	    | get_gcs_from_opcode(MirTypes.RAISE rd, map) =
	      define_gc(map, rd)
	    | get_gcs_from_opcode(MirTypes.COMMENT _, map) = map

	  fun get_gcs_from_block(MirTypes.BLOCK(_, instr_list), map) =
	    List.foldl get_gcs_from_opcode map instr_list

          (* The set of gc registers used *)
	  val gc = MirTypes.GC.Map.domain(List.foldl get_gcs_from_block MirTypes.GC.Map.empty block_list)

	  val fps = Set.list_to_set(map (fn r => MirTypes.FP.Map.apply'(fp_map, r)) fp)
	  val gcs = Set.list_to_set(map (fn r => MirTypes.GC.Map.apply'(gc_map, r)) gc)
	  val fps_to_preserve =
	    Set.set_to_list(Set.setdiff(fps, #fp MachSpec.corrupted_by_callee))
	
	  val fp_save_size = List.length fps_to_preserve
	  val preserve_fps = fp_save_size <> 0

	  fun check_gp_op(MirTypes.GP_GC_REG r) = false
	    | check_gp_op(MirTypes.GP_NON_GC_REG r) = false
	    | check_gp_op(MirTypes.GP_IMM_INT _) = false
	    | check_gp_op(MirTypes.GP_IMM_ANY _) = false
	    | check_gp_op(MirTypes.GP_IMM_SYMB symbolic) =
	      case symbolic of
		MirTypes.GC_SPILL_SIZE => false
	      | MirTypes.NON_GC_SPILL_SIZE => false
	      | MirTypes.GC_SPILL_SLOT _ => true
	      | MirTypes.NON_GC_SPILL_SLOT _ => true
	      | MirTypes.FP_SPILL_SLOT _ => true

	  (* check_instr: determines instrs that need preserving *)
	  fun check_instr(MirTypes.BRANCH_AND_LINK _) = true
	    | check_instr MirTypes.CALL_C = true
	    | check_instr(MirTypes.SWITCH _) = true
	    (* handler manipulations need the stack *)
            | check_instr(MirTypes.NEW_HANDLER _) = true
	    | check_instr(MirTypes.ADR _) = true
	    | check_instr(MirTypes.ALLOCATE_STACK _) = true
	    | check_instr(MirTypes.DEALLOCATE_STACK _) = true
	    | check_instr(MirTypes.STACKOP _) = true
	    (* Loads and stores can reference the stack directly *)
	    | check_instr(MirTypes.STOREOP(_, _, _, gp_op)) =
	      check_gp_op gp_op
	    | check_instr(MirTypes.STOREFPOP(_, _, _, gp_op)) =
	      check_gp_op gp_op
	    (* nothing else needs the stack *)
	    | check_instr _ = false

	  fun check_instr_block(MirTypes.BLOCK(_, instr_list)) =
	    List.exists check_instr instr_list

	  (* needs_preserve: checks if non-leaf, non-leaf operations or uses non-leaf registers *)
	  (* the 'ch' stuff has got to go...
	     check_reg is dependant on exceptions because it transverses non-list datatypes and provides
	     short-cut evaluation. This is why it looks so ugly.
	     check if leaf optimisation is allowed
	     check if stack has been used (sparc version)
	     check if fps needs preserving
	     check if instructions force non-leaf
	     check if non_leaf registers are used
	     and finaly get that magic exception catch all shyte
	  *)
	  local
	     fun ch f s = (app f s; false) handle MachTypes.NeedsPreserve => true
	  in
            val needs_preserve =
              not opt_leaf_fns
	      orelse preserve_fps
	      orelse (ch (fn r =>
			  MachTypes.check_reg(MirTypes.GC.Map.apply'(gc_map, r))) gc)
(* Unnecessary, we never preserve non_gc values
	      orelse (ch (fn r =>
			  MachTypes.check_reg(MirTypes.NonGC.Map.apply'(non_gc_map, r))) non_gc)
*)
	      orelse List.exists check_instr_block block_list
	  end (* local *)

          val _ =
            if generate_debug_info orelse debug_variables orelse generate_moduler
              then
                debug_map := Debugger_Types.set_proc_data (procedure_name,
                                                           not needs_preserve,
							   generate_debug_info,
                                                           runtime_env,
                                                           !debug_map)
            else ()

	  val _ =
	    if needs_preserve then ()
	    else
	      diagnostic_output 3
	      (fn _ => [procedure_name, " is leaf\n"])

	  (* move_first: does a lookup on a tag and stuffs an entry after the tagged element back into the list AND
	     the transversed entries so far are reversed *)
	  fun move_first (_, []) = Crash.impossible "move_first"
	    | move_first (L, (t, code) :: rest) =
	      if t = tag then (t, code) :: (L @@ rest)
	      else move_first ((t, code) :: L, rest)

	  (* Moved this from do_block as it's independent of block number *)
	  val spills_opt = spill_sizes
	  val stack_opt = stack_allocated
	  val (gc_spill_size, non_gc_spill_size, fp_spill_size) =
	    case spills_opt of
	      SOME{gc = gc_spill_size,
			       non_gc = non_gc_spill_size,
			       fp = fp_spill_size} =>
	      (gc_spill_size, non_gc_spill_size, fp_spill_size)
	     | _ => Crash.impossible"Spill sizes missing to mach_cg"
	  val stack_extra = case stack_opt of
	    SOME stack_extra => stack_extra
	  | _ =>  Crash.impossible"Stack size missing to mach_cg"
	  val float_value_size = case MachTypes.fp_used of
	    MachTypes.single => 4
	  | MachTypes.double => 8
	  | MachTypes.extended => 16
	  val total_fp_size = fp_spill_size + fp_save_size
	  val total_gc_size = gc_spill_size + stack_extra

	  val non_gc_stack_size =
	    non_gc_spill_size * 4 + float_value_size * total_fp_size

	  val linkage_size = 3 (* fp, caller's closure, link to caller *)

	  val callee_saves =
	    Lists.qsort compare_reg
	    (List.filter check_reg (Set.set_to_list gcs))

	  val callee_save_area = List.length callee_saves

	  val register_save_size = 4 * (linkage_size + callee_save_area +
					(if save_arg_for_debugging
					  then 1 else 0))

	  val total = non_gc_stack_size +
	    gc_spill_size * 4 +
	    stack_extra * 4 +
	    register_save_size
	  val non_gc_stack_size =
	    if total mod 8 <> 0 then
	      non_gc_stack_size + 4
	    else
	      non_gc_stack_size
	  val fp_spill_offset = non_gc_spill_size * 4
	  val fp_save_offset =
	    fp_spill_offset + fp_spill_size * float_value_size
	  val gc_spill_offset  = non_gc_stack_size
	  val gc_stack_alloc_offset = gc_spill_offset + gc_spill_size * 4
	  val register_save_offset = gc_stack_alloc_offset + stack_extra * 4

	  val stack_layout =
	    PROC_STACK
	    {non_gc_spill_size = non_gc_spill_size,
	     fp_spill_size = fp_spill_size,
	     fp_save_size = fp_save_size,
	     gc_spill_size = gc_spill_size,
	     gc_stack_alloc_size = stack_extra,
	     register_save_size = register_save_size,
	     non_gc_spill_offset = 0,
	     fp_spill_offset = fp_spill_offset,
	     fp_save_offset = fp_save_offset,
	     gc_spill_offset = gc_spill_offset,
	     gc_stack_alloc_offset = gc_stack_alloc_offset,
	     register_save_offset = register_save_offset,
	     allow_fp_spare_slot = false,
	     float_value_size = float_value_size
	     }

	  val code =
	    move_first([], do_blocks(needs_preserve,
				     block_list,
				     stack_layout,
				     fps_to_preserve,
				     callee_saves))

	  val code_len =
	    List.foldl (op+) 0 (map (fn (_, opcodes) => List.length opcodes) code)

	  fun zeroes 1 = "\000"
	    | zeroes 2 = "\000\000"
	    | zeroes 3 = "\000\000\000"
	    | zeroes 4 = "\000\000\000\000"
	    | zeroes n = Crash.impossible"zeroes: Int.toString n"

	  (* generate_nulls and normalise_to_four_bytes *)
          val padded_name =
	    procedure_name ^ zeroes(4-(size procedure_name mod 4))

	in
	  {code=(tag, code),
	   non_gc_area_size=non_gc_stack_size,
           name=procedure_name,
           padded_name=padded_name,
	   leaf=not needs_preserve,
	   saves=callee_save_area,
	   parms=0}
	end

      (* proc_cg end *)

      (* remove_redundant_loads checks for save,store using the same registers *)
      fun remove_redundant_loads(acc, []) = rev acc
	| remove_redundant_loads(acc, arg as [x]) = rev(x :: acc)
	| remove_redundant_loads(acc, (ins1 as (Mips_Assembly.LOAD_AND_STORE
						(Mips_Assembly.SW, rd1, rs11, rs12),
						tag1, comment1)) ::
				 (ins2 as (Mips_Assembly.LOAD_AND_STORE
					   (Mips_Assembly.LW, rd2, rs21, rs22),
					   tag2, comment2)) :: rest) =
	  if rs11 = rs21 andalso rs12 = rs22 andalso rd1 = rd2 then
	    (diagnostic_output 3
	     (fn _ => ["Removing redundant load after store\n"]);
	     remove_redundant_loads(acc, ins1 :: rest))
	  else
	    remove_redundant_loads(ins2 :: ins1 :: acc, rest)
	| remove_redundant_loads(acc, x :: rest) = remove_redundant_loads(x :: acc, rest)

      val remove_redundant_loads = fn x => remove_redundant_loads([], x)

      fun remove_redundant_loads_from_block(tag, opcode_list) =
	(tag, remove_redundant_loads opcode_list)

      fun remove_redundant_loads_from_proc(tag, block_list) =
	(tag, map remove_redundant_loads_from_block block_list)

    (* fun list_proc_cg code generates for a list of (mutually
     * recursive) procedures. It uses proc_cg above to generate for
     * each individual procedure, then reschedules the code,
     * linearises it (see linearise_list above), and finally assembles
     * the code into machine code in a string (using
     * Mips_Opcodes.output_opcode), and returns a wordset containing
     * that string.
    *)

      fun list_proc_cg proc_list =
	let
	  fun print_unscheduled_code((tag, block_list),name) =
	    let
	      fun print_block(tag, opcode_list) =
		let
		  fun print_opcode(opcode, tag_opt, comment) =
		    Print.print(
			  Mips_Assembly.print opcode ^
			  (case tag_opt of
			    SOME tag =>
			       " tag " ^ MirTypes.print_tag tag
			  | NONE => " no tag") ^
			     " ; " ^ comment ^ "\n")
		in
		  (Print.print("Block tag " ^ MirTypes.print_tag tag ^ "\n");
		   app print_opcode opcode_list)
		end
	    in
	      (Print.print("Procedure entry tag " ^ MirTypes.print_tag tag ^
                           " " ^ name ^
			   "\n");
	       app print_block block_list)
	    end

	  val temp_code_list =
	    Timer.xtime
	    ("main proc_cg stage", !do_timings,
	     fn () => map proc_cg proc_list)

	  val code_list =
            map (fn tuple=>remove_redundant_loads_from_proc (#code(tuple))) temp_code_list
          val procedure_name_list = map #name temp_code_list
	  val leaf_list = map #leaf temp_code_list
	  val stack_parameters = map #parms temp_code_list

	  val code_list' = code_list

	  val _ = diagnostic_output 3
	    (fn _ => ["Unscheduled code\n"])

	  val _ = diagnostic_output 3
	    (fn _ => (app print_unscheduled_code
                      (ListPair.zip(code_list',procedure_name_list)) ;
		      []))

	  fun print_scheduled_code (code_list) =
	    let
	      fun print_proc((proc_tag, proc),name) =
		let
		  fun print_block(tag, opcode_list) =
		    let
		      fun print_opcode(opcode, tag_opt, comment) =
			Print.print(
			      Mips_Assembly.print opcode ^
			      (case tag_opt of
				 SOME tag =>
				   " tag " ^ MirTypes.print_tag tag
			       | NONE => " no tag") ^
				 " ; " ^ comment ^ "\n")
		    in
		      (Print.print("Block tag " ^ MirTypes.print_tag tag ^ " " ^ name ^ "\n");
		       map print_opcode opcode_list)
		    end
		in
		  (Print.print("Procedure tag " ^ MirTypes.print_tag proc_tag ^ "\n");
		   map print_block proc)
		end
	    in
	      map print_proc code_list
	    end

          val (nopcode,_,_) = nop
          fun is_nop (opcode,_,_) = opcode = nopcode

          (* Eliminate branch to branches *)
          fun elim_simple_branches (tag,blocklist) =
            let
              (* Given a block. returns the tag if it is just an unconditional branch *)
              fun get_branch_tag ([(Mips_Assembly.BRANCH (Mips_Assembly.BA,_,_,_),SOME tag,_),
                                   op2]) =
                if is_nop op2
                  then SOME tag
                else NONE
                | get_branch_tag _ = NONE
              (* Find all the blocks with just a branch *)
              val branch_map =
		List.foldl
		(fn ((tag,opcodes), map)=>
                 case get_branch_tag opcodes of
                   SOME tag' => Map.define (map,tag,tag')
                 | _ => map)
                Map.empty blocklist
              val branch_fn = Map.tryApply branch_map
              (* Return the new tag if the tag is just a block with a branch *)
              (* The counter is to prevent infinite looping *)
              fun lookup_branch (tag,0) = tag
                | lookup_branch (tag,n) =
                  (case branch_fn tag of
                     SOME tag' => lookup_branch (tag',n-1)
                   | _ => tag)
              (* Replace branch destinations *)
              (* We could do this just for the branches that need it *)
              fun scan (op1 as (Mips_Assembly.BRANCH b,SOME tag,c) :: rest,acc) =
                  scan (rest, (Mips_Assembly.BRANCH b,SOME (lookup_branch (tag,20)), c) :: acc)
                | scan (op1 ::rest,acc) = scan (rest,op1 :: acc)
                | scan ([],acc) = rev acc
            in
              (tag, map (fn (tag,opcodes) => (tag, scan (opcodes, []))) blocklist)
            end

          (* Return a list of the tags referenced by the opcode list *)
          (* Maybe this should use a more efficient table *)

          fun tags_from opcode_list =
	    List.foldl (fn ((opcode, SOME t, _), acc)=>t::acc
			|  (_, acc)=> acc) [] opcode_list

          fun elim_unreachable (tag,blocklist) =
            let
              val block_map = Map.from_list blocklist
              val block_fn = Map.tryApply block_map
              val seen = ref [] : MirTypes.tag list ref
              val result = ref Map.empty : unit Map.T ref
              fun scan tag =
		if List.exists (fn x=>x=tag) (!seen) then
		  ()
                else
                  (seen := tag :: (!seen);
                   case block_fn tag of
                     SOME opcode_list =>
                       let
                         val tags = tags_from opcode_list
                       in
                         result := Map.define (!result,tag,());
                         List.app scan (tags_from opcode_list)
                       end
                   | _ => ())
              val _ = scan tag
              val blocklist' =
                List.filter
		(fn (tag,_) => isSome (Map.tryApply' (!result, tag))) blocklist
            in
              (tag,blocklist')
            end

	  val new_code_list = map (elim_unreachable o elim_simple_branches) code_list

	  val _ = diagnostic_output 3 (fn _ => ["Linearising\n"])

          val new_code_list =
            Timer.xtime
            ("reordering blocks", !do_timings,
             fn () => map reorder_blocks new_code_list)

	  val linear_code' =
	    Timer.xtime
	    ("linearising", !do_timings,
	     fn () => linearise_list (mips_r4000, new_code_list))

	  val nop_offsets = map find_nop_offsets linear_code'
	  val _ = diagnostic_output 3 (fn _ => ["Linearised\n"])

	  val nop_instruction =
	    Mips_Opcodes.output_opcode
	    (Mips_Assembly.assemble (Mips_Assembly.nop_code))
		
	  fun make_tagged_code linear_code =
            (map
	     (fn ((tag, code),{non_gc_area_size, padded_name, saves, ...}) =>
		{a_clos=Lists.assoc(tag, loc_refs),
		 b_spills=non_gc_area_size,
		 c_saves=saves,
		 d_code =
		 let
                   fun do_point (debug,count) =
                     let
                       val unpadded_name =
                         let
                           val s = size padded_name
                           fun check_index to =
			     if String.sub (padded_name, to) = #"\000" then
                               check_index(to-1)
			     else String.substring (padded_name, 0, to+1)
                         in
                           check_index (s-1)
			   handle Subscript => ""
                         end
                     in
                       debug_map := Debugger_Types.add_annotation (unpadded_name,
                                                                   count,
                                                                   debug,
                                                                   !debug_map)
                     end
                   fun annotation_points ([],_,res) = rev res
                     | annotation_points ((inst,_)::t,count,res) =
                       (case inst of
                          Mips_Assembly.JUMP (_,_,_,debug) => do_point (debug,count)
                        | Mips_Assembly.CALL (_,_,_,debug) => do_point (debug,count)
                        | _ => ();
                            annotation_points(t,count+4,
                                              Mips_Opcodes.output_opcode(Mips_Assembly.assemble inst)::res))
                   val code =
                     if generate_debug_info
                       then String.concat (annotation_points (code,0,[]))
                     else
                       String.concat
                       (map
                        (fn (x, _) =>
                         Mips_Opcodes.output_opcode(Mips_Assembly.assemble x))
                        code)

                   val padded_code =
                     if size code mod 8 = 4
                       then code ^ nop_instruction
                     else code
		 in
                   padded_code
		 end})
	       (ListPair.zip(linear_code,temp_code_list)))
	      handle Lists.Assoc => Crash.impossible"Assoc tagged_code"
	    handle Lists.Assoc => Crash.impossible"Assoc tagged_code"

	  val tagged_code' = make_tagged_code linear_code'

	(* Here we have leaf_list corresponding to procedure_name_list *)
	in
	  (Code_Module.WORDSET(Code_Module.WORD_SET
			       {a_names=procedure_name_list,
				b=tagged_code',
				c_leafs=leaf_list,
				d_intercept=nop_offsets,
				e_stack_parameters=stack_parameters}),
	   ListPair.zip(linear_code', procedure_name_list))
	end

      val (proc_elements, code_list) =
	ListPair.unzip(map list_proc_cg proc_list_list)

      fun code_size proc_elements =
	let
	  fun sizeof_element (Code_Module.WORDSET
			      (Code_Module.WORD_SET{b=tagged_code', ...})) =
	    List.foldl
	    (fn ({d_code=y, ...}, sofar) => (size y) + sofar) 0 tagged_code'
	    | sizeof_element _ = 0
	  fun f (e, sofar) = sofar + (sizeof_element e)
	in
	  List.foldl f 0 proc_elements
	end

      val _ =
        if ! print_code_size
          then
            print ("Normalised code size is " ^
                   Int.toString (code_size proc_elements)  ^ "\n")
        else ()

      fun make_external_refs(con, list) = map (fn (x, y) => con(y, x)) list

      val ext_elements = make_external_refs(Code_Module.EXTERNAL, ext_refs)
      val ext_vars = make_external_refs(Code_Module.VAR, vars)
      val ext_exns = make_external_refs(Code_Module.EXN, exns)
      val ext_strs = make_external_refs(Code_Module.STRUCT, strs)
      val ext_funs = make_external_refs(Code_Module.FUNCT, funs)

      val module =
	Code_Module.MODULE(value_elements @@
			 proc_elements @@
			 ext_elements @@
			 ext_vars @@
			 ext_exns @@
			 ext_strs @@
			 ext_funs)
	in
	  ((module, !debug_map), code_list)
	end
end
@


1.121.1.1
log
@branched from trunk for label MLW_daveb_inline_1_4_99
@
text
@a6 4
 * Revision 1.121  1998/04/23  10:54:57  mitchell
 * [Bug #30349]
 * Fix non-unit non-final expression warnings
 *
@


1.120
log
@[Bug #70055]
Make sure argument saved whenever debugging or tracing are enabled
@
text
@d7 4
d990 1
a990 1
             (map
d5001 1
a5001 1
	     fun ch f s = (map f s; false) handle MachTypes.NeedsPreserve => true
d5189 1
a5189 1
		   map print_opcode opcode_list)
d5195 1
a5195 1
	       map print_block block_list)
d5215 1
a5215 1
	    (fn _ => (map print_unscheduled_code
@


1.119
log
@[Bug #30326]
Merge in change from branch MLWorks_workspace_97
@
text
@d7 4
d1523 1
a1523 1
    (Options.OPTIONS {compiler_options = Options.COMPILEROPTIONS {generate_debug_info, debug_variables, generate_moduler, opt_leaf_fns, mips_r4000, ...},
d1538 1
a1538 1
      val save_arg_for_debugging = generate_debug_info
@


1.118
log
@[Bug #30089]
Modify TIMER (from utils) to be INTERNAL_TIMER to keep bootstrap happy
@
text
@d7 10
d411 1
a411 1
require "../utils/timer";
@


1.117
log
@[Bug #30243]
Remove tests for out of range shifts as we no longer generate them
@
text
@d7 4
d421 1
a421 1
  structure Timer : TIMER
@


1.117.2.1
log
@branched from trunk for label MLWorks_workspace_97
@
text
@a6 4
 * Revision 1.117  1997/08/08  09:49:42  jont
 * [Bug #30243]
 * Remove tests for out of range shifts as we no longer generate them
 *
@


1.117.2.2
log
@[Bug #30326]
@
text
@a6 3
 * Revision 1.117.2.1  1997/09/11  20:57:59  daveb
 * branched from trunk for label MLWorks_workspace_97
 *
d401 1
a401 1
require "../utils/mlworks_timer";
@


1.117.1.1
log
@branched from trunk for label MLWorks_dt_wizard
@
text
@a6 4
 * Revision 1.117  1997/08/08  09:49:42  jont
 * [Bug #30243]
 * Remove tests for out of range shifts as we no longer generate them
 *
@


1.116
log
@[Bug #30215]
Remove BIC, and replace by INTTAG instruction
@
text
@d7 4
d2681 1
a2681 12
				val shift_size =
				  if gp_check_range(gp_operand', true,
						    arith_imm_limit) then
				    convert_small_imm gp_operand'
				  else
				    (* Out of range shift *)
				    Mips_Assembly.IMM
				    (case binary_op of
				       MirTypes.LSR => 32
				     | MirTypes.ASR => 29
				     | MirTypes.ASL => 32
				     | _ => Crash.impossible"mach_cg: non-shift in shift case")
d2690 2
a2691 52
				    if shift_val >= 32 then
				      (* Out of range shift right, replace by zero *)
				      let
					val new_opc =
					  MirTypes.UNARY(MirTypes.MOVE,
							 reg_operand,
							 MirTypes.GP_IMM_INT 0)
				      in
					([], new_opc :: opcode_list,
					 block_list, final_result)
				      end
				    else
				      (* Deal with possible immediate value here *)
				      if is_reg gp_operand then
					let
					  val rs1 = lookup_gp_operand gp_operand
					in
					  ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					     (opcode, rd, rs1, shift_size),
					     absent, "")],
					   opcode_list, block_list, final_result)
					end
				      else
					(* A rare case, just replace by move *)
					(* and shift the result *)
					([],
					 MirTypes.UNARY(MirTypes.MOVE,
							global_reg,
							gp_operand) ::
					 MirTypes.BINARY(binary_op,
							 reg_operand,
							 global_gp,
							 gp_operand') ::
					 opcode_list,
					 block_list, final_result)
				| MirTypes.ASR =>
				  if is_reg gp_operand then
				    if shift_val >= 32 then
				      (* Out of range shift right, *)
				      (* replace by shift by 31 or 29 *)
				      let
					val new_shift = 31
					val new_opc =
					  MirTypes.BINARY(binary_op,
							  reg_operand,
							  gp_operand,
							  MirTypes.GP_IMM_ANY new_shift)
				      in
					([], new_opc :: opcode_list,
					 block_list, final_result)
				      end
				    else
d2700 23
d2737 2
a2738 2
				    if shift_val >= 32 then
				      (* Out of range shift right, replace by zero *)
d2740 1
a2740 4
					val new_opc =
					  MirTypes.UNARY(MirTypes.MOVE,
							 reg_operand,
							 MirTypes.GP_IMM_INT 0)
d2742 4
a2745 2
					([], new_opc :: opcode_list,
					 block_list, final_result)
d2748 12
a2759 23
				      (* Deal with possible immediate value here *)
				      if is_reg gp_operand then
					let
					  val rs1 = lookup_gp_operand gp_operand
					in
					  ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					     (opcode, rd, rs1, shift_size),
					     absent, "")],
					   opcode_list, block_list, final_result)
					end
				      else
					(* A rare case, just replace by move *)
					(* and shift the result *)
					([],
					 MirTypes.UNARY(MirTypes.MOVE,
							global_reg,
							gp_operand) ::
					 MirTypes.BINARY(binary_op,
							 reg_operand,
							 global_gp,
							 gp_operand') ::
					 opcode_list,
					 block_list, final_result)
@


1.115
log
@[Bug #20071]
 Use 32 bit not for BIC
@
text
@d7 4
d2548 9
a2556 2
		  (case binary_op of
                     MirTypes.BIC =>
d2558 32
a2589 62
			if is_reg gp_operand then
			  MirTypes.UNARY(MirTypes.NOT32, global_reg,
					 gp_operand') ::
			  MirTypes.BINARY(MirTypes.AND, reg_operand, gp_operand,
					  global_gp) ::
			  opcode_list
			else
			  MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand) ::
			  MirTypes.UNARY(MirTypes.NOT32, global_reg,
					 gp_operand') ::
			  MirTypes.BINARY(MirTypes.AND, reg_operand,
					  gp_from_reg reg_operand,
					  global_gp) ::
			  opcode_list, block_list, final_result)
		   | _ =>
                       if is_mult_op binary_op
                         then
                          (if not (is_reg gp_operand)
                             then
                               ([],
                                MirTypes.UNARY (MirTypes.MOVE, reg_operand, gp_operand) ::
                                MirTypes.BINARY (binary_op, reg_operand,
                                                 gp_from_reg reg_operand, gp_operand') ::
                                opcode_list, block_list, final_result)
                           else if not (is_reg gp_operand')
                                  then
                                    ([],
                                     MirTypes.UNARY(MirTypes.MOVE,
                                                    global_reg, gp_operand') ::
                                     MirTypes.BINARY(binary_op, reg_operand, gp_operand, global_gp) ::
                                     opcode_list,
                                     block_list, final_result)
                                else (* its a mult_op and both operands are registers *)
                                  let
                                    val r1 = lookup_gp_operand gp_operand
                                    val r2 = lookup_gp_operand gp_operand'
                                    val r3 = lookup_reg_operand reg_operand
                                    val (opcode,result_opcode,untag) =
                                      case binary_op of
                                        MirTypes.MULU =>
                                          (Mips_Assembly.MULTU,Mips_Assembly.MFLO,true)
                                      | MirTypes.MUL32U =>
                                          (Mips_Assembly.MULTU,Mips_Assembly.MFLO,false)
                                      | _ => Crash.impossible ("mult_op opcode")
                                  in
                                    ((if untag then
                                        [(Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SRA,
                                                                                MachTypes.global,
                                                                                r2,
                                                                                Mips_Assembly.IMM 2),
                                          absent, "Untag arg")]
                                      else []) @@
                                        [(Mips_Assembly.MULT_AND_DIV (opcode,
                                                                      r1,
                                                                      if untag
                                                                        then MachTypes.global
                                                                      else r2),
                                          absent, "")] @@
                                        [(Mips_Assembly.MULT_AND_DIV_RESULT (result_opcode,r3),
                                          absent, "")],
                                    opcode_list, block_list, final_result)
                                  end) (* of mult_op case *)
d2592 32
a2623 12
			 (* Shifts are difficult, we'll do them separately *)
			 fun is_shift MirTypes.ADDU = false
			   | is_shift MirTypes.SUBU = false
			   | is_shift MirTypes.MULU = false
			   | is_shift MirTypes.MUL32U = false
			   | is_shift MirTypes.AND = false
			   | is_shift MirTypes.OR = false
			   | is_shift MirTypes.BIC = false
			   | is_shift MirTypes.EOR = false
			   | is_shift MirTypes.LSR = true
			   | is_shift MirTypes.ASL = true
			   | is_shift MirTypes.ASR = true
d2625 20
a2644 75
			 val rd = lookup_reg_operand reg_operand
			 val opcode =
			   case binary_op of
			     MirTypes.ADDU => Mips_Assembly.ADDU
			   | MirTypes.SUBU => Mips_Assembly.SUBU
			   | MirTypes.AND => Mips_Assembly.AND
			   | MirTypes.OR => Mips_Assembly.OR
			   | MirTypes.BIC =>
			       Crash.impossible"mach_cg:BIC imm match failed"
			   | MirTypes.EOR => Mips_Assembly.XOR
			   | MirTypes.LSR => Mips_Assembly.SRL
			   | MirTypes.ASL => Mips_Assembly.SLL
			   | MirTypes.ASR => Mips_Assembly.SRA
			   | MirTypes.MULU => Crash.impossible"MirTypes.MULU"
			   | MirTypes.MUL32U => Crash.impossible"MirTypes.MULS"

			 fun needs_reverse Mips_Assembly.SUB	= true
			   | needs_reverse Mips_Assembly.SUBU	= true
			   | needs_reverse Mips_Assembly.SRL	= true
			   | needs_reverse Mips_Assembly.SLL	= true
			   | needs_reverse Mips_Assembly.SRA	= true
			   | needs_reverse _ 			= false

			 val (gp_operand, gp_operand', redo) =
			   if is_reg gp_operand then
			     (gp_operand, gp_operand', false)
			   else
			     if is_reg gp_operand' then
			       if needs_reverse opcode then
				 (gp_operand, gp_operand', true)
			       else
				 (gp_operand', gp_operand, false)
			     else (* Both immediate so no problem *)
			       (gp_operand, gp_operand', false)
			 val is_a_shift = is_shift binary_op
		       in
			 if redo andalso not is_a_shift then
			   let
			     val inter_reg =
			       case gp_operand' of
				 MirTypes.GP_GC_REG r =>
				   (if r = global_mir then
				      (* The nasty case *)
				      (case reg_operand of
					 MirTypes.GC_REG r' =>
					   if r = r' then
					     Crash.impossible "source and dest global with large int"
					   else
					     r'
				       | MirTypes.NON_GC_REG _ =>
					   Crash.impossible"BINARY doesn't deliver GC")
				    else
				      global_mir)
			       | _ => Crash.impossible "BINARY has non-gc register"
			   in
			     ([],
			      MirTypes.UNARY(MirTypes.MOVE,
					     MirTypes.GC_REG inter_reg,
					     gp_operand) ::
			      MirTypes.BINARY(binary_op, reg_operand,
					      MirTypes.GP_GC_REG inter_reg,
					      gp_operand') ::
			      opcode_list, block_list, final_result)
			   end
			 else
			   if is_a_shift then
			     (* Deal with possible out of range shifts *)
			     (* and also bad code from LSR/ASR :: BIC *)
			     let
			       val has_bic =
				 case opcode_list of
				   MirTypes.BINARY(MirTypes.BIC,
						   reg_operand',
						   MirTypes.GP_GC_REG inter_reg,
						   MirTypes.GP_IMM_ANY 3) :: _ =>
d2646 55
a2700 129
				      MirTypes.GC_REG reg =>
					(inter_reg = reg) andalso
					reg_operand = reg_operand'
				    | _ => false)
				 | _ => false
			       val const_shift = case gp_operand' of
				 MirTypes.GP_GC_REG _ => false
			       | MirTypes.GP_NON_GC_REG _ => false
			       | _ => true
			     in
			       if const_shift then
				 let
				   val shift_size =
				     if gp_check_range(gp_operand', true,
						       arith_imm_limit) then
				       convert_small_imm gp_operand'
				     else
				       (* Out of range shift *)
				       Mips_Assembly.IMM
				       (case binary_op of
					  MirTypes.LSR => 32
					| MirTypes.ASR => 29
					| MirTypes.ASL => 32
					| _ => Crash.impossible"mach_cg: non-shift in shift case")
				   fun get_shift(Mips_Assembly.IMM i) = i
                                     | get_shift(Mips_Assembly.REG (MachTypes.R0)) = 0
				     | get_shift _ =
				       Crash.impossible"mach_cg:non_constant in shift by constant"
				   val shift_val = get_shift shift_size
				 in
				   case binary_op of
				     MirTypes.LSR =>
				       if shift_val >= 32 orelse
					 (shift_val >= 30 andalso has_bic) then
					 (* Out of range shift right, replace by zero *)
					 let
					   val new_opc =
					     MirTypes.UNARY(MirTypes.MOVE,
							    reg_operand,
							    MirTypes.GP_IMM_INT 0)
					 in
					   if has_bic then
					     ([], new_opc :: tl opcode_list,
					      block_list, final_result)
					   else
					     ([], new_opc :: opcode_list,
					      block_list, final_result)
					 end
				       else
					 (* Deal with possible immediate value here *)
					 if is_reg gp_operand then
					   let
					     val rs1 = lookup_gp_operand gp_operand
					   in
					     if has_bic then
					     (* Shift by two more, then back again *)
					       ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
						  (opcode, rd, rs1,
						   Mips_Assembly.IMM(shift_val + 2)),
						  absent, ""),
						 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
						  (Mips_Assembly.SLL, rd, rd,
						   Mips_Assembly.IMM 2),
						  absent, "tag as arithmetic")],
						tl opcode_list,
						block_list, final_result)
					     else
					       ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
						  (opcode, rd, rs1, shift_size),
						  absent, "")],
						opcode_list, block_list, final_result)
					   end
					 else
					   (* A rare case, just replace by move *)
					   (* and shift the result *)
					   ([],
					    MirTypes.UNARY(MirTypes.MOVE,
							   global_reg,
							   gp_operand) ::
					    MirTypes.BINARY(binary_op,
							    reg_operand,
							    global_gp,
							    gp_operand') ::
					    opcode_list,
					    block_list, final_result)
				   | MirTypes.ASR =>
				       if is_reg gp_operand then
					 if shift_val >= 32 orelse
					   (shift_val >= 30 andalso has_bic) then
					   (* Out of range shift right, *)
					   (* replace by shift by 31 or 29 *)
					   let
					     val new_shift =
					       if has_bic then 29 else 31
					     val new_opc =
					       MirTypes.BINARY(binary_op,
							       reg_operand,
							       gp_operand,
							       MirTypes.GP_IMM_ANY new_shift)
					   in
					     ([], new_opc :: opcode_list,
					      block_list, final_result)
					   end
					 else
					   let
					     val rs1 = lookup_gp_operand gp_operand
					   in
					     if has_bic then
					       (* Shift by two more, then back again *)
					       ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
						  (opcode, rd, rs1,
						   Mips_Assembly.IMM(shift_val + 2)),
						  absent, ""),
						 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
						  (Mips_Assembly.SLL, rd, rd,
						   Mips_Assembly.IMM 2),
						  absent, "tag as arithmetic")],
					       tl opcode_list,
					       block_list, final_result)
					     else
					       ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
						  (opcode, rd, rs1, shift_size),
						  absent, "")],
						opcode_list, block_list, final_result)
					 end
				       else
					 (* A rare case, just replace by move *)
					 (* and shift the result *)
					 ([],
d2702 38
a2739 2
							 global_reg,
							 gp_operand) ::
d2742 76
a2817 150
							  global_gp,
							  gp_operand') ::
					  opcode_list,
					  block_list, final_result)
				   | MirTypes.ASL =>
				       if shift_val >= 32 then
					 (* Out of range shift right, replace by zero *)
					 (* bic always a nop here *)
					 (* So not worth testing for *)
					 (* as it won't be generated *)
					 let
					   val new_opc =
					     MirTypes.UNARY(MirTypes.MOVE,
							    reg_operand,
							    MirTypes.GP_IMM_INT 0)
					 in
					   ([], new_opc :: opcode_list,
					    block_list, final_result)
					 end
				       else
					 (* Deal with possible immediate value here *)
					 if is_reg gp_operand then
					   let
					     val rs1 = lookup_gp_operand gp_operand
					   in
					     ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
						(opcode, rd, rs1, shift_size),
						absent, "")],
					      opcode_list, block_list, final_result)
					   end
					 else
					   (* A rare case, just replace by move *)
					   (* and shift the result *)
					   ([],
					    MirTypes.UNARY(MirTypes.MOVE,
							   global_reg,
							   gp_operand) ::
					    MirTypes.BINARY(binary_op,
							    reg_operand,
							    global_gp,
							    gp_operand') ::
					    opcode_list,
					    block_list, final_result)
				   | _ => Crash.impossible"mach_cg: non-shift in shift case"
				 end
			       else
				 (* Need a range test to sort out shifts by large amounts *)
				 (* This includes the case of a constant shifted by a variable amount *)
				 let
				   val rs1 = lookup_gp_operand gp_operand'
				   val cont_tag = MirTypes.new_tag()
				   fun make_range_test limit =
				     let
				       val bad_tag = MirTypes.new_tag()
				     in
				       (bad_tag,
					[(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					  (Mips_Assembly.SLTIU,
					   MachTypes.global, rs1,
					   Mips_Assembly.IMM limit),
					  absent, "shift range test"),
					 (Mips_Assembly.BRANCH
					  (Mips_Assembly.BEQ, MachTypes.global,
					   zero, 0),
					  SOME bad_tag, ""),
					 nop])
				     end

                                   val continue =
				     [(Mips_Assembly.BRANCH
				       (Mips_Assembly.BA, zero, zero, 0),
				       SOME cont_tag, ""),
				      nop]

				   fun constant_out_of_range_shift gp_op =
				     case binary_op of
				       MirTypes.ASL => [move_imm(rd, 0)]
				     | MirTypes.ASR =>
					 if gp_check_range(gp_op, false, arith_imm_limit) then
					   [move_imm(rd, 0)]
					 else
					   (case gp_operand of
					      MirTypes.GP_IMM_INT i =>
						[move_imm(rd, if i < 0 then ~4 else 0)]
					    | MirTypes.GP_IMM_ANY i =>
						[move_imm(rd, 0)]
					    | _ => Crash.impossible"Mach_cg:shift:bad constant")
				     | MirTypes.LSR => [move_imm(rd, 0)]
				     | _ => Crash.impossible"mach_cg: non-shift in shift case"
				   val shift_limit = case binary_op of
				     MirTypes.ASL => 32
				   | MirTypes.ASR => if has_bic then 29 else 31
				   | MirTypes.LSR => if has_bic then 30 else 32
				   | _ => Crash.impossible"mach_cg: non-shift in shift case"

				   fun variable_out_of_range_shift gp_op =
				     case binary_op of
				       MirTypes.ASL => [move_imm(rd, 0)]
				     | MirTypes.ASR =>
					 (* Shift by 31 and tag if necessary *)
					 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
					  (opcode, rd, lookup_gp_operand gp_op,
					   Mips_Assembly.IMM 31),
					  absent, "") ::
					 (if has_bic then
					    [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					      (Mips_Assembly.SLL, rd, rd,
					       Mips_Assembly.IMM 2),
					      absent, "")]
					  else
					    [])
				     | MirTypes.LSR => [move_imm(rd, 0)]
				     | _ => Crash.impossible"mach_cg: non-shift in shift case"

				   val new_opc_list =
				     if has_bic then
				       tl opcode_list
				     else
				       opcode_list
				   val (bad_tag, range_test) =
				     make_range_test shift_limit
				   val do_bic =
				     if has_bic then
				       (Mips_Assembly.ARITHMETIC_AND_LOGICAL
					(Mips_Assembly.SRA, rd, rd,
					 Mips_Assembly.IMM 2),
					absent, "shift right") ::
				       (Mips_Assembly.ARITHMETIC_AND_LOGICAL
					(Mips_Assembly.SLL, rd, rd,
					 Mips_Assembly.IMM 2),
					absent, "then left to tag as int") ::
				       continue
				     else
				       continue
				   val shift_op =
				     if is_reg gp_operand then
				       [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					 (opcode, rd,
					  lookup_gp_operand gp_operand,
					  Mips_Assembly.REG rs1),
					 absent, "")]
				     else
				       load_imm_into_register(rd, gp_operand) @@
				       [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					 (opcode, rd, rd, Mips_Assembly.REG rs1),
					 absent, "")]
				 in
				   (range_test @@ shift_op @@ do_bic, [],
				    MirTypes.BLOCK(cont_tag, new_opc_list) ::
				    block_list,
d2819 24
a2842 2
				     (if is_reg gp_operand then
					variable_out_of_range_shift gp_operand
d2844 49
a2892 1
					constant_out_of_range_shift gp_operand) @@
d2894 94
a2987 64
				 end
			     end
			   else
			     (* Not a shift *)
			     let
			       fun cant_extend_negative_imm x =
				 case x of
				   Mips_Assembly.ADD => false
				 | Mips_Assembly.ADDI => false
				 | Mips_Assembly.ADDIU => false
				 | Mips_Assembly.ADDU => false
				 | Mips_Assembly.SUB => false
				 | Mips_Assembly.SUBU => false
				 | Mips_Assembly.AND => true
				 | Mips_Assembly.ANDI => true
				 | Mips_Assembly.OR => true
				 | Mips_Assembly.ORI => true
				 | Mips_Assembly.XOR => true
				 | Mips_Assembly.XORI => true
				 | Mips_Assembly.NOR => true
				 | Mips_Assembly.SLT => false
				 | Mips_Assembly.SLTU => false
				 | Mips_Assembly.SLTI => false
				 | Mips_Assembly.SLTIU => false
				 | Mips_Assembly.SLL => false
				 | Mips_Assembly.SRL => false
				 | Mips_Assembly.SRA => false
				 | Mips_Assembly.SLLV => false
				 | Mips_Assembly.SRLV => false
				 | Mips_Assembly.SRAV => false
			       fun negative_imm(Mips_Assembly.IMM i) = i < 0
				 | negative_imm _ = false
			     in
			       if is_reg gp_operand then
				 let
				   val rs1 = lookup_gp_operand gp_operand
				 in
				   if is_reg gp_operand' orelse
				     gp_check_range(gp_operand', true,
						    arith_imm_limit) then
				     let
				       val reg_or_imm =
					 if is_reg gp_operand' then
					   Mips_Assembly.REG(lookup_gp_operand
							     gp_operand')
					 else
					   convert_small_imm gp_operand'
				     in
				       if negative_imm reg_or_imm andalso
					 cant_extend_negative_imm opcode then
					 let
					   val inter_reg =
					     case gp_operand of
					       MirTypes.GP_GC_REG r =>
						 (if r = global_mir then
						    (* The nasty case *)
						    (case reg_operand of
						       MirTypes.GC_REG r' =>
							 if r = r' then
							   Crash.impossible "source and dest global with large int"
							 else
							   r'
						     | MirTypes.NON_GC_REG _ =>
							 Crash.impossible"BINARY doesn't deliver GC")
d2989 10
a2998 56
						    global_mir)
					     | _ => Crash.impossible "BINARY has non-gc register"
					 in
					   ([],
					    MirTypes.UNARY(MirTypes.MOVE,
							   MirTypes.GC_REG inter_reg,
							   gp_operand') ::
					    MirTypes.BINARY(binary_op, reg_operand,
							    gp_operand,
							    MirTypes.GP_GC_REG inter_reg) ::
					    opcode_list, block_list, final_result)
					 end
				       else
				       ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					  (opcode, rd, rs1, reg_or_imm), absent, "")],
					opcode_list, block_list, final_result)
				     end
				   else
				     let
				       val inter_reg =
					 case gp_operand of
					   MirTypes.GP_GC_REG r =>
					     (if r = global_mir then
						(* The nasty case *)
						(case reg_operand of
						   MirTypes.GC_REG r' =>
						     if r = r' then
						       Crash.impossible
						       "source and dest global with large int"
						     else
						       r'
						 | MirTypes.NON_GC_REG _ =>
						     Crash.impossible"BINARY doesn't deliver GC")
					      else
						global_mir)
					 | _ => Crash.impossible "BINARY has non-gc register"
				     in
				       ([],
					MirTypes.UNARY(MirTypes.MOVE,
						       MirTypes.GC_REG inter_reg,
						       gp_operand') ::
					MirTypes.BINARY(binary_op, reg_operand,
							gp_operand,
							MirTypes.GP_GC_REG inter_reg) ::
					opcode_list, block_list, final_result)
				     end
				 end
			       else
				 (* gp_operand not a register *)
				 if is_reg gp_operand' then
				   ([],
				    MirTypes.UNARY(MirTypes.MOVE,
						   global_reg,
						   gp_operand) ::
				    MirTypes.BINARY(binary_op, reg_operand,
						    global_gp,
d3000 29
a3028 13
				    opcode_list, block_list, final_result)
				 else
				   (* gp_operand' also not a register *)
				   ([],
				    MirTypes.UNARY(MirTypes.MOVE,
						   reg_operand,
						   gp_operand) ::
				    MirTypes.BINARY(binary_op, reg_operand,
						    gp_from_reg reg_operand,
						    gp_operand') ::
				    opcode_list, block_list, final_result)
			     end
		       end)
d3091 24
a3114 1

@


1.114
log
@[Bug #20064]
Ensure r2 not overwritten in 32 bit int arithmetic.
@
text
@d7 4
d2545 1
a2545 1
		     MirTypes.BIC =>
d2548 1
a2548 1
			  MirTypes.UNARY(MirTypes.NOT, global_reg,
d2555 1
a2555 1
			  MirTypes.UNARY(MirTypes.NOT, global_reg,
d3187 1
a3187 38
(*
		    let
		      val rd = lookup_reg_operand reg_operand
		      fun not_seq(rs1, imm) =
			[(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			  (Mips_Assembly.SUBU, rd, zero,
			   Mips_Assembly.REG rs1), absent, "rd := -rs1"),
			 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			  (Mips_Assembly.ADDIU, rd, rd, Mips_Assembly.IMM imm),
			  absent, "rd -:= 1")]
		    in (* let *)
		      if is_reg gp_operand then
			let
			  val rs1 = lookup_gp_operand gp_operand
			  val imm = case gp_operand of
			    MirTypes.GP_NON_GC_REG _ => ~1
			  | _ => ~4
			in (* let *)
			  (not_seq(rs1, imm),
			   opcode_list, block_list, final_result)
			end (* let *)
		      else
			case gp_operand of
			  MirTypes.GP_IMM_ANY imm =>
			    let
			      val rs1 = global
			    in
			      (load_imm_into_register(rs1, gp_operand) @@
			       not_seq(rs1, ~1), opcode_list, block_list, final_result)
			    end
			  | _ =>
			      ([],
			       MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand) ::
			       MirTypes.UNARY(MirTypes.NOT, reg_operand,
					      gp_from_reg reg_operand)
			       :: opcode_list, block_list, final_result)
		    end (* let *)
*)
@


1.113
log
@[Bug #30076]
Modifications to allow stack based parameter passing on the I386
@
text
@d7 4
d2397 15
d2438 2
a2439 1
					   ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
d2442 1
a2442 1
					      (Mips_Assembly.BLTZ, rs2, zero, 0),
@


1.112
log
@[Bug #30136]
Removed early-mips-r4000 option.
@
text
@d7 4
d107 1
a107 1
 * 
d110 1
a110 1
 * 
d114 1
a114 1
 * 
d117 1
a117 1
 * 
d120 1
a120 1
 * 
d124 1
a124 1
 * 
d127 1
a127 1
 * 
d130 1
a130 1
 * 
d135 1
a135 1
 * 
d138 1
a138 1
 * 
d142 1
a142 1
 * 
d145 1
a145 1
 * 
d149 1
a149 1
 * 
d152 1
a152 1
 * 
d155 1
a155 1
 * 
d158 1
a158 1
 * 
d161 1
a161 1
 * 
d164 1
a164 1
 * 
d167 1
a167 1
 * 
d170 1
a170 1
 * 
d175 1
a175 1
 * 
d179 1
a179 1
 * 
d182 1
a182 1
 * 
d185 1
a185 1
 * 
d189 1
a189 1
 * 
d192 1
a192 1
 * 
d195 1
a195 1
 * 
d198 1
a198 1
 * 
d201 1
a201 1
 * 
d204 1
a204 1
 * 
d208 1
a208 1
 * 
d211 1
a211 1
 * 
d214 1
a214 1
 * 
d219 1
a219 1
 * 
d222 1
a222 1
 * 
d226 1
a226 1
 * 
d229 1
a229 1
 * 
d233 1
a233 1
 * 
d237 1
a237 1
 * 
d240 1
a240 1
 * 
d244 1
a244 1
 * 
d247 1
a247 1
 * 
d250 1
a250 1
 * 
d262 1
a262 1
 * 
d269 1
a269 1
 * 
d272 1
a272 1
 * 
d275 1
a275 1
 * 
d278 1
a278 1
 * 
d282 1
a282 1
 * 
d285 1
a285 1
 * 
d288 1
a288 1
 * 
d291 1
a291 1
 * 
d295 1
a295 1
 * 
d298 1
a298 1
 * 
d301 1
a301 1
 * 
d304 1
a304 1
 * 
d307 1
a307 1
 * 
d310 1
a310 1
 * 
d313 1
a313 1
 * 
d316 1
a316 1
 * 
d319 1
a319 1
 * 
d322 1
a322 1
 * 
d325 1
a325 1
 * 
d328 1
a328 1
 * 
d331 1
a331 1
 * 
d334 1
a334 1
 * 
d339 1
a339 1
 * 
d342 1
a342 1
 * 
d347 1
a347 1
 * 
d353 1
a353 1
 * 
d357 1
a357 1
 * 
d360 1
a360 1
 * 
d363 1
a363 1
 * 
d366 1
a366 1
 * 
d369 1
a369 1
 * 
d372 1
a372 1
 * 
d416 1
a416 1
  
d422 1
a422 1
  sharing type Mips_Schedule.Mips_Assembly.Mips_Opcodes.MachTypes.Mips_Reg 
d450 1
a450 1
  val trace_dummy_instructions = 
d458 3
a460 3
  val diagnostic_output = 
    if do_diag 
      then Diagnostic.output 
d515 1
a515 1
    if check_range(i, signed, pos_limit) 
d517 1
a517 1
    else 
d534 1
a534 1
    
d536 1
a536 1
  fun copy n x = 
d540 1
a540 1
    in 
d544 1
a544 1
	copy' (n,[]) 
d565 1
a565 1
  fun move_regc(rd, rs, comment) = 
d573 1
a573 1
     (Mips_Assembly.OR, rd, rs, zero_op), 
d621 1
a621 1
  fun to_binary (digits:int, value:int) : char list = 
d624 1
a624 1
	| to_sub(digs_to_go, value, done) = 
d648 1
a648 1
	    Info.error' 
d663 1
a663 1
      val binary_list = 
d708 1
a708 1
        Code_Module.REAL(i, encoding_function(sign, mantissa, exponent)) 
d722 1
a722 1
    | last_opcode([elem as (Mips_Assembly.BRANCH(Mips_Assembly.BA, _, _, _), _, _), _]) 
d724 1
a724 1
    | last_opcode([elem as (Mips_Assembly.FIXED_BRANCH(Mips_Assembly.BA, _, _, _), _, _), _]) 
d787 1
a787 1
            
d829 1
a829 1
               rev(rev rest @@ (block::done)) = rev(block::done) @@ rest 
d831 1
a831 1
               = rev done @@ (block :: rest) 
d839 1
a839 1
		       val (tag,_) = 
d849 1
a849 1
							      next_block, 
d879 1
a879 1
	    Lists.partition continues rest 
d883 1
a883 1
      
d933 1
a933 1
        
d951 1
a951 1
	    (fn _ => 
d959 2
a960 2
	  fun copy_n( limit, xs, ys) = 
	    if limit < 0 orelse limit > length xs then 
d971 1
a971 1
	  fun linearise_proc(proc_offset, offset, [], done) = 
d994 1
a994 1
                       SOME res => 
d1043 1
a1043 1
				  (Mips_Assembly.JR, global_op, 
d1065 1
a1065 1
			 SOME res => 
d1080 1
a1080 1
			 SOME res => 
d1094 1
a1094 1
			 SOME res => 
d1153 1
a1153 1
				  NONE, 
d1287 1
a1287 1
			 SOME res => 
d1302 1
a1302 1
			 SOME res => 
d1367 1
a1367 1
                  fun subst_block ([],offset,subst_list,acc) = 
d1378 1
a1378 1
                  val (offset,subst_list,opcodelist) = 
d1383 2
a1384 2
                
              val (offset,subst_list,blocklist) = 
d1408 1
a1408 1
          | subst_list => 
d1420 1
a1420 1
    
d1440 5
a1444 5
    | check_reg MachTypes.R11 = true 
    | check_reg MachTypes.R12 = true 
    | check_reg MachTypes.R13 = true 
    | check_reg MachTypes.R14 = true 
    | check_reg MachTypes.R15 = true 
d1466 1
a1466 1
	  
d1487 1
a1487 1
  fun mach_cg 
d1576 3
a1578 3
	      let 
		val symbolic_value = 
		  fn i => 
d1589 2
a1590 2
                case i of 
                  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1 i),name) => 
d1598 1
a1598 1
                | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(_, i)),name) => 
d1604 1
a1604 1
	      let 
d1619 2
a1620 2
                case i of 
                  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1 i),name) => 
d1628 1
a1628 1
                | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2(_, i)),name) => 
d1634 1
a1634 1
	      let 
d1636 2
a1637 2
		fun symbolic_value i = 
		  let 
d1641 1
a1641 1
		       Crash.impossible 
d1645 1
a1645 1
		     else 
d1652 2
a1653 2
		case i of 
		  MirTypes.DEBUG(spill as ref(RuntimeEnv.OFFSET1 i),name) => 
d1671 1
a1671 1
	      Crash.impossible"gp_check_range of non-immediate" 
d1677 1
a1677 1
	  fun split_imm(MirTypes.GP_IMM_INT i) = 
d1679 1
a1679 1
	    | split_imm(MirTypes.GP_IMM_ANY i) = 
d1687 1
a1687 1
	    | split_imm _ = Crash.impossible"split_imm of non-immediate" 
d1691 1
a1691 1
	  fun get_small_imm (MirTypes.GP_IMM_INT i) = 
d1693 1
a1693 1
	    | get_small_imm (MirTypes.GP_IMM_ANY i) = 
d1695 1
a1695 1
	    | get_small_imm (MirTypes.GP_IMM_SYMB symb) = 
d1705 1
a1705 1
                | i => 
d1743 1
a1743 1
	  fun convert_small_imm (MirTypes.GP_IMM_INT i) = 
d1745 1
a1745 1
	    | convert_small_imm (MirTypes.GP_IMM_ANY i) = 
d1747 1
a1747 1
	    | convert_small_imm (MirTypes.GP_IMM_SYMB symb) = 
d1781 1
a1781 1
		   (Mips_Assembly.SWC1, fp, 
d1784 1
a1784 1
		   "save float") :: 
d1786 1
a1786 1
		   (Mips_Assembly.SWC1, 
d1790 1
a1790 1
		   "save float") :: 
d1806 1
a1806 1
		     (Mips_Assembly.LWC1, fp, 
d1809 1
a1809 1
		     "restore float") :: 
d1811 1
a1811 1
		     (Mips_Assembly.LWC1, 
d1830 1
a1830 1
	      (Mips_Assembly.LOAD_AND_STORE 
d1834 1
a1834 1
	      
d1837 1
a1837 1
		  (Mips_Assembly.LOAD_AND_STORE 
d1856 1
a1856 1
	  
d1905 1
a1905 1
	    (needs_preserve, tag', 
d1911 1
a1911 1
	  | do_everything 
d1965 1
a1965 1
                      val preserve_order = 
d1983 1
a1983 1
                        
d1997 1
a1997 1
                        then 
d2006 1
a2006 1
                             then 
d2010 1
a2010 1
                                opcode_list, 
d2012 1
a2012 1
                          else 
d2019 2
a2020 2
                              val check = 
                                if r3 = global 
d2027 1
a2027 1
                              fun make_clean_blocks (error_tag,true) = 
d2040 1
a2040 1
                                     
d2045 1
a2045 1
                                  val (overflow_tag,overflow_blocks) = 
d2069 1
a2069 1
                                    if not tag_result 
d2117 1
a2117 1
                                  val (div_tag,div_blocks) = 
d2119 1
a2119 1
                                  val (overflow_tag,overflow_blocks) = 
d2125 4
a2128 4
                                  val arg_test = 
                                    [(Mips_Assembly.BRANCH (Mips_Assembly.BEQ, 
                                                            r2, 
                                                            zero, 
d2147 3
a2149 3
                                     (Mips_Assembly.BRANCH (Mips_Assembly.BLTZ, 
                                                            r1, 
                                                            zero, 
d2180 1
a2180 1
                                                 Mips_Assembly.ARITHMETIC_AND_LOGICAL 
d2188 1
a2188 1
                                   [], 
d2193 1
a2193 1
                                  val (div_tag,div_blocks) = 
d2201 1
a2201 1
                                                 Mips_Assembly.ARITHMETIC_AND_LOGICAL 
d2209 1
a2209 1
                                   [], 
d2214 1
a2214 1
                                  val (div_tag,div_blocks) = 
d2229 1
a2229 1
                                  val (div_tag,div_blocks) = 
d2236 1
a2236 1
                                  val tag_result = 
d2238 1
a2238 1
                                      [(Mips_Assembly.ARITHMETIC_AND_LOGICAL 
d2267 2
a2268 2
                              ((if untag then 
                                  if r1 = global 
d2539 1
a2539 1
                         then 
d2548 1
a2548 1
                                  then 
d2553 1
a2553 1
                                     opcode_list, 
d2562 1
a2562 1
                                        MirTypes.MULU => 
d2564 1
a2564 1
                                      | MirTypes.MUL32U => 
d2568 1
a2568 1
                                    ((if untag then 
d2570 2
a2571 2
                                                                                MachTypes.global, 
                                                                                r2, 
d2577 2
a2578 2
                                                                      if untag 
                                                                        then MachTypes.global 
d3106 2
a3107 2
			let val rs1 = lookup_gp_operand gp_operand in 
			  (if rd = rs1 then 
d3150 1
a3150 1
			let 
d3152 1
a3152 1
                        in 
d3201 1
a3201 1
		| MirTypes.NULLARY(MirTypes.CLEAN, reg_operand) => 
d3309 1
a3309 1
			    val mov_instr = 
d3416 2
a3417 2
		    
		    fun gp_op_is_large arg = 
d3419 1
a3419 1
			MirTypes.GP_IMM_ANY i     => gp_check_range(arg, true, arith_imm_limit) andalso 
d3467 2
a3468 2
			    else 
			      let val i = case  gp_operand of 
d3481 1
a3481 1
				(make_imm_for_store gp_operand, 
d3485 1
a3485 1
                          (if MachTypes.fp_used = MachTypes.single 
d3534 1
a3534 1
			 MirTypes.UNARY(MirTypes.MOVE, 
d3548 1
a3548 1
		  
d3555 1
a3555 1
		   
d3559 1
a3559 1
		   
d3568 1
a3568 1
		      test rs2 fp_global 
d3573 1
a3573 1
		      negate fp_global fp_global 
d3593 1
a3593 1
			 saveRoundingMode rd gl = 
d3615 2
a3616 2
			    (Mips_Assembly.CVT_W_S, Mips_Assembly.CVT_S_W, 
			     Mips_Assembly.C_OLT_S, Mips_Assembly.C_OLE_S, 
d3618 3
a3620 3
                        | MachTypes.double => 
			    (Mips_Assembly.CVT_W_D, Mips_Assembly.CVT_D_W, 
			     Mips_Assembly.C_OLT_D, Mips_Assembly.C_OLE_D, 
d3623 1
a3623 1
			    
d3625 1
a3625 1
		         fun changeRoundingMode bitseq = 
d3643 1
a3643 1
		      val restore_rounding_mode = 
d3669 3
a3671 3
			 (Mips_Assembly.MTC1, global, MachTypes.fp_global, 
			  dummy_op), 
			 absent,""), 
d3680 1
a3680 1
                        (Mips_Assembly.FUNARY(negate, MachTypes.fp_global, MachTypes.fp_global), 			 
d3695 1
a3695 1
			 absent,""), 
d3702 1
a3702 1
		  
d3707 1
a3707 1
			  (Mips_Assembly.JR, 
d3770 1
a3770 1
			    else 
d3772 1
a3772 1
                        
d3795 1
a3795 1
                                if n >= 0 
d3945 1
a3945 1
				    | MirTypes.BGT => 
d3950 1
a3950 1
				    | MirTypes.BLE => 
d3955 1
a3955 1
				    | MirTypes.BLS => 
d4002 1
a4002 1
		    val (test_instr, branch) = 
d4033 1
a4033 1
		    opcode_list, block_list, final_result) 
d4054 1
a4054 1
                      else 
d4056 1
a4056 1
                    val reset = 
d4059 1
a4059 1
                               (Mips_Assembly.LW, MachTypes.fp, MachTypes.sp, 0), 
d4063 1
a4063 1
                    val postRestores = 
d4077 2
a4078 2
                           (Mips_Assembly.JR, global_op, 
                            dummy, 
d4103 1
a4103 1
			if List.length tag_list <= 2 then 
d4109 1
a4109 1
				    (Mips_Assembly.BA, dummy, dummy, 0), 
d4128 1
a4128 1
			else if needs_preserve then 
d4131 3
a4133 3
			   absent, "call self") :: 
                          (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADDIU, 
                                                                 lr, 
d4136 2
a4137 2
                          (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADDU, 
                                                                 global, 
d4140 2
a4141 2
                          (Mips_Assembly.LOAD_AND_STORE  (Mips_Assembly.LW, 
                                                          global, 
d4145 2
a4146 2
			  (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADDU, 
                                                                 lr, 
d4148 4
a4151 4
                           absent, "calculate destination") :: 
			  (Mips_Assembly.JUMP (Mips_Assembly.JR, 
                                               lr_op, dummy, 
                                               Debugger_Types.null_backend_annotation), 
d4155 1
a4155 1
                                   (fn (tag,(l,n)) => 
d4162 1
a4162 1
(*		       
d4167 1
a4167 1
			if List.length tag_list <= 2 then 
d4173 1
a4173 1
				    (Mips_Assembly.BA, dummy, dummy, 0), 
d4192 1
a4192 1
			else if needs_preserve then 
d4207 1
a4207 1
			      (Mips_Assembly.JR, lr_op, dummy, Debugger_Types.null_backend_annotation), 
d4214 1
a4214 1
			     (Mips_Assembly.BA, dummy, dummy, 0), 
d4221 1
a4221 1
*)		       
d4243 1
a4243 1
		    
d4268 1
a4268 1
                      val branch_finish = 
d4277 1
a4277 1
		      val gc_test = 
d4281 1
a4281 1
		      val gc_test_branch = 
d4285 2
a4286 2
		      val get_gc_entry = 
			(Mips_Assembly.LOAD_AND_STORE 
d4289 2
a4290 2
		      val call_gc = 
			(Mips_Assembly.JUMP 
d4292 1
a4292 1
			  Debugger_Types.null_backend_annotation), 
d4294 2
a4295 2
		      fun tag_result(primary) = 
			(Mips_Assembly.ARITHMETIC_AND_LOGICAL 
d4299 1
a4299 1
		      val (allocation,finish_block) = 
d4301 1
a4301 1
			MirTypes.GP_IMM_INT size => 
d4332 2
a4333 2
			    if secondary = 0 then 
			      [] 
d4335 3
a4337 3
			      (load_large_number_into_register (global, secondary) @@ 
			       [(Mips_Assembly.LOAD_AND_STORE 
                                 (Mips_Assembly.SW, global, rd, ~primary), 
d4341 2
a4342 2
			   ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL 
                              (Mips_Assembly.ADD, gc1, gc1, Mips_Assembly.IMM bytes), 
d4346 1
a4346 1
                             (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
d4357 1
a4357 1
                              (Mips_Assembly.LOAD_AND_STORE 
d4365 1
a4365 1
                             [(Mips_Assembly.ARITHMETIC_AND_LOGICAL 
d4370 1
a4370 1
                              (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
d4397 1
a4397 1
				 | MirTypes.ALLOC_VECTOR => 
d4403 1
a4403 1
				     (Tags.REFPTR, Tags.ARRAY, false, 12+7, true, "array length")        
d4425 2
a4426 2
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
				  (Mips_Assembly.ADDU, gc1, gc1, Mips_Assembly.REG rd), 
d4443 1
a4443 1
				    (Mips_Assembly.LOAD_AND_STORE 
d4462 1
a4462 1
		      (allocation, 
d4464 1
a4464 1
                       MirTypes.BLOCK (finish_tag,opcode_list) :: block_list, 
d4491 1
a4491 1
	      
d4495 1
a4495 1
	      
d4497 1
a4497 1
		(* T[INTERRUPT] => 
d4505 1
a4505 1
			val (implicit_offset,link) = 
d4510 1
a4510 1
			val event_check_code = 
d4523 1
a4523 1
			   (Mips_Assembly.JUMP 
d4527 1
a4527 1
			     Debugger_Types.null_backend_annotation), 
d4539 1
a4539 1
		  
d4544 1
a4544 1
		    if not needs_preserve then 
d4549 1
a4549 1
                        (* There are three kinds of frame: 
d4559 1
a4559 1
			datatype frame = 
d4578 1
a4578 1
                         (0) saving the fp 
d4592 1
a4592 1
			val check_for_stack_overflow = 
d4598 1
a4598 1
			      | Medium => 
d4604 1
a4604 1
			    | Large => 
d4614 1
a4614 1
				val stack_overflow_bool_reg = 
d4618 1
a4618 1
				val stack_overflow_test_reg = 
d4637 1
a4637 1
			    val stack_extension = 
d4643 1
a4643 1
				  | _ => 
d4666 1
a4666 1
			    preCheck @@ stack_overflow_test @@ stack_extension 
d4670 2
a4671 2
			  
			val make_frame = 
d4675 1
a4675 1
				Large => 
d4681 1
a4681 1
			      | _ => 
d4693 1
a4693 1
				 MachTypes.sp, 4), absent, "save closure"), 
d4710 1
a4710 1
			    val endInstrs = 
d4713 1
a4713 1
				 dummy, 0), 
d4721 1
a4721 1
				fun saveInstr offset = 
d4726 1
a4726 1
				  
d4728 1
a4728 1
				  | initStackSlots(offset, n, done) = 
d4779 2
a4780 2
                        (* phases 2, 3, and part of 4 *)			      
                        val stackOKblock = 
d4790 4
a4793 4
		    if needs_preserve then 
			(restore_fps @@ 
			 restore_gcs @@ 
			 [(Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, lr, MachTypes.sp, 8), 
d4795 1
a4795 1
			  (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, MachTypes.callee_closure, MachTypes.sp, 4), 
d4805 1
a4805 1
		     ([(Mips_Assembly.JUMP 
d4830 1
a4830 1
		       (if needs_preserve then 
d4858 1
a4858 1
		     (Mips_Assembly.JALR, 
d4887 2
a4888 2
          fun less_than_three_opcodes_that_are_not_comments([],occ) = true 
            | less_than_three_opcodes_that_are_not_comments(MirTypes.COMMENT _ :: rest,occ) = 
d4891 1
a4891 1
            | less_than_three_opcodes_that_are_not_comments(h::t,occ) = 
d5062 1
a5062 1
	    
d5113 1
a5113 1
            val needs_preserve = 
d5126 1
a5126 1
            if generate_debug_info orelse debug_variables orelse generate_moduler 
d5179 1
a5179 1
	  val register_save_size = 4 * (linkage_size + callee_save_area + 
d5219 1
a5219 1
				     block_list, 
d5234 1
a5234 1
          val padded_name = 
d5238 7
a5244 6
	  ((tag, code), 
	   non_gc_stack_size,
           procedure_name,
           padded_name,
	   not needs_preserve,
	   callee_save_area)
d5308 1
a5308 1
	  val temp_code_list = 
d5313 5
a5317 4
	  val code_list = 
            map (fn tuple=>remove_redundant_loads_from_proc (#1(tuple))) temp_code_list
          val procedure_name_list = map #3 temp_code_list
	  val leaf_list = map #5 temp_code_list
d5325 1
a5325 1
	    (fn _ => (map print_unscheduled_code 
d5364 1
a5364 1
                if is_nop op2 
d5371 1
a5371 1
		(fn ((tag,opcodes), map)=> 
d5393 1
a5393 1
                
d5449 1
a5449 1
		    
d5452 1
a5452 1
	     (fn ((tag, code),(_,spills,_,padded_name,_,saves)) =>
d5454 1
a5454 1
		 b_spills=spills,
d5468 1
a5468 1
                           check_index (s-1) 
d5479 1
a5479 1
                       (case inst of 
d5485 1
a5485 1
                   val code = 
d5488 1
a5488 1
                     else 
d5514 2
a5515 1
				d_intercept=nop_offsets}),
d5522 1
a5522 1
      fun code_size proc_elements = 
d5526 1
a5526 1
	    List.foldl 
d5535 2
a5536 2
        if ! print_code_size 
          then 
d5557 1
a5557 1
	in 
@


1.111
log
@Speeding up linearization
@
text
@d7 3
d919 1
a919 1
  fun linearise_list ((mips_r4000,early_mips_r4000), proc_list) =
d940 1
a940 64
             (Mips_Assembly.nop_code,"ERROR -- Dummy instruction for bad offset -- shouldn't see this"))

	  fun is_a_transfer(opcode) = 
	    (case opcode of 
	       Mips_Assembly.BRANCH _  => true
	     | Mips_Assembly.FIXED_BRANCH _  => true
	     | Mips_Assembly.CALL _    => true
	     | Mips_Assembly.JUMP _    => true
	     | Mips_Assembly.FBRANCH _ => true
	     | _                       => false)

	  (* The R4000 chip revision 2.2 (and earlier) has a bug in it
	   that can cause a failure when a jump register instruction
	   is the last instruction on a memory page, and accessing the
	   next instruction (i.e. the instruction in the delay slot)
	   results in a TLB miss.  We can avoid this situation by
	   double-word aligning all jump register instructions (so
	   that the instruction in the delay slot will be on the same
	   page as the jump). This is done if the variable
	   branches_double_word_aligned is true.

	   If you have a rev 3.0 (or higher) R4000, or you do not care
	   about running on an R4000, then you may use this flag to
	   turn off the fix and produce "normal" code that will be
	   slightly faster. *)

	  val branches_double_word_aligned = early_mips_r4000
	    
	  fun align_transfers_in_block ([], done, aligned) = (rev done, aligned)
	    | align_transfers_in_block (instr :: oplist, done, aligned) =
	      if aligned
		then align_transfers_in_block (oplist, instr :: done, false)
	      else
		if (let val (instruction, tag, comment) = instr in
		      (is_a_transfer instruction) end)
		  then
		    align_transfers_in_block 
		    (oplist,
		     instr
		     :: (Mips_Assembly.nop_code, NONE, "doubleword aligned branch follows") 
		     :: done, 
		     false)
		else
		  align_transfers_in_block (oplist, (instr) :: done, true)
		  
	  fun align_transfers_in_proc ([], done, _) = rev done
	    | align_transfers_in_proc ((m,block) :: blocklist, done, aligned) = 
	      let val (this_block_done, aligned) =
		align_transfers_in_block (block, [], aligned)
	      in 
		align_transfers_in_proc (blocklist, 
					 (m,this_block_done)::done, aligned)
	      end
	    
	  fun align_transfers_in_proclist ([], done) = rev done
	    | align_transfers_in_proclist ((m,proc) :: proclist, done) =
	      align_transfers_in_proclist 
	      (proclist, 
	       (m,align_transfers_in_proc (proc, [], true)) :: done)
	      
	  val proc_list = 
	    if branches_double_word_aligned 
	      then align_transfers_in_proclist (proc_list, []) 
	    else proc_list
d1485 1
a1485 1
    (Options.OPTIONS {compiler_options = Options.COMPILEROPTIONS {generate_debug_info, debug_variables, generate_moduler, opt_leaf_fns, mips_r4000, early_mips_r4000,...},
d5435 1
a5435 1
	     fn () => linearise_list ((mips_r4000,early_mips_r4000),new_code_list))
@


1.110
log
@[Bug #30088]
Get rid of MLWorks.Option
@
text
@d7 4
a371 1
require "../basis/__general";
d551 7
d801 1
d838 1
a838 1
		     end) handle General.Option =>
a903 2
  exception BadOffset of MirTypes.tag * (Mips_Assembly.opcode * MirTypes.tag option * string) list

a917 5
      datatype ('a, 'b)union = INL of 'a | INR of 'b
      val new_proc_list =
	Timer.xtime
	("reordering blocks", !do_timings,
	 fn () => map reorder_blocks proc_list)
d925 1
a925 1
	 fn () => map (Mips_Schedule.reschedule_proc no_delay) new_proc_list)
a927 4
(*
      val _ = diagnostic_output 3 
        (fn _ => (print_scheduled_code (ListPair.zip(new_code_list',procedure_name_list)); []))
*)
d933 1
a933 1
      fun do_linearise' proc_list =
d935 4
d965 2
a966 2
	  fun align_transfers_in_block([], done, aligned) = (rev done, aligned)
	    | align_transfers_in_block((instr) :: oplist, done, aligned) =
d968 1
a968 1
		then align_transfers_in_block (oplist, (instr) :: done, false)
a1001 1

d1007 5
a1011 4
	    (fn _ => (map
	     (fn (x, y) => Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ Int.toString y ^ "\n"))
		      (Map.to_list tag_env) ;
		      [] ))
a1014 19
	  val perform_branch_check = branches_double_word_aligned

	  fun check_branches ([], _) = ()
	    | check_branches (_ :: oplist, true) = check_branches (oplist, false)
	    | check_branches ((opcode,comment) :: oplist, false) =
	      if (is_a_transfer opcode) then
		Crash.impossible ("Unaligned branch: " ^ comment ^ "\n")
	      else 
		check_branches (oplist, true)
		 
	  fun check_for_unaligned_branches (oplist) =
	    (if perform_branch_check 
	       then (check_branches (oplist, true))
	     else ();
	       oplist
	       )
	  (* drop with lots of checks *)
	  fun drop (n:int, xs:'a list):'a list = List.drop (xs, n) handle General.Subscript => Crash.impossible "drop bad list"
	      
d1028 1
a1028 1
	    (offset, check_for_unaligned_branches(rev done))
d1039 1
a1039 1
		      (MLWorks.IO.output(MLWorks.IO.std_out, "fault_range fails on " ^ x ^
d1078 1
a1078 1
			       val new_tail =
d1103 3
a1105 4
				 nop ::
				 tail
                               val new_tail = case branch of
				 Mips_Assembly.BA => new_tail
d1111 1
a1111 1
				 new_tail
d1113 1
a1113 2
                               raise BadOffset(block_tag,
						copy_n(head_size, opcode_list, new_tail))
d1175 1
a1175 1
			       val new_tail =
d1200 2
a1201 2
				 tail
			       val new_tail = case (call, r) of
d1203 1
a1203 1
				   new_tail
d1211 1
a1211 1
				 new_tail
d1213 1
a1213 2
                               raise BadOffset(block_tag,
						copy_n(head_size, opcode_list, new_tail))
d1239 1
a1239 1
				 val new_tail =
d1246 1
a1246 1
				    SOME tag, new_comment) :: tail
d1248 1
a1248 3
				 raise BadOffset
				   (block_tag,
				    copy_n(head_size, opcode_list, new_tail))
d1277 1
a1277 1
				 val new_tail =
d1279 1
a1279 1
                                  (Mips_Assembly.LUI, rd, i),
d1288 1
a1288 1
				    absent, new_comment) :: tail
d1290 1
a1290 2
				 raise BadOffset(block_tag,
						  copy_n(head_size, opcode_list, new_tail))
a1395 12
	  fun subst_bad_offset_block(proc_list, block as (tag, opcode_list)) =
	    let
	      fun remap(proc_tag, block_list) =
		(proc_tag,
		 map
		 (fn (block' as (block_tag, _)) =>
		  if block_tag = tag then block else block')
		 block_list)
	    in
	      map remap proc_list
	    end

d1397 1
a1397 4
	  INR (do_linearise_sub(0, proc_list))
	  handle BadOffset bad_offset_block =>
	    ((*output (std_out, "Found bad offset ... restarting linearise_sub\n");*)
             INL (subst_bad_offset_block(proc_list, bad_offset_block)))
d1399 58
d1458 10
a1467 3
        case do_linearise' proclist of
          INR result => result
        | INL new_proclist => do_linearise new_proclist
d5483 1
a5483 1
	  val new_code_list' = map (elim_unreachable o elim_simple_branches) code_list
d5487 5
d5495 1
a5495 1
	     fn () => linearise_list ((mips_r4000,early_mips_r4000),new_code_list'))
d5590 1
a5590 1
            MLWorks.IO.output(MLWorks.IO.std_out, "Normalised code size is " ^
@


1.109
log
@[Bug #1995]
Changed the definition of no_delay so that the mips_r4000 and early_mips_r4000
definitions are no longer linked.
@
text
@d7 5
d909 1
d1430 1
a1430 1
	  MLWorks.Option.INR (do_linearise_sub(0, proc_list))
d1433 1
a1433 1
             MLWorks.Option.INL (subst_bad_offset_block(proc_list, bad_offset_block)))
d1437 2
a1438 2
          MLWorks.Option.INR result => result
        | MLWorks.Option.INL new_proclist => do_linearise new_proclist
@


1.109.1.1
log
@branched from 1.109
@
text
@a6 5
 * Revision 1.109  1997/04/01  12:23:59  daveb
 * [Bug #1995]
 * Changed the definition of no_delay so that the mips_r4000 and early_mips_r4000
 * definitions are no longer linked.
 *
@


1.109.1.1.3.1
log
@branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_10r3
@
text
@a6 3
 * Revision 1.109.1.1  1997/05/12  10:37:27  hope
 * branched from 1.109
 *
@


1.109.1.1.2.1
log
@branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_10r2_551
@
text
@a6 3
 * Revision 1.109.1.1  1997/05/12  10:37:27  hope
 * branched from 1.109
 *
@


1.109.1.1.1.1
log
@branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_11
@
text
@a6 3
 * Revision 1.109.1.1  1997/05/12  10:37:27  hope
 * branched from 1.109
 *
@


1.109.1.1.1.1.1.1
log
@branched from MLWorks_11 for label MLWorks_11r1
@
text
@a6 3
 * Revision 1.109.1.1.1.1  1997/07/28  18:22:40  daveb
 * branched from MLWorks_1_0_r2c1_1997_05_12 for label MLWorks_11
 *
@


1.108
log
@Renamed R4000 option
@
text
@d7 3
d909 1
a909 1
      val no_delay = mips_r4000 orelse early_mips_r4000
@


1.107
log
@Changing CGT code
@
text
@d7 3
d899 1
a899 1
  fun linearise_list ((mips2,mips_r4000), proc_list) =
d906 1
d912 1
a912 1
	 fn () => map (Mips_Schedule.reschedule_proc mips2) new_proc_list)
d950 1
a950 1
	  val branches_double_word_aligned = mips_r4000
d1507 1
a1507 1
    (Options.OPTIONS {compiler_options = Options.COMPILEROPTIONS {generate_debug_info, debug_variables, generate_moduler, opt_leaf_fns, mips2, mips_r4000,...},
d5452 1
a5452 1
	     fn () => linearise_list ((mips2,mips_r4000),new_code_list'))
@


1.106
log
@Adding version options
@
text
@d7 3
d430 4
a433 4
    [(Mips_Assembly.other_nop_code,NONE,"Tracing nop"),
     (Mips_Assembly.other_nop_code,NONE,"Tracing nop"),
     (Mips_Assembly.other_nop_code,NONE,"Tracing nop"),
     (Mips_Assembly.other_nop_code,NONE,"Tracing nop")]
d467 1
d478 1
a478 1
	if opcode = Mips_Assembly.other_nop_code then
d4106 71
d4235 1
a4235 1
		       
@


1.105
log
@Adding hardware multiply
@
text
@d7 3
d892 1
a892 1
  fun linearise_list proc_list =
d904 1
a904 1
	 fn () => map Mips_Schedule.reschedule_proc new_proc_list)
d942 1
a942 1
	  val branches_double_word_aligned = true
d1499 1
a1499 1
    (Options.OPTIONS {compiler_options = Options.COMPILEROPTIONS {generate_debug_info, debug_variables, generate_moduler, opt_leaf_fns, ...},
a5265 28
(*
	  fun do_reschedule code_list =
	    let
	      val code_list' =
		Timer.xtime
		("rescheduling blocks", !do_timings,
		 fn () =>
		 map
		 (fn (proc_tag, proc) =>
		  (proc_tag, map
		   (fn (tag, x) => (tag, Mips_Schedule.reschedule_block x))
		   proc))
		 code_list)

	      val _ = diagnostic_output 3 (fn _ => ["Proc level rescheduling\n"])
	      val _ = diagnostic_output 3 (fn _ => ["Result so far\n"])
	      val _ = diagnostic_output 3 (fn _ => (map print_unscheduled_code
                                                    (ListPair.zip(code_list',procedure_name_list)) ;
						    []))
	      val code_list'' =
		Timer.xtime
		("rescheduling procs", !do_timings,
		 fn () => map Mips_Schedule.reschedule_proc code_list')
	    in
	      code_list''
	    end
*)

d5373 1
a5373 1
	     fn () => linearise_list new_code_list')
@


1.104
log
@[Bug #1832]
event_check_code: add a couple of nops to avoid load hazzards
on an R3000.
@
text
@d7 5
d554 17
a570 1
    
d1471 1
d1944 17
a1960 1
		
d1970 15
a1984 11
		  MirTypes.TBINARY(tagged_op, tag, reg, gp, gp') =>
		  let
		    val rd = lookup_reg_operand reg
		    val preserve_order = case tagged_op of
			                   MirTypes.SUBV => true
					 | MirTypes.DIVV => true
					 | MirTypes.MODV => true
					 | MirTypes.SUBW => true
					 | MirTypes.DIVW => true
					 | MirTypes.MODW => true
					 | _ => false
d1986 1
a1986 2
		    val is_reg_gp = is_reg gp
		    val is_reg_gp' = is_reg gp'
d1988 5
a1992 2
		    val xchg = (not is_reg_gp) andalso is_reg_gp' andalso (not preserve_order)
		    val redo = (not is_reg_gp) andalso is_reg_gp' andalso preserve_order
d1994 295
a2288 12
		    val (gp,gp') = if xchg then (gp',gp) else (gp,gp')
		    val is_reg_gp = is_reg gp
		    val is_reg_gp' = is_reg gp'
		  in
		    if redo then
		      ([],
		       MirTypes.UNARY(MirTypes.MOVE, global_reg, gp) ::
		       MirTypes.TBINARY(tagged_op, tag, reg, global_gp, gp') ::
		       opcode_list, block_list, final_result)
		    else
		      if is_reg_gp then
			if is_reg_gp' orelse
d2296 3
a2298 10
				MirTypes.ADDV => true
			      | MirTypes.SUBV => true
			      | MirTypes.MULV => true
			      | MirTypes.DIVV => true
			      | MirTypes.MODV => true
			      | MirTypes.ADDW => false
			      | MirTypes.SUBW => false
			      | MirTypes.MULW => false
			      | MirTypes.DIVW => false
			      | MirTypes.MODW => false
d2300 1
d2305 3
a2307 10
				  MirTypes.ADDV => Mips_Assembly.ADD
				| MirTypes.SUBV => Mips_Assembly.SUB
				| MirTypes.MULV => Crash.impossible"do_opcodes(TBINARY(MULV))"
				| MirTypes.DIVV => Crash.impossible"do_opcodes(TBINARY(DIVV))"
				| MirTypes.MODV => Crash.impossible"do_opcodes(TBINARY(MODV))"
				| MirTypes.ADDW => Crash.impossible"do_opcodes(TBINARY(MULV))"
				| MirTypes.SUBW => Crash.impossible"do_opcodes(TBINARY(MULV))"
				| MirTypes.MULW => Crash.impossible"do_opcodes(TBINARY(MULV))"
				| MirTypes.DIVW => Crash.impossible"do_opcodes(TBINARY(MULV))"
				| MirTypes.MODW => Crash.impossible"do_opcodes(TBINARY(MULV))"
a2308 1

d2316 3
a2318 10
				  MirTypes.ADDW => Mips_Assembly.ADDU
				| MirTypes.SUBW => Mips_Assembly.SUBU
				| MirTypes.MULV => Crash.impossible"do_opcodes(TBINARY(MULV))"
				| MirTypes.DIVV => Crash.impossible"do_opcodes(TBINARY(DIVV))"
				| MirTypes.MODV => Crash.impossible"do_opcodes(TBINARY(MODV))"
				| MirTypes.ADDV => Crash.impossible"do_opcodes(TBINARY(MULV))"
				| MirTypes.SUBV => Crash.impossible"do_opcodes(TBINARY(MULV))"
				| MirTypes.MULW => Crash.impossible"do_opcodes(TBINARY(MULV))"
				| MirTypes.DIVW => Crash.impossible"do_opcodes(TBINARY(MULV))"
				| MirTypes.MODW => Crash.impossible"do_opcodes(TBINARY(MULV))"
d2328 3
a2330 13
				val regs_to_clean = Lists.rev_remove_dups regs_to_clean
				val regs_to_clean =
				  List.filter
				  (fn reg => reg <> MachTypes.R0 andalso
				   reg <> MachTypes.global)
				  regs_to_clean
				(* No point in cleaning global as it's non-gc *)
				(* R0 is already clean *)
				val clean_code =
				  (map
				   (fn reg => move_reg(reg, zero))
				   regs_to_clean) @@
				  [(Mips_Assembly.BRANCH
d2332 1
a2332 1
				    tag, ""),
d2385 1
a2385 1
					    MirTypes.TBINARY(tagged_op, tag, reg, gp', gp) :: opcode_list,
d2395 1
a2395 1
					      MirTypes.TBINARY(tagged_op, tag, reg, MirTypes.GP_GC_REG MirRegisters.global, gp') ::
d2455 1
d2515 1
a2515 1
			   MirTypes.TBINARY(tagged_op, tag,
d2521 1
a2521 1
			  MirTypes.TBINARY(tagged_op, tag, reg,
d2545 49
a2593 1
		       let
d2595 2
a2596 2
			 fun is_shift MirTypes.ADD = false
			   | is_shift MirTypes.SUB = false
d2598 1
a2598 5
			   | is_shift MirTypes.MULS = false
			   | is_shift MirTypes.DIVU = false
			   | is_shift MirTypes.DIVS = false
			   | is_shift MirTypes.MODU = false
			   | is_shift MirTypes.MODS = false
d2610 2
a2611 8
			     MirTypes.ADD => Mips_Assembly.ADDU
			   | MirTypes.SUB => Mips_Assembly.SUBU
			   | MirTypes.MULU => Crash.unimplemented"MirTypes.MULU"
			   | MirTypes.MULS => Crash.unimplemented"MirTypes.MULS"
			   | MirTypes.DIVU => Crash.unimplemented"MirTypes.DIVU"
			   | MirTypes.DIVS => Crash.unimplemented"MirTypes.DIVS"
			   | MirTypes.MODU => Crash.unimplemented"MirTypes.MODU"
			   | MirTypes.MODS => Crash.unimplemented"MirTypes.MODS"
d2620 2
d3269 1
a3269 1
		| MirTypes.TBINARYFP(tagged_binary_fp_op, tag, fp_operand,
d3275 1
d3376 1
a3376 1
		       (MirTypes.ADD, global_reg,
d3437 1
a3437 1
			 MirTypes.BINARY(MirTypes.ADD,
d3506 1
a3506 1
			 MirTypes.BINARY(MirTypes.ADD,
d3740 1
a3740 1
			 MirTypes.BINARY(MirTypes.SUB,
d4171 1
a4171 1
			     MirTypes.BINARY(MirTypes.SUB, reg_operand,
@


1.104.2.1
log
@branched from 1.104
@
text
@a6 5
 * Revision 1.104  1996/12/05  09:29:02  stephenb
 * [Bug #1832]
 * event_check_code: add a couple of nops to avoid load hazzards
 * on an R3000.
 *
@


1.104.1.1
log
@branched from 1.104
@
text
@a6 5
 * Revision 1.104  1996/12/05  09:29:02  stephenb
 * [Bug #1832]
 * event_check_code: add a couple of nops to avoid load hazzards
 * on an R3000.
 *
@


1.104.1.1.1.1
log
@branched from 1.104.1.1
@
text
@a6 3
 * Revision 1.104.1.1  1996/12/17  17:50:46  hope
 * branched from 1.104
 *
@


1.103
log
@[Bug #1728]
__integer becomes __int
@
text
@d7 4
d4114 1
d4120 1
@


1.103.2.1
log
@branched from 1.103
@
text
@a6 4
 * Revision 1.103  1996/11/06  11:11:08  matthew
 * [Bug #1728]
 * __integer becomes __int
 *
@


1.103.1.1
log
@branched from 1.103
@
text
@a6 4
 * Revision 1.103  1996/11/06  11:11:08  matthew
 * [Bug #1728]
 * __integer becomes __int
 *
@


1.103.1.1.1.1
log
@branched from 1.103.1.1
@
text
@a6 3
 * Revision 1.103.1.1  1996/11/14  12:53:17  hope
 * branched from 1.103
 *
@


1.103.1.1.1.2
log
@[Bug #1832]
event_check_code: add a couple of nops to avoid load hazzards
on an R3000.
@
text
@a6 3
 * Revision 1.103.1.1.1.1  1996/11/28  15:04:14  hope
 * branched from 1.103.1.1
 *
a4116 1
                           nop, (* See bug #1834 *)
a4121 1
                           nop,
@


1.102
log
@[Bug #1725]
Remove unsafe string operations introduced when String structure removed
@
text
@d7 4
d338 1
a338 1
require "../basis/__integer";
@


1.101
log
@Remove basis.toplevel
@
text
@d7 3
a505 15
  (* copyStr : duplicates element N times *)
  fun copyStr (n:int) (c:char) : string = 
    let
      val alloc_s = MLWorks.Internal.Value.alloc_string (n+1)
      val _ = MLWorks.Internal.Value.unsafe_string_update (alloc_s, n, 0);
      fun scan (i:int) : string= 
	if i < n then
	  (MLWorks.Internal.Value.unsafe_string_update (alloc_s, i, ord c);
	   scan (i+1))
	else
	  alloc_s
    in
      scan 0
    end (* copyStr *)
      
d4815 6
d4823 2
a4824 4
	    let val s = procedure_name ^ String.str #"\000"
	    in
	      s ^ (copyStr ((4-((size s) mod 4)) mod 4) #"\000")
	    end
@


1.100
log
@Adding restore_fps in tail call code
@
text
@d1 329
a329 1
(* Copyright (c) 1993 Harlequin Ltd. *)
a332 1
require "../basis/toplevel";
a5176 325


(************************************************************************** 
 * Revison Log
 * $Log: _mach_cg.sml,v $
 * Revision 1.99  1996/08/16  17:57:49  io
 * basify mach_cg
 *
 * Revision 1.98  1996/08/08  16:58:40  jont
 * [bug 1535]
 * Ensure spill references are faulted if no stack specified
 *
 * Revision 1.97  1996/08/01  16:40:33  jont
 * Problems with parameters to set_proc_data being wrong order
 *
 * Revision 1.96  1996/08/01  12:59:07  jont
 * [Bug #1503]
 * Add field to FUNINFO to say if arg actually saved
 *
 * Revision 1.95  1996/05/30  12:43:18  daveb
 * The Ord exception is no longer at top level.
 *
 * Revision 1.94  1996/05/17  09:41:03  matthew
 * Moving Bits to Internal
 *
 * Revision 1.93  1996/05/14  10:41:14  matthew
 * Adding NOT32 MIR instruction
 *
 * Revision 1.92  1996/05/08  14:32:24  matthew
 * Fixing problem with untagged arithmetic.
 *
 * Revision 1.91  1996/05/07  16:54:14  jont
 * Array moving to MLWorks.Array
 *
 * Revision 1.90  1996/05/01  12:07:50  jont
 * String functions explode, implode, chr and ord now only available from String
 * io functions and types
 * instream, oustream, open_in, open_out, close_in, close_out, input, output and end_of_stream
 * now only available from MLWorks.IO
 *
 * Revision 1.89  1996/04/29  14:51:39  matthew
 * Removing checks for validity of FP results
 *
 * Revision 1.88  1996/03/28  18:16:14  jont
 * Fixing looping problems generating ADDW rn, rn, rm
 *
 * Revision 1.87  1996/03/21  15:22:25  matthew
 * Fixing problem with immediate shifts
 *
 * Revision 1.86  1996/02/05  11:38:32  jont
 * Add implemetations of ADDW and SUBW
 * These are like ADDV and SUBV, except that
 * they cannot use exception trapping adds etc because they are untagged
 * and also when they detect overflow they must clean
 * all registers involved in the operation
 *
 * Revision 1.85  1996/01/30  14:26:59  jont
 * Ensure that stack frame sizes are always double word aligned
 * 
 * Revision 1.84  1996/01/29  18:12:43  jont
 * Fix bug in polymorphic equality sequence by decrementing instead
 * 
 * Revision 1.83  1995/12/22  13:26:43  jont
 * Add extra field to procedure_parameters to contain old (pre register allocation)
 * spill sizes. This is for the i386, where spill assignment is done in the backend
 * 
 * Revision 1.82  1995/11/22  10:56:12  jont
 * Tidy up some missing constructors in BINARY code generation
 * 
 * Revision 1.81  1995/11/21  15:53:53  jont
 * Fix bugs in xor (and others) with immediate negative constants
 * 
 * Revision 1.80  1995/11/21  12:05:32  jont
 * Modification for improved runtime env spill offsets
 * to indicate the kind of data spilled
 * 
 * Revision 1.79  1995/09/22  15:59:50  jont
 * Fix bug in compiler crash when number of fp spill slots exceeded
 * 
 * Revision 1.78  1995/09/15  13:49:34  io
 * fix MirTypes.TEST from overflowing ~1 on unsigned operations.
 * 
 * Revision 1.77  1995/09/08  16:31:48  jont
 * Add a fixed branch type which can't be expanded beyond the 16 bit limit
 * This can be used to detect disastrous code generation in computed gotos
 * If this ever occurs, we can then fix the bug
 * 
 * Revision 1.76  1995/09/08  13:30:20  io
 * ambiguity between const0 and reg0 in TEST
 * 
 * Revision 1.75  1995/08/18  13:32:43  io
 * used slt/sltu in TEST, fixed bug introduced in BTA&BNT
 * sorted out overflow
 * 
 * Revision 1.74  1995/08/10  16:00:10  io
 * implement jon's suggestion with imm32 cases in test and unsigned const comparisons
 * 
 * Revision 1.73  1995/08/09  20:03:22  io
 * fix large imm problem, update mirtypes.test for unsigned code, shortcuts
 * [eg [<u lhs zero] -> bnez lhs, optimize zero_reg tests
 * 
 * Revision 1.72  1995/07/28  15:14:10  io
 * emit for BLO case (incomplete stub so that compiler can bootstrap)
 * 
 * Revision 1.71  1995/07/25  15:50:23  jont
 * Add WORD to value_cg
 * 
 * Revision 1.70  1995/07/19  14:22:18  jont
 * Add CHAR to value_cg
 * 
 * Revision 1.69  1995/07/10  15:57:19  jont
 * Fix code generation problems with shifts
 * 
 * Revision 1.68  1995/06/20  12:49:48  matthew
 * Fixing problem with not restoring fp registers
 * 
 * Revision 1.67  1995/06/19  16:19:37  jont
 * Fix missing case in store floating point value
 * 
 * Revision 1.66  1995/06/15  15:03:09  jont
 * Remove message about restarting linearise_sub
 * 
 * Revision 1.65  1995/05/31  15:21:37  nickb
 * Rewrote the allocation code to get ml_gc_leaf to work.
 * Also tidied it up, and added a bunch of shorthand
 * names for registers &c.
 * 
 * Revision 1.64  1995/05/09  15:39:29  nickb
 * Change stack overflow entry code; using fp as a temporary breaks
 * the profiler.
 * 
 * Revision 1.63  1995/05/04  14:41:52  matthew
 * Partially fixing "restarting linearize_sub .." problem
 * 
 * Revision 1.62  1995/05/02  15:31:39  matthew
 * Removing step and polyvariable options
 * 
 * Revision 1.61  1995/04/27  15:59:26  nickb
 * Move the debugging argument save.
 * Plus a few general tidying changes.
 * 
 * Revision 1.60  1995/04/20  10:52:30  nickb
 * Rearrange tail call instructions to make life easier for the profiler.
 * 
 * Revision 1.59  1995/04/12  14:57:07  nickb
 * Turn on MIPS R4000 v 2.2 bug work-around
 * 
 * Revision 1.58  1995/03/20  12:37:49  matthew
 * Disabling generation of "debugging" code
 * 
 * Revision 1.57  1995/03/07  16:17:48  matthew
 * Fixing debugger stuff
 * 
 * Revision 1.56  1995/03/01  17:20:21  matthew
 * Changes to Options structure/
 * 
 * Revision 1.55  1995/02/02  15:27:08  nickb
 * Make arithmetic operations trap.
 * Also reduce code verbosity by adding some local names for things.
 * 
 * Revision 1.54  1995/01/30  14:54:25  matthew
 * Debugger changes
 * 
 * Revision 1.53  1995/01/10  18:06:51  nickb
 * Make the test for stack overflow unsigned so it catches the asynch events.
 * 
 * Revision 1.52  1995/01/10  14:09:27  nickb
 * Add support for INTERRUPT.
 * Also extend INTERCEPT code.
 * Also allow functions which raise, or call real() or floor(), to be leaf.
 * 
 * Revision 1.51  1994/12/09  12:00:14  nickb
 * Fix implicit entry points.
 * 
 * Revision 1.50  1994/11/28  16:43:10  matthew
 * Fix for bytearray allocation length problem.
 * Changed real number unrepresentable message
 * 
 * Revision 1.49  1994/11/25  17:59:46  nickb
 * Stack extension / function entry code changes.
 * 
 * Revision 1.48  1994/11/24  14:44:35  matthew
 * Added code for ALLOC_VECTOR
 * Fixed problem with loop in initStackSlots
 * 
 * Revision 1.47  1994/11/22  17:08:52  io
 * updating floor,
 * updating MirTypes.TEST for constant operands
 * 
 * Revision 1.46  1994/11/16  12:28:31  jont
 * Add support for immediate store operation
 * 
 * Revision 1.45  1994/11/15  12:14:50  matthew
 * Some changes for scheduling
 * Added elim_simple_branches functions
 * 
 * Revision 1.44  1994/11/09  16:33:57  io
 * making stack initialisation shorter
 * 
 * Revision 1.43  1994/11/08  19:22:30  io
 * rewriting real
 * 
 * Revision 1.42  1994/11/02  12:37:27  matthew
 * Fixed problems with loading immediates:
 * use ADDUI for -2**15 .. 2**15-1
 * use ORI for 2**15 ..2**16-1
 * use LUI & ORI for other immediates
 * Fixed order of loading halves of double floats --
 * this may be endianness specific
 * Moved scheduling phase to during linearization.
 * Changed jumps in ALLOCATE to be to labels rather than by
 * fixed amounts.  This was confusing the scheduler.
 * Added removal of unreachable blocks before linearization.
 * 
 * Revision 1.41  1994/10/24  14:21:57  matthew
 * Various things:
 * Fixed problems with pc-relative long branches
 * Rationalized some of the code comments
 * Reformatted a little
 * Commented out the "append_small_exit" part
 * 
 * Revision 1.40  1994/10/05  13:42:27  jont
 * Changes for new NEW_HANDLER instruction
 * 
 * Revision 1.39  1994/09/23  13:00:18  matthew
 * Abstraction of debug information
 * 
 * Revision 1.38  1994/08/25  13:39:49  matthew
 * Changes to PROC_PARAMS
 * 
 * Revision 1.37  1994/08/25  10:41:10  jont
 * Remove dependence on mir optimiser for fp registers used
 * Remove dependence on mir optimiser for gc registers used as well
 * 
 * Revision 1.36  1994/07/28  16:27:52  jont
 * Use non-exception detecting arithmetic for the present
 * 
 * Revision 1.35  1994/07/27  16:15:48  jont
 * Fix loading of large tagged integers
 * 
 * Revision 1.34  1994/07/25  14:17:17  matthew
 * Added register lists to BRANCH_AND_LINK, TAIL_CALL and ENTER instructions.
 * 
 * Revision 1.33  1994/07/22  13:29:45  jont
 * Modifications to include number of callee saves in wordsets
 * Fixed bugs in BIC, NOT and array length calculations
 * 
 * Revision 1.32  1994/07/15  16:30:07  jont
 * Fix alignment and size calculation for arrays and bytearrays
 * 
 * Revision 1.31  1994/07/15  14:22:18  io
 * fixed rest of ALLOCATE
 * 
 * Revision 1.30  1994/07/15  13:11:33  jont
 * Fix restore fp not allowed in delay slot for the second time
 * 
 * Revision 1.29  1994/07/14  12:28:14  jont
 * Fix problem with load_large_IMM_ANY_into_register
 * 
 * Revision 1.28  1994/07/14  10:12:36  io
 * unifying jon's changes & revising ALLOCATE.
 * 
 * Revision 1.25  1994/07/07  14:08:36  io
 * cleared up redundant match patterns
 * 
 * Revision 1.24  1994/07/07  13:12:39  io
 * revised changes
 * 
 * Revision 1.23  1994/06/24  14:17:43  jont
 * Update debugger information production
 * 
 * Revision 1.22  1994/06/16  18:36:03  sml
 * Blotched checkin: redoing again
 * 
 * Revision 1.21  1994/06/16  18:11:55  io
 * Blotched checkin: redoing
 * 
 * Revision 1.20  1994/06/16  15:27:54  io
 * add new ENTER conventions
 * 
 * Revision 1.19  1994/06/14  12:59:11  io
 * cleaning up caller_arg and callee_arg
 * 
 * Revision 1.18  1994/06/13  12:13:29  io
 * added path change to accomodate new runtime structure
 * 
 * Revision 1.14  1994/03/18  18:18:42  jont
 * Rationalise stack layout information
 * Fix bug whereby spills were written in the wrong place
 * Fix bug whereby gc initialisation was starting and finishing too low
 * 
 * Revision 1.13  1994/03/11  16:21:06  jont
 * Fix code generation of LEO for mutually recursive function case
 * 
 * Revision 1.12  1994/03/10  12:53:19  jont
 * Added code generation of load_offset.
 * Added handling of case where load_offset can't be one instruction
 * similar to case where adr expands to more than one
 * 
 * Revision 1.11  1994/03/09  10:39:27  jont
 * Moved module types to separate file (code_module)
 * Fixed out of range branches and calls when compiling large functions
 * Recoded switch statements for semantic integrity
 * and to avoid long branch problems
 * 
 * Revision 1.10  1994/03/04  12:40:46  jont
 * Moved machpsec from mips to main
 * Fixed problem where store offset zero was returned as register 0
 * 
 * Revision 1.9  1994/03/04  11:08:24  jont
 * Fixing some store instruction problems
 * 
 * Revision 1.8  1994/03/01  17:56:52  jont
 * Bring into line with debugger changes
 * 
 * Revision 1.5  1994/02/23  18:10:11  jont
 * Updates to entry sequence
 * 
 * Revision 1.3  1993/12/20  14:53:36  io
 * minor path change
 * 
 * Revision 1.2  1993/11/17  13:42:01  io
 * Deleted old SPARC comments and fixed type errors
 * 
 *)
@


1.100.2.1
log
@branched from 1.100
@
text
@a4854 3
 * Revision 1.100  1996/09/27  12:33:59  matthew
 * Adding restore_fps in tail call code
 *
@


1.100.1.1
log
@branched from 1.100
@
text
@a4854 3
 * Revision 1.100  1996/09/27  12:33:59  matthew
 * Adding restore_fps in tail call code
 *
@


1.99
log
@basify mach_cg
@
text
@d3391 2
a3392 1
			 restore_gcs @@
d4855 3
@


1.99.1.1
log
@branched from 1.99
@
text
@a4853 3
 * Revision 1.99  1996/08/16  17:57:49  io
 * basify mach_cg
 *
@


1.98
log
@[bug 1535]
Ensure spill references are faulted if no stack specified
@
text
@d1 1
a1 319
(*
 Copyright (c) 1993 Harlequin Ltd.
 
 Revison Log
 -----------
 $Log: _mach_cg.sml,v $
 * Revision 1.97  1996/08/01  16:40:33  jont
 * Problems with parameters to set_proc_data being wrong order
 *
 * Revision 1.96  1996/08/01  12:59:07  jont
 * [Bug #1503]
 * Add field to FUNINFO to say if arg actually saved
 *
 * Revision 1.95  1996/05/30  12:43:18  daveb
 * The Ord exception is no longer at top level.
 *
 * Revision 1.94  1996/05/17  09:41:03  matthew
 * Moving Bits to Internal
 *
 * Revision 1.93  1996/05/14  10:41:14  matthew
 * Adding NOT32 MIR instruction
 *
 * Revision 1.92  1996/05/08  14:32:24  matthew
 * Fixing problem with untagged arithmetic.
 *
 * Revision 1.91  1996/05/07  16:54:14  jont
 * Array moving to MLWorks.Array
 *
 * Revision 1.90  1996/05/01  12:07:50  jont
 * String functions explode, implode, chr and ord now only available from String
 * io functions and types
 * instream, oustream, open_in, open_out, close_in, close_out, input, output and end_of_stream
 * now only available from MLWorks.IO
 *
 * Revision 1.89  1996/04/29  14:51:39  matthew
 * Removing checks for validity of FP results
 *
 * Revision 1.88  1996/03/28  18:16:14  jont
 * Fixing looping problems generating ADDW rn, rn, rm
 *
 * Revision 1.87  1996/03/21  15:22:25  matthew
 * Fixing problem with immediate shifts
 *
 * Revision 1.86  1996/02/05  11:38:32  jont
 * Add implemetations of ADDW and SUBW
 * These are like ADDV and SUBV, except that
 * they cannot use exception trapping adds etc because they are untagged
 * and also when they detect overflow they must clean
 * all registers involved in the operation
 *
Revision 1.85  1996/01/30  14:26:59  jont
Ensure that stack frame sizes are always double word aligned

Revision 1.84  1996/01/29  18:12:43  jont
Fix bug in polymorphic equality sequence by decrementing instead

Revision 1.83  1995/12/22  13:26:43  jont
Add extra field to procedure_parameters to contain old (pre register allocation)
spill sizes. This is for the i386, where spill assignment is done in the backend

Revision 1.82  1995/11/22  10:56:12  jont
Tidy up some missing constructors in BINARY code generation

Revision 1.81  1995/11/21  15:53:53  jont
Fix bugs in xor (and others) with immediate negative constants

Revision 1.80  1995/11/21  12:05:32  jont
Modification for improved runtime env spill offsets
to indicate the kind of data spilled

Revision 1.79  1995/09/22  15:59:50  jont
Fix bug in compiler crash when number of fp spill slots exceeded

Revision 1.78  1995/09/15  13:49:34  io
fix MirTypes.TEST from overflowing ~1 on unsigned operations.

Revision 1.77  1995/09/08  16:31:48  jont
Add a fixed branch type which can't be expanded beyond the 16 bit limit
This can be used to detect disastrous code generation in computed gotos
If this ever occurs, we can then fix the bug

Revision 1.76  1995/09/08  13:30:20  io
ambiguity between const0 and reg0 in TEST

Revision 1.75  1995/08/18  13:32:43  io
used slt/sltu in TEST, fixed bug introduced in BTA&BNT
sorted out overflow

Revision 1.74  1995/08/10  16:00:10  io
implement jon's suggestion with imm32 cases in test and unsigned const comparisons

Revision 1.73  1995/08/09  20:03:22  io
fix large imm problem, update mirtypes.test for unsigned code, shortcuts
[eg [<u lhs zero] -> bnez lhs, optimize zero_reg tests

Revision 1.72  1995/07/28  15:14:10  io
emit for BLO case (incomplete stub so that compiler can bootstrap)

Revision 1.71  1995/07/25  15:50:23  jont
Add WORD to value_cg

Revision 1.70  1995/07/19  14:22:18  jont
Add CHAR to value_cg

Revision 1.69  1995/07/10  15:57:19  jont
Fix code generation problems with shifts

Revision 1.68  1995/06/20  12:49:48  matthew
Fixing problem with not restoring fp registers

Revision 1.67  1995/06/19  16:19:37  jont
Fix missing case in store floating point value

Revision 1.66  1995/06/15  15:03:09  jont
Remove message about restarting linearise_sub

Revision 1.65  1995/05/31  15:21:37  nickb
Rewrote the allocation code to get ml_gc_leaf to work.
Also tidied it up, and added a bunch of shorthand
names for registers &c.

Revision 1.64  1995/05/09  15:39:29  nickb
Change stack overflow entry code; using fp as a temporary breaks
the profiler.

Revision 1.63  1995/05/04  14:41:52  matthew
Partially fixing "restarting linearize_sub .." problem

Revision 1.62  1995/05/02  15:31:39  matthew
Removing step and polyvariable options

Revision 1.61  1995/04/27  15:59:26  nickb
Move the debugging argument save.
Plus a few general tidying changes.

Revision 1.60  1995/04/20  10:52:30  nickb
Rearrange tail call instructions to make life easier for the profiler.

Revision 1.59  1995/04/12  14:57:07  nickb
Turn on MIPS R4000 v 2.2 bug work-around

Revision 1.58  1995/03/20  12:37:49  matthew
Disabling generation of "debugging" code

Revision 1.57  1995/03/07  16:17:48  matthew
Fixing debugger stuff

Revision 1.56  1995/03/01  17:20:21  matthew
Changes to Options structure/

Revision 1.55  1995/02/02  15:27:08  nickb
Make arithmetic operations trap.
Also reduce code verbosity by adding some local names for things.

Revision 1.54  1995/01/30  14:54:25  matthew
Debugger changes

Revision 1.53  1995/01/10  18:06:51  nickb
Make the test for stack overflow unsigned so it catches the asynch events.

Revision 1.52  1995/01/10  14:09:27  nickb
Add support for INTERRUPT.
Also extend INTERCEPT code.
Also allow functions which raise, or call real() or floor(), to be leaf.

Revision 1.51  1994/12/09  12:00:14  nickb
Fix implicit entry points.

Revision 1.50  1994/11/28  16:43:10  matthew
Fix for bytearray allocation length problem.
Changed real number unrepresentable message

Revision 1.49  1994/11/25  17:59:46  nickb
Stack extension / function entry code changes.

Revision 1.48  1994/11/24  14:44:35  matthew
Added code for ALLOC_VECTOR
Fixed problem with loop in initStackSlots

Revision 1.47  1994/11/22  17:08:52  io
updating floor,
updating MirTypes.TEST for constant operands

Revision 1.46  1994/11/16  12:28:31  jont
Add support for immediate store operation

Revision 1.45  1994/11/15  12:14:50  matthew
Some changes for scheduling
Added elim_simple_branches functions

Revision 1.44  1994/11/09  16:33:57  io
making stack initialisation shorter

Revision 1.43  1994/11/08  19:22:30  io
rewriting real

Revision 1.42  1994/11/02  12:37:27  matthew
Fixed problems with loading immediates:
 use ADDUI for -2**15 .. 2**15-1
 use ORI for 2**15 ..2**16-1
 use LUI & ORI for other immediates
Fixed order of loading halves of double floats --
  this may be endianness specific
Moved scheduling phase to during linearization.
Changed jumps in ALLOCATE to be to labels rather than by
fixed amounts.  This was confusing the scheduler.
Added removal of unreachable blocks before linearization.

Revision 1.41  1994/10/24  14:21:57  matthew
Various things:
Fixed problems with pc-relative long branches
Rationalized some of the code comments
Reformatted a little
Commented out the "append_small_exit" part

Revision 1.40  1994/10/05  13:42:27  jont
Changes for new NEW_HANDLER instruction

Revision 1.39  1994/09/23  13:00:18  matthew
Abstraction of debug information

Revision 1.38  1994/08/25  13:39:49  matthew
Changes to PROC_PARAMS

Revision 1.37  1994/08/25  10:41:10  jont
Remove dependence on mir optimiser for fp registers used
Remove dependence on mir optimiser for gc registers used as well

Revision 1.36  1994/07/28  16:27:52  jont
Use non-exception detecting arithmetic for the present

Revision 1.35  1994/07/27  16:15:48  jont
Fix loading of large tagged integers

Revision 1.34  1994/07/25  14:17:17  matthew
Added register lists to BRANCH_AND_LINK, TAIL_CALL and ENTER instructions.

Revision 1.33  1994/07/22  13:29:45  jont
Modifications to include number of callee saves in wordsets
Fixed bugs in BIC, NOT and array length calculations

Revision 1.32  1994/07/15  16:30:07  jont
Fix alignment and size calculation for arrays and bytearrays

Revision 1.31  1994/07/15  14:22:18  io
fixed rest of ALLOCATE

Revision 1.30  1994/07/15  13:11:33  jont
Fix restore fp not allowed in delay slot for the second time

Revision 1.29  1994/07/14  12:28:14  jont
Fix problem with load_large_IMM_ANY_into_register

Revision 1.28  1994/07/14  10:12:36  io
unifying jon's changes & revising ALLOCATE.

Revision 1.25  1994/07/07  14:08:36  io
cleared up redundant match patterns

Revision 1.24  1994/07/07  13:12:39  io
revised changes

Revision 1.23  1994/06/24  14:17:43  jont
Update debugger information production

Revision 1.22  1994/06/16  18:36:03  sml
Blotched checkin: redoing again

Revision 1.21  1994/06/16  18:11:55  io
Blotched checkin: redoing

Revision 1.20  1994/06/16  15:27:54  io
add new ENTER conventions

Revision 1.19  1994/06/14  12:59:11  io
cleaning up caller_arg and callee_arg

Revision 1.18  1994/06/13  12:13:29  io
added path change to accomodate new runtime structure

Revision 1.14  1994/03/18  18:18:42  jont
Rationalise stack layout information
Fix bug whereby spills were written in the wrong place
Fix bug whereby gc initialisation was starting and finishing too low

Revision 1.13  1994/03/11  16:21:06  jont
Fix code generation of LEO for mutually recursive function case

Revision 1.12  1994/03/10  12:53:19  jont
Added code generation of load_offset.
Added handling of case where load_offset can't be one instruction
similar to case where adr expands to more than one

Revision 1.11  1994/03/09  10:39:27  jont
Moved module types to separate file (code_module)
Fixed out of range branches and calls when compiling large functions
Recoded switch statements for semantic integrity
and to avoid long branch problems

Revision 1.10  1994/03/04  12:40:46  jont
Moved machpsec from mips to main
Fixed problem where store offset zero was returned as register 0

Revision 1.9  1994/03/04  11:08:24  jont
Fixing some store instruction problems

Revision 1.8  1994/03/01  17:56:52  jont
Bring into line with debugger changes

Revision 1.5  1994/02/23  18:10:11  jont
Updates to entry sequence

Revision 1.3  1993/12/20  14:53:36  io
minor path change

 Revision 1.2  1993/11/17  13:42:01  io
 Deleted old SPARC comments and fixed type errors

 *)
d4 6
a9 1

a11 1
require "../utils/lists";
a27 1

a74 1
  val makestring = Int.toString
d77 8
a84 5
  val trace_dummy_instructions =
    [(Mips_Assembly.other_nop_code,MLWorks.Option.NONE,"Tracing nop"),
     (Mips_Assembly.other_nop_code,MLWorks.Option.NONE,"Tracing nop"),
     (Mips_Assembly.other_nop_code,MLWorks.Option.NONE,"Tracing nop"),
     (Mips_Assembly.other_nop_code,MLWorks.Option.NONE,"Tracing nop")]
a123 13
  (* contract_sexpr: flattens a user defined list of lists *)
  local 
    fun contract_sexpr(Sexpr.NIL, [], acc) =
      Lists.reducel (fn (x, y) => y @@ x) ([], acc)
      | contract_sexpr(Sexpr.NIL, x :: xs, acc) = contract_sexpr(x, xs, acc)
      | contract_sexpr(Sexpr.ATOM x, to_do, acc) =
	contract_sexpr(Sexpr.NIL, to_do, x :: acc)
      | contract_sexpr(Sexpr.CONS(x, y), to_do, acc) =
	contract_sexpr(x, y :: to_do, acc)
  in
    val contract_sexpr = fn x => contract_sexpr(x, [], [])
  end (* local *)

d149 1
a149 1
		 makestring i,
d151 1
a151 1
		 makestring pos_limit]);
d162 1
a162 1
  val absent = MLWorks.Option.NONE
a163 11
  (* checkAList: checks for properties in all elements of a list *)
  fun checkAList f e l = let
    fun checkList [] = e
      | checkList (x::xs) = f x andalso checkList xs
  in 
    checkList l 
  end (* checkAList *)

  (* curry: call tuple requesting functions *)
  fun curry f a b = f (a,b)

d176 15
d227 1
a227 1
  fun binary_list_to_string(done, [], _, 128) = MLWorks.String.implode(rev done)
d230 1
a230 1
		       makestring l)
d232 1
a232 2
      let
	val x = MLWorks.String.ord x - MLWorks.String.ord "0"
d235 1
a235 1
	  binary_list_to_string(MLWorks.String.chr(digit + x) :: done, xs, 0, 128)
d240 1
d242 1
a242 1
  fun to_binary(digits, value) =
d245 1
a245 1
	| to_sub(digs_to_go, value, done) =
d247 1
a247 1
	    val digit = MLWorks.String.chr(value mod 2 + MLWorks.String.ord"0")
d258 1
a258 1
    fun mantissa_is_zero mantissa = checkAList ((curry op=) "0") true (MLWorks.String.explode mantissa)
d274 1
a274 1
	    if exponent < ~bits then (MLWorks.String.implode(copy bits "0"), 0)
d276 1
a276 1
	      (MLWorks.String.implode(copy (abs exponent) "0") ^ mantissa, 0)
d283 3
a285 2
      val binary_list =
	(if sign then "1" else "0") ::
d287 1
a287 1
	   MLWorks.String.explode(MLWorks.String.substring(mantissa, 1, 23))
d297 1
a297 1
	(if sign then "1" else "0") ::
d299 1
a299 1
	   MLWorks.String.explode(MLWorks.String.substring(mantissa, 1, 52))
d310 1
a310 1
	(if sign then "1" else "0") ::
d312 3
a314 3
	   copy 16 "0" @@
	   MLWorks.String.explode(MLWorks.String.substring(mantissa, 0, 64)) @@
	   copy 32 "0"
d354 1
a354 1
	  ((_, MLWorks.Option.SOME tag, _), true) => (tag, true)
a363 1
  (* rev_app is (rev xs) @@ ys *)
d459 2
a460 6
		       val (tag, _) = Lists.findp
			 (fn (x, _) =>
			  case tag_tree_map x of
			    MLWorks.Option.NONE => true
			  | _ => false)
			 continuers
d465 2
a466 2
		     end) handle Lists.Find =>
		       (Lists.hd continuers, Lists.tl continuers)
d495 1
a495 1
	      MLWorks.Option.SOME(_, t) => t
d513 1
a513 1
      tag_offsets(rest, disp + 4 * (Lists.length ho_list),
d531 1
a531 1
  exception BadOffset of MirTypes.tag * (Mips_Assembly.opcode * MirTypes.tag MLWorks.Option.option * string) list
d562 1
a562 1
        (fn _ => (print_scheduled_code (Lists.zip(new_code_list',procedure_name_list)); []))
d608 1
a608 1
		     :: (Mips_Assembly.nop_code, MLWorks.Option.NONE, "doubleword aligned branch follows") 
d641 1
a641 1
	     (fn (x, y) => Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ makestring y ^ "\n"))
d664 2
a665 25
	  fun drop(n, the_list) =
	    if n < 0 then
	      Crash.impossible"drop negative arg"
	    else
	      if n = 0 then the_list
	      else
		case the_list of
		  [] => Crash.impossible"drop bad list"
		| _ :: rest => drop(n-1, rest)

	  (* take: should there be impossible checks? *)
	  fun take(limit, xs) = 
	    let
	      fun take'(0, xs, acc) = acc
		| take'(_, [], acc) = acc
		| take'(limit, x::xs, acc) = take'(limit-1, xs, x::acc)
	    in
	      rev (take'(limit, xs, []))
	    end
	  fun take(0, _)  = []
	    | take(_, []) = []
	    | take(n, x::xs) = x :: take(n-1, xs)
	  (* easy to understand definition *)
	  fun copy_n( limit, xs, ys) = (take(limit, xs)) @@ ys
	  (* faster version? check for speed improvements  *)
d667 2
a668 4
	    if limit < 0 then
	      Crash.impossible "copy_n: neg limit"
	    else if limit > Lists.length xs then
	      Crash.impossible "copy_n: limit > length"
d671 3
a673 4
		fun copy_n'(0,         _, acc) = acc
		  | copy_n'(limit, x::xs, acc) = copy_n'(limit-1, xs, x::acc)
		  | copy_n'(_,     _,     _)   = Crash.impossible "warnings & mmaps hate each other"
		val acc = copy_n'(limit, xs, [])
d675 2
a676 2
		rev_app(acc, ys)
	      end
d691 1
a691 1
			      " with offset " ^ makestring offset ^
d697 1
a697 26
		  (* TL[BRANCH b r1 r2 imm tag offset] =>
		        | check_range(tag', true, branch_disp_limit) =
			     b r1 r2 tag'
			| otherwise = (* raise *)
			     | b == BA =
			          raise BadOffset block_tag (copy_n head_size opcode_list new_tail)
			     | b == BGEZAL =
			          raise BadOffset block_tag (copy_n head_size opcode_list  
				     ( bltz r1 r2 7 'short inverted branch to skip over long jump' : new_tail)) 
			     | b == BLTZAL =
			          raise BadOffset block_tag (copy_n head_size opcode_list 
				      ( bgtz r1 r2 7 'short inverted branch to skip over long jump' : new_tail))
		     where
		        tag' = (tag - offset) div 4 - 1
			head_size = (offset - block_start) div 4
			delay_instr : tail = drop (1 + head_size, opcode_list)
			
			new_tail = delay_instr : 
			   bgezal zero 1 'call .'
			   lui global imm tag
			   add_and_mask global (imm+4) global tag
			   add global lr global 
			   jr global 'jump to original destination'
			   nop
			   tail
		  *)
d699 1
a699 1
				 tag_opt as MLWorks.Option.SOME tag, comment), offset) =
d701 1
a701 1
                       MLWorks.Option.SOME res => 
d715 1
a715 1
					   makestring disp,
d736 1
a736 1
                                  MLWorks.Option.NONE,
d740 1
a740 1
                                  MLWorks.Option.SOME tag, new_comment) ::
d753 1
a753 1
				  MLWorks.Option.NONE, "jump to original destination") ::
d761 1
a761 1
				   r1, r2, 9), MLWorks.Option.NONE,
d769 1
a769 1
                     | MLWorks.Option.NONE =>
a770 6
		    (* TL[FBRANCH b i tag offset] =>
		          | fault_range("fbranch", ((tag - offset) div 4 - 1, true, branch_disp_limit) = b tag'
			  | otherwise =
			  where
			     tag' = (tag - offset) div 4 - 1
		     *)
d772 1
a772 1
				 tag_opt as MLWorks.Option.SOME tag, comment), offset) =
d774 1
a774 1
			 MLWorks.Option.SOME res => 
d784 1
a784 1
		       | MLWorks.Option.NONE =>
d787 1
a787 1
				 MLWorks.Option.SOME tag, comment), offset) =
d789 1
a789 1
			 MLWorks.Option.SOME res => 
d797 1
a797 1
		       | MLWorks.Option.NONE =>
d799 1
a799 27
		    (* TL[CALL call r1 imm tag comment offset] =>
		          | check_range(tag', true, branch_disp_limit) = 
			       bgezal r1 tag' comment
			  | otherwise = (* raise *)
			       | call == bgezal and r1 == r0 =
				    raise BadOffset block_tag (copy_n head_size opcode_list new_tail)
			       | call = BGEZAL =
				    raise BadOffset block_tag (copy_n head_size opcode_list
				       ( bltz r1 zero 7 'short inverted branch to skip over long jump' : new_tail))
			       | call == BLTZAL =
				    raise BadOffset block_tag (copy_n head_size opcode_list
				       ( bgtz r1 zero 7 'short inverted branch to skip over long jump' : new_tail))
		          where
			     tag' = (tag - offset) div 4 - 1
			     head_size = (offset - block_start) div 4
			     delay_instr : tail = drop (1 + head_size)  opcode_list
			     comment' = comment ^ " (expanded call)"
			     new_tail = 
			        delay_instr
				bgezal zero 1 'call .'
				lui global imm tag comment'
				add_and_mask global (imm+4) global tag comment'
				add global lr global comment'
				jr global 'jump to original destination'
				nop
				tail
		     *)
d801 1
a801 1
				 tag_opt as MLWorks.Option.SOME tag, comment), offset) =
d803 1
a803 1
			 MLWorks.Option.SOME res => 
d818 1
a818 1
					   makestring disp,
d834 1
a834 1
                                  MLWorks.Option.NONE,
d842 1
a842 1
                                  MLWorks.Option.SOME tag, new_comment) ::
d851 1
a851 1
				  MLWorks.Option.NONE, "jump and link to original destination") ::
d862 1
a862 1
				  MLWorks.Option.NONE, 
d870 1
a870 1
		       | MLWorks.Option.NONE => Crash.impossible "Assoc do_opcode call")
d872 1
a872 1
				 MLWorks.Option.SOME tag, comment), offset) =
d875 1
a875 1
			 MLWorks.Option.SOME res =>
d897 1
a897 1
				    MLWorks.Option.SOME tag, new_comment) ::
d900 1
a900 1
				    MLWorks.Option.SOME tag, new_comment) :: tail
d907 1
a907 1
		       | MLWorks.Option.NONE => Crash.impossible "Assoc do_opcode LEO")
d910 1
a910 1
				 MLWorks.Option.SOME tag, comment), offset) =
d912 1
a912 1
			 MLWorks.Option.SOME res =>
d936 1
a936 1
				    MLWorks.Option.SOME tag, new_comment) ::
d940 1
a940 1
				    MLWorks.Option.SOME tag, new_comment) ::
d950 1
a950 1
		       | MLWorks.Option.NONE =>
d956 1
a956 1
				 MLWorks.Option.SOME tag, comment), offset) =
d960 1
a960 1
			 MLWorks.Option.SOME res =>
d971 1
a971 1
		       | MLWorks.Option.NONE =>
d975 1
a975 1
				 MLWorks.Option.SOME tag, comment), _) =
d977 1
a977 1
			 MLWorks.Option.SOME res =>
d994 1
a994 1
		       | MLWorks.Option.NONE =>
d998 1
a998 1
				 MLWorks.Option.SOME tag, comment), offset) =
d1000 1
a1000 1
			 MLWorks.Option.SOME res => 
d1009 1
a1009 1
		       | MLWorks.Option.NONE =>
d1012 1
a1012 1
		    | do_opcode((Mips_Assembly.OFFSET i, MLWorks.Option.SOME tag, comment),
d1015 1
a1015 1
			 MLWorks.Option.SOME res => 
d1021 1
a1021 1
		       | MLWorks.Option.NONE =>
d1024 1
a1024 1
		    | do_opcode((opcode, MLWorks.Option.NONE, comment), offset) =
d1194 1
a1194 1

d1243 2
a1244 2
		     ("Spill slot " ^ makestring i ^
		      " requested, but only " ^ makestring gc_spill_size ^
d1273 2
a1274 2
		      ("non gc spill slot " ^ makestring i ^
		       " requested, but only " ^ makestring non_gc_spill_size ^
d1304 2
a1305 2
		       ("fp spill slot " ^ makestring i ^
			" requested, but only " ^ makestring fp_spill_size ^
d1384 1
a1384 1
                    absent, MachTypes.reg_to_string reg ^ " := " ^ makestring high ^ ", load upper half")]
d1388 2
a1389 2
                      MirTypes.GP_IMM_ANY x => "ANY(" ^ makestring x ^ ")"
                    | MirTypes.GP_IMM_INT x => "INT(" ^ makestring x ^ ")"
d1391 1
a1391 1
                        "SYMB(" ^ makestring(symbolic_value symb) ^ ")"
d1439 1
a1439 1
		    Mips_Assembly.IMM offset), MLWorks.Option.NONE,
d1445 1
a1445 1
		    Mips_Assembly.IMM (offset+4)), MLWorks.Option.NONE,
d1451 1
a1451 1
		    Mips_Assembly.IMM (offset)), MLWorks.Option.NONE,
d1462 1
a1462 1
		      Mips_Assembly.IMM offset), MLWorks.Option.NONE,
d1470 1
a1470 1
		      Mips_Assembly.IMM (offset+4)), MLWorks.Option.NONE,
d1476 1
a1476 1
		      Mips_Assembly.IMM (offset)), MLWorks.Option.NONE,
d1489 1
a1489 1
		MLWorks.Option.NONE, "save argument for debugging")]
d1494 1
a1494 1
		offset), MLWorks.Option.NONE,
d1501 1
a1501 1
		    offset), MLWorks.Option.NONE,
d1510 1
a1510 1
	    Lists.length gcs_to_preserve +
d1561 2
a1562 3

	  fun do_everything(_, tag, [], done, [], final_result) = (tag, contract_sexpr done) :: final_result
	  | do_everything
d1567 7
a1573 3
	    (needs_preserve, tag', Lists.filter_outp is_comment opcodes, Sexpr.NIL, blocks,
	     (tag, contract_sexpr done) :: final_result)
	  | do_everything
d1701 1
a1701 1
				  Lists.filterp
d1716 1
a1716 1
				val exn_tag_opt = MLWorks.Option.SOME exn_tag
d1802 1
a1802 1
					     MLWorks.Option.SOME second_test_tag
d1805 1
a1805 1
					     MLWorks.Option.SOME cont_tag
a1904 24
		(* T[BINARY op r1 r2 r3] =>
		      ????
		         | isReg r3' or gp_check_range(r3', true, arith_imm_limit) =
			      opcode r1 r2' reg_or_imm =
		         | otherwise = 
			      T[UNARY MOVE (GC_REG inter_reg) r3', BINARY op r1' r2' (GP_REG inter_reg)]
		      | otherwise = T[UNARY MOVE global gp_operand, BINARY binary_op reg_operand global gp_operand']
		      where
		         (r2', r3', redo)
			    | isReg r2 
			         | isReg r3'
				      | needs_reverse = (r2, r3, true)
				      | otherwise     = (r2, r3, false)
				 | otherwise = (r3, r2, false)
			    | otherwise = (r2, r3, false)
			  needs_reverse op
			     | SUB = true
			     | SRL = true
			     | SLL = true
			     | SRA = true
			     | otherwise = false
			  (op', r3'')
			     | op == ADD = (
		 *)
d2065 1
a2065 1
					     ([], new_opc :: Lists.tl opcode_list,
d2087 1
a2087 1
						Lists.tl opcode_list,
d2140 1
a2140 1
					       Lists.tl opcode_list,
d2221 1
a2221 1
					  MLWorks.Option.SOME bad_tag, ""),
d2228 1
a2228 1
				       MLWorks.Option.SOME cont_tag, ""),
d2273 1
a2273 1
				       Lists.tl opcode_list
a2447 7
		(* T[UNARY(MOVE r1 r2)] =>
		      | isReg r1 =
			   | r1 == r2 = []
			   | otherwise = or r1 r2 'put tagged value into reg'
		      | otherwise = 
			   load_imm_any_into_register r1 r2
		 *)
a2547 1
		  (* T[NULLARY CLEAN r1] => or r1 zero zero 'clean' *)
a2608 17
		(* T[TBINARY(op fp1 fp2 fp3)] =>
		         FBINARY TOP[op] fp1 fp2 fp3
		      where
		         TOP[op] =>
			   | fp_used == single
			        | FADD = ADD_S
				| FSUB = SUB_S
				| FMUL = MUL_S
				| FDIV = DIV_S
			   | fp_used == double
			        | FADD = ADD_D
				| FSUB = SUB_D
				| FMUL = MUL_D
				| FDIV = DIV_D
			   | fp_used == extended
			        _ = BANG!
		 *)
a2632 17
		(* T[TUNARYFP op fp1 fp2] => FUNARY TOP[op] fp1 fp2, post_moves
		      where
		         post_moves = unspecified so far
		         TOP[op] =>
			    | fp_used == single
			         | FSQRT = BANG!
				 | FMOVE = MOV_S
				 | FABS  = ABS_S
				 | FNEG  = NEG_S
			    | fp_used == double
			         | FSQRT = BANG!
				 | FMOVE = MOV_D
				 | FABS  = ABS_D
				 | FNEG  = NEG_S
			    | fp_used == extended
			         | _     = BANG!
		 *)
d2672 1
a2672 1
				   MLWorks.Option.SOME offset) =>
d2680 1
a2680 1
					 makestring offset ^
d2682 1
a2682 1
					 makestring
a2742 10
		(* T[STOREFPOP store_fp_op frd rs1 gp_operand] =>
		      | repeat =
			   | gp_op_is_large_gp_operand =
			        T[ADD global gp_operand]
			   | otherwise =
			        store frd rs1 imm ""
				store ((next o next) frd) ((next o next) rs1) imm' ""
		      | isReg gp_operand orelse gp_checkRange gp_operand =
		   INCOMPLETE REWRITE
		  *)
a2853 10
		(* T[REAL int_to_float fp1 gp1] =>
		      | isReg gp1 =
			   sra global gp1 2 "untag operand"
			   mtc1 global fp1  ""
			   nop
			   cvt.d.w fp1 fp1  "convert from fixed point format"
		      | otherwise =
			   T[ MOVE global gp1
			      REAL int_to_float fp1 global ]
		 *)
d3024 1
a3024 1
			 MLWorks.Option.SOME tag, "branch on overflow, unable to tag"),
d3031 1
a3031 1
			 MLWorks.Option.SOME tag, "branch on overflow, unable to tag"),
a3048 3
		(* T[BRANCH b r1] => JR r1 'branch indirect'
		  T[BRANCH b tag]=> BA tag, nop
		 *)
d3061 1
a3061 1
			  MLWorks.Option.SOME tag, "branch"),
d3091 1
a3091 1
			      MLWorks.Option.SOME zero_virtual => MirTypes.GP_GC_REG zero_virtual
d3202 1
a3202 1
				    MLWorks.Option.SOME tag, ""),
d3207 1
a3207 1
				   MLWorks.Option.SOME tag, ""),
d3258 1
a3258 1
				     MLWorks.Option.SOME tag, ""),
d3263 1
a3263 1
				     MLWorks.Option.SOME tag, ""),
d3334 1
a3334 1
				     MLWorks.Option.SOME tag, ""),
d3342 1
a3342 1
				     MLWorks.Option.SOME tag, ""),
d3366 1
a3366 1
		       MLWorks.Option.SOME tag, "Do the branch"),
a3369 7
		(* T[BRANCH_AND_LINK _ r1 debug] => 
		      addu global r1 CODE_OFFSET "address to jump to"
		      jalr lr global debug "call to tagged value"
		   T[BRANCH_AND_LINK _ tag _] => 
		       bgezal zero 0 tag "call' ???"
		       nop
		 *)
d3384 1
a3384 1
		      MLWorks.Option.SOME tag, "Call"),
a3387 29
		(* T[TAIL_CALL bl_dest] => case bl_dest of
                T[TAIL_CALL bl_dest] => case bl_dest of
                   | REG r =>
                        | leaf case =
                             addu   global         r      3
                             jr     global
                             nop
                        | otherwise =
                             restore_gcs
                             lw     lr             8(sp)
                             lw     callee_closure 4(sp)
                             move   sp             fp
                             addu   global         r      3
                             lw     fp             0(sp)
                             jr     global
                             nop
                | TAG t =>
                        | leaf case =
                             ba     tag
                             nop
                        | otherwise =
                             restore_gcs
                             lw     lr             8(sp)
                             lw     callee_closure 4(sp)
                             move   sp             fp
                             lw     fp             0(sp)
                             ba     tag
                             nop
		 *)
d3432 1
a3432 1
                           MLWorks.Option.SOME tag, "branch"),
a3436 42
		(* T[SWITCH computed_goto reg_operand tag_list] => 
		      | tag_list <= 2 =
			   do_tests
		      | not needs_preserve && reg_operand == global = 
			  BANG! "incorrect MIR SWITCH output"
		      | needs_preserve =
			   instrs
		      | otherwise =
			   BANG "unaccounted SWITCH case"
			   move_reg lr global
			   instrs
		      where
			do_tests = rev(do_test done tag_list)
			where 
			   do_test [] = []
			   do_test [tag] = 
			      nop "table entry padding"
			      ba annulled tag "do the branch"
			   do_test (tag : xs) =
			      nop "table entry padding"
			      beq global zero tag "comparison entry"
			      sub global reg 4 "do the test"
			      do_test xs
			instrs = 
			   bgezal zero 4 "call self"
			   addiu lr lr 16 "point lr to start of table"
			   addu global reg_operand reg_operand "forgot!"
			   addu lr lr global "calculate offset into table"
			   jr lr "jump to table offset"
			   nop
			   table
			table =
			   foldl (@@) [] 
			      (map (\t->
			         [ ba t "table entry",
				   nop "table entry padding"
				   ]) tag_list)
			    
			foldl f z [] = z
			foldl f z (x:xs) = foldl f (f z x) xs
		   *)

d3441 1
a3441 1
			if Lists.length tag_list <= 2 then 
d3448 1
a3448 1
				    MLWorks.Option.SOME tag, "branch to table entry")
d3455 1
a3455 1
					       MLWorks.Option.SOME tag, "")
d3489 1
a3489 1
			     MLWorks.Option.SOME t, "branch to table entry")
a3495 9
		(* T[ALLOCATE_STACK op r1 alloc_size  fp_offset_tag] =>
		      | alloc_size + fp_offset_tag > gc_stack_alloc_size = BANG!
		      | op == ALLOC =
			   T[SUB r1 (GP_GC_REG fp) (GP_IMM_ANY gc_stack_alloc_offset + 4*(fp_offset + alloc_size) - Tags.PAIRPTR)
		      | op == ALLOCATE_STACK = BANG!
		      | op == DEALLOCATE_STACK _ = []
		   T[ALLOCATE_STACK _] => BANG!
		      
		 *)
d3497 1
a3497 1
					  MLWorks.Option.SOME fp_offset) =>
d3499 1
a3499 1
		    Crash.impossible("Stack allocation of "^makestring alloc_size
d3501 1
a3501 1
				     ^makestring fp_offset
d3503 1
a3503 1
				     ^makestring gc_stack_alloc_size
a3518 1
		(* T[DEALLOCATE_STACK _ => [] *)
d3545 1
a3545 1
                          MLWorks.Option.SOME finish_tag, ""),
d3550 1
a3550 1
			 MLWorks.Option.SOME end_gc_tag, "")
d3558 1
a3558 1
			 MLWorks.Option.SOME end_gc_tag, "branch if no GC required")
a3740 7
		 (* T[ADR op r1 tag] => 
		       | op == LEA =
			    bgezal zero 1 'call self'
			    add r1 lr 4 tag 'udate gc pointer'
		       | op == LEO =
			    leo tag 'get offset of tag from procedure start'
		  *)
d3753 1
a3753 1
			      MLWorks.Option.SOME tag, "Update gc pointer")]
d3757 1
a3757 1
			      MLWorks.Option.SOME tag,
d3788 1
a3788 1
			    MLWorks.Option.SOME continue_tag,
d3805 1
a3805 1
			    MLWorks.Option.SOME continue_tag, "End of block"),
d3904 1
a3904 1
				  MLWorks.Option.SOME stackOKTag, "branch if OK"),
d3934 1
a3934 1
				  MLWorks.Option.SOME stackOKTag, "Do the branch"),
d3986 1
a3986 1
				MLWorks.Option.SOME endTag, "branch"),
d4022 1
a4022 1
				   MLWorks.Option.SOME loop_tag, ""),
d4040 1
a4040 1
				    MLWorks.Option.SOME loop_tag, "and loop"),
a4060 14
		(* T[RTS] =>
		      | needsPreserve =
			   restoreFps
			   restoreGcs
			   lw lr 8(sp) "restore lr"
			   lw callee 4(sp)
			   addu sp fp 0 "restore previous sp"
			   lw fp 0(sp) "restore fp not in delay slot"
			   jr lr init "return"
			   nop
		       | otherwise =
			   jr lr init "return"
			   nop
		 *)
d4066 1
a4066 1
			   MLWorks.Option.NONE, "restore lr"),
d4068 1
a4068 1
			   MLWorks.Option.NONE, ""),
d4071 1
a4071 1
			   MLWorks.Option.NONE, "restore fp not in delay slot"),
d4073 1
a4073 1
			  MLWorks.Option.NONE, "return"),
d4081 1
a4081 1
		(* T[NEW_HANDLER tag] => [] *)
d4089 1
a4089 1
		(* T[OLD_HANDLER] => lw handler handler ~1 'restore old handler', nop *)
a4097 9
		(* T[RAISE r1] =>
		      | needsPreserve =
			   lw global implicit 4*raise_code 'find handler'
		      | otherwise =
			   lw global implicit 4*leaf_raise_code 'find handler'
		      nop
		      jr global 'raise'
		      or caller r1  zero 'move arg to raise into arg reg'
		 *)
d4122 1
a4122 6
		(* T[CALL_C] =>
		      lw global implicit 4*external 'get address of callc'
		      nop
		      jalr lr global 'do call_c'
		      nop
		 *)
d4143 1
a4143 1
	  do_everything(needs_preserve, tag, Lists.filter_outp is_comment opcodes,
d4149 1
a4149 1
      fun exit_block [] = MLWorks.Option.NONE
d4151 1
a4151 1
	if Lists.exists
d4154 1
a4154 1
	  then MLWorks.Option.SOME block
d4172 1
a4172 1
	    if Lists.exists
d4220 2
a4221 2
	      MLWorks.Option.NONE => block_list
	    | MLWorks.Option.SOME exit_block =>
d4230 1
a4230 1
	      MLWorks.Option.NONE => MirTypes.FP.Map.define(map, fp, true)
d4233 1
a4233 1
	  fun get_fps_from_opcode(map, MirTypes.TBINARYFP(_, _, fp1, fp2, fp3)) =
d4235 1
a4235 1
	    | get_fps_from_opcode(map, MirTypes.TUNARYFP(_, _, fp1, fp2)) =
d4237 1
a4237 1
	    | get_fps_from_opcode(map, MirTypes.BINARYFP(_, fp1, fp2, fp3)) =
d4239 1
a4239 1
	    | get_fps_from_opcode(map, MirTypes.UNARYFP(_, fp1, fp2)) =
d4241 1
a4241 1
	    | get_fps_from_opcode(map, MirTypes.STOREFPOP(_, fp1, _, _)) =
d4243 1
a4243 1
	    | get_fps_from_opcode(map, MirTypes.REAL(_, fp1, _)) =
d4245 1
a4245 1
	    | get_fps_from_opcode(map, MirTypes.FLOOR(_, _, _, fp1)) =
d4247 1
a4247 1
	    | get_fps_from_opcode(map, MirTypes.FTEST(_, _, fp1, fp2)) =
d4249 1
a4249 1
	    | get_fps_from_opcode(map, _) = map
d4251 2
a4252 2
	  fun get_fps_from_block(map, MirTypes.BLOCK(_, instr_list)) =
	    Lists.reducel get_fps_from_opcode (map, instr_list)
d4254 1
a4254 1
	  val fp = MirTypes.FP.Map.domain(Lists.reducel get_fps_from_block (MirTypes.FP.Map.empty, block_list))
d4258 1
a4258 1
	       MLWorks.Option.NONE => MirTypes.GC.Map.define(map, r, true)
d4264 1
a4264 1
               MLWorks.Option.NONE => MirTypes.GC.Map.define(map, r, true)
d4271 1
a4271 1
	  fun get_gcs_from_opcode(map, MirTypes.TBINARY(_, _, rd, g1, g2)) =
d4273 1
a4273 1
	    | get_gcs_from_opcode(map, MirTypes.BINARY(_, rd, g1, g2)) =
d4275 1
a4275 1
	    | get_gcs_from_opcode(map, MirTypes.UNARY(_, rd, g)) =
d4277 1
a4277 1
	    | get_gcs_from_opcode(map, MirTypes.NULLARY(_, rd)) =
d4279 5
a4283 5
	    | get_gcs_from_opcode(map, MirTypes.TBINARYFP _) = map
	    | get_gcs_from_opcode(map, MirTypes.TUNARYFP _) = map
	    | get_gcs_from_opcode(map, MirTypes.BINARYFP _) = map
	    | get_gcs_from_opcode(map, MirTypes.UNARYFP _) = map
	    | get_gcs_from_opcode(map, MirTypes.STACKOP(_, rd, _)) =
d4285 1
a4285 1
	    | get_gcs_from_opcode(map, MirTypes.IMMSTOREOP _) =
d4287 1
a4287 1
	    | get_gcs_from_opcode(map, MirTypes.STOREOP(_, rd, rs, g)) =
d4289 1
a4289 1
	    | get_gcs_from_opcode(map, MirTypes.STOREFPOP(_, _, rs, g)) =
d4291 1
a4291 1
	    | get_gcs_from_opcode(map, MirTypes.REAL(_, _, g)) =
d4293 1
a4293 1
	    | get_gcs_from_opcode(map, MirTypes.FLOOR(_, _, rd, _)) =
d4295 1
a4295 1
	    | get_gcs_from_opcode(map, MirTypes.BRANCH(_, dest)) =
d4297 1
a4297 1
	    | get_gcs_from_opcode(map, MirTypes.TEST(_, _, g1, g2)) =
d4299 2
a4300 2
	    | get_gcs_from_opcode(map, MirTypes.FTEST _) = map
	    | get_gcs_from_opcode(map, MirTypes.BRANCH_AND_LINK(_, dest, _, _)) =
d4302 1
a4302 1
	    | get_gcs_from_opcode(map, MirTypes.TAIL_CALL(_, dest, _)) =
d4304 2
a4305 2
	    | get_gcs_from_opcode(map, MirTypes.CALL_C) = map
	    | get_gcs_from_opcode(map, MirTypes.SWITCH(_, rs, _)) =
d4307 1
a4307 1
	    | get_gcs_from_opcode(map, MirTypes.ALLOCATE(_, rd, g)) =
d4309 1
a4309 1
	    | get_gcs_from_opcode(map, MirTypes.ALLOCATE_STACK(_, rd, _, _)) =
d4311 2
a4312 2
	    | get_gcs_from_opcode(map, MirTypes.DEALLOCATE_STACK _) = map
	    | get_gcs_from_opcode(map, MirTypes.ADR(_, rd, _)) =
d4314 7
a4320 7
	    | get_gcs_from_opcode(map, MirTypes.INTERCEPT) = map
	    | get_gcs_from_opcode(map, MirTypes.INTERRUPT) = map
	    | get_gcs_from_opcode(map, MirTypes.ENTER _) = map
	    | get_gcs_from_opcode(map, MirTypes.RTS) = map
	    | get_gcs_from_opcode(map, MirTypes.NEW_HANDLER _) = map
	    | get_gcs_from_opcode(map, MirTypes.OLD_HANDLER) = map
	    | get_gcs_from_opcode(map, MirTypes.RAISE rd) =
d4322 1
a4322 1
	    | get_gcs_from_opcode(map, MirTypes.COMMENT _) = map
d4324 2
a4325 2
	  fun get_gcs_from_block(map, MirTypes.BLOCK(_, instr_list)) =
	    Lists.reducel get_gcs_from_opcode (map, instr_list)
d4328 1
a4328 1
	  val gc = MirTypes.GC.Map.domain(Lists.reducel get_gcs_from_block (MirTypes.GC.Map.empty, block_list))
d4335 1
a4335 1
	  val fp_save_size = Lists.length fps_to_preserve
d4369 1
a4369 1
	    Lists.exists check_instr instr_list
d4394 1
a4394 1
	      orelse Lists.exists check_instr_block block_list
d4425 1
a4425 1
	      MLWorks.Option.SOME{gc = gc_spill_size,
d4431 1
a4431 1
	    MLWorks.Option.SOME stack_extra => stack_extra
d4447 1
a4447 1
	    (Lists.filterp check_reg (Set.set_to_list gcs))
d4449 1
a4449 1
	  val callee_save_area = Lists.length callee_saves
d4497 1
a4497 12
	    Lists.reducel op +
	    (0, map (fn (_, opcodes) => Lists.length opcodes) code)

          val padded_name =
            let
              fun generate_nulls 0 = ""
                | generate_nulls n = MLWorks.String.chr(0) ^ generate_nulls (n-1)
              fun normalise_to_four_bytes (x) = 
                x ^ generate_nulls((4 - ((size x) mod 4)) mod 4)
            in
              normalise_to_four_bytes(procedure_name ^ MLWorks.String.chr(0))
            end
d4499 6
d4560 1
a4560 1
			    MLWorks.Option.SOME tag =>
d4562 1
a4562 1
			  | MLWorks.Option.NONE => " no tag") ^
d4592 1
a4592 1
                      (Lists.zip(code_list',procedure_name_list)) ;
d4612 1
a4612 1
                                                    (Lists.zip(code_list',procedure_name_list)) ;
d4633 1
a4633 1
				 MLWorks.Option.SOME tag =>
d4635 1
a4635 1
			       | MLWorks.Option.NONE => " no tag") ^
d4656 1
a4656 1
              fun get_branch_tag ([(Mips_Assembly.BRANCH (Mips_Assembly.BA,_,_,_),MLWorks.Option.SOME tag,_),
d4659 3
a4661 3
                  then MLWorks.Option.SOME tag
                else MLWorks.Option.NONE
                | get_branch_tag _ = MLWorks.Option.NONE
d4664 2
a4665 2
                Lists.reducel
                (fn (map,(tag,opcodes)) =>
d4667 1
a4667 1
                   MLWorks.Option.SOME tag' => Map.define (map,tag,tag')
d4669 1
a4669 1
                (Map.empty,blocklist)
d4676 1
a4676 1
                     MLWorks.Option.SOME tag' => lookup_branch (tag',n-1)
d4680 2
a4681 2
              fun scan (op1 as (Mips_Assembly.BRANCH b,MLWorks.Option.SOME tag,c) :: rest,acc) =
                  scan (rest, (Mips_Assembly.BRANCH b,MLWorks.Option.SOME (lookup_branch (tag,20)), c) :: acc)
d4692 2
a4693 5
            Lists.reducel
            (fn (acc,(opcode,MLWorks.Option.SOME t,_)) =>
             t :: acc
          | (acc,_) => acc)
            ([],opcode_list)
d4702 2
a4703 2
                if Lists.member (tag,!seen)
                  then ()
d4707 1
a4707 1
                     MLWorks.Option.SOME opcode_list =>
d4712 1
a4712 1
                         Lists.iterate scan (tags_from opcode_list)
d4717 2
a4718 6
                Lists.filterp
                (fn (tag,_) => 
                 case Map.tryApply' (!result,tag) of
                   MLWorks.Option.SOME _ => true
                 | _ => false)
                blocklist
d4753 3
a4755 3
                             if MLWorks.String.ordof(padded_name,to) = 0 
                               then check_index(to-1)
                             else MLWorks.String.substring(padded_name,0,to+1)
d4758 1
a4758 2
                           handle MLWorks.String.Substring => ""
                                | MLWorks.String.Ord => ""
d4776 1
a4776 1
                       then MLWorks.String.implode (annotation_points (code,0,[]))
d4778 1
a4778 1
                       MLWorks.String.implode
a4787 3
(*
		   val _ = MLWorks.IO.output(MLWorks.IO.std_out, "make_tagged_code: " ^ padded_name ^ "\n")
*)
d4791 1
a4791 1
	       (Lists.zip(linear_code,temp_code_list)))
d4804 1
a4804 1
	   Lists.zip(linear_code', procedure_name_list))
d4808 1
a4808 1
	Lists.unzip(map list_proc_cg proc_list_list)
d4814 2
a4815 2
	    Lists.reducel (fn (sofar,{d_code=y, ...}) =>
			   (size y) + sofar) (0,tagged_code')
d4817 1
a4817 1
	  fun f (sofar,e) = sofar + (sizeof_element e)
d4819 1
a4819 1
	  Lists.reducel f (0,proc_elements)
d4826 1
a4826 1
                   makestring (code_size proc_elements)  ^ "\n")
d4849 322
@


1.97
log
@Problems with parameters to set_proc_data being wrong order
@
text
@d7 3
d4956 12
d4977 6
d5419 3
@


1.96
log
@[Bug #1503]
Add field to FUNINFO to say if arg actually saved
@
text
@d7 4
d4998 1
a4999 1
                                                           not needs_preserve,
@


1.95
log
@The Ord exception is no longer at top level.
@
text
@d7 3
d4994 1
@


1.94
log
@Moving Bits to Internal
@
text
@d7 3
d539 1
a539 1
  fun binary_list_to_string(done, [], _, 128) = String.implode(rev done)
d545 1
a545 1
	val x = String.ord x - String.ord "0"
d548 1
a548 1
	  binary_list_to_string(String.chr(digit + x) :: done, xs, 0, 128)
d559 1
a559 1
	    val digit = String.chr(value mod 2 + String.ord"0")
d570 1
a570 1
    fun mantissa_is_zero mantissa = checkAList ((curry op=) "0") true (String.explode mantissa)
d586 1
a586 1
	    if exponent < ~bits then (String.implode(copy bits "0"), 0)
d588 1
a588 1
	      (String.implode(copy (abs exponent) "0") ^ mantissa, 0)
d598 1
a598 1
	   String.explode(String.substring(mantissa, 1, 23))
d610 1
a610 1
	   String.explode(String.substring(mantissa, 1, 52))
d624 1
a624 1
	   String.explode(String.substring(mantissa, 0, 64)) @@
d5092 1
a5092 1
                | generate_nulls n = String.chr(0) ^ generate_nulls (n-1)
d5096 1
a5096 1
              normalise_to_four_bytes(procedure_name ^ String.chr(0))
d5354 1
a5354 1
                             if String.ordof(padded_name,to) = 0 
d5356 1
a5356 1
                             else String.substring(padded_name,0,to+1)
d5359 2
a5360 2
                           handle String.Substring => ""
                                | Ord => ""
d5378 1
a5378 1
                       then String.implode (annotation_points (code,0,[]))
d5380 1
a5380 1
                       String.implode
@


1.93
log
@Adding NOT32 MIR instruction
@
text
@d7 3
d371 2
@


1.92
log
@Fixing problem with untagged arithmetic.
@
text
@d7 3
d2882 1
a2882 4
		(* T[UNARY(NOT r1 r2)] =>
		      | isReg r2 = xor r1 r2 ~3
		      | otherwise = T[UNARY(MOVE r1 r2)]
		 *)
d2889 46
d2966 1
a2966 1

@


1.91
log
@Array moving to MLWorks.Array
@
text
@d7 3
a1713 7
	  (* gp_value : ??? *)
	  fun gp_value gpmush = case gpmush of
	    MirTypes.GP_IMM_INT i  => (i,0)
	  | MirTypes.GP_IMM_ANY i  => (i div 4, i mod 4)
	  | MirTypes.GP_IMM_SYMB s => (symbolic_value s, 0)
	  | _             => Crash.impossible "gp_value: non constant operand"

d2355 2
a2356 2
			     MirTypes.ADD => Mips_Assembly.ADD
			   | MirTypes.SUB => Mips_Assembly.SUB
d2373 1
d3562 6
d3569 9
d3579 3
a3581 3
				if mn = MirTypes.BGE orelse mn = MirTypes.BHS then
                                  gp11 > gp22 orelse (gp11 = gp21 andalso gp12 >= gp22)
				else if mn = MirTypes.BLE orelse mn = MirTypes.BLS then
d3583 1
a3583 1
				else if mn = MirTypes.BGT orelse mn = MirTypes.BHI then
d3585 1
a3585 1
				else if mn = MirTypes.BLT orelse mn = MirTypes.BLO then
d3587 9
@


1.90
log
@String functions explode, implode, chr and ord now only available from String
io functions and types
instream, oustream, open_in, open_out, close_in, close_out, input, output and end_of_stream
now only available from MLWorks.IO
@
text
@d7 6
d1553 1
a1553 1
      val gc_array = Array.array(gc, global)
d1557 1
a1557 1
	 Array.update(gc_array, MirTypes.GC.unpack mir_reg, reg))
d1559 1
a1559 1
      val non_gc_array = Array.array(non_gc, global)
d1563 1
a1563 1
	 Array.update(non_gc_array, MirTypes.NonGC.unpack mir_reg, reg))
d1565 1
a1565 1
      val fp_array = Array.array(fp, global)
d1569 1
a1569 1
	 Array.update(fp_array, MirTypes.FP.unpack mir_reg, reg))
d1968 1
a1968 1
		  val reg = Array.sub(table, reg)
d1987 1
a1987 1
		Array.sub(fp_array, MirTypes.FP.unpack reg)
@


1.89
log
@Removing checks for validity of FP results
@
text
@d7 3
d519 1
a519 1
  fun binary_list_to_string(done, [], _, 128) = implode(rev done)
d525 1
a525 1
	val x = ord x - ord "0"
d528 1
a528 1
	  binary_list_to_string(chr(digit + x) :: done, xs, 0, 128)
d539 1
a539 1
	    val digit = chr(value mod 2 + ord"0")
d550 1
a550 1
    fun mantissa_is_zero mantissa = checkAList ((curry op=) "0") true (explode mantissa)
d566 1
a566 1
	    if exponent < ~bits then (implode(copy bits "0"), 0)
d568 1
a568 1
	      (implode(copy (abs exponent) "0") ^ mantissa, 0)
d578 1
a578 1
	   explode(String.substring(mantissa, 1, 23))
d590 1
a590 1
	   explode(String.substring(mantissa, 1, 52))
d604 1
a604 1
	   explode(String.substring(mantissa, 0, 64)) @@
d1012 1
a1012 1
		      (output(std_out, "fault_range fails on " ^ x ^
d5011 1
a5011 1
                | generate_nulls n = chr(0) ^ generate_nulls (n-1)
d5015 1
a5015 1
              normalise_to_four_bytes(procedure_name ^ chr(0))
d5297 1
a5297 1
                       then implode (annotation_points (code,0,[]))
d5299 1
a5299 1
                       implode
d5346 1
a5346 1
            output(std_out, "Normalised code size is " ^
@


1.88
log
@Fixing looping problems generating ADDW rn, rn, rm
@
text
@d7 3
d290 2
d357 1
a357 1
  val makestring = MLWorks.Integer.makestring
a2978 4
			 FCMP op2 fp1 fp2 'test validity of result'
			 nop
			 bc1t 0 tag
			 nop
d3015 1
a3015 5
		    ([(Mips_Assembly.FBINARY(operation, rd, rs1, rs2), absent, ""),
                      (Mips_Assembly.FCMP(test, rd, rs1), absent, "Test validity of result"),
		      nop,
                      (Mips_Assembly.FBRANCH(Mips_Assembly.BC1T, 0), tag, ""),
		      nop],
a3069 4
                       (Mips_Assembly.FCMP(test, rd, rs2), absent, "Test validity of result") ::
		       nop ::
                       (Mips_Assembly.FBRANCH(Mips_Assembly.BC1T, 0), tag, "") ::
		       nop ::
@


1.87
log
@Fixing problem with immediate shifts
@
text
@d7 3
d2141 1
a2141 1
					    MirTypes.TBINARY(tagged_op, tag, reg, gp, gp') :: opcode_list,
@


1.86
log
@Add implemetations of ADDW and SUBW
These are like ADDV and SUBV, except that
they cannot use exception trapping adds etc because they are untagged
and also when they detect overflow they must clean
all registers involved in the operation
@
text
@d7 7
d2443 1
@


1.85
log
@Ensure that stack frame sizes are always double word aligned
@
text
@d7 3
a1976 7
		    val opcode = case tagged_op of
		      MirTypes.ADDV => Mips_Assembly.ADD
		    | MirTypes.SUBV => Mips_Assembly.SUB
		    | MirTypes.MULV => Crash.impossible"do_opcodes(TBINARY(MULV))"
		    | MirTypes.DIVV => Crash.impossible"do_opcodes(TBINARY(DIVV))"
		    | MirTypes.MODV => Crash.impossible"do_opcodes(TBINARY(MODV))"

d1981 3
d2010 12
d2023 232
a2254 3
			    ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (opcode, rd, lookup_gp_operand gp, reg_or_imm), absent, "")],
			     opcode_list, block_list, final_result)
@


1.84
log
@Fix bug in polymorphic equality sequence by decrementing instead
@
text
@d7 3
d1584 6
d4716 9
@


1.83
log
@Add extra field to procedure_parameters to contain old (pre register allocation)
spill sizes. This is for the i386, where spill assignment is done in the backend
@
text
@d7 4
d3237 53
a3289 31
		| MirTypes.TEST (mn, tag, lhs, rhs) => let
                    (* is_zero identifies if is a 0 or zero_reg *)
                    local
                      val zero_virtual = case MirRegisters.zero of
                        MLWorks.Option.SOME zero_virtual => MirTypes.GP_GC_REG zero_virtual
                      | _ => Crash.impossible "zero_virtual"
                    in
                      fun is_zero (MirTypes.GP_IMM_INT 0) = true
                        | is_zero (MirTypes.GP_IMM_ANY 0) = true
                        | is_zero x = x = zero_virtual
                      fun convert0 (MirTypes.GP_IMM_INT 0) = zero_virtual
                        | convert0 (MirTypes.GP_IMM_ANY 0) = zero_virtual
                        | convert0 e = e

                      fun convertImm0 e =
                        if e=zero_virtual then
                          (MirTypes.GP_IMM_ANY 0)
                        else
                          e
                    end
                    val imm_lhs = is_imm lhs
                    val imm_rhs = is_imm rhs

                    (* if lhs and rsh are constants or zero_regs then make both constants
                     otherwise convert Imm0s to zero_regs in both lhs and rhs *)
                    val (lhs, rhs) =
                      if (imm_lhs orelse is_zero lhs) andalso
                        (imm_rhs orelse is_zero rhs) then
                        (convertImm0 lhs, convertImm0 rhs)
                      else 
                        (convert0 lhs, convert0 rhs)
d3291 123
a3413 5
                    val imm_lhs = is_imm lhs
                    val imm_rhs = is_imm rhs
                        
                    val imm32_rhs = is_imm32 rhs
                    val imm32_lhs = is_imm32 lhs
d3415 80
a3494 193
                    val simpler = case mn of
                      MirTypes.BEQ => true
                    | MirTypes.BNE => true
                    | _ => false    
                  in
                    if imm_lhs andalso imm_rhs then let
                      val (gp1 as (gp11, gp12), gp2 as (gp21, gp22)) = (gp_value lhs, gp_value rhs)
                      val branch =
                        if mn = MirTypes.BGE orelse mn = MirTypes.BHS then
                          gp11 > gp22 orelse (gp11 = gp21 andalso gp12 >= gp22)
                        else if mn = MirTypes.BLE orelse mn = MirTypes.BLS then
                          gp11 < gp21 orelse (gp11 = gp21 andalso gp12 <= gp22)
                        else if mn = MirTypes.BGT orelse mn = MirTypes.BHI then
                          gp11 > gp21 orelse (gp11 = gp21 andalso gp12 > gp22)
                        else if mn = MirTypes.BLT orelse mn = MirTypes.BLO then
                          gp11 < gp21 orelse (gp11 = gp21 andalso gp12 < gp22)
                             else case mn of
                               MirTypes.BEQ => gp1 =  gp2
                             | MirTypes.BNE => gp1 <> gp2
                             | MirTypes.BNT => Bits.andb (gp12, gp22) =  0
                             | MirTypes.BTA => Bits.andb (gp12, gp22) <> 0
                             | _ => Crash.impossible "mir test const precalc failed"
                    in
                      if branch (* precalculated result *) then
                        (* remainder of opcode_list irrelevant here *)
                        ([], [MirTypes.BRANCH (MirTypes.BRA, MirTypes.TAG tag)],
                         block_list, final_result)
                      else (* false, so fall through *)
                        ([], opcode_list, block_list, final_result)
                    end
                    else if imm32_lhs then
                      ([],
                       MirTypes.UNARY (MirTypes.MOVE, global_reg, lhs)
                       ::
                       MirTypes.TEST (mn, tag, global_gp, rhs)
                       :: opcode_list, block_list, final_result)
                    else if imm32_rhs then
                      ([],
                       MirTypes.UNARY (MirTypes.MOVE, global_reg, rhs)
                       ::
                       MirTypes.TEST (mn, tag, lhs, global_gp)
                       :: opcode_list, block_list, final_result)
                    else if simpler then let
                      val branch = case mn of
                        MirTypes.BEQ => Mips_Assembly.BEQ
                      | MirTypes.BNE => Mips_Assembly.BNE
                      | _ => Crash.impossible "simplebranch"
                      val (lhs, rhs) = if is_imm lhs then (rhs, lhs) else (lhs, rhs)
                    in
                      (if is_imm16 rhs then
                         (load_imm_into_register (MachTypes.global, rhs)
                          @@
                          [(Mips_Assembly.BRANCH
                            (branch, lookup_gp_operand lhs, MachTypes.global, 0),
                            MLWorks.Option.SOME tag, ""),
                           nop])
                       else
                         [(Mips_Assembly.BRANCH
                           (branch, lookup_gp_operand lhs, lookup_gp_operand rhs, 0),
                           MLWorks.Option.SOME tag, ""),
                          nop],
                         opcode_list, block_list, final_result)
                    end
                    else if is_zero lhs orelse is_imm16 lhs then let
                      val mn' = case mn of
                        MirTypes.BGT => MirTypes.BLT
                      | MirTypes.BLT => MirTypes.BGT
                      | MirTypes.BGE => MirTypes.BLE
                      | MirTypes.BLE => MirTypes.BGE
                      | MirTypes.BEQ => MirTypes.BEQ
                      | MirTypes.BNE => MirTypes.BNE
                      | MirTypes.BNT => MirTypes.BNT
                      | MirTypes.BTA => MirTypes.BTA
                      | MirTypes.BHS => MirTypes.BLS
                      | MirTypes.BLS => MirTypes.BHS
                      | MirTypes.BHI => MirTypes.BLO
                      | MirTypes.BLO => MirTypes.BHI
                    in
                      ([],
                       MirTypes.TEST (mn', tag, rhs, lhs)
                       :: opcode_list, block_list, final_result)
                    end
                    else if is_zero rhs then (* rhs is in focus *)
                      if mn = MirTypes.BNT orelse mn = MirTypes.BHS then (* shortcut branch-true *)
                        ([], [MirTypes.BRANCH (MirTypes.BRA, MirTypes.TAG tag)],
                         block_list, final_result)
                      else if mn = MirTypes.BTA orelse mn = MirTypes.BLO then (* shortcut branch-false *)
                        ([], opcode_list, block_list, final_result)
                      else let
                        val branch = case mn of
                          MirTypes.BGT => Mips_Assembly.BGTZ
                        | MirTypes.BLT => Mips_Assembly.BLTZ
                        | MirTypes.BGE => Mips_Assembly.BGEZ
                        | MirTypes.BLE => Mips_Assembly.BLEZ
                        | MirTypes.BEQ => Mips_Assembly.BEQZ
                        | MirTypes.BNE => Mips_Assembly.BNEZ
                        | MirTypes.BLS => Mips_Assembly.BEQZ
                        | MirTypes.BHI => Mips_Assembly.BNEZ
                        (* MirTypes.BNT => branch-true
                         * MirTypes.BTA => branch-false
                         * MirTypes.BHS => branch-true
                         * MirTypes.BLO => branch-false
                         *)
                        | _ => Crash.impossible "shortbranch"
                      in
                        if is_zero lhs then (* uncertain if imm and zero can exist at same time *)
                          ([(Mips_Assembly.BRANCH
                             (Mips_Assembly.reverse_branch branch, lookup_gp_operand rhs, zero, 0),
                             MLWorks.Option.SOME tag, ""),
                            nop], opcode_list, block_list, final_result)
                        else (* is_zero rhs *)
                          ([(Mips_Assembly.BRANCH
                             (branch, lookup_gp_operand lhs, zero, 0),
                             MLWorks.Option.SOME tag, ""),
                            nop], opcode_list, block_list, final_result)
                      end

                    else (* rhs is in focus *) let
                      val andt = Mips_Assembly.AND
                      val sltu = Mips_Assembly.SLTU
                      val slt = Mips_Assembly.SLT
                      val iftrue = Mips_Assembly.BNEZ
                      val iffalse = Mips_Assembly.BEQ
                      val (test, (lhs, rhs), branch) = let
                        val swap = (rhs, lhs)
                        val usual = (lhs, rhs)
                        fun inc (MirTypes.GP_IMM_INT n) = MirTypes.GP_IMM_INT (n+1)
                          | inc (MirTypes.GP_IMM_ANY n) = MirTypes.GP_IMM_ANY (n+1)
                          | inc s = s
                        val rhs' = inc rhs
                        val imm16_rhs' = is_imm16 rhs'
                      in
                        case mn of
                          MirTypes.BNT => (andt, usual, iffalse)
                        | MirTypes.BTA => (andt, usual, iftrue)
                        | MirTypes.BLT => (slt,  usual, iftrue)
                        | MirTypes.BLO => (sltu, usual, iftrue)
                        | MirTypes.BGE => (slt,  usual, iffalse)
                        | MirTypes.BHS => (sltu, usual, iffalse)
                        | MirTypes.BGT => 
                            if imm16_rhs' then
                              (slt, (lhs, rhs'), iffalse)
                            else
                              (slt, swap, iftrue)
                        | MirTypes.BLE => 
                                if imm16_rhs' then
                                  (slt, (lhs, rhs'), iftrue)
                                else
                                  (slt, swap, iffalse)
                        | MirTypes.BLS => 
                                  if imm16_rhs' andalso not (is_zero rhs') then
                                    (sltu, (lhs, rhs'), iftrue)
                                  else
                                    (sltu, swap, iffalse)
                        | MirTypes.BHI =>
                                    if imm16_rhs' andalso not (is_zero rhs') then
                                      (sltu, (lhs, rhs'), iffalse)
                                    else
                                      (sltu, swap, iftrue)
                        | _ => Crash.impossible "mirtypes"
                      end
                      val rhs' =
                        if is_imm16 rhs then convert_small_imm rhs
                        else Mips_Assembly.REG (lookup_gp_operand rhs)
                    in
                      if is_imm lhs then (* this is a hack to ensure
                                          * when BHS ~1 r2
                                          * => li global ~1; sltu global r2, global; beqz global
                                          * optimised to
                                          * => sltiu global r2 (~1+1); bnez global
                                          * doesnt happen, as thats wrong
                                          * ~1 unsigned is maxint
                                          * maxint+1=0 is a problem
                                          *)
                        (load_imm_into_register (MachTypes.global, lhs)
                         @@
                         [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                           (test, MachTypes.global, MachTypes.global, rhs'),
                           absent, ""),
                          (Mips_Assembly.BRANCH
                           (branch, MachTypes.global, zero, 0),
                           MLWorks.Option.SOME tag, ""),
                          nop], opcode_list, block_list, final_result)
                      else
                        ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                           (test, MachTypes.global, lookup_gp_operand lhs, rhs'),
                           absent, ""),
                          (Mips_Assembly.BRANCH
                           (branch, MachTypes.global, zero, 0),
                           MLWorks.Option.SOME tag, ""),
                          nop], opcode_list, block_list, final_result)
                    end
                  end
@


1.82
log
@Tidy up some missing constructors in BINARY code generation
@
text
@d7 3
a308 1
  sharing MirTables.MirTypes.Option = MirTables.MirTypes.Debugger_Types.RuntimeEnv.Option = MirRegisters.Option
a326 1
  structure Option = RuntimeEnv.Option
d336 4
a339 4
    [(Mips_Assembly.other_nop_code,Option.ABSENT,"Tracing nop"),
     (Mips_Assembly.other_nop_code,Option.ABSENT,"Tracing nop"),
     (Mips_Assembly.other_nop_code,Option.ABSENT,"Tracing nop"),
     (Mips_Assembly.other_nop_code,Option.ABSENT,"Tracing nop")]
d430 1
a430 1
  val absent = Option.ABSENT
d617 1
a617 1
	  ((_, Option.PRESENT tag, _), true) => (tag, true)
d799 1
a799 1
  exception BadOffset of MirTypes.tag * (Mips_Assembly.opcode * MirTypes.tag Option.opt * string) list
d876 1
a876 1
		     :: (Mips_Assembly.nop_code, Option.ABSENT, "doubleword aligned branch follows") 
d1018 1
a1018 1
				 tag_opt as Option.PRESENT tag, comment), offset) =
d1055 1
a1055 1
                                  Option.ABSENT,
d1059 1
a1059 1
                                  Option.PRESENT tag, new_comment) ::
d1072 1
a1072 1
				  Option.ABSENT, "jump to original destination") ::
d1080 1
a1080 1
				   r1, r2, 9), Option.ABSENT,
d1097 1
a1097 1
				 tag_opt as Option.PRESENT tag, comment), offset) =
d1112 1
a1112 1
				 Option.PRESENT tag, comment), offset) =
d1152 1
a1152 1
				 tag_opt as Option.PRESENT tag, comment), offset) =
d1185 1
a1185 1
                                  Option.ABSENT,
d1193 1
a1193 1
                                  Option.PRESENT tag, new_comment) ::
d1202 1
a1202 1
				  Option.ABSENT, "jump and link to original destination") ::
d1213 1
a1213 1
				  Option.ABSENT, 
d1223 1
a1223 1
				 Option.PRESENT tag, comment), offset) =
d1248 1
a1248 1
				    Option.PRESENT tag, new_comment) ::
d1251 1
a1251 1
				    Option.PRESENT tag, new_comment) :: tail
d1261 1
a1261 1
				 Option.PRESENT tag, comment), offset) =
d1287 1
a1287 1
				    Option.PRESENT tag, new_comment) ::
d1291 1
a1291 1
				    Option.PRESENT tag, new_comment) ::
d1307 1
a1307 1
				 Option.PRESENT tag, comment), offset) =
d1326 1
a1326 1
				 Option.PRESENT tag, comment), _) =
d1349 1
a1349 1
				 Option.PRESENT tag, comment), offset) =
d1363 1
a1363 1
		    | do_opcode((Mips_Assembly.OFFSET i, Option.PRESENT tag, comment),
d1375 1
a1375 1
		    | do_opcode((opcode, Option.ABSENT, comment), offset) =
d1791 1
a1791 1
		    Mips_Assembly.IMM offset), Option.ABSENT,
d1797 1
a1797 1
		    Mips_Assembly.IMM (offset+4)), Option.ABSENT,
d1803 1
a1803 1
		    Mips_Assembly.IMM (offset)), Option.ABSENT,
d1814 1
a1814 1
		      Mips_Assembly.IMM offset), Option.ABSENT,
d1822 1
a1822 1
		      Mips_Assembly.IMM (offset+4)), Option.ABSENT,
d1828 1
a1828 1
		      Mips_Assembly.IMM (offset)), Option.ABSENT,
d1841 1
a1841 1
		Option.ABSENT, "save argument for debugging")]
d1846 1
a1846 1
		offset), Option.ABSENT,
d1853 1
a1853 1
		    offset), Option.ABSENT,
d2355 1
a2355 1
					  Option.PRESENT bad_tag, ""),
d2362 1
a2362 1
				       Option.PRESENT cont_tag, ""),
d2817 1
a2817 1
				   Option.PRESENT offset) =>
d3189 1
a3189 1
			 Option.PRESENT tag, "branch on overflow, unable to tag"),
d3196 1
a3196 1
			 Option.PRESENT tag, "branch on overflow, unable to tag"),
d3229 1
a3229 1
			  Option.PRESENT tag, "branch"),
d3237 1
a3237 1
                        Option.PRESENT zero_virtual => MirTypes.GP_GC_REG zero_virtual
d3325 1
a3325 1
                            Option.PRESENT tag, ""),
d3330 1
a3330 1
                           Option.PRESENT tag, ""),
d3379 1
a3379 1
                             Option.PRESENT tag, ""),
d3384 1
a3384 1
                             Option.PRESENT tag, ""),
d3452 1
a3452 1
                           Option.PRESENT tag, ""),
d3460 1
a3460 1
                           Option.PRESENT tag, ""),
d3483 1
a3483 1
		       Option.PRESENT tag, "Do the branch"),
d3508 1
a3508 1
		      Option.PRESENT tag, "Call"),
d3585 1
a3585 1
                           Option.PRESENT tag, "branch"),
d3643 1
a3643 1
				    Option.PRESENT tag, "branch to table entry")
d3650 1
a3650 1
					       Option.PRESENT tag, "")
d3684 1
a3684 1
			     Option.PRESENT t, "branch to table entry")
d3701 1
a3701 1
					  Option.PRESENT fp_offset) =>
d3750 1
a3750 1
                          Option.PRESENT finish_tag, ""),
d3755 1
a3755 1
			 Option.PRESENT end_gc_tag, "")
d3763 1
a3763 1
			 Option.PRESENT end_gc_tag, "branch if no GC required")
d3965 1
a3965 1
			      Option.PRESENT tag, "Update gc pointer")]
d3969 1
a3969 1
			      Option.PRESENT tag,
d4000 1
a4000 1
			    Option.PRESENT continue_tag,
d4017 1
a4017 1
			    Option.PRESENT continue_tag, "End of block"),
d4116 1
a4116 1
				  Option.PRESENT stackOKTag, "branch if OK"),
d4146 1
a4146 1
				  Option.PRESENT stackOKTag, "Do the branch"),
d4198 1
a4198 1
				Option.PRESENT endTag, "branch"),
d4234 1
a4234 1
				   Option.PRESENT loop_tag, ""),
d4252 1
a4252 1
				    Option.PRESENT loop_tag, "and loop"),
d4292 1
a4292 1
			   Option.ABSENT, "restore lr"),
d4294 1
a4294 1
			   Option.ABSENT, ""),
d4297 1
a4297 1
			   Option.ABSENT, "restore fp not in delay slot"),
d4299 1
a4299 1
			  Option.ABSENT, "return"),
d4389 1
a4389 1
      fun exit_block [] = Option.ABSENT
d4394 1
a4394 1
	  then Option.PRESENT block
d4460 2
a4461 2
	      Option.ABSENT => block_list
	    | Option.PRESENT exit_block =>
d4646 1
a4646 1
	      Option.PRESENT{gc = gc_spill_size,
d4652 1
a4652 1
	    Option.PRESENT stack_extra => stack_extra
d4777 1
a4777 1
			    Option.PRESENT tag =>
d4779 1
a4779 1
			  | Option.ABSENT => " no tag") ^
d4850 1
a4850 1
				 Option.PRESENT tag =>
d4852 1
a4852 1
			       | Option.ABSENT => " no tag") ^
d4873 1
a4873 1
              fun get_branch_tag ([(Mips_Assembly.BRANCH (Mips_Assembly.BA,_,_,_),Option.PRESENT tag,_),
d4897 2
a4898 2
              fun scan (op1 as (Mips_Assembly.BRANCH b,Option.PRESENT tag,c) :: rest,acc) =
                  scan (rest, (Mips_Assembly.BRANCH b,Option.PRESENT (lookup_branch (tag,20)), c) :: acc)
d4910 1
a4910 1
            (fn (acc,(opcode,MirTypes.Option.PRESENT t,_)) =>
@


1.81
log
@Fix bugs in xor (and others) with immediate negative constants
@
text
@d7 3
d2512 1
@


1.80
log
@Modification for improved runtime env spill offsets
to indicate the kind of data spilled
@
text
@d7 4
d2446 73
a2518 12
			     if is_reg gp_operand then
			       let
				 val rs1 = lookup_gp_operand gp_operand
			       in
				 if is_reg gp_operand' orelse
				   gp_check_range(gp_operand', true,
						  arith_imm_limit) then
				   let
				     val reg_or_imm =
				       if is_reg gp_operand' then
					 Mips_Assembly.REG(lookup_gp_operand
							   gp_operand')
d2520 45
a2564 6
					 convert_small_imm gp_operand'
				   in
				     ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					(opcode, rd, rs1, reg_or_imm), absent, "")],
				      opcode_list, block_list, final_result)
				   end
d2566 10
a2575 38
				   let
				     val inter_reg =
				       case gp_operand of
					 MirTypes.GP_GC_REG r =>
					   (if r = global_mir then
					      (* The nasty case *)
					      (case reg_operand of
						 MirTypes.GC_REG r' =>
						   if r = r' then
						     Crash.impossible
						     "source and dest global with large int"
						   else
						     r'
					       | MirTypes.NON_GC_REG _ =>
						   Crash.impossible"BINARY doesn't deliver GC")
					    else
					      global_mir)
				       | _ => Crash.impossible "BINARY has non-gc register"
				   in
				     ([],
				      MirTypes.UNARY(MirTypes.MOVE,
						     MirTypes.GC_REG inter_reg,
						     gp_operand') ::
				      MirTypes.BINARY(binary_op, reg_operand,
						      gp_operand,
						      MirTypes.GP_GC_REG inter_reg) ::
				      opcode_list, block_list, final_result)
				   end
			       end
			     else
			       ([],
				MirTypes.UNARY(MirTypes.MOVE,
					       global_reg,
					       gp_operand) ::
				MirTypes.BINARY(binary_op, reg_operand,
						global_gp,
						gp_operand') ::
				opcode_list, block_list, final_result)
@


1.79
log
@Fix bug in compiler crash when number of fp spill slots exceeded
@
text
@d7 3
d1591 7
a1597 2
                     (fn value => (spill := RuntimeEnv.OFFSET2 value; value)) (symbolic_value i))
                | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2 i),name) => 
d1621 7
a1627 2
                     (fn value => (spill := RuntimeEnv.OFFSET2 value;value)) (symbolic_value i))
                | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2 i),name) => 
d1653 7
a1659 3
		    (fn value => (spill := RuntimeEnv.OFFSET2 value; value)) 
		    (symbolic_value i)
		  | MirTypes.DEBUG(ref(RuntimeEnv.OFFSET2 i),name) => i
@


1.78
log
@fix MirTypes.TEST from overflowing ~1 on unsigned operations.
@
text
@d7 3
d1603 1
a1603 2
		       " requested, but only " ^
		       makestring non_gc_spill_size ^
d1628 2
a1629 3
		       ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
			" requested, but only " ^
			MLWorks.Integer.makestring non_gc_spill_size ^
@


1.77
log
@Add a fixed branch type which can't be expanded beyond the 16 bit limit
This can be used to detect disastrous code generation in computed gotos
If this ever occurs, we can then fix the bug
@
text
@d7 5
d3171 1
a3289 1
                      val imm16_rhs = is_imm16 rhs
d3322 1
a3322 1
                                  if imm16_rhs' then
d3327 1
a3327 1
                                    if imm16_rhs' then
d3334 1
a3334 1
                        if imm16_rhs then convert_small_imm rhs
d3337 26
a3362 7
                      ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                         (test, MachTypes.global, lookup_gp_operand lhs, rhs'),
                         absent, ""),
                        (Mips_Assembly.BRANCH
                         (branch, MachTypes.global, zero, 0),
                         Option.PRESENT tag, ""),
                        nop], opcode_list, block_list, final_result)
@


1.76
log
@ambiguity between const0 and reg0 in TEST
@
text
@d7 3
d436 10
a445 3
  (* foldl: cant find foldl yet hack it into here *)
  fun foldl f z [] = z
    | foldl f z (x::xs) = foldl f (f(z,x)) xs
d589 2
d624 5
d823 1
a895 8
	  fun rev_map f arg =
	    let
	      fun map_sub([], acc) = acc
		| map_sub(x :: xs, acc) = map_sub(xs, f x :: acc)
	    in
	      map_sub arg
	    end

d1026 1
a1026 1
                               (* This should be save even if r1 or r2 are spills as their values *)
d1077 15
d3510 1
a3510 2
		     (
		      let
a3511 24
			val instrs = 
			  (Mips_Assembly.CALL
			   (Mips_Assembly.BGEZAL, zero, 1,
                            Debugger_Types.null_backend_annotation),
			   absent, "call self")
			  :: (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADDIU, lr, lr, Mips_Assembly.IMM (4*4)),
			      absent, "point lr to start of table")
			  :: (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADDU, global, reg, Mips_Assembly.REG reg),
			      absent, "forgot!")
			  :: (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADDU, lr, lr, global_op),
			      absent, "calculate offset into table")
			  :: (Mips_Assembly.JUMP
			      (Mips_Assembly.JR, lr_op, dummy, Debugger_Types.null_backend_annotation), 
			      absent, "jump to table offset")
			  :: nop
			  :: foldl op@@ [] (map (fn t=>
				  (Mips_Assembly.BRANCH
				   (Mips_Assembly.BA, dummy, dummy, 0), 
				   Option.PRESENT t, "branch to table entry")
				  :: Mips_Assembly.nopc "table entry padding"
				  :: []) tag_list)
d3535 1
a3535 1
			  end (* let *)
d3539 25
a3563 1
			  instrs
@


1.75
log
@used slt/sltu in TEST, fixed bug introduced in BTA&BNT
sorted out overflow
@
text
@d7 4
d3117 6
a3125 2
                    val (lhs, rhs) = if imm_lhs andalso imm_rhs then (convert0 lhs, convert0 rhs)
                                     else (lhs, rhs)
d3127 12
@


1.74
log
@implement jon's suggestion with imm32 cases in test and unsigned const comparisons
@
text
@d7 10
a456 1

d2515 3
a2517 3
		    (move_regc(lookup_reg_operand reg_operand, zero, "clean")
		     :: [], opcode_list, block_list, final_result)
	        (* T[BINARYFP op fp1 fp2 fp3] => FBINARY op' fp1 fp2 fp3 *)
a2520 3
		    val rd = lookup_fp_operand fp_operand
		    val rs1 = lookup_fp_operand fp_operand'
		    val rs2 = lookup_fp_operand fp_operand''
d2535 5
a2539 2
		    ([(Mips_Assembly.FBINARY(operation, rd, rs1, rs2), absent,
		       "")], opcode_list, block_list, final_result)
d2541 1
a2541 20
	        (* T[UNARYFP op fp1 fp2] => FUNARY TOP[op] fp1 fp2
		   where
		      TOP[op] =>
			| fp_used == single
			     | FSQRT = BANG! no hardware square root
			     | FMOVE = MOV_S
			     | FABS  = ABS_S
			     | FNEG  = NEG_S
			| fp_used == double
			     | FSQRT = BANG! no hardware square root
			     | FMOVE = MOV_D
			     | FABS  = ABS_D
			     | FNEG  = NEG_D
			| fp_used == extended
			     | FSQRT = BANG! Extended floats not supported
			     | FMOVE = BANG! ""
			     | FABS  = BANG! ""
	                     | FNEG  = BANG! ""
			| otherwise = BANG! Bad unary fp generated
		 *)
d2682 1
a2682 7
		(* T[STACKOP op r1 offset] => T[STOREOP U[op] r1 (GC_REG fp) (GP_IMM_ANY offset')]
		      where
		         U[op] =>
			   | PUSH = STREF
			   | POP  = LDREF
			 offset' = ~(gc_stack_alloc_offset + 4*(offset+1))
		 *)
d2689 9
a2697 9
		  val _ =
		    if offset > gc_stack_alloc_size then
		      Crash.impossible("Stack access at offset " ^
				       makestring offset ^
				       " requested, in total area of only " ^
				       makestring
				       gc_stack_alloc_size ^
				       "\n")
		    else()
a2708 2
		(* T[STOREOP op r1 r2 r3] => 
		  *)
a2792 1

d3002 21
a3022 27
		      fun saveRoundingMode rd gl =
			let
			  fun changeRoundingMode bitseq = 
			    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			     (Mips_Assembly.ORI, gl, rd, Mips_Assembly.IMM 3),
			     absent, "mask & reset rounding mode")
			    ::
			    (if bitseq = 3 then 
			       []
			     else
			       [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				 (Mips_Assembly.XORI, gl, gl, Mips_Assembly.IMM bitseq),
				 absent, "")])
			    @@
			    [ (Mips_Assembly.LOAD_AND_STORE_FLOAT
			       (Mips_Assembly.CTC1, gl, MachTypes.R31, dummy_op),
			       absent, ""),
			     nop
			    ]
			in (* saveRoundingMode *)
			  (Mips_Assembly.LOAD_AND_STORE_FLOAT
			   (Mips_Assembly.CFC1, rd, MachTypes.R31, dummy_op),
			   absent, "get FPU status")
			  :: nop
			  :: changeRoundingMode 3
			end (* saveRoundingMode *)
		      fun restoreRoundingMode rd = 
d3027 11
a3037 3

		      val rs2 = lookup_fp_operand fp_operand
		      val rd = lookup_reg_operand reg_operand
d3039 3
a3041 3
		      (saveRoundingMode rd global
		       @@ [
		       (* Test for a possible overflow if the number is too big in magnitude *)
d3055 2
a3056 1
                        (Mips_Assembly.FBRANCH(Mips_Assembly.BC1F, 0), Option.PRESENT tag, "branch on overflow, unable to tag"),
d3062 2
a3063 1
                        (Mips_Assembly.FBRANCH(Mips_Assembly.BC1F, 0), Option.PRESENT tag, "branch on overflow, unable to tag"),
a3064 1

d3069 10
a3078 11
		      @@ restoreRoundingMode rd
		      @@ [
			 (Mips_Assembly.LOAD_AND_STORE_FLOAT
			  (Mips_Assembly.MFC1, rd, MachTypes.fp_global, dummy_op),
			  absent,""), 
			 nop,
			 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			  (Mips_Assembly.SLL, rd, rd, Mips_Assembly.IMM 2),
			  absent, "Tag the result, no more overflow")
			 ],
		      opcode_list, block_list, final_result)
d3080 1
a3080 1

d3082 1
a3082 1
		   T[BRANCH b tag]=> BA tag, nop
d3101 196
a3296 309
		    local
		      val zero_virtual = case MirRegisters.zero of
			Option.PRESENT zero_virtual => zero_virtual
		      | _ => Crash.impossible "TEST: zero_virtual failed"
		    in (* local *)
		      fun convert0 e = case e of
			MirTypes.GP_IMM_INT 0 => MirTypes.GP_GC_REG zero_virtual
		      | MirTypes.GP_IMM_ANY 0 => MirTypes.GP_GC_REG zero_virtual
		      | _ => e
		      fun is_zero (MirTypes.GP_IMM_INT 0) = true
			| is_zero (MirTypes.GP_IMM_ANY 0) = true
			| is_zero x = x = MirTypes.GP_GC_REG zero_virtual
		      val (lhs, rhs) = (* do not alter if both are constants *)
			if is_imm lhs andalso is_imm rhs then (lhs, rhs)
			else (convert0 lhs, convert0 rhs) (* need to munge imm0s to zero_regs *)
		    end (* local *)

		    datatype Sense = Normal | Inverse | Redo
		    datatype ArgType = Imm16 | Imm32 | Reg
		    fun argType reg =
		      if is_reg reg then Reg
		      else if is_imm32 reg then Imm32
		      else (* is imm16 *) Imm16

		    (* simplify mir test expressions, arbritrary choices *)
		    val reverse = case mn of
		      MirTypes.BGT => true
		    | MirTypes.BGE => true
		    | MirTypes.BHS => true
		    | MirTypes.BHI => true
		    | _ => false

		    val iffalse = 0
		    val iftrue = 1
		    val bgtz = 3
		    val bgez = 4
		    val bltz = 5
		    val blez = 6

		    (* signed used to determine testing instr needed
		     * nb equality is neutral
		     *)
		    val signed = case mn of
		      MirTypes.BHI => false
		    | MirTypes.BLO => false
		    | MirTypes.BHS => false
		    | MirTypes.BLS => false
		    | _ => true
			  
		    (* one instr operators *)
		    val (short, reversible) =
		      case mn of
			MirTypes.BEQ => (true, true)
		      | MirTypes.BNE => (true, true)
		      | _ => (* activates bgtz, bgez, bltz, blez *)
			  if signed andalso (is_zero lhs orelse is_zero rhs) then
			    (true, false)
			  else
			    (false, false)
		  in (* patternlet *)
		    if (is_imm lhs orelse is_zero lhs) andalso (is_imm rhs orelse is_zero rhs) then let
		      val (gp1 as (gp11, gp12), gp2 as (gp21, gp22)) = (gp_value lhs, gp_value rhs)
		      val branch =
			if mn = MirTypes.BGE orelse mn = MirTypes.BHS then
			  gp11 > gp22 orelse (gp11 = gp21 andalso gp12 >= gp22)
			else if mn = MirTypes.BLE orelse mn = MirTypes.BLS then
			  gp11 < gp21 orelse (gp11 = gp21 andalso gp12 <= gp22)
			else if mn = MirTypes.BGT orelse mn = MirTypes.BHI then
			  gp11 > gp21 orelse (gp11 = gp21 andalso gp12 > gp22)
			else if mn = MirTypes.BLT orelse mn = MirTypes.BLO then
			  gp11 < gp21 orelse (gp11 = gp21 andalso gp12 < gp22)
			else case mn of
			  MirTypes.BEQ => gp1 =  gp2
			| MirTypes.BNE => gp1 <> gp2
			| MirTypes.BNT => Bits.andb (gp12, gp22) =  0
			| MirTypes.BTA => Bits.andb (gp12, gp22) <> 0
			| _ => Crash.impossible "mir test const precalc failed"
		    in
		      if branch (* precalculated result *) then
			(* remainder of opcode_list irrelevant here *)
			([], [MirTypes.BRANCH (MirTypes.BRA, MirTypes.TAG tag)],
			 block_list, final_result)
		      else (* false, so fall through *)
			([], opcode_list, block_list, final_result)
		    end
		    else
		      if reverse (* simplif test *) then let
			val reverse_mir = case mn of
			  MirTypes.BGT => MirTypes.BLT
			| MirTypes.BGE => MirTypes.BLE
			| MirTypes.BHS => MirTypes.BLS
			| MirTypes.BHI => MirTypes.BLO
			| _ => Crash.impossible "reverse_mir failed"
		      in
			([],
			 MirTypes.TEST (reverse_mir, tag, rhs, lhs)
			 :: opcode_list, block_list, final_result)
		      end
		      else if not signed andalso mn = MirTypes.BLO andalso (is_zero lhs orelse is_zero rhs) then
			if is_zero lhs then (* bltu zero rhs -> bnez rhs *)
			  ([(Mips_Assembly.BRANCH (Mips_Assembly.BNEZ, lookup_gp_operand rhs, zero, 0),
			     Option.PRESENT tag, "bltu zero rhs -> bnez rhs"),
			    nop],
			   opcode_list, block_list, final_result)
			else if is_zero rhs then (* bltu lhs zero -> branch-false *)

			  ([], opcode_list, block_list, final_result)
			  (*
			  ([(Mips_Assembly.JUMP (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr, dummy,
						 Debugger_Types.null_backend_annotation),
			     absent, "bltu lhs zero -> branch-false"),
			    move_imm(MachTypes.arg, 0)] (* stuff false into arg register in nop *),
			  [], block_list, final_result)
			  *)
			else Crash.impossible "unsigned zero shortcutting failed"

			else if short then (* is beq or bne *)
			if reversible (* args switchable *) then let
			  val (branch, comment) = case mn of
			    MirTypes.BEQ => (Mips_Assembly.BEQ, "==")
			  | MirTypes.BNE => (Mips_Assembly.BNE, "<>")
			  | _ => Crash.impossible "val branch failed"
			  (* imm16, rhs
			   * imm32, rhsn
			   * lhs, imm16
			   * lhs, imm32 *)
			  val (lhs, rhs) = if is_imm lhs then (rhs, lhs) else (lhs, rhs)
			in
			  if is_imm rhs then
			    (load_imm_into_register (MachTypes.global, rhs)
			     @@
			     [(Mips_Assembly.BRANCH (branch, lookup_gp_operand lhs, MachTypes.global, 0),
			       Option.PRESENT tag, comment), nop],
			     opcode_list, block_list, final_result)
			else 
			  ([(Mips_Assembly.BRANCH (branch, lookup_gp_operand lhs, lookup_gp_operand rhs, 0),
			     Option.PRESENT tag, comment), nop],
			   opcode_list, block_list, final_result)
			end
			else (* one of the args is a zero_reg and args are not reversible *) let
			  val (branch, comment) = case mn of
			    MirTypes.BGT => (Mips_Assembly.BGTZ, ">")
			  | MirTypes.BGE => (Mips_Assembly.BGEZ, ">=")
			  | MirTypes.BLT => (Mips_Assembly.BLTZ, "<")
			  | MirTypes.BLE => (Mips_Assembly.BLEZ, "<=")
			  | _ => Crash.impossible "branch instr for zero_reg failed"
			  val branch_instr =
			    if is_zero lhs then (Mips_Assembly.reverse_branch branch, lookup_gp_operand rhs, zero, 0)
			    else (branch, lookup_gp_operand lhs, zero, 0)
			in (* elselet *)
			  ([(Mips_Assembly.BRANCH branch_instr, Option.PRESENT tag, comment),
			    nop],
			   opcode_list, block_list, final_result)
			end (* elselet *)
		      else let
			val sub = Mips_Assembly.SUB
			val andt = Mips_Assembly.AND
			val sltu = Mips_Assembly.SLTU
			  
			fun inc (MirTypes.GP_IMM_INT n) = MirTypes.GP_IMM_INT (n+1)
			  | inc (MirTypes.GP_IMM_ANY n) = MirTypes.GP_IMM_ANY (n+1)
			  | inc _ = Crash.impossible "inc failed"

			val (test, (lhs, rhs), branch) = let
			  val usual = (lhs, rhs)
			  val swapped = (rhs, lhs)
			in
			  if (is_reg lhs andalso is_reg rhs) then
			    case mn of
			      MirTypes.BLT => (sub,  usual,   bltz)
			    | MirTypes.BLO => (sltu, usual,   iftrue)  (* bltu *)
			    | MirTypes.BLE => (sub,  usual,   blez)
			    (*
			    | MirTypes.BLE => (sub,  swapped, bgez)
				*)
			    | MirTypes.BLS => (sltu, swapped, iffalse) (* bleu *)
			    | MirTypes.BNT => (andt, usual,   iftrue)  (* bitand *)
			    | MirTypes.BTA => (andt, usual,   iffalse) (* not bitand *)
			    | _ => Crash.impossible "hint is_reg failed"
			  else
			    case (mn, (argType lhs, argType rhs)) of
			      (MirTypes.BNT, (Imm16, Reg)) => (andt, swapped, iftrue)
			    | (MirTypes.BNT, (_, _))       => (andt, usual, iftrue)
				
			    | (MirTypes.BTA, (Imm16, Reg)) => (andt, swapped, iffalse)
			    | (MirTypes.BTA, (_, _))       => (andt, usual, iffalse)

			    | (MirTypes.BLT, (    _, Reg)) => (sub, swapped, bgtz)
			    (*
			    | (MirTypes.BLT, (Imm16, Reg)) => (sub, swapped, bgtz)
			    | (MirTypes.BLT, (Imm32, Reg)) => (sub, swapped, bgtz)
				*)
			    | (MirTypes.BLT, (Reg,     _)) => (sub, usual, bltz)
			    (*
			    | (MirTypes.BLT, (Reg, Imm16)) => (sub, usual, bltz)
			    | (MirTypes.BLT, (Reg, Imm32)) => (sub, usual, bltz)
			     *)
			    (* bltu *)
			    | (MirTypes.BLO, (Imm16, Reg)) => let
				val lhs' = inc lhs
			      in
				if is_imm16 lhs' then
				  (sltu, (rhs, lhs'), iffalse)
				else (* same as rest *)
				  (sltu, usual, iftrue)
			      end
			    | (MirTypes.BLO, (_,     _  )) => (sltu, usual, iftrue)
			    (*
			    | (MirTypes.BLO, (Imm32, Reg)) => (sltu, usual, iftrue)
			    | (MirTypes.BLO, (Reg, Imm16)) => (sltu, usual, iftrue)
			    | (MirTypes.BLO, (Reg, Imm32)) => (sltu, usual, iftrue)
			     *)
				
			    | (MirTypes.BLE, (    _, Reg)) => (sub, swapped, bgez)
			    (*
			    | (MirTypes.BLE, (Imm16, Reg)) => (sub, swapped, bgez)
			    | (MirTypes.BLE, (Imm32, Reg)) => (sub, swapped, bgez)
			     *)
			    | (MirTypes.BLE, (Reg,     _)) => (sub, usual, blez)
			    (*
			    | (MirTypes.BLE, (Reg, Imm16)) => (sub, usual, blez)
			    | (MirTypes.BLE, (Reg, Imm32)) => (sub, usual, blez)
			     *)

			    (* bleu *)
			    | (MirTypes.BLS, (    _, Reg)) => (sltu, swapped, iffalse)
			    (*
			    | (MirTypes.BLS, (Imm16, Reg)) => (sltu, swapped, iffalse)
			    | (MirTypes.BLS, (Imm32, Reg)) => (sltu, swapped, iffalse)
			     *)
			    | (MirTypes.BLS, (Reg, y)) => let
				val rhs' = inc rhs
			      in
				if is_imm16 rhs' then
				  (sltu, (lhs, rhs'), iftrue)
				else (* imm16+1 or imm32 case *)
				  (sltu, (lhs, rhs'), iftrue)
			      end
			    | _ => Crash.impossible "hint not is_reg failed"
			end

			val test_instr = let
			  (* fun gen_test (test, (lhs, rhs)) = let *)
			  val comment = case mn of
			    MirTypes.BLT => "<"
			  | MirTypes.BLE => "<="
			  | MirTypes.BLS => "<=u"
			  | MirTypes.BLO => "<u"
			  | MirTypes.BNT => "&="
			  | MirTypes.BTA => "&!"
			  | _ => Crash.impossible "comment failed"
			in
			  if is_imm32 rhs then
			    load_imm_into_register (MachTypes.global, rhs)
			    @@
			    [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (test, MachTypes.global, lookup_gp_operand lhs,
			       Mips_Assembly.REG MachTypes.global), absent, comment),
			     nop]
			  else let
			    val rhs' = if is_reg rhs then Mips_Assembly.REG (lookup_gp_operand rhs)
				       else (* is imm16 rhs *) Mips_Assembly.IMM (get_small_imm rhs)
			  in
			    if is_imm lhs then
			      load_imm_into_register (MachTypes.global, lhs)
			      @@
			      [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				(test, MachTypes.global, MachTypes.global, rhs'), absent, comment),
			       nop]
			    else (* is imm16 rhs or reg rhs *)
			      [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				(test, MachTypes.global, lookup_gp_operand lhs, rhs'),
				absent, comment)]
			  end
			end
			val branch_instr = let 
			  (* fun gen_branch branch = let *)
			  val branch =
			    if      branch = bgtz then Mips_Assembly.BGTZ
			    else if branch = bltz then Mips_Assembly.BLTZ
			    else if branch = blez then Mips_Assembly.BLEZ
			    else if branch = bgez then Mips_Assembly.BGEZ
			    else if branch = iffalse then Mips_Assembly.BEQ
			    else if branch = iftrue then Mips_Assembly.BNE
				 else Crash.impossible "gen_branch failed"
			in
			  [(Mips_Assembly.BRANCH
			    (branch, MachTypes.global, zero, 0),
			    Option.PRESENT tag, "branch"),
			   nop]
			end
		      in
			(* blt ble bls blo bne beq
			 * lhs rhs
			 * lhs imm16
			 * lhs imm32
			 * imm16 rhs
			 * imm32 rhs
			 *)
			(test_instr @@ branch_instr,
			 opcode_list, block_list, final_result)
		      end
		  end

	    | MirTypes.FTEST(fcond_branch, tag, fp_operand,
				 fp_operand') =>
		  let
		    val rs1 = lookup_fp_operand fp_operand
		    val rs2 = lookup_fp_operand fp_operand'
d3309 4
a3312 2
		    ([(Mips_Assembly.FCMP(test_instr, rs1, rs2),
		       absent, "Do the test"),
d3314 1
a3314 1
		      (Mips_Assembly.FBRANCH(branch, 0), (* was annulled *)
d3316 1
a3316 2
		      nop],
		    opcode_list, block_list, final_result)
a3317 3
		      
		    
		    
@


1.73
log
@fix large imm problem, update mirtypes.test for unsigned code, shortcuts
[eg [<u lhs zero] -> bnez lhs, optimize zero_reg tests
@
text
@d3180 15
a3194 17
		      val branch = case mn of
			MirTypes.BEQ => gp1 =  gp2
		      | MirTypes.BNE => gp1 <> gp2
		      | MirTypes.BGT => gp11 > gp21
			  orelse (gp11 = gp21 andalso gp12 > gp22)
		      | MirTypes.BLE => gp11 < gp21
			  orelse (gp11 = gp21 andalso gp12 <= gp22)
		      | MirTypes.BGE => gp11 > gp22
			  orelse (gp11 = gp21 andalso gp12 >= gp22)
		      | MirTypes.BLT => gp11 < gp21
			  orelse (gp11 = gp21 andalso gp12 < gp22)
		      | MirTypes.BNT => Bits.andb (gp12, gp22) =  0
		      | MirTypes.BTA => Bits.andb (gp12, gp22) <> 0
		      | MirTypes.BHI => Crash.impossible "TEST: const BHI"
		      | MirTypes.BLS => Crash.impossible "TEST: const BLS"
		      | MirTypes.BHS => Crash.impossible "TEST: const BHS"
		      | MirTypes.BLO => Crash.impossible "TEST: const BLO"
d3268 3
a3270 6
			  if is_imm lhs andalso is_imm rhs then
			    Crash.impossible "zero_reg optimisation failed"
			  else (* default *)
			    ([(Mips_Assembly.BRANCH branch_instr, Option.PRESENT tag, comment),
			      nop],
			     opcode_list, block_list, final_result)
d3289 2
d3292 1
d3304 3
a3306 1
				     
d3309 3
d3314 1
d3316 11
a3326 2
			    | (MirTypes.BLO, (Imm16, Reg)) => (sltu, (rhs, inc lhs), iffalse)
			    | (MirTypes.BLO, (Imm32, Reg)) => (sltu, (rhs, inc lhs), iffalse)
d3329 1
d3331 2
d3335 3
d3340 2
d3343 2
d3347 9
a3355 2
			    | (MirTypes.BLS, (Reg, Imm16)) => (sltu, (lhs, inc rhs), iftrue)
			    | (MirTypes.BLS, (Reg, Imm32)) => (sltu, (lhs, inc rhs), iftrue)
@


1.72
log
@emit for BLO case (incomplete stub so that compiler can bootstrap)
@
text
@d448 1
d1377 1
d1618 4
d3116 1
a3116 1
(*
d3118 45
a3162 22
		    val (test,mn') = case mn of
		      MirTypes.BNT => ([], Mips_Assembly.BEQ)
		    | MirTypes.BTA => ([], Mips_Assembly.BNE)
		    | MirTypes.BEQ => ([], Mips_Assembly.BEQ)
		    | MirTypes.BNE => ([], Mips_Assembly.BNE)
		    | MirTypes.BGT => ([Mips_Assembly.SLT], Mips_Assembly.BNE)
		    | MirTypes.BLE => ([Mips_Assembly.SLT], Mips_Assembly.BEQ)
		    | MirTypes.BGE => ([Mips_Assembly.SLT], Mips_Assembly.BEQ)
		    | MirTypes.BLT => ([Mips_Assembly.SLT], Mips_Assembly.BNE)
		    | MirTypes.BHI => (* bgtu *)
			([Mips_Assembly.SLTU], Mips_Assembly.BNE)
		    | MirTypes.BLS => (* bleu *)
			([Mips_Assembly.SLTU], Mips_Assembly.BEQ)
		    | MirTypes.BHS => (* bgeu *)
			([Mips_Assembly.SLTU], Mips_Assembly.BEQ)
		    | MirTypes.BLO => (* bltu *)
			([Mips_Assembly.SLTU], Mips_Assembly.BNE)

		    (* slt needs reversed operands *)
		    val slt_rev = case mn' of
		      MirTypes.BGE => false
		    | MirTypes.BLT => false
d3164 1
a3164 1
		    | MirTypes.BLO => false
d3166 11
a3176 19

		    val swappable = case mn of (* lhs & rhs are swappable *)
		      MirTypes.BNT => true
		    | MirTypes.BTA => true
		    | MirTypes.BEQ => true
		    | MirTypes.BNE => true
		    | _ => false

		    val swap = (* lhs is a const *)
		      swappable
		      andalso (not (is_reg lhs))
		      andalso (is_reg rhs)
			
		    val redo = (not swappable) (* lhs is a big const *)
		      andalso (not (is_reg lhs))
		      andalso (is_reg rhs)
		      
		    val (lhs, rhs) = if swap then (rhs, lhs) else (lhs, rhs)
		      
d3178 38
a3215 9
		    if redo then (* shove it into a global *)
		      (MirTypes.UNARY (MirTypes.MOVE, global_reg, rhs)
		       :: MirTypes.TEST (mn, tag, lhs, global_reg)
		       :: opcode_list, block_list, final_result)
		    else if swap then
		      if not (gp_check_range (rhs, true, arith_imm_limit)) then
			(* stuff into global *)
			(MirTypes.UNARY (MirTypes.MOVE, global_reg, lhs)
			 :: MirTypes.TEST (mn, tag, global_reg, rhs)
d3217 8
a3224 28
		      else (* generate MIPS itself *)
			if test = [] then (* no need test instr *)
			  ([(Mips_Assembly.BRANCH (mn', lhs', rhs', 0), Option.PRESENT tag,
			     "Do the test")
			    :: Mips_Assembly.nop],
			  opcode_list, block_list, final_result)
			else (* needs test instr *)
			  ((if slt_rev then
			      (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (test, global, rhs' lhs'), absent, "Do the test")
			    else
			      (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (test, global, lhs', rhs'), absent, "Do the test2"))
			      ::
			      [(Mips_Assembly.BRANCH
				(mn', lhs', Mips_Assembly.zero, 0), Option.PRESENT tag,
				"do the test")
			       :: Mips_Assembly.nop],
			      opcode_list, block_list, final_result)
			    
		    else if is_reg rhs (* both sides are registers *) then
		      (* generate MIPS code *)
		      nop
		    else (* both sides are constants *)
		      (* precalculate *)
		  end (* patternlet *)
		    
*)
d3226 55
a3280 26
		| MirTypes.TEST(cond_branch, tag, gp_operand, gp_operand') =>
		    let

		        
		      val zero_virtual = case MirRegisters.zero of
			Option.PRESENT zero_virtual => zero_virtual
		      | _ => Crash.impossible "TEST: zero_virtual failed"
		      fun make_reg0_from_imm0 (MirTypes.GP_IMM_INT 0) = 
			MirTypes.GP_GC_REG zero_virtual
			| make_reg0_from_imm0 (MirTypes.GP_IMM_ANY 0) 
			  = MirTypes.GP_GC_REG zero_virtual
			| make_reg0_from_imm0 a = a

		      val (branch, short) = case cond_branch of
			MirTypes.BNT => (Mips_Assembly.BEQ,  false)
		      | MirTypes.BTA => (Mips_Assembly.BNE,  false)
		      | MirTypes.BEQ => (Mips_Assembly.BEQ,  true)
		      | MirTypes.BNE => (Mips_Assembly.BNE,  true)
		      | MirTypes.BGT => (Mips_Assembly.BGTZ, false)
		      | MirTypes.BLE => (Mips_Assembly.BLEZ, false)
		      | MirTypes.BGE => (Mips_Assembly.BGEZ, false)
		      | MirTypes.BLT => (Mips_Assembly.BLTZ, false)
		      | MirTypes.BHI => (Mips_Assembly.BNE, false) (* bgtu *)
		      | MirTypes.BLS => (Mips_Assembly.BEQ, false) (* bleu *)
		      | MirTypes.BHS => (Mips_Assembly.BEQ, false) (* bgeu *)
		      | MirTypes.BLO => (Mips_Assembly.BNE, false) (* bltu *)
d3282 46
a3327 14
		      val (branch, gp_op, gp_op') =
			case gp_operand of
			  MirTypes.GP_GC_REG _ =>
			    (branch, gp_operand, make_reg0_from_imm0 gp_operand')
			| MirTypes.GP_NON_GC_REG _ =>
			    (branch, gp_operand, make_reg0_from_imm0 gp_operand')
			| _ => (Mips_Assembly.reverse_branch branch, gp_operand',
				make_reg0_from_imm0 gp_operand)

		      (* are both operands constants? *)
		      val constant = case gp_op of
			MirTypes.GP_GC_REG _     => false
		      | MirTypes.GP_NON_GC_REG _ => false
		      | _                        => true
d3329 44
a3372 46
		    in
		      if constant (* both operands are constants *) then let
			val gp1 as (gp11, gp12) = gp_value gp_operand
			val gp2 as (gp21, gp22) = gp_value gp_operand'
			val branch = case cond_branch of
			  MirTypes.BEQ => gp1 =  gp2
			| MirTypes.BNE => gp1 <> gp2
			| MirTypes.BGT => gp11 > gp21 orelse (gp11 = gp21 andalso gp12 > gp22)
			| MirTypes.BLE => gp11 < gp21 orelse (gp11 = gp21 andalso gp12 <= gp22)
			| MirTypes.BGE => gp11 > gp22 orelse (gp11 = gp21 andalso gp12 >= gp22)
			| MirTypes.BLT => gp11 < gp21 orelse (gp11 = gp21 andalso gp12 < gp22)
			| MirTypes.BNT => Bits.andb (gp12, gp22) =  0
			| MirTypes.BTA => Bits.andb (gp12, gp22) <> 0
			| MirTypes.BHI => Crash.impossible "TEST: unsigned constant operands"
			| MirTypes.BLS => Crash.impossible "TEST: unsigned constant operands"
			| MirTypes.BHS => Crash.impossible "TEST: unsigned constant operands"
			| MirTypes.BLO => Crash.impossible "TEST: unsigned constant operands"
		      in (* let *)
			if branch (* precalculate comparison of operands *) then
			  (* remainder of opcode_list irrelevant here *)
			  ([],
			   [MirTypes.BRANCH( MirTypes.BRA, MirTypes.TAG tag)],
			   block_list, final_result)
			else (* Branch is nop in this case *)
			  ([], opcode_list, block_list, final_result)
		      end (* let *)
		      else if is_reg gp_op' orelse
			gp_check_range(gp_op', true, arith_imm_limit) then
			let
			  val rs1 = lookup_gp_operand gp_op

			  (* some arguments are reversed to allow for limited
			   * mips instruction set *)
			  val (test_instr, reversed) = case cond_branch of
			    MirTypes.BTA => (Mips_Assembly.AND,  false)
			  | MirTypes.BNT => (Mips_Assembly.AND,  false)
			  | MirTypes.BHI => (Mips_Assembly.SLTU, true)  (* bgtu *)
			  | MirTypes.BLS => (Mips_Assembly.SLTU, true)  (* bleu *)
			  | MirTypes.BHS => (Mips_Assembly.SLTU, false) (* bgeu *)
			  | MirTypes.BLO => (Mips_Assembly.SLTU, false) (* bltu *)
			  | _            => (Mips_Assembly.SUB,  false)
			  val reg_or_imm =
			    if is_reg gp_op' then
			      Mips_Assembly.REG(lookup_gp_operand gp_op')
			    else
			      convert_small_imm gp_op'
d3374 4
a3377 77
			  if short then
                            case reg_or_imm of
                              Mips_Assembly.REG stuff =>
                                ([(Mips_Assembly.BRANCH
                                   (branch, rs1, stuff, 0), 
                                   Option.PRESENT tag, "Do the branch"),
                                  nop], 
                                opcode_list, block_list, final_result)
                            | Mips_Assembly.IMM imm =>
				([move_imm (global,imm),
				  (Mips_Assembly.BRANCH (branch, rs1, global, 0),
				   Option.PRESENT tag, "Do the branch"),
				  nop], 
				opcode_list, block_list, final_result)
(*
			    if (is_reg gp_op') then
			      ([(Mips_Assembly.BRANCH
				 (branch, rs1, lookup_gp_operand gp_op', 0), 
				 Option.PRESENT tag, "Do the branch"),
				nop], 
			       opcode_list, block_list, final_result)
			    else
                              (* Haven't we excluded this case? *)
			      if gp_op' = MirTypes.GP_GC_REG zero_virtual then
				([(Mips_Assembly.BRANCH
				   (branch, rs1, zero, 0), 
				   Option.PRESENT tag, "Do the branch"),
				  nop], 
				 opcode_list, block_list, final_result)
			      else
				([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				   (Mips_Assembly.OR, 
				    global, zero, reg_or_imm), 
				   absent, "temporary register"),
				  (Mips_Assembly.BRANCH (branch, rs1, global, 0),
				   Option.PRESENT tag, "Do the branch"),
				  nop], 
				opcode_list, block_list, final_result)
*)
			  else
			    if gp_op' = MirTypes.GP_GC_REG zero_virtual then
			      ([(Mips_Assembly.BRANCH
				 (branch, rs1, zero, 0), 
				 Option.PRESENT tag, "Do the branch"),
				nop], 
			       opcode_list, block_list, final_result)
			    else
			      ((if reversed then (* swap arguments around *) let
				  exception Swap;
				  fun swap (gp_op, gp_op') = let
				    val imm_or_reg =
				      if is_reg gp_op then
					Mips_Assembly.REG (lookup_gp_operand gp_op)
				      else
					convert_small_imm gp_op'
				  in
				    if is_reg gp_op' then
				      (lookup_gp_operand gp_op', imm_or_reg)
				    else
				      raise Swap
				  end
				val (gp_op, gp_op') = swap (gp_op, gp_op')
			      in 
				(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (test_instr, global, gp_op, gp_op'),
				  absent, "testing...")
			      end
				else (* not usigned stuff *)
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				   (test_instr, global,
				    rs1, reg_or_imm),
				   absent, "Do the test")
				 )::
				  [(Mips_Assembly.BRANCH(branch, global, zero, 0),
				    Option.PRESENT tag, "Do the branch"),
				   nop],
				 opcode_list, block_list, final_result)
d3379 9
a3387 5
		      else
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					global_reg, gp_op') ::
			 MirTypes.TEST(cond_branch, tag, gp_op, global_gp) ::
d3389 4
a3392 16
		    end
		(* T[FTEST fcond_branch tag rs1 rs2] => 
		      test rs1 rs2 "do the test"
		      nop
		   where
		      case fcond_branch of
		         FBEQ => (C_EQ_, BC1T)
			 FBNE => (C_EQ,  BC1F)
			 FBLE => (C_OLE, BC1T)
			 FBLT => (C_OLT, BC1T)
			 FBEQ => (C_EQ,  BC1T)
			 FBNE => (C_EQ,  BC1F)
			 FBLE => (C_OLE, BC1T)
			 FBLT => (C_OLT, BC1T)
*)
		| MirTypes.FTEST(fcond_branch, tag, fp_operand,
d3417 3
@


1.71
log
@Add WORD to value_cg
@
text
@d7 3
d3110 85
a3195 16
		(* T[TEST cond_branch tag gp_operand gp_operand'] =>
		   where
		      (branch, short) = case cond_branch of
		         | BNT => (BEQ, false)
			 | BTA => (BNE, false)
			 | BEQ => (BEQ, true)
			 | BNE => (BNE, true)
			 | BGT => (BGTZ,false) (* unary *)
			 | BLE => (BLEZ,false) (* unary *)
			 | BGE => (BGEZ,false) (* unary *)
			 | BLT => (BLTZ,false) (* unary *)
			 | BHI => BANG! "Bcc BHI unsupported"
			 | BLS => BANG! "Bcc BLS unsupported" 
			 | BHS => BANG! "Bcc BHS unsupported"
			 | BLO => BANG! "Bcc BLO unsupported"
		 *)
d3198 2
d3208 1
d3210 13
a3222 12
			MirTypes.BNT => (Mips_Assembly.BEQ, false)
		      | MirTypes.BTA => (Mips_Assembly.BNE, false)
		      | MirTypes.BEQ => (Mips_Assembly.BEQ, true)
		      | MirTypes.BNE => (Mips_Assembly.BNE, true)
		      | MirTypes.BGT => (Mips_Assembly.BGTZ, false) (* unary *)
		      | MirTypes.BLE => (Mips_Assembly.BLEZ, false) (* unary *)
		      | MirTypes.BGE => (Mips_Assembly.BGEZ, false) (* unary *)
		      | MirTypes.BLT => (Mips_Assembly.BLTZ, false) (* unary *)
		      | MirTypes.BHI => Crash.impossible "MirTypes.Bcc BHI unsupported"
		      | MirTypes.BLS => Crash.impossible "MirTypes.Bcc BLS unsupported"
		      | MirTypes.BHS => Crash.impossible "MirTypes.Bcc BHS unsupported"
		      | MirTypes.BLO => Crash.impossible "MirTypes.Bcc BLO unsupported"
d3225 6
a3230 4
			  MirTypes.GP_GC_REG _     => (branch, gp_operand, make_reg0_from_imm0 gp_operand')
			| MirTypes.GP_NON_GC_REG _ => (branch, gp_operand, make_reg0_from_imm0 gp_operand')
			| _ => (Mips_Assembly.reverse_branch branch, gp_operand', make_reg0_from_imm0 gp_operand)

d3268 11
a3278 4
			  val test_instr = case cond_branch of
			    MirTypes.BTA => Mips_Assembly.AND
			  | MirTypes.BNT => Mips_Assembly.AND
			  | _            => Mips_Assembly.SUB
d3332 30
a3361 8
			      ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				 (test_instr, global,
				  rs1, reg_or_imm),
				 absent, "Do the test"),
				(Mips_Assembly.BRANCH(branch, global, zero, 0),
				 Option.PRESENT tag, "Do the branch"),
				nop],
			      opcode_list, block_list, final_result)
@


1.70
log
@Add CHAR to value_cg
@
text
@d7 3
d554 1
@


1.69
log
@Fix code generation problems with shifts
@
text
@d7 3
d550 1
@


1.68
log
@Fixing problem with not restoring fp registers
@
text
@d7 3
d1905 10
a1914 18
			  if is_reg_gp' orelse
			    gp_check_range(gp', true, arith_imm_limit) then
			    let
			      val reg_or_imm =
				if is_reg_gp' then
				  Mips_Assembly.REG(lookup_gp_operand gp')
				else convert_small_imm gp'
			    in
			      ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				 (opcode, rd, lookup_gp_operand gp, reg_or_imm), absent, "")],
			       opcode_list, block_list, final_result)
			    end
			  else
			    ([],
			     MirTypes.UNARY(MirTypes.MOVE,
					    global_reg, gp') ::
			     MirTypes.TBINARY(tagged_op, tag,
					      reg, gp, global_gp) ::
d1916 8
d1976 17
d1994 1
a1994 1
			 val (opcode, gp_operand') =
d1996 2
a1997 2
			     MirTypes.ADD => (Mips_Assembly.ADD, gp_operand')
			   | MirTypes.SUB => (Mips_Assembly.SUB, gp_operand')
d2004 2
a2005 2
			   | MirTypes.AND => (Mips_Assembly.AND, gp_operand')
			   | MirTypes.OR => (Mips_Assembly.OR, gp_operand')
d2008 4
a2011 6
			   | MirTypes.EOR => (Mips_Assembly.XOR, gp_operand')
			   | MirTypes.LSR => (Mips_Assembly.SRL, gp_operand')
			   (* Temporary conversion into SRA from SRL *)
			   (* And back again *)
			   | MirTypes.ASL => (Mips_Assembly.SLL, gp_operand')
			   | MirTypes.ASR => (Mips_Assembly.SRA, gp_operand')
d2022 9
a2030 7
			   else if is_reg gp_operand' then
			     if needs_reverse opcode then
			       (gp_operand, gp_operand', true)
			     else
			       (gp_operand', gp_operand, false)
				else (* Both immediate so no problem *)
				  (gp_operand, gp_operand', false)
d2032 1
a2032 1
			 if redo then
d2061 3
a2063 1
			   if is_reg gp_operand then
d2065 16
a2080 1
			       val rs1 = lookup_gp_operand gp_operand
d2082 1
a2082 3
			       if is_reg gp_operand' orelse
				 gp_check_range(gp_operand', true,
						arith_imm_limit) then
d2084 16
a2099 5
				   val reg_or_imm =
				     if is_reg gp_operand' then
				       Mips_Assembly.REG(lookup_gp_operand
							 gp_operand')
				     else convert_small_imm gp_operand'
d2101 148
a2248 3
				   ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				      (opcode, rd, rs1, reg_or_imm), absent, "")],
				    opcode_list, block_list, final_result)
d2251 2
d2254 60
a2313 14
				   val inter_reg =
				     case gp_operand of
				       MirTypes.GP_GC_REG r =>
					 (if r = global_mir then
					    (* The nasty case *)
					    (case reg_operand of
					       MirTypes.GC_REG r' =>
						 if r = r' then
						   Crash.impossible
						   "source and dest global with large int"
						 else
						   r'
					     | MirTypes.NON_GC_REG _ =>
						 Crash.impossible"BINARY doesn't deliver GC")
d2315 36
a2350 2
					    global_mir)
				     | _ => Crash.impossible "BINARY has non-gc register"
d2352 9
a2360 8
				   ([],
				    MirTypes.UNARY(MirTypes.MOVE,
						   MirTypes.GC_REG inter_reg,
						   gp_operand') ::
				    MirTypes.BINARY(binary_op, reg_operand,
						    gp_operand,
						    MirTypes.GP_GC_REG inter_reg) ::
				    opcode_list, block_list, final_result)
d2364 58
a2421 8
			     ([],
			      MirTypes.UNARY(MirTypes.MOVE,
					     global_reg,
					     gp_operand) ::
			      MirTypes.BINARY(binary_op, reg_operand,
					      global_gp,
					      gp_operand') ::
			      opcode_list, block_list, final_result)
d2713 9
a2721 71
                    (*val _ = output(std_out,"\n MirTypes.STOREOP ... \n")*)
(*
		    val (shuffle, new_opcode_list) =
		      if is_reg gp_operand orelse
			gp_check_range(gp_operand, true, arith_imm_limit) then
			(
			 case opcode_list of
			   (store_op as MirTypes.STOREOP(MirTypes.LD, MirTypes.GC_REG g,
							 c_reg as MirTypes.GC_REG c,
							 MirTypes.GP_IMM_ANY ~1)) ::
			   (tail as (MirTypes.BRANCH_AND_LINK _ :: _)) =>
			     if g = global_mir andalso c = MirRegisters.caller_closure
			       andalso reg_operand' <> c_reg andalso reg_operand <> c_reg then
				 (true, store_op :: opcode :: tail)
			     else
			       (false, [])
			 | (store_op as MirTypes.STOREOP(MirTypes.LD, MirTypes.GC_REG g,
							 c_reg as MirTypes.GC_REG c,
							 MirTypes.GP_IMM_ANY ~1)) ::
			   (tail as (MirTypes.TAIL_CALL _ :: _)) =>
			     if (not needs_preserve) andalso
			       g = global_mir andalso c = MirRegisters.callee_closure
			       andalso reg_operand' <> c_reg andalso reg_operand <> c_reg then
			       (true, store_op :: opcode :: tail)
			     else
			       (false, [])
		         | (move_op as MirTypes.UNARY(MirTypes.MOVE, c_reg as MirTypes.GC_REG c,
						      MirTypes.GP_GC_REG r)) ::
			   (store_op as MirTypes.STOREOP(MirTypes.LD, MirTypes.GC_REG g,
							 MirTypes.GC_REG c',
							 MirTypes.GP_IMM_ANY ~1)) ::
			   (tail as (MirTypes.BRANCH_AND_LINK _ :: _)) =>
			     let
			       val r_reg = MirTypes.GC_REG r
			     in
			       if g = global_mir andalso c = MirRegisters.caller_closure
				 andalso c' = c
				 andalso reg_operand' <> c_reg
				 andalso reg_operand' <> r_reg
				 andalso reg_operand <> c_reg
				 andalso reg_operand <> r_reg then
				 (true, move_op :: store_op :: opcode :: tail)
			       else
				 (false, [])
			     end
		         | (move_op as MirTypes.UNARY(MirTypes.MOVE, c_reg as MirTypes.GC_REG c,
						      MirTypes.GP_GC_REG r)) ::
			   (store_op as MirTypes.STOREOP(MirTypes.LD, MirTypes.GC_REG g,
							 MirTypes.GC_REG c',
							 MirTypes.GP_IMM_ANY ~1)) ::
			   (tail as (MirTypes.TAIL_CALL _ :: _)) =>
			     let
			       val r_reg = MirTypes.GC_REG r
			     in
			       if (not needs_preserve) andalso
				 g = global_mir andalso c = MirRegisters.callee_closure
				 andalso c' = c
				 andalso reg_operand' <> c_reg
				 andalso reg_operand' <> r_reg
				 andalso reg_operand <> c_reg
				 andalso reg_operand <> r_reg then
				 (true, move_op :: store_op :: opcode :: tail)
			       else
				 (false, [])
			     end
			 | _ => (false, [])
			     )
		      else
			(false, [])
		    (* Don't bother if the store will use global, cos it won't work *)
*)
d2723 11
a2733 3
(*
		    if shuffle then
		      ([], new_opcode_list, block_list, final_result)
d2735 9
a2743 22
*)
		      let
			val rd = lookup_reg_operand reg_operand
			val rs1 = lookup_reg_operand reg_operand'
			val (load_or_store, noop_if_needed) = case store_op of
			  MirTypes.LD => (Mips_Assembly.LW, [nop])
			| MirTypes.ST => (Mips_Assembly.SW, [])
			| MirTypes.LDB => (Mips_Assembly.LBU, [nop])
			| MirTypes.STB => (Mips_Assembly.SB, [])
			| MirTypes.LDREF => (Mips_Assembly.LW, [nop])
			| MirTypes.STREF => (Mips_Assembly.SW, [])
		      in
			if is_reg gp_operand then
			  (* Difficult case, we have two registers for the store *)
			  (* but the mips doesn't allow this *)
			  ([],
			   MirTypes.BINARY
			   (MirTypes.ADD, global_reg,
			    gp_from_reg reg_operand', gp_operand) ::
			   MirTypes.STOREOP(store_op, reg_operand,
					    global_reg,
					    MirTypes.GP_IMM_ANY 0) ::
d2745 10
a2754 23
			   
			else
			  if gp_check_range(gp_operand, true, arith_imm_limit) then
			    let
			      val imm = case make_imm_for_store gp_operand of
				Mips_Assembly.IMM(n) => n
			      | _ => Crash.impossible "Store, expecting immediate offset"
			    in
			      (((Mips_Assembly.LOAD_AND_STORE(load_or_store, rd, rs1,
							      imm)), absent, "")
			       :: noop_if_needed,
			       opcode_list, block_list, final_result)
			    end
			else
			  ([],
			   MirTypes.UNARY(MirTypes.MOVE,
					  global_reg,
					  gp_operand) ::
			   MirTypes.STOREOP(store_op, reg_operand,
					    reg_operand',
					    global_gp) ::
			   opcode_list, block_list, final_result)
		      end
@


1.67
log
@Fix missing case in store floating point value
@
text
@d7 3
d3598 1
a3598 1
(* There are three kinds of frame: 
d3600 7
a3606 7
 	- Normal, which means it will fit in the leeway on the stack
		(i.e. if sp >= stackLimit, we're OK)
	- Medium, which means we can fit the frame size into an immediate
	- Large, which means we can't
		(so we put the frame size in 'global' and then keep it
		 there).
*)
d3625 1
a3625 1
(* there are five phases to the entry:
d3627 7
a3633 7
 	(0) saving the fp 
	(1) checking for stack overflow
 .stackOK:
	(2) making the stack frame and linkage,
	(3) saving any GC saves (already constructed as save_gcs),
	(4) initialising GC stack slots to zero. (can require a loop).
*)
d3635 1
a3635 1
(* (0) one instruction to save the fp *)
d3640 1
a3640 1
(* (1) checking for stack overflow *)
d3643 1
a3643 1
	(* first, get the value to check against the stack limit in a reg *)
d3660 1
a3660 1
	(* next, compare it to the stack limit and skip to part (2) if OK *)
d3685 1
a3685 1
	(* last, if the stack check failed, call the stack extension code *)
d3718 1
a3718 1
(* (2) making the stack frame and linkage *)			
d3751 1
a3751 1
(* (4) initialising  GC stack slots to zero *)
d3767 1
a3767 1
	(* For small numbers of stack slots, initialize each one separately *)
d3785 1
a3785 1
	(* For larger numbers, we make a loop *)
d3824 9
a3832 9
(* Now put it all together *)
(* phases 0 and 1 *)
			    val entry =
			      save_the_fp :: check_for_stack_overflow
(* phases 2, 3, and part of 4 *)			      
			    val stackOKblock = 
			      (stackOKTag,
			       make_frame @@ save_gcs @@ clear_frame_code)
(* rest of 4 is in clear_frame_blocks *)
@


1.66
log
@Remove message about restarting linearise_sub
@
text
@d7 3
d1536 8
a1543 8
		       Crash.impossible
		       ("non gc spill slot " ^ makestring i ^
			" requested, but only " ^
			makestring non_gc_spill_size ^
			" allocated\n")
		     else
		       ();
		       ~(non_gc_spill_offset + 4 * (1 + offset + i))
d1558 16
a1573 16
		  fun symbolic_value i = 
		    let 
		      val offset = if allow_fp_spare_slot then 1 else 0
		    in
		      (if i>= fp_spill_size then
			 Crash.impossible 
			 ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
			  " requested, but only " ^
			  MLWorks.Integer.makestring non_gc_spill_size ^
			  " allocated\n")
			 else 
			   ();
			   ~(fp_spill_offset + float_value_size * (1 + i) +
			     offset * spare_size)
			   )
		    end
d2593 13
a2605 4
				| _ => Crash.unimplemented "Store FP Op"
				in
			      (make_imm_for_store gp_operand, 
			       make_imm_for_store (MirTypes.GP_IMM_ANY (4+i)))
@


1.65
log
@Rewrote the allocation code to get ml_gc_leaf to work.
Also tidied it up, and added a bunch of shorthand
names for registers &c.
@
text
@d7 5
d1341 1
a1341 1
	    (output (std_out, "Found bad offset ... restarting linearise_sub\n");
@


1.64
log
@Change stack overflow entry code; using fp as a temporary breaks
the profiler.
@
text
@d7 4
d302 15
d364 1
a364 1
  fun make_imm_fault(0, signed, max_pos) = Mips_Assembly.REG MachTypes.zero_reg
d402 1
a402 1
     (Mips_Assembly.OR, rd, rs, Mips_Assembly.REG MachTypes.zero_reg),
d408 1
a408 1
     (Mips_Assembly.OR, rd, rs, Mips_Assembly.REG MachTypes.zero_reg), 
d414 1
a414 1
     (Mips_Assembly.ADDIU, rd, MachTypes.zero_reg, Mips_Assembly.IMM imm),
d421 1
a421 1
     (Mips_Assembly.ADDIU, rd, MachTypes.zero_reg, Mips_Assembly.IMM imm),
a423 5
  val global_mir = MirRegisters.global
  val global = MachTypes.global
  val global_op = Mips_Assembly.REG global
  val global_reg = MirTypes.GC_REG global_mir
  val global_gp = MirTypes.GP_GC_REG global_mir
d537 1
a537 1
  fun last_opcode [] = (Mips_Assembly.nop, false)
d982 1
a982 1
                                 move_regc (hacky_temporary_reg,MachTypes.lr,"Save current lr") ::
d985 1
a985 1
				   MachTypes.zero_reg, 1,
d997 1
a997 2
                                  (Mips_Assembly.ADD, global, MachTypes.lr,
                                   Mips_Assembly.REG global),
d999 1
a999 1
                                 move_regc (MachTypes.lr,hacky_temporary_reg,"Restore current lr") ::
d1001 2
a1002 3
				  (Mips_Assembly.JR, 
				   Mips_Assembly.REG global,
				   MachTypes.dummy_reg,
d1005 1
a1005 1
				 Mips_Assembly.nop ::
d1100 1
a1100 1
				   MachTypes.zero_reg, 1,
d1112 2
a1113 2
                                  (Mips_Assembly.ADD, global, MachTypes.lr,
                                   Mips_Assembly.REG global),
d1117 1
a1117 2
				  (Mips_Assembly.JALR, 
                                   Mips_Assembly.REG MachTypes.lr, global,
d1120 1
a1120 1
				 Mips_Assembly.nop ::
d1129 1
a1129 1
				   r, MachTypes.zero_reg, 7),
d1150 1
a1150 1
                                (Mips_Assembly.ADD, rd, MachTypes.zero_reg, Mips_Assembly.IMM disp),
d1164 1
a1164 1
				     MachTypes.zero_reg, i),
d1618 1
a1618 1
                  0 => [move_reg (reg, MachTypes.zero_reg)]
d1621 1
a1621 1
                      (Mips_Assembly.ADDIU, reg, MachTypes.zero_reg, Mips_Assembly.IMM i),
d1630 1
a1630 1
                      (Mips_Assembly.ORI, reg, MachTypes.zero_reg,
d1716 1
a1716 1
		    Mips_Assembly.nop ::
d2119 1
a2119 1
			  (Mips_Assembly.SUBU, rd, MachTypes.zero_reg,
d2154 1
a2154 1
		    (move_regc(lookup_reg_operand reg_operand, MachTypes.zero_reg, "clean")
d2277 1
a2277 1
		      Mips_Assembly.nop,
d2279 1
a2279 1
		      Mips_Assembly.nop],
d2335 1
a2335 1
		       Mips_Assembly.nop ::
d2337 1
a2337 1
		       Mips_Assembly.nop ::
d2459 1
a2459 1
			  MirTypes.LD => (Mips_Assembly.LW, [Mips_Assembly.nop])
d2461 1
a2461 1
			| MirTypes.LDB => (Mips_Assembly.LBU, [Mips_Assembly.nop])
d2463 1
a2463 1
			| MirTypes.LDREF => (Mips_Assembly.LW, [Mips_Assembly.nop])
d2518 1
a2518 1
			(MachTypes.single, MirTypes.FLD)    => (Mips_Assembly.LWC1, false, [Mips_Assembly.nop])
d2520 1
a2520 1
		      | (MachTypes.single, MirTypes.FLDREF) => (Mips_Assembly.LWC1, false, [Mips_Assembly.nop])
d2522 1
a2522 1
		      | (MachTypes.double, MirTypes.FLD)    => (Mips_Assembly.LWC1, false, [Mips_Assembly.nop])
d2524 1
a2524 1
		      | (MachTypes.double, MirTypes.FLDREF) => (Mips_Assembly.LWC1, false, [Mips_Assembly.nop])
d2642 1
a2642 1
			   (Mips_Assembly.MTC1, global, rd, Mips_Assembly.REG MachTypes.dummy_reg),
d2644 1
a2644 1
			  Mips_Assembly.nop,
d2755 1
a2755 1
			       (Mips_Assembly.CTC1, gl, MachTypes.R31, Mips_Assembly.REG MachTypes.dummy_reg),
d2757 1
a2757 1
			     Mips_Assembly.nop
d2761 1
a2761 1
			   (Mips_Assembly.CFC1, rd, MachTypes.R31, Mips_Assembly.REG MachTypes.dummy_reg),
d2763 1
a2763 1
			  :: Mips_Assembly.nop
d2768 1
a2768 1
			  (Mips_Assembly.CTC1, rd, MachTypes.R31, Mips_Assembly.REG MachTypes.dummy_reg),
d2770 1
a2770 1
			 Mips_Assembly.nop]
d2784 1
a2784 1
			  Mips_Assembly.REG MachTypes.dummy_reg), 
d2786 1
a2786 1
			Mips_Assembly.nop,
d2790 1
a2790 1
			Mips_Assembly.nop,
d2792 1
a2792 1
                        Mips_Assembly.nop,
d2796 1
a2796 1
			Mips_Assembly.nop,
d2798 1
a2798 1
                        Mips_Assembly.nop,
d2803 1
a2803 1
			Mips_Assembly.nop]
d2807 1
a2807 1
			  (Mips_Assembly.MFC1, rd, MachTypes.fp_global, Mips_Assembly.REG MachTypes.dummy_reg),
d2809 1
a2809 1
			 Mips_Assembly.nop,
d2825 1
a2825 1
			   Mips_Assembly.REG (lookup_reg_operand reg), MachTypes.dummy_reg,
d2828 1
a2828 1
			 Mips_Assembly.nop]
d2830 1
a2830 1
			[(Mips_Assembly.BRANCH(Mips_Assembly.BA, MachTypes.dummy_reg,MachTypes.dummy_reg,0),
d2833 1
a2833 1
			 Mips_Assembly.nop]),
d2934 1
a2934 1
                                  Mips_Assembly.nop], 
d2940 1
a2940 1
				  Mips_Assembly.nop], 
d2947 1
a2947 1
				Mips_Assembly.nop], 
d2953 1
a2953 1
				   (branch, rs1, MachTypes.zero_reg, 0), 
d2955 1
a2955 1
				  Mips_Assembly.nop], 
d2960 1
a2960 1
				    global, MachTypes.zero_reg, reg_or_imm), 
d2964 1
a2964 1
				  Mips_Assembly.nop], 
d2970 1
a2970 1
				 (branch, rs1, MachTypes.zero_reg, 0), 
d2972 1
a2972 1
				Mips_Assembly.nop], 
d2979 1
a2979 1
				(Mips_Assembly.BRANCH(branch, global, MachTypes.zero_reg, 0),
d2981 1
a2981 1
				Mips_Assembly.nop],
d3024 1
a3024 1
		      Mips_Assembly.nop,
d3027 1
a3027 1
		      Mips_Assembly.nop],
d3044 1
a3044 1
		       (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, global, debug_information),
d3046 1
a3046 1
		      Mips_Assembly.nop],
d3051 1
a3051 1
		      (Mips_Assembly.BGEZAL, MachTypes.zero_reg, 0,debug_info),
d3053 1
a3053 1
		     Mips_Assembly.nop],
d3090 1
a3090 1
                           (Mips_Assembly.LW, MachTypes.lr, MachTypes.sp, 8),
d3109 1
a3109 1
                        Mips_Assembly.nop
d3119 2
a3120 2
                           (Mips_Assembly.JR, Mips_Assembly.REG global, 
                            MachTypes.dummy_reg, 
d3128 1
a3128 1
                           (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
d3182 1
a3182 1
			   (Mips_Assembly.BGEZAL, MachTypes.zero_reg, 1,
d3186 1
a3186 1
			      (Mips_Assembly.ADDIU, MachTypes.lr, MachTypes.lr, Mips_Assembly.IMM (4*4)),
d3192 1
a3192 1
			      (Mips_Assembly.ADDU, MachTypes.lr, MachTypes.lr, Mips_Assembly.REG global),
d3195 1
a3195 1
			      (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr, MachTypes.dummy_reg, Debugger_Types.null_backend_annotation), 
d3197 1
a3197 1
			  :: Mips_Assembly.nop
d3200 1
a3200 1
				   (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0), 
d3211 1
a3211 1
				    (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0), 
d3218 1
a3218 1
					       (Mips_Assembly.BEQ, global, MachTypes.zero_reg, 0),
d3271 1
a3271 52
                  T[ALLOCATE allocate reg_operand GP_IMM_INT gp_operand] => 
                     | high == 0 =
		          add gc1 gc1 bytes "Size required"
			  sub global gc1 gc2 "gc?"
			  bltz global 6 "no gc? then branch"
			  add rd gc1 (primary-bytes) "tag primary in delay slot"
			  lw global gc_entry(implicit) "get gc entry"
			  move_regc rd zero "clear invalid data done in prev nop"
			  jalr lr global "call gc"
			  move_immc global bytes "pass size to gc"
			  add rd global primary "tag primary"
	                  | aligned = []
	                  | otherwise = 
			       sw zero (bytes-primary-4)(rd) "zero unaligned extra word"
			       secondary_code
                    | otherwise =
		         load_large_number_into_register rd bytes
			 add gc1 gc1 rd "Size required"
			 sub global gc1 gc2 "gc?"
			 bltz global 5 "no gc? then branch"
			 sub global gc1 rd "point to new object in delay slot"
			 lw global gc_entry(implicit) "get gc entry"
			 nop
			 jalr lr global "call gc"
			 move_regc global rd "pass arg size to gc"
                         | aligned = 
			      add rd global primary "tag primary"
	                 | otherwise =
			      add rd global rd "zero unaligned extra word at end"
			      sw zero ~4(rd) 
			      add rd global primary "tag primary"
			 secondary_code
		    where
		       secondary_code = 
                          | secondary == 0 = []
                          | otherwise = 
			       load_large_number_into_register global secondary
			       sw global ~primary(rd) "initialise secondary"

		       (bytes, primary, secondary, aligned) = 
                       case allocate of
                          | ALLOC = 
                               | size == 2 = (8, PAIRPTR, true, 0)
	                       | otherwise = (8 * ((size + 2) div 2), POINTER, size mod 2 <> 0, 64 * size + RECORD)
                          | ALLOC_VECTOR = (8 * ((size + 2) div 2), POINTER, size mod 2 <> 0, 64 * size + RECORD)
                          | ALLOC_STRING = ((size + 11) div 8) * 8, POINTER, true, 64 * size * STRING)
                          | ALLOC_REAL =
                               | fp_used == double = (16, POINTER, true, 64 * (16 - 4) + BYTEARRAY)
	                       | otherwise = BANG! "fp_used space unhandled"
                          | ALLOC_REF = (8 + 8 * ((size + 2) div 2), REFPTR, size mod 2 <> 0, 64 * size + ARRAY)
                          | ALLOC_BYTEARRAY = ((size + 11) div 8) * 8, REFPTR, true, 64 * size + BYTEARRAY)
                       (high,_) = split_imm bytes
d3274 1
a3274 1
		    let
d3276 6
a3281 1
			
d3284 1
a3284 1
			  (MachTypes.lr, 4 * Implicit_Vector.gc)
d3291 1
d3294 1
a3294 1
                          (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
d3296 26
a3321 1
                        Mips_Assembly.nop]
d3327 1
a3327 1
			  val (bytes, primary, aligned, secondary) =
d3331 1
a3331 1
				  (8, Tags.PAIRPTR, true, 0)
d3334 1
a3334 1
				   size mod 2 <> 0, 64*size+Tags.RECORD)
d3337 1
a3337 1
                                 size mod 2 <> 0, 64*size+Tags.RECORD)
d3340 1
a3340 1
				 Tags.POINTER, true, 64*size+Tags.STRING)
d3346 1
a3346 1
					(16, Tags.POINTER, true,
d3350 1
a3350 1
				 Tags.REFPTR, size mod 2 <> 0, 64*size+Tags.ARRAY)
d3352 1
a3352 1
				(((size+11) div 8) * 8, Tags.REFPTR, true,
d3355 1
a3355 1
			  val secondary_code =
d3362 1
a3362 1
                                 absent, "tag secondary")])
d3366 4
a3369 8
                              (Mips_Assembly.ADD, MachTypes.gc1, MachTypes.gc1, Mips_Assembly.IMM bytes), 
                              absent, "Size required"),
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                              (Mips_Assembly.SUB, global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2),
                              absent, "gc?"),
                             (Mips_Assembly.BRANCH
                              (Mips_Assembly.BLTZ, global, MachTypes.dummy_reg, 0),
                              Option.PRESENT end_gc_tag, "no gc? then branch"),
d3371 5
a3375 9
                              (Mips_Assembly.ADD, rd, MachTypes.gc1, Mips_Assembly.IMM (primary - bytes)),
                              absent, "tag primary in delay slot"),
                             (Mips_Assembly.LOAD_AND_STORE 
                              (Mips_Assembly.LW, global, MachTypes.implicit, gc_entry),
                              absent, "get gc entry"),
                             move_regc(rd,MachTypes.zero_reg,"clear invalid data set above"),
                             (Mips_Assembly.JUMP 
                              (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, global, Debugger_Types.null_backend_annotation), 
                              absent, "call gc"),
d3377 8
a3384 9
                             (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
                              (Mips_Assembly.ADD, rd, global, Mips_Assembly.IMM primary),
                              absent, "tag primary"),
                             (Mips_Assembly.BRANCH
                              (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
                              Option.PRESENT end_gc_tag, ""),
                             Mips_Assembly.nop],
                           (if aligned then
                              secondary_code
d3386 1
a3386 3
                              (Mips_Assembly.LOAD_AND_STORE 
                               (Mips_Assembly.SW, MachTypes.zero_reg, rd, bytes - primary - 4), absent, "Zero unaligned extra word") ::
                              secondary_code))
d3390 4
a3393 8
                               (Mips_Assembly.ADD, MachTypes.gc1, MachTypes.gc1, Mips_Assembly.REG rd),
                               absent, "try to get "^makestring bytes),
			      (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
                               (Mips_Assembly.SUB, global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2),
                               absent, "gc?"),
                              (Mips_Assembly.BRANCH
                               (Mips_Assembly.BLTZ, global, MachTypes.dummy_reg,0),
                               Option.PRESENT end_gc_tag, "no gc? then branch"),
d3395 1
a3395 1
                               (Mips_Assembly.SUB, global, MachTypes.gc1, Mips_Assembly.REG rd),
d3397 9
a3405 15
                              (Mips_Assembly.LOAD_AND_STORE 
                               (Mips_Assembly.LW, global, MachTypes.implicit, gc_entry), absent, "get gc entry"),
                              Mips_Assembly.nop,
                              (Mips_Assembly.JUMP 
                               (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, global, Debugger_Types.null_backend_annotation),
                               absent, "call gc"),
                              move_regc(global, rd, "pass arg size to gc"),
                             (Mips_Assembly.BRANCH
                              (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
                              Option.PRESENT end_gc_tag, ""),
                             Mips_Assembly.nop],
			     (if aligned then
				(Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, global, Mips_Assembly.IMM primary),
				 absent, "tag primary") ::
				secondary_code
d3407 7
a3413 6
				(Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, global, Mips_Assembly.REG rd),
				 absent, "zero unaligned extra word at end") ::
				(Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.zero_reg, rd, ~4), absent, "") ::
				(Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, global, Mips_Assembly.IMM primary),
				 absent, "tag primary") :: 
				secondary_code))
a3414 40
		      (*
		       T[ALLOCATE allocate reg_operand GP_GC_REG reg ] =>
		          length_code
			  addu gc1 gc1 rd "Size required"
			  sub global gc1 gc2 "gc?"
			  bltz global 8 "no? then branch"
			  subu global gc1 rd "point to new object"
			  lw global gc_entry(implicit) "get gc entry"
			  nop
			  jalr link global "call gc"
			  move_regc global rd "pass arg size to gc"
			  add rd global rd "zero unaligned extra word at end"
			  sw zero ~4(rd) 
			  add rd global primary "tag primary"
			  sll global reg 4
			  add global global secondary
			  sw global ~primary(rd) "tag secondary"
		       where
		          rd = reg_operand
			  length_code = 
			     get_length
			     and rd rd ~7 "ignore primary tag"

			  (primary, secondary, get_length) = 
                            case allocate of
			     | ALLOC_REF = (REFPTR, ARRAY,
			          add rd reg (12+7) "array length")
                             | ALLOC_BYTEARRAY = (REFPTR, BYTEARRAY,
			          srl rd reg 2 "bytearray length"
				  add rd rd (4+7))
                             | ALLOC_STRING = (POINTER, STRING,
			          srl rd reg 2 "string length"
				  add rd reg (4+7))
                             | ALLOC_VECTOR = (POINTER, RECORD,
			          add rd reg (4+7) "vector length")
                             | _ = crash
			  (link,gc_entry) =
                             | needs_preserve = (lr, 4 * gc)
                             | otherwise =      (gc2, 4 * gc_leaf)
*)
d3417 2
a3418 1
			    val (primary, secondary, get_length) =
d3422 1
a3422 4
                                     (Tags.POINTER,Tags.RECORD,
				      [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					(Mips_Assembly.ADD, rd, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM (4+7)),
					absent, "vector length")])
d3424 1
a3424 7
				     (Tags.POINTER, Tags.STRING,
				      [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					(Mips_Assembly.SRL, rd, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM 2),
					absent, "string length"),
				      (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				       (Mips_Assembly.ADD, rd, rd, Mips_Assembly.IMM (4+7)),
				       absent, "")])
d3427 1
a3427 4
				     (Tags.REFPTR, Tags.ARRAY,
				      [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					(Mips_Assembly.ADD, rd, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM (12+7)),
					absent, "array length")])                                
d3429 1
a3429 16
				     (Tags.REFPTR, Tags.BYTEARRAY,
				      [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
					(Mips_Assembly.SRL, rd, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM 2),
					absent, "bytearray length"),
				      (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				       (Mips_Assembly.ADD, rd, rd, Mips_Assembly.IMM (4+7)),
				       absent, "")])
			     val length_code =
			       get_length 
			       @@ [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				   (Mips_Assembly.SRL, rd, rd, Mips_Assembly.IMM 3),
				   absent, "clear bottom bits"),
				  (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				   (Mips_Assembly.SLL, rd, rd, Mips_Assembly.IMM 3),
				   absent, "and realign")]
			       
d3431 52
a3482 40
			    (length_code @@
			     [(Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			      (Mips_Assembly.ADDU, MachTypes.gc1, MachTypes.gc1, Mips_Assembly.REG rd), 
			      absent, "Size required"),
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			      (Mips_Assembly.SUB, global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2),
			      absent, "gc?"),
			     (Mips_Assembly.BRANCH
			      (Mips_Assembly.BLTZ, global, MachTypes.dummy_reg, 0), 
			      Option.PRESENT end_gc_tag, "no? then branch"),
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.SUBU, global, MachTypes.gc1, Mips_Assembly.REG rd),
			      absent, "point to new object"),
			     (Mips_Assembly.LOAD_AND_STORE 
			      (Mips_Assembly.LW, global, MachTypes.implicit, gc_entry), 
			      absent, "get gc entry"),
			     Mips_Assembly.nop,
			     (Mips_Assembly.JUMP 
			      (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, global, Debugger_Types.null_backend_annotation),
			      absent, "call gc"),
			     move_regc(global, rd, "pass arg size to gc"),
                             (Mips_Assembly.BRANCH
                              (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
                              Option.PRESENT end_gc_tag, ""),
                             Mips_Assembly.nop],
			     [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                               (Mips_Assembly.ADD, rd, global, Mips_Assembly.REG rd),
                               absent, "zero unaligned extra word at end"),
			      (Mips_Assembly.LOAD_AND_STORE 
                               (Mips_Assembly.SW, MachTypes.zero_reg, rd, ~4),
                               absent, ""),
                              (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                               (Mips_Assembly.ADD, rd, global, Mips_Assembly.IMM primary), absent, "tag primary"),
                              (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                               (Mips_Assembly.SLL, global, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM 4),
                               absent, ""),
                              (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, global, global, Mips_Assembly.IMM secondary),
                               absent, "tag secondary"),
                              (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, global, rd, ~primary),
                               absent, "")])
d3505 1
a3505 1
			      (Mips_Assembly.BGEZAL, MachTypes.zero_reg, 1,Debugger_Types.null_backend_annotation),
d3508 1
a3508 1
			      (Mips_Assembly.ADD, reg, MachTypes.lr,
d3538 1
a3538 1
			    (4 * Implicit_Vector.event_check, MachTypes.lr)
d3544 1
a3544 1
			     MachTypes.dummy_reg, 0),
d3560 2
a3561 2
			    (Mips_Assembly.BA, MachTypes.dummy_reg,
			     MachTypes.dummy_reg, 0),
d3563 1
a3563 1
			   Mips_Assembly.nop]
d3638 1
a3638 2
				     MachTypes.sp,
				     Mips_Assembly.REG global),
d3660 1
a3660 1
				   MachTypes.zero_reg,0),
d3689 2
a3690 2
				  (Mips_Assembly.BA, MachTypes.dummy_reg,
				   MachTypes.dummy_reg, 0),
d3692 1
a3692 1
				 Mips_Assembly.nop]
d3708 1
a3708 2
				    MachTypes.sp,
				    Mips_Assembly.REG global),
d3724 1
a3724 1
				(Mips_Assembly.SW, MachTypes.lr,
d3741 2
a3742 2
				(Mips_Assembly.BA, MachTypes.dummy_reg,
				 MachTypes.dummy_reg, 0), 
d3744 1
a3744 1
			       Mips_Assembly.nop]
d3752 1
a3752 1
				   (Mips_Assembly.SW, MachTypes.zero_reg,
d3777 2
a3778 2
				   (Mips_Assembly.BA, MachTypes.dummy_reg,
				    MachTypes.dummy_reg, 0),
d3780 1
a3780 1
				  Mips_Assembly.nop],
d3783 1
a3783 1
				    (Mips_Assembly.SW, MachTypes.zero_reg,
d3796 1
a3796 1
				     MachTypes.dummy_reg, 0),
d3798 1
a3798 1
				   Mips_Assembly.nop] @@
d3836 1
a3836 1
			 [(Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, MachTypes.lr, MachTypes.sp, 8), 
d3843 1
a3843 1
			  (Mips_Assembly.JUMP (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr,MachTypes.dummy_reg, Debugger_Types.null_backend_annotation),
d3845 1
a3845 1
			  Mips_Assembly.nop],
d3849 2
a3850 2
			(Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr, MachTypes.dummy_reg, Debugger_Types.null_backend_annotation),
			absent, "return"), Mips_Assembly.nop],
d3867 1
a3867 1
		      Mips_Assembly.nop], opcode_list, block_list, final_result)
d3887 1
a3887 1
		     :: Mips_Assembly.nop
d3889 1
a3889 1
			 (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr,
d3913 1
a3913 1
		      Mips_Assembly.nop,
d3916 1
a3916 1
		      Mips_Assembly.REG MachTypes.lr, global,
d3918 1
a3918 1
		     absent, "Do call_c"), Mips_Assembly.nop],
a4131 2
	    (* when ml_gc_leaf is checked in, this can be removed : *)
	    | check_instr(MirTypes.ALLOCATE _) = true
d4411 1
a4411 1
          val (nopcode,_,_) = Mips_Assembly.nop
@


1.63
log
@Partially fixing "restarting linearize_sub .." problem
@
text
@d7 3
d3767 1
a3767 1
				   Mips_Assembly.REG MachTypes.fp,
@


1.62
log
@Removing step and polyvariable options
@
text
@d7 3
d745 1
a745 1
      fun do_linearise proc_list =
d1320 1
a1320 1
	  do_linearise_sub(0, proc_list)
d1323 1
a1323 1
             do_linearise (subst_bad_offset_block(proc_list, bad_offset_block)))
d1325 4
@


1.61
log
@Move the debugging argument save.
Plus a few general tidying changes.
@
text
@d7 4
d1397 1
a1397 1
    (Options.OPTIONS {compiler_options = Options.COMPILEROPTIONS {generate_debug_info, debug_variables, generate_moduler, debug_polyvariables, opt_leaf_fns, ...},
d4242 1
a4242 1
            if generate_debug_info orelse debug_polyvariables orelse debug_variables orelse generate_moduler 
@


1.60
log
@Rearrange tail call instructions to make life easier for the profiler.
@
text
@d7 3
a260 1
  val debugging = false (* Leave this off for the moment *)
d263 4
a266 4
    [(Mips_Assembly.other_nop_code,Option.ABSENT,"Dummy instructions for tracing"),
     (Mips_Assembly.other_nop_code,Option.ABSENT,"Dummy instructions for tracing"),
     (Mips_Assembly.other_nop_code,Option.ABSENT,"Dummy instructions for tracing"),
     (Mips_Assembly.other_nop_code,Option.ABSENT,"Dummy instructions for tracing")]
d275 3
d279 2
a280 1
  val print_code_size = ref false
d282 5
a286 10
  val arith_imm_limit = 32768 (* 2 ** 15 *)
  val unsigned_arith_imm_limit = 2 * 32768 (* 2 ** 16 *)
  val branch_disp_limit = 32768 (* 2 ** 15 *)
  val call_disp_limit = 32768 (* 2 ** 15 *)

  (* Some numbers for the rest of the code *)

  (* These are the relevant sizes for high and low parts for SETHI *)
  val sethi_hisize = 1024 * 8 * 8 (* 2 ** 16 *)
  val sethi_losize = 1024 * 8 * 8 (* 2 ** 16 *)
d293 2
a294 1
    fun contract_sexpr(Sexpr.NIL, [], acc) = Lists.reducel (fn (x, y) => y @@ x) ([], acc)
d296 4
a299 2
      | contract_sexpr(Sexpr.ATOM x, to_do, acc) = contract_sexpr(Sexpr.NIL, to_do, x :: acc)
      | contract_sexpr(Sexpr.CONS(x, y), to_do, acc) = contract_sexpr(x, y :: to_do, acc)
d304 1
a304 1
  (* find_nop_offsets: searches for specific nop for use in linearisation debugging *)
a343 8
  (* checkOList: checks for properties in some elements of a list *)
  fun checkOList f e l = let
    fun checkList [] = e
      | checkList (x::xs) = f x orelse checkList xs
  in 
    checkList l 
  end (* checkOList *)
    
a354 4
  (* copy: duplicates element  N times *)
  fun copy 0 x = []
    | copy n x = x :: copy (n-1) x

d748 15
a763 10
	  (* The R4000 chip revision 2.2 (and earlier) has a bug in it that
	   can cause a failure when a jump register instruction is the last
	   instruction on a memory page, and accessing the next instruction
	   (i.e. the instruction in the delay slot) results in a TLB miss.  
	   By default, we avoid this situation by double-word aligning all 
	   jump register instructions (so that the instruction in the delay 
	   slot will be on the same page as the jump).  If you have a rev
	   3.0 (or higher) R4000, or you do not care about running on an 
	   R4000, then you may use this flag to turn off the fix and produce
	   "normal" code that will be slightly faster. *)
d1376 2
a1377 2
     fp_spill_size         : int, (* In singles, doubles or extendeds as appropriate *)
     fp_save_size          : int, (* As for non_fp_spill_size *)
d1383 1
a1383 1
     fp_save_offset        : int, (* In bytes*)
d1387 1
a1387 1
     allow_fp_spare_slot   : bool, (* Do we need a slot for float to int conversion? *)
a1388 1

d1408 1
d1712 6
a1717 10
(*
	  val real_non_gc_stack_size =
	    if non_gc_stack_size mod 8 = 0 orelse
	      MachTypes.fp_used = MachTypes.single then
	      non_gc_stack_size
	    else
	      non_gc_stack_size - 4
*)

	  fun do_save_gcs(_, []) = []
d1719 5
a1723 5
		  (Mips_Assembly.LOAD_AND_STORE 
		   (Mips_Assembly.SW, gc, MachTypes.fp,
		    offset), Option.ABSENT,
		   "save gcs") :: do_save_gcs(offset+4, rest)

d1736 4
a1739 1
	  val callee_save_size = Lists.length gcs_to_preserve
d3788 4
a3791 3
			    val universal_frame_linkage =
			      (* save values in the newly made slots *)
			      [(Mips_Assembly.LOAD_AND_STORE
a3799 12
			  in
                            (* It would be more convenient to save the arg of the calling function here *)
			    if debugging then 
			      push_frame_instruction ::
			      (Mips_Assembly.LOAD_AND_STORE
			       (Mips_Assembly.SW, MachTypes.arg,
				MachTypes.sp, 12),
			       absent, "save the argument for debugging") ::
			      universal_frame_linkage
			    else
			      push_frame_instruction ::
			      universal_frame_linkage
a4258 22
(* This stuff not necessary for the MIPS

(* This may need rewriting depending on how MIPs real to int and vice versa *)
	  fun block_needs_fp_spare(MirTypes.BLOCK(_, opc_list)) =
	    let
	      fun opc_needs_fp_spare [] = false
	      | opc_needs_fp_spare(MirTypes.REAL _ :: _) = true
	      | opc_needs_fp_spare(MirTypes.FLOOR _ :: _) = true
	      | opc_needs_fp_spare(_ :: rest) = opc_needs_fp_spare rest
	    in
	      opc_needs_fp_spare opc_list
	    end

	  fun proc_needs_fp_spare [] = false
	  | proc_needs_fp_spare(block :: block_list) =
	    block_needs_fp_spare block orelse proc_needs_fp_spare block_list

	  val needs_fp_spare = proc_needs_fp_spare block_list
*)

	  val needs_fp_spare = false

a4268 3
	  val non_gc_spill_size =
	    if needs_fp_spare then non_gc_spill_size + 1
	    else non_gc_spill_size
a4278 10
(* Unnecessary for MIPS as there are no store double instructions
	  val non_gc_spill_size =
	    if total_fp_size <> 0 andalso float_value_size = 4 andalso
	      non_gc_spill_size mod 2 <> 0 then
	      non_gc_spill_size + 1
	    (* Allow an extra word to get alignment for floats *)
	    else
	      non_gc_spill_size
*)

d4282 1
a4282 9
(* Again not needed for the MIPS
	  val gc_stack_size = gc_spill_size * 4 + stack_extra * 4
	  val non_gc_stack_size =
	    if (non_gc_stack_size + gc_stack_size) mod 8 = 0 then
	      non_gc_stack_size
	    else
	      non_gc_stack_size + 4
	  (* Ensure total stack requirement double aligned *)
*)
d4284 3
a4286 1
	  val callee_saves = Lists.qsort compare_reg (Lists.filterp check_reg (Set.set_to_list gcs))
d4289 4
a4292 9
(*
	  val gc_stack_area = non_gc_stack_size + 4 * gc_spill_size
	  (* Base of stack allocation area for gc objects *)
*)
	  val linkage_size = if debugging then 4 else 3
(*
 linkage area in each frame for fp, closure, link
 will be 4 when we get debugging working
*)
a4293 3
(*
	  val frame_size = gc_stack_size + non_gc_stack_size + (linkage_size  + callee_save_area) * 4
*)
d4295 2
a4296 1
	  val fp_save_offset = fp_spill_offset + fp_spill_size * float_value_size
a4297 1

a4300 1
	  val needs_preserve = needs_preserve orelse needs_fp_spare
d4308 1
a4308 1
	     register_save_size = 4 * (linkage_size + callee_save_area),
d4315 1
a4315 1
	     allow_fp_spare_slot = needs_fp_spare,
a4639 1

d4650 14
a4663 1
      val (proc_elements, code_list) = Lists.unzip(map list_proc_cg proc_list_list)
d4669 1
a4669 4
                   makestring (Lists.reducel( fn(x,Code_Module.WORDSET(Code_Module.WORD_SET{b=tagged_code', ...})) =>
                                            (Lists.reducel (fn (x,{d_code=y, ...}) => (size y) + x) (x,tagged_code'))
                                            | _ => Crash.impossible "what the ?")
                   (0,proc_elements)) ^ "\n")
a4691 1

@


1.59
log
@Turn on MIPS R4000 v 2.2 bug work-around
@
text
@d7 3
d3044 1
a3045 1
                             lw     lr             8(sp)
d3057 1
a3058 1
                             lw     lr             8(sp)
d3069 3
a3073 3
                          (Mips_Assembly.LOAD_AND_STORE
                           (Mips_Assembly.LW, MachTypes.lr, MachTypes.sp, 8),
                           absent, "reset link in delay slot"),
@


1.58
log
@Disabling generation of "debugging" code
@
text
@d7 3
d753 1
a753 1
	  val branches_double_word_aligned = false
@


1.57
log
@Fixing debugger stuff
@
text
@d7 3
d252 1
a252 1
  val debugging = true
@


1.56
log
@Changes to Options structure/
@
text
@d7 3
d249 1
a249 1
  val debugging = false
d955 3
a957 1
				   MachTypes.zero_reg, 1), Option.ABSENT,
d1040 1
a1040 1
		    | do_opcode((Mips_Assembly.CALL(call, r, i),
d1049 2
a1050 2
			       (Mips_Assembly.CALL(Mips_Assembly.BGEZAL,
						   r, disp), comment)
d1072 3
a1074 1
				   MachTypes.zero_reg, 1), Option.ABSENT,
d3019 1
a3019 1
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.TAG tag,_,_) =>
d3021 1
a3021 1
		      (Mips_Assembly.BGEZAL, MachTypes.zero_reg, 0),
d3152 2
a3153 1
			   (Mips_Assembly.BGEZAL, MachTypes.zero_reg, 1),
d3569 1
a3569 1
			      (Mips_Assembly.BGEZAL, MachTypes.zero_reg, 1),
d3795 1
d4340 1
a4340 1
	  val linkage_size = 3
d4645 20
d4668 2
a4669 20
                          Mips_Assembly.JUMP (_,_,_,debug) =>        
                            let
                              val unpadded_name =
                                let
                                  val s = size padded_name
                                  fun check_index to =
                                    if String.ordof(padded_name,to) = 0 
                                      then check_index(to-1)
                                    else String.substring(padded_name,0,to+1)
                                in
                                  check_index (s-1) 
                                  handle String.Substring => ""
                                       | Ord => ""
                                end
			     in
                               debug_map := Debugger_Types.add_annotation (unpadded_name,
                                                                           count,
                                                                           debug,
                                                                           !debug_map)
                            end
@


1.55
log
@Make arithmetic operations trap.
Also reduce code verbosity by adding some local names for things.
@
text
@d7 4
d185 1
d207 1
d239 1
a239 2
  structure Options = Debugger_Types.Options
  structure NewMap = Debugger_Types.NewMap
d1381 1
a1381 1
    (Options.OPTIONS {compiler_options = Options.COMPILEROPTIONS {debug, debug_variables, generate_moduler, debug_polyvariables, opt_leaf_fns, ...},
d4235 1
a4235 1
            if debug orelse debug_polyvariables orelse debug_variables orelse generate_moduler 
d4663 1
a4663 1
                     if debug
@


1.54
log
@Debugger changes
@
text
@a3 1
 based on Revision 1.161
d7 3
d386 6
d950 1
a950 1
                                  (Mips_Assembly.LUI, MachTypes.global, i-4),
d953 2
a954 2
                                  (Mips_Assembly.ADD_AND_MASK, MachTypes.global,
                                   Mips_Assembly.IMM i, MachTypes.global),
d957 2
a958 2
                                  (Mips_Assembly.ADD, MachTypes.global, MachTypes.lr,
                                   Mips_Assembly.REG MachTypes.global),
d963 1
a963 1
				   Mips_Assembly.REG MachTypes.global,
d1065 1
a1065 1
                                  (Mips_Assembly.LUI, MachTypes.global, i-4),
d1068 2
a1069 2
                                  (Mips_Assembly.ADD_AND_MASK, MachTypes.global,
                                   Mips_Assembly.IMM i, MachTypes.global),
d1072 2
a1073 2
                                  (Mips_Assembly.ADD, MachTypes.global, MachTypes.lr,
                                   Mips_Assembly.REG MachTypes.global),
d1078 1
a1078 1
                                   Mips_Assembly.REG MachTypes.lr, MachTypes.global,
d1392 1
a1392 1
      val gc_array = Array.array(gc, MachSpec.global)
d1398 1
a1398 1
      val non_gc_array = Array.array(non_gc, MachSpec.global)
d1404 1
a1404 1
      val fp_array = Array.array(fp, MachSpec.global)
d1815 2
a1816 36
		  (* T[TBINARY op tag r1 r2 r3] => (* not so good *)
		        | redo = T[MOVE global r2', TBINARY op tag r1 global r3']
			| isReg r2' =
			     | isReg r3' or gp_check_range r3' true arith_imm_limit =
			          [ xor temp_reg r2' 'check the sign of the sources'
				    op' r1 r2'
				    test temp_reg zero new_tag 'do the branch on ok'
				    xor temp_reg r2' r1 'check the sign of the results'
				    bltz temp_reg tag 'else go to exception'
				    nop
				    ba new_tag 'this branch removed on linearisation'
				    nop
				  ] BLOCK(new_tag, opcode_list) : block_list 
				    opcode_list@@[]
			     | otherwise = T[MOVEW global r3', TBINARY op' tag r1 r2' global]
			| otherwise = T[UNARY MOVE r1 r2', TBINARY op' tag r1 r2' r3']
			where
			   (redo, regTuple@@(r2',r3')) =
			      | isReg r2 = (false, regTuple)
			      | isReg r3 = 
				   | preserve_order op = (true, regTuple)
				   | otherwise = (false, swap regTuple)
			      | otherwise = (false, regTuple)
			   (op',test) =
			      | op == ADDV = (addu, bltz)
			      | op == SUBV = (subu, bgez)
			      | op == MULV = BANG!
			      | op == MODV = BANG!
			   temp_reg = global
			   preserve_order op =
			      | op == SUBV = true
			      | op == DIVV = true
			      | op == MODV = true
		  *)
		  MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
				   gp_operand, gp_operand') =>
d1818 19
a1836 16
		    val rd = lookup_reg_operand reg_operand
		    val temp_reg = MachTypes.global
		    val (opcode, test) = case tagged_binary_op of
		      MirTypes.ADDV => (Mips_Assembly.ADDU, Mips_Assembly.BLTZ)
		    | MirTypes.SUBV => (Mips_Assembly.SUBU, Mips_Assembly.BGEZ)
		    | MirTypes.MULV =>
			Crash.impossible"do_opcodes(TBINARY(MULV))"
		    | MirTypes.DIVV =>
			Crash.impossible"do_opcodes(TBINARY(DIVV))"
		    | MirTypes.MODV =>
			Crash.impossible"do_opcodes(TBINARY(MODV))"

		    fun preserve_order MirTypes.SUBV = true
		    | preserve_order MirTypes.DIVV = true
		    | preserve_order MirTypes.MODV = true
		    | preserve_order _ = false
d1838 3
a1840 14
		    val (gp_operand, gp_operand', redo) =
		      if is_reg gp_operand then
			(gp_operand, gp_operand', false)
		      else
                        if is_reg gp_operand'
                          then
                            if preserve_order tagged_binary_op 
                              then 
                                (gp_operand, gp_operand', true)
                            else 
                              (gp_operand', gp_operand, false)
                        else
                          (* Both are immediate so no problem *)
                          (gp_operand, gp_operand', false)
d1844 2
a1845 6
		       MirTypes.UNARY(MirTypes.MOVE,
				      MirTypes.GC_REG MirRegisters.global,
				      gp_operand) ::
		       MirTypes.TBINARY(tagged_binary_op, tag, reg_operand,
					MirTypes.GP_GC_REG MirRegisters.global,
					gp_operand') ::
d1848 3
a1850 8
		      if is_reg gp_operand then
			let
			  val rs1 = lookup_gp_operand gp_operand
			in
			  if is_reg gp_operand' orelse
			    gp_check_range(gp_operand', true,
					   arith_imm_limit) then
			    (* Actually making some code here *)
a1851 6
			      val new_tag = MirTypes.new_tag()
			      (* We're going to reverse the sense *)
			      (* of the overflow test, and rely on the *)
			      (* scheduler to fill delay slot. *)
			      (* This should shorten the normal *)
			      (* (non-overflow) path by one instruction *)
d1853 3
a1855 4
				if is_reg gp_operand' then
				  Mips_Assembly.REG(lookup_gp_operand
						     gp_operand')
				else convert_small_imm gp_operand'
d1857 3
a1859 32
(*			      ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				 (Mips_Assembly.XOR, temp_reg, rs1, reg_or_imm),
				 absent, "check the sign of the sources"),
				(Mips_Assembly.ARITHMETIC_AND_LOGICAL (*was tagged*)
				 (opcode, rd, rs1, reg_or_imm), absent, ""),
				(Mips_Assembly.BRANCH
				 (test, temp_reg, MachTypes.zero_reg, 0),
				 Option.PRESENT new_tag, "Do the branch on ok"),	
				(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				 (Mips_Assembly.XOR, temp_reg, rs1, Mips_Assembly.REG rd),
				 absent, "check the sign of the result"),
				(Mips_Assembly.BRANCH
				 (Mips_Assembly.BLTZ, temp_reg, MachTypes.dummy_reg, 0),
				 tag, "Else go to exception"),
				Mips_Assembly.nop,		
				(Mips_Assembly.BRANCH
				 (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
				 Option.PRESENT new_tag, "This branch removed on linearisation?"),	
				Mips_Assembly.nop],
			      [],
			      MirTypes.BLOCK(new_tag, opcode_list) :: block_list,
			      final_result)
*)
			      ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL (*was tagged*)
				 (opcode, rd, rs1, reg_or_imm), absent, ""),
				(Mips_Assembly.BRANCH
				 (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
				 Option.PRESENT new_tag, "This branch removed on linearisation?"),	
				Mips_Assembly.nop],
			       [],
			       MirTypes.BLOCK(new_tag, opcode_list) :: block_list,
			       final_result)
a1862 2
			     (* Ok to use the global register here *)
			     (* Because it won't be the result *)
d1864 3
a1866 8
					    MirTypes.GC_REG
					    MirRegisters.global,
					    gp_operand') ::
			     MirTypes.TBINARY(tagged_binary_op, tag,
					      reg_operand,
					      gp_operand,
					      MirTypes.GP_GC_REG
					      MirRegisters.global) ::
a1867 1
			end
d1869 5
a1873 11
			(* Oh dear, both operands gp *)
			(diagnostic_output 3
			  (fn _ => ["Mach_Cg(TBINARY) first arg not reg\n"]);
			 ([],
			  MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					 gp_operand) ::
			  MirTypes.TBINARY(tagged_binary_op, tag,
					   reg_operand,
					   gp_from_reg reg_operand,
					   gp_operand') ::
			  opcode_list, block_list, final_result))
d1905 1
a1905 1
			  MirTypes.UNARY(MirTypes.NOT, MirTypes.GC_REG MirRegisters.global,
d1908 1
a1908 1
					  MirTypes.GP_GC_REG MirRegisters.global) ::
d1912 1
a1912 1
			  MirTypes.UNARY(MirTypes.NOT, MirTypes.GC_REG MirRegisters.global,
d1916 1
a1916 1
					  MirTypes.GP_GC_REG MirRegisters.global) ::
d1964 1
a1964 1
				   (if r = MirRegisters.global then
d1975 1
a1975 1
				      MirRegisters.global)
d2011 1
a2011 1
					 (if r = MirRegisters.global then
d2023 1
a2023 1
					    MirRegisters.global)
d2039 1
a2039 1
					     MirTypes.GC_REG MirRegisters.global,
d2042 1
a2042 1
					      MirTypes.GP_GC_REG MirRegisters.global,
d2097 1
a2097 1
			      val rs1 = MachTypes.global
d2347 1
a2347 1
			     if g = MirRegisters.global andalso c = MirRegisters.caller_closure
d2357 1
a2357 1
			       g = MirRegisters.global andalso c = MirRegisters.callee_closure
d2371 1
a2371 1
			       if g = MirRegisters.global andalso c = MirRegisters.caller_closure
d2391 1
a2391 1
				 g = MirRegisters.global andalso c = MirRegisters.callee_closure
d2429 1
a2429 1
			   (MirTypes.ADD, MirTypes.GC_REG MirRegisters.global,
d2432 1
a2432 1
					    MirTypes.GC_REG MirRegisters.global,
d2451 1
a2451 1
					  MirTypes.GC_REG MirRegisters.global,
d2455 1
a2455 2
					    MirTypes.GP_GC_REG
					    MirRegisters.global) ::
d2504 1
a2504 1
					 MirTypes.GC_REG MirRegisters.global,
d2508 1
a2508 2
					    MirTypes.GC_REG
					    MirRegisters.global,
d2564 1
a2564 1
					 MirTypes.GC_REG MirRegisters.global,
d2568 1
a2568 2
					    MirTypes.GC_REG
					    MirRegisters.global,
d2593 1
a2593 1
			  MachTypes.global
d2597 1
a2597 1
			   (Mips_Assembly.SRA, MachTypes.global, lookup_gp_operand gp_operand, Mips_Assembly.IMM 2),
d2600 1
a2600 1
			   (Mips_Assembly.MTC1, MachTypes.global, rd, Mips_Assembly.REG MachTypes.dummy_reg),
d2609 2
a2610 5
					MirTypes.GC_REG MirRegisters.global,
					gp_operand) ::
			 MirTypes.REAL(int_to_float, fp_operand,
				       MirTypes.GP_GC_REG
				       MirRegisters.global) ::
d2733 1
a2733 1
		      (saveRoundingMode rd MachTypes.global
d2736 1
a2736 1
			move_imm(MachTypes.global,1),
d2738 1
a2738 1
                         (Mips_Assembly.SLL,MachTypes.global,MachTypes.global, Mips_Assembly.IMM 29),
d2741 1
a2741 1
			 (Mips_Assembly.MTC1, MachTypes.global, MachTypes.fp_global, 
d2895 2
a2896 2
				([move_imm (MachTypes.global,imm),
				  (Mips_Assembly.BRANCH (branch, rs1, MachTypes.global, 0),
d2918 1
a2918 1
				    MachTypes.global, MachTypes.zero_reg, reg_or_imm), 
d2920 1
a2920 1
				  (Mips_Assembly.BRANCH (branch, rs1, MachTypes.global, 0),
d2934 1
a2934 1
				 (test_instr, MachTypes.global,
d2937 1
a2937 1
				(Mips_Assembly.BRANCH(branch, MachTypes.global, MachTypes.zero_reg, 0),
d2945 2
a2946 5
					MirTypes.GC_REG
					MirRegisters.global,
					gp_op') ::
			 MirTypes.TEST(cond_branch, tag, gp_op,
				       MirTypes.GP_GC_REG MirRegisters.global) ::
d2998 1
a2998 1
		       (Mips_Assembly.ADDU, MachTypes.global,
d3002 1
a3002 1
		       (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, MachTypes.global, debug_information),
d3073 1
a3073 1
                           (Mips_Assembly.ADDU, MachTypes.global, lookup_reg_operand reg, Mips_Assembly.IMM 3),
d3077 1
a3077 1
                           (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.global, 
d3146 1
a3146 1
			      (Mips_Assembly.ADDU, MachTypes.global, reg, Mips_Assembly.REG reg),
d3149 1
a3149 1
			      (Mips_Assembly.ADDU, MachTypes.lr, MachTypes.lr, Mips_Assembly.REG MachTypes.global),
d3175 1
a3175 1
					       (Mips_Assembly.BEQ, MachTypes.global, MachTypes.zero_reg, 0),
d3178 1
a3178 1
					       (Mips_Assembly.SUB, MachTypes.global, reg, Mips_Assembly.IMM 4),
d3185 1
a3185 1
			else if not needs_preserve andalso reg = MachTypes.global then
d3336 1
a3336 1
			      (load_large_number_into_register (MachTypes.global, secondary) @@ 
d3338 1
a3338 1
                                 (Mips_Assembly.SW, MachTypes.global, rd, ~primary), 
d3346 1
a3346 1
                              (Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2),
d3349 1
a3349 1
                              (Mips_Assembly.BLTZ, MachTypes.global, MachTypes.dummy_reg, 0),
d3355 1
a3355 1
                              (Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, gc_entry),
d3359 1
a3359 1
                              (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, MachTypes.global, Debugger_Types.null_backend_annotation), 
d3361 1
a3361 1
                             move_immc(MachTypes.global, bytes, "pass size to gc"),
d3363 1
a3363 1
                              (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary),
d3381 1
a3381 1
                               (Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2),
d3384 1
a3384 1
                               (Mips_Assembly.BLTZ, MachTypes.global, MachTypes.dummy_reg,0),
d3387 1
a3387 1
                               (Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG rd),
d3390 1
a3390 1
                               (Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, gc_entry), absent, "get gc entry"),
d3393 1
a3393 1
                               (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, MachTypes.global, Debugger_Types.null_backend_annotation),
d3395 1
a3395 1
                              move_regc(MachTypes.global, rd, "pass arg size to gc"),
d3401 1
a3401 1
				(Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary),
d3405 1
a3405 1
				(Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.REG rd),
d3408 1
a3408 1
				(Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary),
d3499 1
a3499 1
			      (Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2),
d3502 1
a3502 1
			      (Mips_Assembly.BLTZ, MachTypes.global, MachTypes.dummy_reg, 0), 
d3505 1
a3505 1
			      (Mips_Assembly.SUBU, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG rd),
d3508 1
a3508 1
			      (Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, gc_entry), 
d3512 1
a3512 1
			      (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, MachTypes.global, Debugger_Types.null_backend_annotation),
d3514 1
a3514 1
			     move_regc(MachTypes.global, rd, "pass arg size to gc"),
d3520 1
a3520 1
                               (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.REG rd),
d3526 1
a3526 1
                               (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary), absent, "tag primary"),
d3528 1
a3528 1
                               (Mips_Assembly.SLL, MachTypes.global, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM 4),
d3530 1
a3530 1
                              (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, MachTypes.global, MachTypes.global, Mips_Assembly.IMM secondary),
d3532 1
a3532 1
                              (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.global, rd, ~primary),
d3599 1
a3599 1
			    (Mips_Assembly.LW, MachTypes.global,
d3606 1
a3606 1
			     MachTypes.global,
d3680 1
a3680 1
				    (Mips_Assembly.ADDIU, MachTypes.global,
d3686 1
a3686 1
				(MachTypes.global, frame_size)
d3690 1
a3690 1
				     Mips_Assembly.REG MachTypes.global),
d3698 1
a3698 1
				  | _ => MachTypes.global
d3702 1
a3702 1
				  | Medium => MachTypes.global
d3725 1
a3725 1
				      move_imm(MachTypes.global, frame_size)
d3761 1
a3761 1
				    Mips_Assembly.REG MachTypes.global),
d3835 1
a3835 1
				   (Mips_Assembly.ADDIU, MachTypes.global,
d3847 1
a3847 1
				     MachTypes.global, 0),
d3850 2
a3851 2
				    (Mips_Assembly.ADDI, MachTypes.global,
				     MachTypes.global, Mips_Assembly.IMM 4),
d3944 1
a3944 1
		      (Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, 4 *
d3953 1
a3953 1
			  MachTypes.global,
d3973 1
a3973 1
		       (Mips_Assembly.LW, MachTypes.global,
d3979 1
a3979 1
		      Mips_Assembly.REG MachTypes.lr, MachTypes.global,
d4195 1
a4195 1
	    (* ALLOCATE uses the link register and also requires the closure *)
d4197 1
d4237 1
@


1.53
log
@Make the test for stack overflow unsigned so it catches the asynch events.
@
text
@d8 3
d1368 1
a1368 1
    (Options.OPTIONS {compiler_options = Options.COMPILEROPTIONS {debug, debug_polyvariables, opt_leaf_fns, ...},
d4331 7
a4337 18
            let
              val Debugger_Types.INFO i = !debug_map
            in
              (case NewMap.tryApply' (i, procedure_name) of
                 MLWorks.Option.SOME((a, b, c),_, is_exn) =>
                   debug_map := 
                   ((*output(std_out,"\n map defined at "^procedure_name^"\n");*)
                   Debugger_Types.INFO (NewMap.define(i, 
                         procedure_name,((a,if needs_preserve then b
                                            else true,c),runtime_env, is_exn))))
               | _ => 
                   debug_map := 
                   ((*output(std_out,"\n map defined at "^procedure_name^"\n");*)
                   Debugger_Types.INFO (NewMap.define(i, 
                         procedure_name,((Debugger_Types.null_type,false,nil),
					 runtime_env, false)))))
            end

d4734 1
a4734 2
                          Mips_Assembly.JUMP (_,_,_,Debugger_Types.Nop) => ()        
                        | Mips_Assembly.JUMP (_,_,_,debug) =>        
a4747 1
                              val Debugger_Types.INFO i = !debug_map
d4749 4
a4752 8
			       case NewMap.tryApply'(i, unpadded_name) of
				 MLWorks.Option.SOME((ty,leaf,annotations),runtime_env, is_exn) =>
				   debug_map :=
                                     Debugger_Types.INFO
				     (NewMap.define( i,unpadded_name,
                                        ((ty,leaf,(count,debug)::annotations),
					 runtime_env, is_exn)))
			       | _ => ()
@


1.52
log
@Add support for INTERRUPT.
Also extend INTERCEPT code.
Also allow functions which raise, or call real() or floor(), to be leaf.
@
text
@d8 5
d3805 1
a3805 1
				  (Mips_Assembly.SLT, stack_overflow_bool_reg,
@


1.51
log
@Fix implicit entry points.
@
text
@d8 3
d236 1
d3674 40
a3713 24
		      check_instrs
		      irupt_code
		      continue_tag:
		   where
		      check_instrs = 
		         addcc g0 1 slimit "check for interrupt"
			 bne continue_tag "branch if no interrupt"
			 nop

		      irupt_code =
		         | needs_preserve = 
			      lw global 4*event_check( implicit) "get address of event check"
			      jmpl lr 0 global "do event_check"
			      nop
			 | otherwise =
			      lw global 4*event_check_leaf(implicit) "get address of event check"
			      jmpl global 0 global "do event_check_leaf"
			      nop
			      continue
		      continue =
		        ba continue_tag "branch if no interrupt"
			nop
		*)
		| MirTypes.INTERRUPT => Crash.unimplemented "MirTypes.INTERRUPT"
d4284 1
d4289 2
a4290 9
	    | check_instr(MirTypes.ALLOCATE _) = true (* For the moment *)
	    | check_instr(MirTypes.RAISE _) = true (* For the moment *)
(* Warning. If we ever make a leaf adr, we must ensure
   handler continuations are done safely. This is not currently 
   true since they use o1 as the address.
*)
            (* These need the extra slot for fp moves *)
            | check_instr (MirTypes.REAL _) = true
            | check_instr (MirTypes.FLOOR _) = true
@


1.50
log
@Fix for bytearray allocation length problem.
Changed real number unrepresentable message
@
text
@d8 4
d3803 2
a3804 1
				   MachTypes.implicit, Implicit_Vector.extend),
@


1.49
log
@Stack extension / function entry code changes.
@
text
@d8 3
d413 1
a413 1
	     "Real number too big : " ^ x)
d473 1
a473 1
	(Info.FATAL, location, "Real number too big : " ^ x)
d3527 1
a3527 1
				  add rd reg (4+7))
d3554 1
a3554 1
				       (Mips_Assembly.ADD, rd, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM (4+7)),
d3568 1
a3568 1
				       (Mips_Assembly.ADD, rd, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM (4+7)),
@


1.48
log
@Added code for ALLOC_VECTOR
Fixed problem with loop in initStackSlots
@
text
@d8 4
d3688 1
a3688 94
		      (* leaf case *)
		      | not needs_preserve = ([], opcode_list, block_list, final_result)
		      | otherwise =
			   (result, opcode_list', block_list'', (stackOKTag, stackOKTagCode) : final_result)
			where
			   opcode_list' = []
			   block_list'' =
			      | opcode_list == [] = BANG! opcode_list == [] and end_tag not defined at all (* block_list *)
			      | otherwise = BLOCK(end_tag, opcode_list') : block_list
			   result =
			      sw fp 0(sp)
			      check_for_stack_overflow
			   check_for_stack_overflow =
			      | normal_frame = 
				   slt global slimit sp 'test for stack overflow'
			      | medium_frame = 
				   addiu global sp ~frame_size
				   slt global slimit global
			      | very_large_frame = 
				   ori global zero lo(frame_size) 'get frame_size into global'
				   lui global hi(frame_size)
				   subu tempReg sp global
			      stack_overflow_test
			      stack_extension
			   where
			      normal_frame = non_save_frame_size <= 0
			      medium_frame = non_save_frame_size < arith_imm_limit
			      very_large_frame = non_save_frame_size > arith_imm_limit
			      
			      stack_overflow_test =
			         | very_large_frame = 
				      nop "unwritten: bne temp zero stackOKTag"
				 | normal_frame or medium_frame = 
				      bne global zero stackOKTag (* aka non_ov_tag *)
				 addu fp sp zero "update frame pointer in delay slot"
			      
			      stack_extension =
			         | normal_frame or medium_frame = 
				      ?lw fp 16(implicit)
				      ?ori global zero frame_size
				      ?jalr slimit fp
				      ?nop "Can't fill this"
				 | very_large_frame =
				      ?lw fp 16(implicit)
				      nop "Can't fill this"
				      jalr slimit fp
				      nop "Can't fill this"
			      stackOKTagCode = 
			         | normal_frame or medium_frame = 
				      addiu sp sp ~frame_size
				 | very_large_frame = 
				      subu sp sp global
				 saveFrame
				 addu $callee-closure caller-closure zero "register move"
				 saveGcs
				 saveFps
				 initStackSlots sp gc_stack_slots
				 ba endTag
				 nop
			      
			      gc_stack_slots = (gc_spill_size + gc_stack_alloc_size)
			      saveFrame =
			         sw callee-closure 4(sp)
				 sw lr 8(sp)
				 | debugging =
				      sw arg 12(sp) "*** which arg? callee-arg or caller-arg?"
				 | otherwise =
				      []
			      initStackSlots reg slotSize
			         | check_range end_limit true arith_imm_limit =
				      | slotSize < 10 =
					   initStackSlot register_save_size slotSize endInstrs
				      | otherwise =
					   initStackSlotFolded register_save_size slotSize 
				 | otherwise = BANG!
				 where
				    (* initStackSlot: sw zero reg offset for all stack slots(words) *)
				    initStackSlot offset 0 done = done
				    initStackSlot offset 1 done = saveinstr offset :: done
				    initStackSlot offset n done =
				       | n<0 = BANG!
				       | otherwise = initStackSlot (offset+4) (n-1) (saveInstr offset :: done)
				       where
				          saveInstr offset = sw zero reg offset "init stack slot"
			            initStackSlotFolded offset n =
				       ori hacky_temporary_reg zero slotSize
				       addiu global $sp offset
				       sw r0 0(global)
				       nop
				       addi global global 4
				       subi hacky_temporary_reg r17 1
				       bgtz hacky_temporary_reg ~5
				       nop
		  *)
d3695 19
a3713 3
			val normal_frame = non_save_frame_size <= 0
			val medium_frame = (non_save_frame_size < arith_imm_limit) andalso (not normal_frame)
			val large_frame = non_save_frame_size > arith_imm_limit
d3715 2
d3718 3
d3722 10
a3731 36
			val block_list' = 
			  if opcode_list = [] then 
			    Crash.impossible "opcode_list is [] and end_tag is not defined, uncertain here" (* block_list *)
			  else 
			    MirTypes.BLOCK(endTag, opcode_list) :: block_list
			    
			local
			  val preCheck =
			    if normal_frame then 
			      (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (Mips_Assembly.SLT, MachTypes.global, MachTypes.stack_limit, Mips_Assembly.REG MachTypes.sp),
			       absent, "test for stack overflow")
			      :: []
			    else if medium_frame then
			      (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (Mips_Assembly.ADDIU, MachTypes.global, MachTypes.sp, Mips_Assembly.IMM (~frame_size)),
			       absent, "")
			      :: (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.SLT, MachTypes.global, MachTypes.stack_limit, Mips_Assembly.REG MachTypes.global),
				  absent, "")
			      :: []
			    else (* very_large_frame *)
			      load_large_number_into_register(MachTypes.global, frame_size)
			      @@ (Mips_Assembly.nopc "unwritten: subu tempReg sp global"
				 :: [])
				   
			  val stack_overflow_test = 
			    (if normal_frame orelse medium_frame then
			       (Mips_Assembly.BRANCH
				(Mips_Assembly.BNE, MachTypes.global, MachTypes.zero_reg, 0),
				Option.PRESENT stackOKTag, "Do the branch") (* aka non_ov_tag *)
			     else (* very_large_frame *) 
			       Mips_Assembly.nopc "unwritten: bne tempReg zero stackOKTag"
			       )
			       :: move_regc(MachTypes.fp, MachTypes.sp, "update fp in delay slot")
			       :: []
d3733 82
a3814 5
                          val final_branch =
                            [(Mips_Assembly.BRANCH
                              (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
                              Option.PRESENT stackOKTag, "Do the branch"),
                             Mips_Assembly.nop]
d3816 34
a3849 2
			  val stack_extension =
			    if normal_frame orelse medium_frame then
d3851 10
a3860 86
			       (Mips_Assembly.LW, MachTypes.fp, MachTypes.implicit, 16),
			       absent, "")
			      :: move_imm(MachTypes.global, frame_size)
			      :: (Mips_Assembly.JUMP
				  (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.stack_limit, MachTypes.fp, Debugger_Types.null_backend_annotation),
				  absent, "")
			      :: Mips_Assembly.nopc "Can't fill this"
			      :: final_branch
			    else (* very_large_frame *)
			      (Mips_Assembly.LOAD_AND_STORE
			       (Mips_Assembly.LW, MachTypes.fp, MachTypes.implicit, 16),
			       absent, "")
			      :: Mips_Assembly.nopc "Can't fill this"
			      :: (Mips_Assembly.JUMP
				  (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.stack_limit, MachTypes.fp, Debugger_Types.null_backend_annotation),
				  absent, "")
			      :: Mips_Assembly.nopc "Can't fill this"
			      :: final_branch
			in (* local *)
			  val check_for_stack_overflow =
			    preCheck @@ stack_overflow_test @@ stack_extension 
			end (* local *)
			val result = 
			  (Mips_Assembly.LOAD_AND_STORE
			   (Mips_Assembly.SW, MachTypes.fp, MachTypes.sp, 0), absent, "")
			  :: check_for_stack_overflow
			val saveFrame = 
			  (Mips_Assembly.LOAD_AND_STORE
			   (Mips_Assembly.SW, MachTypes.callee_closure, MachTypes.sp, 4), absent, "")
			  :: (Mips_Assembly.LOAD_AND_STORE
			      (Mips_Assembly.SW, MachTypes.lr, MachTypes.sp, 8), absent, "")
			  :: (if debugging then 
				(Mips_Assembly.LOAD_AND_STORE
				 (Mips_Assembly.SW, MachTypes.arg, MachTypes.sp, 12),
				 absent, "")
				:: []
			      else [])

                        (* Generates (codelist,blocklist) to initialize stack slots to zero *)
                        (* endTag is where to jump to after initialization *)
			fun initStackSlots (reg,num_slots,endTag) = 
                          let
                            (* For small numbers of stack slots, initialize each one separately *)
                            fun initStackSlot(offset, 0, done) = (done,[])
                              | initStackSlot(offset, n, done) = 
                                let
                                  fun saveInstr offset = 
                                    (Mips_Assembly.LOAD_AND_STORE
                                     (Mips_Assembly.SW, MachTypes.zero_reg, reg, offset), absent, "init stack slot")
                                in
                                  if n<0 then 
                                    Crash.impossible "initStackSlot: failed"
                                  else initStackSlot(offset+4, n-1, saveInstr offset :: done)
                                end

                            (* For larger numbers, we make a loop *)
                            fun initStackSlotFolded(offset, num_slots, endInstrs) =
                              let
                                val loop_tag = MirTypes.new_tag ()
                              in
                                ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                                   (Mips_Assembly.ORI, hacky_temporary_reg, MachTypes.zero_reg, Mips_Assembly.IMM num_slots),
                                   absent, "Move number of slots to temp as counter"),
                                  (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                                   (Mips_Assembly.ADDIU, MachTypes.global, MachTypes.sp, Mips_Assembly.IMM offset),
                                   absent, "initial sp offset in global"),
                                  (Mips_Assembly.BRANCH
                                   (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0), Option.PRESENT loop_tag, ""),
                                  Mips_Assembly.nop],
                                 [(loop_tag,
                                   [(Mips_Assembly.LOAD_AND_STORE
                                     (Mips_Assembly.SW, MachTypes.zero_reg, MachTypes.global, 0),
                                     absent, "init stack slot"),
                                   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                                    (Mips_Assembly.ADDI, MachTypes.global, MachTypes.global, Mips_Assembly.IMM 4),
                                    absent, ""),
                                   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                                    (Mips_Assembly.SUB, hacky_temporary_reg, hacky_temporary_reg, Mips_Assembly.IMM 1),
                                    absent, ""),
                                   (Mips_Assembly.BRANCH
                                    (Mips_Assembly.BGTZ, hacky_temporary_reg, MachTypes.dummy_reg, 0),
                                    Option.PRESENT loop_tag, ""),
                                   Mips_Assembly.nop] @@
                                   endInstrs)])
                                   (* temp is now zero so no need to clean *)
                              end
d3862 4
a3865 1
                            val end_limit = register_save_size + (num_slots-1)*4
d3867 2
a3868 2
                            (* Branch to end *)
                            val endInstrs = 
d3870 62
a3931 3
				  (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0), 
                                  Option.PRESENT endTag, "branch"),
				 Mips_Assembly.nop]
d3933 9
a3941 24
                          in (* initStackSlots *)
                            if check_range(end_limit, true, arith_imm_limit) 
                              then
                                if num_slots < 10 
                                  then initStackSlot(register_save_size, num_slots, endInstrs)
                                else initStackSlotFolded(register_save_size, num_slots, endInstrs)
                            else Crash.impossible("initStackSlots: end_limit = " ^ makestring end_limit)
                          end (* initStackSlots *)
		      
			val gc_stack_slots = (gc_spill_size + gc_stack_alloc_size)
                        val (init_stack_code,init_stack_blocks) =
                          initStackSlots (MachTypes.sp, gc_stack_slots, endTag)
			val stackOKTagCode =
			  (if normal_frame orelse medium_frame then
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADDIU, MachTypes.sp, MachTypes.sp, Mips_Assembly.IMM (~frame_size)),
			      absent, "")
			   else (* large_frame *)
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.SUBU, MachTypes.sp, MachTypes.sp, Mips_Assembly.REG MachTypes.global),
			      absent, "")) :: 
                          (saveFrame @@
                           (move_reg(MachTypes.callee_closure, MachTypes.caller_closure) :: save_gcs) @@
                           init_stack_code)
d3943 2
a3944 1
			(result, opcode_list', block_list', (stackOKTag, stackOKTagCode) :: init_stack_blocks @@ final_result)
@


1.47
log
@updating floor,
updating MirTypes.TEST for constant operands
@
text
@d8 4
d907 4
a910 3
                               (* Hack to save lr in R18 during calculation of offset *)
                               (* This should be sorted out properly sometime *)
                               (* I don't think R18 will be used as a spill temporary *)
d3346 2
a3347 1
		       (bytes, primary, secondary, aligned) = case allocate of
d3351 1
d3391 3
d3514 2
a3515 1
			  (primary, secondary, get_length) = case allocate of
d3521 6
a3526 2
                             | otherwise = BANG! "strange parameter to ALLOCATE"
	
d3536 13
a3548 1
				 | MirTypes.ALLOC_STRING => Crash.unimplemented "ALLOC_STRING variable size"
d3873 67
a3939 43
			  
			fun initStackSlots reg slotSize = let
			  val end_limit = register_save_size + (slotSize-1)*4
			  val endInstrs = []

			  fun saveInstr offset = (Mips_Assembly.LOAD_AND_STORE
						  (Mips_Assembly.SW, MachTypes.zero_reg, reg, offset), absent, "init stack slot")
			  fun initStackSlot(offset, 0, done) = done
			    | initStackSlot(offset, n, done) = 
			      if n<0 then 
				Crash.impossible "initStackSlot: failed"
			      else initStackSlot(offset+4, n-1, saveInstr offset :: done)
			  fun initStackSlotFolded(offset, n) =
			    [
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ORI, hacky_temporary_reg, MachTypes.zero_reg, Mips_Assembly.IMM slotSize),
			      absent, ""),
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADDIU, MachTypes.global, MachTypes.sp, Mips_Assembly.IMM offset),
			      absent, ""),
			     (Mips_Assembly.LOAD_AND_STORE                                                          (* branch target *)
			      (Mips_Assembly.SW, MachTypes.R0, MachTypes.global, 0),
			      absent, ""),
			     Mips_Assembly.nop,
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADDI, MachTypes.global, MachTypes.global, Mips_Assembly.IMM 4),
			      absent, ""),
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.SUB, hacky_temporary_reg, hacky_temporary_reg, Mips_Assembly.IMM 1),
			      absent, ""),
			     (Mips_Assembly.BRANCH
			      (Mips_Assembly.BGTZ, hacky_temporary_reg, MachTypes.dummy_reg, ~5),                  (* branch offset ~5 *)
			      absent, ""),
			     Mips_Assembly.nop
			     ]
			in (* initStackSlots *)
			  if check_range(end_limit, true, arith_imm_limit) then
			    if slotSize < 10 then 
			      initStackSlot(register_save_size, slotSize, endInstrs)
			    else
			      initStackSlotFolded(register_save_size, slotSize)
			  else Crash.impossible("initStackSlots: end_limit = " ^ makestring end_limit)
			end (* initStackSlots *)
d3942 2
d3952 7
a3958 19
			      absent, "")
			  )
			  :: (saveFrame
			      @@ (
				 move_reg(MachTypes.callee_closure, MachTypes.caller_closure)
				 :: save_gcs
				 )
			      @@ initStackSlots MachTypes.sp gc_stack_slots
			      @@ (
				 (Mips_Assembly.BRANCH
				  (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0), 
                                  Option.PRESENT endTag, "branch")
				 :: Mips_Assembly.nop
				 :: []
				 )
			     )
		      in (* let *)
			(result, opcode_list', block_list', (stackOKTag, stackOKTagCode) :: final_result)
		      end (* let *)
@


1.46
log
@Add support for immediate store operation
@
text
@d8 3
d284 1
a284 1
  (* make_imm_fault: puts arg into IMM form: partial *)
d323 4
a326 1
      copy' (n,[]) 
d490 2
a491 1
  fun rev_app([], ys) = ys
d790 1
a790 1

d801 20
a820 3
	  fun copy_n(n, from, acc, new_tail) =
	    if n < 0 then
	      Crash.impossible"copy_n negative arg"
d822 8
a829 7
	      if n = 0 then
		rev_app(acc, new_tail)
	      else
		case from of
		  (x :: xs) =>
		    copy_n(n-1, xs, x :: acc, new_tail)
		| _ => Crash.impossible"copy_n short list"
d855 1
a855 1
			          raise BadOffset block_tag (copy_n head_size opcode_list [] new_tail)
d857 1
a857 1
			          raise BadOffset block_tag (copy_n head_size opcode_list [] 
d860 1
a860 1
			          raise BadOffset block_tag (copy_n head_size opcode_list [] 
d943 1
a943 1
						copy_n(head_size, opcode_list, [], new_tail))
d972 1
a972 1
				    raise BadOffset block_tag (copy_n head_size opcode_list [] new_tail)
d974 1
a974 1
				    raise BadOffset block_tag (copy_n head_size opcode_list []
d977 1
a977 1
				    raise BadOffset block_tag (copy_n head_size opcode_list []
d1060 1
a1060 1
						copy_n(head_size, opcode_list, [], new_tail))
d1097 1
a1097 1
				    copy_n(head_size, opcode_list, [], new_tail))
d1140 1
a1140 1
						  copy_n(head_size, opcode_list, [], new_tail))
a1413 1

d1496 7
d1943 1
a1943 1
			      opcode r1 r2' reg_or_imm 
d2525 10
a2534 1
		(* T[STOREFPOP op fp1 fp2 fp3] => *)
d2542 2
a2543 2
			(MachTypes.single, MirTypes.FLD) => (Mips_Assembly.LWC1, false, [Mips_Assembly.nop])
		      | (MachTypes.single, MirTypes.FST) => (Mips_Assembly.SWC1, false, [])
d2546 2
a2547 2
		      | (MachTypes.double, MirTypes.FLD) => (Mips_Assembly.LWC1, false, [Mips_Assembly.nop])
		      | (MachTypes.double, MirTypes.FST) => (Mips_Assembly.SWC1, false, [])
d2550 1
a2550 1
		      | (MachTypes.extended, _) => Crash.impossible "Extended floats not supported"
d2685 23
a2707 2
		(* T[FLOOR float_to_int tag r1 fp1] =>
		      add global zero 1 
a2708 1
		      sub global global 1
d2711 3
a2713 2
		      CONV_OP op' fp_global fp_global
		      fcmp test fp1' fp_global
d2715 1
a2715 1
		      bc1f 0 tag
d2717 1
d2719 1
a2719 1
		      test' fp1' fp_global
d2721 1
a2721 1
		      bc1t 0 tag
d2723 3
a2725 5
		      (* test for negative quantity *)
		      subtract fp_global fp_global fp_global
		      test'' fp1' fp_global 
		      nop
		      bc1f 7
d2727 2
a2728 4
		      (* negative so subtract one *)
		      add global zero 1 
		      sw global ~4(fp)
		      lwc1 fp_global ~4(fp) 'save converted value'
d2730 1
a2730 8
		      operation' fp_global fp_global
		      subtract fp1' fp1' fp_global
		      (* do the conversion operation *)
		      operation fp_global fp1'
		      mfc1 fp_global r1 zero (* dont have to store&load *)
		      nop
		      sll r1 r1 2 'tag the result'
		      
d2732 1
a2732 1
		         (operation, operation', test, test', test'', subtract, negate)
d2734 1
a2734 1
			         (CVT_S_W, CVT_W_S, C_OLE_S, C_OLT_S, C_ULT_S, SUB_S)
d2736 17
a2752 2
			         (CVT_W_D, CVT_D_W, C_OLE_D, C_OLT_D, C_ULT_D, SUB_D, NEG_D)
			    | fp_used == extended = BANG! extended floats not supported
d2754 1
d2757 5
a2761 6
		      val (operation,operation',test,test',test'',subtract, negate) = 
                        case MachTypes.fp_used of
                          MachTypes.single => 
			    (Mips_Assembly.CVT_S_W, Mips_Assembly.CVT_W_S, 
			     Mips_Assembly.C_OLE_S, Mips_Assembly.C_OLT_S, 
			     Mips_Assembly.C_ULT_S, Mips_Assembly.SUB_S,
d2765 1
a2765 2
			     Mips_Assembly.C_OLE_D, Mips_Assembly.C_OLT_D, 
			     Mips_Assembly.C_ULT_D, Mips_Assembly.SUB_D,
d2767 34
a2800 2
                        | MachTypes.extended => 
			    Crash.impossible "extended floats not supported"
d2804 3
a2806 2
		      ([
                        (* Test for a possible overflow if the number is too big in magnitude *)
d2809 2
a2810 6
                         (Mips_Assembly.SLL,MachTypes.global,MachTypes.global,
                          Mips_Assembly.IMM 29),absent,""),
                        (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                         (Mips_Assembly.SUB,MachTypes.global,MachTypes.global,
                          Mips_Assembly.IMM 1),absent,""),

d2812 3
a2814 2
			 (Mips_Assembly.MTC1, MachTypes.global, 
			  MachTypes.fp_global, Mips_Assembly.REG MachTypes.dummy_reg), absent,""), (*don't have to store&load!*)
d2816 2
a2817 3

                        (Mips_Assembly.CONV_OP(operation', MachTypes.fp_global, 
					       MachTypes.fp_global), absent, ""),
d2820 1
a2820 1
                        (Mips_Assembly.FBRANCH(Mips_Assembly.BC1F, 0), Option.PRESENT tag, ""),
d2822 3
a2824 4

                        (Mips_Assembly.FUNARY(negate, MachTypes.fp_global, 
					      MachTypes.fp_global), absent, ""),
                        (Mips_Assembly.FCMP(test', rs2, MachTypes.fp_global), absent, ""),
d2826 1
a2826 11
                        (Mips_Assembly.FBRANCH(Mips_Assembly.BC1T, 0), 
			 Option.PRESENT tag, ""),
                        Mips_Assembly.nop,

                        (* Test for a negative quantity *)
                        (Mips_Assembly.FBINARY(subtract, MachTypes.fp_global, 
					       MachTypes.fp_global, MachTypes.fp_global), 
                         absent, ""),
                       (Mips_Assembly.FCMP(test'', rs2, MachTypes.fp_global), absent, ""),
		       Mips_Assembly.nop,
                        (Mips_Assembly.FBRANCH(Mips_Assembly.BC1F, 7), Option.ABSENT, ""),
a2828 13
                        (* Negative so subtract one *)
			move_imm(MachTypes.global, 1),
                        (Mips_Assembly.LOAD_AND_STORE
                         (Mips_Assembly.SW, MachTypes.global, MachTypes.fp, ~4), absent,""),
                        (Mips_Assembly.LOAD_AND_STORE_FLOAT
                         (Mips_Assembly.LWC1, MachTypes.fp_global,
                          MachTypes.fp, Mips_Assembly.IMM ~4), absent, "Save converted value"),
			Mips_Assembly.nop,
                        (Mips_Assembly.CONV_OP(operation', MachTypes.fp_global,
					       MachTypes.fp_global), absent, ""),
                        (Mips_Assembly.FBINARY(subtract, rs2, rs2, MachTypes.fp_global), 
                         absent, ""),

d2832 11
a2842 7
			(Mips_Assembly.LOAD_AND_STORE_FLOAT
			 (Mips_Assembly.MFC1, MachTypes.fp_global, 
			  rd, Mips_Assembly.REG MachTypes.zero_reg), absent,""), (*don't have to store&load!*)
			Mips_Assembly.nop,
			(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			 (Mips_Assembly.SLL, rd, rd, Mips_Assembly.IMM 2),
			 absent, "Tag the result")],
d2865 16
a2880 1
		(* T[TEST op tag r1 r2] => *)
a2895 4
		      | MirTypes.BHI => Crash.impossible "MirTypes.Bcc unsigned not supported"
		      | MirTypes.BLS => Crash.impossible "MirTypes.Bcc unsigned not supported"
		      | MirTypes.BHS => Crash.impossible "MirTypes.Bcc unsigned not supported"
		      | MirTypes.BLO => Crash.impossible "MirTypes.Bcc unsigned not supported"
d2900 4
d2906 1
a2906 1
			  MirTypes.GP_GC_REG _ => (branch, gp_operand, make_reg0_from_imm0 gp_operand')
d2909 8
a2916 9
		      val _ = case gp_op of
			MirTypes.GP_GC_REG _ => ()
		      | MirTypes.GP_NON_GC_REG _ => ()
		      | _ => Crash.impossible"Two constant operands to test"
		      val rs1 = lookup_gp_operand gp_op
		      val test_instr = case cond_branch of
			MirTypes.BTA => Mips_Assembly.AND
		      | MirTypes.BNT => Mips_Assembly.AND
		      | _ => Mips_Assembly.SUB
d2918 26
a2943 1
		      if is_reg gp_op' orelse
d2946 5
d3023 14
a3036 1
		(* T[FTEST op tag fp1 fp2] => *)
d3051 1
a3051 1
		      | (MachTypes.double, MirTypes.FBLT) => (Mips_Assembly.C_OLT_D, Mips_Assembly.BC1F)
d3631 24
a4074 5

		(* check this funny definition for rev_app *)
		fun rev_app([], x) = x
		  | rev_app(y, []) = y
		  | rev_app(y :: ys, x) = rev_app(ys, y :: x)
@


1.45
log
@Some changes for scheduling
Added elim_simple_branches functions
@
text
@d8 4
d2363 2
d4021 2
@


1.44
log
@making stack initialisation shorter
@
text
@d8 3
d16 1
a16 1
\n use ADDUI for -2**15 .. 2**15-1
d19 1
a19 1
\nFixed order of loading halves of double floats --
d21 2
a22 2
\nMoved scheduling phase to during linearization.
\nChanged jumps in ALLOCATE to be to labels rather than by
d24 1
a24 1
\nAdded removal of unreachable blocks before linearization.
d666 2
d673 6
d918 1
a918 1
                         Crash.impossible"Assoc do_opcode branch")
d937 1
a937 1
			   Crash.impossible"Assoc do_opcode fbranch")
a2755 1

d2765 1
d3957 1
d4100 1
a4100 2
	     fun ch f s = 
		(map f s; false) handle MachTypes.NeedsPreserve => true
d4102 1
a4102 2

	    val needs_preserve = 
d4132 1
d4165 1
d4421 2
a4422 2
(*
	  val _ = diagnostic_output 3 (fn _ => (["Rescheduling code\n"]))
d4424 36
a4459 10
	  val new_code_list' =
	    Timer.xtime
	    ("rescheduling", !do_timings,
	     fn () => do_reschedule code_list')

	  val _ = diagnostic_output 3 (fn _ => ["Rescheduled code\n"])
	  val _ = diagnostic_output 3 (fn _ => (print_scheduled_code (Lists.zip(new_code_list',procedure_name_list)) ;
						 []))
*)

d4501 2
a4502 2
          
	  val new_code_list' = map elim_unreachable code_list
d4580 2
@


1.43
log
@rewriting real
@
text
@d8 3
d3555 4
a3558 1
				      initStackSlot register_save_size slotSize endInstrs
d3569 9
a3577 1

d3686 23
d3711 4
a3714 1
			    initStackSlot(register_save_size, slotSize, endInstrs)
@


1.42
log
@Fixed problems with loading immediates:
\n use ADDUI for -2**15 .. 2**15-1
 use ORI for 2**15 ..2**16-1
 use LUI & ORI for other immediates
\nFixed order of loading halves of double floats --
  this may be endianness specific
\nMoved scheduling phase to during linearization.
\nChanged jumps in ALLOCATE to be to labels rather than by
fixed amounts.  This was confusing the scheduler.
\nAdded removal of unreachable blocks before linearization.
@
text
@d8 12
d2581 5
a2585 5
		      | isReg gp1 = 
			   sra global gp1' 2 'untag operand'
			   sw global fp ~4 'store the value to be converted in spare slot'
			   lwc1 fp1 fp ~4 'and reload to fp register'
			   CONV_OP op fp1 fp1
d2587 2
a2588 1
			   T[move global gp1, REAL int_to_float fp1 global]
d2593 3
a2595 3
			MachTypes.single => Mips_Assembly.CVT_W_S
		      | MachTypes.double => Mips_Assembly.CVT_W_D
		      | MachTypes.extended => Crash.impossible "extended floats not supported"
d2605 2
a2606 8
			   (Mips_Assembly.SRA, MachTypes.global, 
			    rs2, Mips_Assembly.IMM 2), absent,
			   "Untag operand"),
			  (Mips_Assembly.LOAD_AND_STORE(Mips_Assembly.SW,
							 MachTypes.global,
							 MachTypes.fp,
							 ~4), absent,
			   "Store the value to be converted in spare slot"),
d2608 6
a2613 6
			   (Mips_Assembly.LWC1, rd, MachTypes.fp,
			    Mips_Assembly.IMM ~4), absent,
			   "And reload to fp register"),
			  (Mips_Assembly.CONV_OP(operation, rd, rd),
			   absent, "")],
			 opcode_list, block_list, final_result)
d2616 1
a2616 1
			 MirTypes.UNARY(MirTypes.MOVE,
d2624 1
@


1.41
log
@Various things:
Fixed problems with pc-relative long branches
Rationalized some of the code comments
Reformatted a little
Commented out the "append_small_exit" part
@
text
@d8 7
d247 1
a247 4
  (* fault_range: checks for branching outside offset limits: partial
   nb.
     Mips branch offset measured from the delay slot not like SPARC,
     which measures it from the branching instruction *)
d259 1
a259 1
  (* make_imm_fault: puts arg into IMM form: partial  *)
d316 1
a316 1
  (* move_imm: or rd, $0 *)
d319 1
a319 1
     (Mips_Assembly.ORI, rd, MachTypes.zero_reg, Mips_Assembly.IMM imm),
d322 2
a323 1
  (* move_immc :: ori rd, $0 *)
d326 1
a326 1
     (Mips_Assembly.ORI, rd, MachTypes.zero_reg, Mips_Assembly.IMM imm),
d648 5
d1096 1
d1451 1
a1451 1
	  fun split_int(MirTypes.GP_IMM_INT i) = 
d1453 1
a1453 1
	    | split_int(MirTypes.GP_IMM_ANY i) = 
d1455 1
a1455 1
	    | split_int(MirTypes.GP_IMM_SYMB symb) =
d1461 1
a1461 1
	    | split_int _ = Crash.impossible"split_int of non-immediate" 
d1463 61
a1523 37
	  (* load_large_IMM_into_register reg num =
	        case split_int num of
		|  (0,0)      = or reg zero zero 'reg_to_string reg = 0'
	        |  (0,low)    = or reg zero low  
		|  (high,0)   = lui reg high     
		|  (high,low) = 
		      lui reg high 'reg := num, loading large number'
		      addu reg reg low 
	        where
		   (high, low) = split_int num
	  *)
	  fun load_large_IMM_into_register (reg, num) =
	    case (split_int num) of
	      (0,0) =>
		[move_reg(reg, MachTypes.zero_reg)]
	    | (0, low) => [move_imm(reg, low)]
	    | (high, 0) =>
		[(Mips_Assembly.SETHI
		  (Mips_Assembly.LUI, reg, high),
		  absent, MachTypes.reg_to_string reg ^ " := " ^ makestring high ^ ", load upper half")]
	    | (high, low) =>
		let
		  val comment = case num of
		    MirTypes.GP_IMM_ANY x => "ANY(" ^ makestring x ^ ")"
		  | MirTypes.GP_IMM_INT x => "INT(" ^ makestring x ^ ")"
		  | MirTypes.GP_IMM_SYMB symb =>
		      "SYMB(" ^ makestring(symbolic_value symb) ^ ")"
		  | _ => Crash.impossible"load_large_IMM_into_register bad value"
		in
		  [(Mips_Assembly.SETHI
		    (Mips_Assembly.LUI, reg, high),
		    absent, MachTypes.reg_to_string reg ^ " := " ^ comment ^ ", loading large number"),
		   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
		    (Mips_Assembly.ORI, reg, reg,
		     Mips_Assembly.IMM low),
		    absent, "")]
		end
d1526 1
a1526 1
	    load_large_IMM_into_register (reg, MirTypes.GP_IMM_ANY num)
a1527 6
	  (* make_imm_format3: override make_imm_format with IMM<<2 *)
	  fun make_imm_format3(MirTypes.GP_IMM_INT i) = make_imm_fault(4*i, true, arith_imm_limit)
	    | make_imm_format3(MirTypes.GP_IMM_ANY i) = make_imm_fault(i, true, arith_imm_limit)
	    | make_imm_format3(MirTypes.GP_IMM_SYMB symb) = make_imm_fault(symbolic_value symb, true, arith_imm_limit)
	    | make_imm_format3 _ = Crash.impossible"make_imm of non-immediate"

d1543 2
d1557 1
a1557 1
		    Mips_Assembly.IMM offset), Option.ABSENT,
d1563 1
a1563 1
		    Mips_Assembly.IMM (offset+4)), Option.ABSENT,
d1582 1
a1582 1
		      Mips_Assembly.IMM offset), Option.ABSENT,
d1588 1
a1588 1
		      Mips_Assembly.IMM (offset+4)), Option.ABSENT,
d1816 1
a1816 1
				else make_imm_format3 gp_operand'
d2004 1
a2004 1
				     else make_imm_format3 gp_operand'
d2070 1
a2070 1
			(load_large_IMM_into_register(rd, gp_operand), opcode_list, block_list, final_result)
d2103 1
a2103 1
			      (load_large_IMM_into_register(rs1, gp_operand) @@
d2494 1
d2532 1
d2544 11
a2554 8
			  ((Mips_Assembly.LOAD_AND_STORE_FLOAT(store, frd, rs1, reg_or_imm), absent, "") ::
			   (if MachTypes.fp_used = MachTypes.single 
			     then noop_if_required
			    else
			      (Mips_Assembly.LOAD_AND_STORE_FLOAT
			       (store, MachTypes.next_reg frd, rs1, reg_or_imm'), 
			       absent, "") :: noop_if_required),
			  opcode_list, block_list, final_result)
d2809 1
a2809 1
			      make_imm_format3 gp_op'
d2812 14
d2833 1
d2849 1
d2930 27
a2956 32
		      | REG r =>
		           | leaf case =
			        BANG!
				lw callee_closure 4(sp) "restore our own's caller closure"
				addu global r 3
				jr global "tail call"
				nop
		           | otherwise =
			        restore_gcs
				lw callee_closure 4(sp) "restore our own's caller closure"
				lw lr 8(sp) "reset link in delay slot"
				move_reg sp fp
				addu global r 3
				lw fp 0(sp) "reset fp to old fp"
				jr global "tail call"
				nop "delay slot unusable for fp"
		      | TAG tag =>
		           | leaf case =
			        BANG! 
				lw callee_closure 4(sp) "restore our own's callers closure"
				nop
				ba tag
				nop
		           | otherwise =
			        restore_gcs
				lw callee_closure 4(sp) "restore our own caller's closure"
				lw lr 8(sp) "reset link in delay slot"
				move_reg sp fp
				lw fp 0(sp) "reset fp to old fp"
				ba tag
				nop "delay slot unusable for fp"

d2960 23
a2982 29
		      (
		       if needs_preserve then
			 restore_gcs
		       else
			 []
		      )
		      @@ (
			 (Mips_Assembly.LOAD_AND_STORE
			  (Mips_Assembly.LW, MachTypes.callee_closure, MachTypes.sp, 4),
			  absent, "restore our own caller's closure")
			 :: (
			     if needs_preserve then 
			       (Mips_Assembly.LOAD_AND_STORE
				(Mips_Assembly.LW, MachTypes.lr, MachTypes.sp, 8),
				absent, "reset link in delay slot")
			       :: move_reg(MachTypes.sp, MachTypes.fp)
			       :: []
			     else 
			       [Mips_Assembly.nop]
			       )
			 )
		      val reset = (Mips_Assembly.LOAD_AND_STORE
				   (Mips_Assembly.LW, MachTypes.fp, MachTypes.sp, 0), 
				   absent, "reset fp to old fp")
		      val postRestores = 
			 if needs_preserve then
			   [Mips_Assembly.nopc "delay slot unusable for fp"]
			 else
			   [Mips_Assembly.nop]
d2986 11
a2996 14
			 if not needs_preserve then
			   Crash.impossible "BANG! not fully implemented yet"
			 else
			   restores
			   @@ (
			      (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (Mips_Assembly.ADDU, MachTypes.global, lookup_reg_operand reg, Mips_Assembly.IMM 3),
			       absent, "")
			      :: reset
			      :: (Mips_Assembly.JUMP
				  (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.global, MachTypes.dummy_reg, Debugger_Types.null_backend_annotation),
				  absent, "tail call")
			      :: postRestores
			      )
d2998 7
a3004 12
			 if not needs_preserve then
			   Crash.impossible "BANG! not fully implemented yet"
			 else
			   restores
			   @@ (
			      reset
			      :: (Mips_Assembly.BRANCH
				  (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
				  Option.PRESENT tag, "branch")
			      :: postRestores
			      )
		     , opcode_list, block_list, final_result)
d3105 2
a3106 2
		      end (* let *)
		    , opcode_list, block_list, final_result)
d3192 1
a3192 1
                       (high,_) = split_int bytes
d3203 14
a3216 3
			  
		      val allocation = case gp_operand of
			MirTypes.GP_IMM_INT size => let
d3247 3
a3249 3
			       [(Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.global, rd, ~primary), absent, "tag secondary")])
			      
			  val (high, low) = split_int (MirTypes.GP_IMM_ANY bytes)
d3251 34
a3284 30
			  if high = 0 then
			    (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			     (Mips_Assembly.ADD, MachTypes.gc1, MachTypes.gc1, Mips_Assembly.IMM bytes), 
			     absent, "Size required") ::
			    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			     (Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2),
			     absent, "gc?") ::
			    (Mips_Assembly.BRANCH 
			     (Mips_Assembly.BLTZ, MachTypes.global, MachTypes.dummy_reg, 6),
			     absent, "no gc? then branch") ::
			    (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			     (Mips_Assembly.ADD, rd, MachTypes.gc1, Mips_Assembly.IMM (primary - bytes)),
			     absent, "tag primary in delay slot") ::
			    (Mips_Assembly.LOAD_AND_STORE 
			     (Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, gc_entry),
			     absent, "get gc entry") ::
			    move_regc(rd,MachTypes.zero_reg,"clear invalid data set above") ::
			    (Mips_Assembly.JUMP 
			     (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, MachTypes.global, Debugger_Types.null_backend_annotation), 
			     absent, "call gc") ::
			    move_immc(MachTypes.global, bytes, "pass size to gc") ::
			    (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			     (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary),
			     absent, "tag primary") ::
			    (if aligned then
			       secondary_code
			     else
			       (Mips_Assembly.LOAD_AND_STORE 
				(Mips_Assembly.SW, MachTypes.zero_reg, rd, bytes - primary - 4), absent, "Zero unaligned extra word") ::
			       secondary_code)
d3286 24
a3309 21
			    load_large_number_into_register(rd, bytes) @@
			    (
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			      (Mips_Assembly.ADD, MachTypes.gc1, MachTypes.gc1, Mips_Assembly.REG rd),
			      absent, "try to get "^makestring bytes) ::
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			      (Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2),
			      absent, "gc?") ::
			     (Mips_Assembly.BRANCH 
			      (Mips_Assembly.BLTZ, MachTypes.global, MachTypes.dummy_reg, 5),
			      absent, "no gc? then branch") ::
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			      (Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG rd),
			      absent, "point to new object in delay slot") ::
			     (Mips_Assembly.LOAD_AND_STORE 
			      (Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, gc_entry), absent, "get gc entry") ::
			     Mips_Assembly.nop ::
			     (Mips_Assembly.JUMP 
			      (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, MachTypes.global, Debugger_Types.null_backend_annotation),
			      absent, "call gc") ::
			     move_regc(MachTypes.global, rd, "pass arg size to gc") ::
d3320 1
a3320 2
				secondary_code)
				)
d3387 2
a3388 3
			    length_code @@
			    (
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
d3390 1
a3390 1
			      absent, "Size required") ::
d3393 1
a3393 1
			      absent, "gc?") ::
d3395 2
a3396 2
			      (Mips_Assembly.BLTZ, MachTypes.global, MachTypes.dummy_reg, 5), 
			      absent, "no? then branch") ::
d3399 1
a3399 1
			      absent, "point to new object") ::
d3402 2
a3403 2
			      absent, "get gc entry") ::
			     Mips_Assembly.nop ::
d3406 21
a3426 17
			      absent, "call gc") ::
			     move_regc(MachTypes.global, rd, "pass arg size to gc") ::
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.REG rd),
			      absent, "zero unaligned extra word at end") ::
			     (Mips_Assembly.LOAD_AND_STORE 
			      (Mips_Assembly.SW, MachTypes.zero_reg, rd, ~4),
			      absent, "") ::
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary), absent, "tag primary") ::
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.SLL, MachTypes.global, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM 4),
			      absent, "") ::
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, MachTypes.global, MachTypes.global, Mips_Assembly.IMM secondary),
			      absent, "tag secondary") ::
			     (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.global, rd, ~primary),
			      absent, "") :: nil)
d3430 4
a3433 1
		      (allocation, opcode_list, block_list, final_result)
d3995 1
d4012 4
d4044 2
a4045 1
	    val needs_preserve = (*not opt_leaf_fns*) true (* Leaf not done properly yet *)
d4307 1
d4333 1
d4361 1
d4372 46
@


1.40
log
@Changes for new NEW_HANDLER instruction
@
text
@d8 3
d188 7
a194 1
  val diagnostic_output = Diagnostic.output
d199 1
d203 10
a212 1
(* contract_sexpr: flattens a user defined list of lists *)
d222 1
a222 1
(* find_nop_offsets: searches for specific nop for use in linearisation debugging *)
a233 1
(* check_range: does this mean 31 bit unsigned and 30 bit int + 1 sign bit? *)
d240 1
a240 1
(* fault_range: checks for branching outside offset limits: partial
d245 2
a246 2
    if check_range(i, signed, pos_limit) then
      i
d253 1
a253 1
       Crash.impossible"Immediate constant out of range"(*raise Match*) )
d255 1
a255 1
(* make_imm_fault: puts arg into IMM form: partial  *)
d265 1
a265 1
(* checkOList: checks for properties in some elements of a list *)
d269 3
a271 1
  in checkList l end (* checkOList *)
d273 1
a273 1
(* checkAList: checks for properties in all elements of a list *)
d277 3
a279 1
  in checkList l end (* checkAList *)
d281 1
a281 1
(* curry: call tuple requesting functions *)
d284 1
a284 1
(* copy: duplicates element  N times *)
d288 12
a299 19
(* copy: duplicates element N times tail-recursively *)
  fun copy n x = let
    fun copy' (0,acc) = acc
      | copy' (n,acc) = copy' (n-1,x :: acc)
  in copy' (n,[]) end (* copy *)

(* foldl: cant find foldl yet hack it into here *)
    fun foldl f z [] = z
      | foldl f z (x::xs) = foldl f (f(z,x)) xs

(* printstats: instruction count facilities *)

(*
  (* move_regc: or rd, rs, $0 c *)
  fun move_regc(rd, rs, comment)
    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
     (Mips_Assembly.OR, rd, rs, Mips_Assembly.REG MachTypes.zero_reg),
     absent, MachTypes.reg_to_string rd ^ " := " ^ MachTypes.reg_to_string rs ^ ", " ^ comment)
*)
d304 1
a304 1
      absent, MachTypes.reg_to_string rd ^ " := " ^ MachTypes.reg_to_string rs ^ ", " ^ comment)
d306 1
a306 1
  (* move_reg: or rd, rs, $0 'rd := rs' *)
d310 1
a310 1
     absent, MachTypes.reg_to_string rd ^ " := " ^ MachTypes.reg_to_string rs)
d312 1
a312 1
  (* move_imm: or rd, $0, #imm 'rd := imm' *)
d316 1
a316 1
     absent, MachTypes.reg_to_string rd ^ ":= " ^ makestring imm )
d318 1
a318 1
  (* move_immc :: ori rd, $0, #imm 'rd := imm' ^ comment *)
d322 1
a322 2
     absent, MachTypes.reg_to_string rd ^ " := " ^ makestring imm ^ ", " ^ comment)

d336 1
a336 1
    end
d338 1
a338 1
(* to_binary converts 'value' into binary number stored in length 'digits' *)
d352 1
a352 1
(* adjust: checks for overflow in expon notation *)
d435 1
a435 6
  type half_op = Mips_Assembly.opcode * MirTypes.tag Option.opt
  type half_op_block = MirTypes.tag * half_op list
  (* A half compiled form with unresolved branches *)


(* last_opcode: return the external branch out of the block if one exists *)
a436 1
    (* Computed GOTOS must be treated specially *)
d461 1
a461 1
(* remove_trailing_branch: deletes sll,ba,nop and stuffs comment into preceding opcode that it did so *)
d549 1
a549 1
			    Map.NO => true
d586 1
a586 1
	      Map.YES(_, t) => t
a611 2
(* Replaced during code vector reform
	(* CT added the following instead of next_offset+4 *)
a612 5
	  next_offset + 4 (* raw spill count *) + 4 (* Back-pointer *)
	  + 4 (* profiler information *) + 4 (* offset to dbug information *)
	  + (size current_proc_padded_name) (* debug information *)
*)
	val next_offset' =
d622 1
a622 2
  exception bad_offset of
  MirTypes.tag * (Mips_Assembly.opcode * MirTypes.tag Option.opt * string) list
d790 1
a790 1
			          raise bad_offset block_tag (copy_n head_size opcode_list [] new_tail)
d792 1
a792 1
			          raise bad_offset block_tag (copy_n head_size opcode_list [] 
d795 1
a795 1
			          raise bad_offset block_tag (copy_n head_size opcode_list [] 
d814 1
a814 1
                       Map.YES res => 
d838 3
d843 1
d849 1
a849 1
                                  (Mips_Assembly.LUI, MachTypes.global, i),
d853 1
a853 1
                                   Mips_Assembly.IMM(i + 4), MachTypes.global),
d859 1
d873 1
a873 1
				   r1, r2, 7), Option.ABSENT,
d877 1
a877 1
                               raise bad_offset(block_tag,
d881 1
a881 1
                     | Map.NO =>
d892 1
a892 1
			 Map.YES res => 
d900 1
a900 1
		       | Map.NO =>
d907 1
a907 1
				    raise bad_offset block_tag (copy_n head_size opcode_list [] new_tail)
d909 1
a909 1
				    raise bad_offset block_tag (copy_n head_size opcode_list []
d912 1
a912 1
				    raise bad_offset block_tag (copy_n head_size opcode_list []
d932 1
a932 1
			 Map.YES res => 
a938 1
						   (*MachTypes.zero_reg*)
d964 1
a964 1
                                  (Mips_Assembly.LUI, MachTypes.global, i),
d968 1
a968 1
                                   Mips_Assembly.IMM(i + 4), MachTypes.global),
d974 1
d976 2
a977 3
				  (Mips_Assembly.JR, 
				   Mips_Assembly.REG MachTypes.global,
				   MachTypes.dummy_reg,
d979 1
a979 1
				  Option.ABSENT, "jump to original destination") ::
d994 1
a994 1
                               raise bad_offset(block_tag,
d998 1
a998 1
		       | Map.NO => Crash.impossible "Assoc do_opcode call")
d1003 1
a1003 1
			 Map.YES res =>
d1030 1
a1030 1
				 raise bad_offset
d1035 1
a1035 1
		       | Map.NO => Crash.impossible "Assoc do_opcode LEO")
d1040 1
a1040 1
			 Map.YES res =>
d1067 1
a1067 1
				     Mips_Assembly.IMM(i + 4), rd),
d1074 1
a1074 1
				 raise bad_offset(block_tag,
d1078 1
a1078 1
		       | Map.NO =>
d1085 1
d1087 1
a1087 1
			 Map.YES res =>
d1091 2
a1092 2
			       ((res + i - offset) mod 1024,
				true, arith_imm_limit)
d1095 1
a1095 1
			      (Mips_Assembly.ADD, rd, rs1, disp),
d1098 1
a1098 1
		       | Map.NO =>
d1104 1
a1104 1
			 Map.YES res =>
d1113 1
a1113 1
				   (disp div 1024) mod (1024 * 1024 * 4)),
d1117 2
a1118 2
				  (Mips_Assembly.ADD, rd, rn,
				   make_imm_fault(disp mod 1024, true, arith_imm_limit)),
d1121 1
a1121 1
		       | Map.NO =>
d1127 1
a1127 1
			 Map.YES res => 
d1130 1
a1130 1
			     val disp = (disp div 1024) mod (1024 * 1024 * 4)
d1136 1
a1136 1
		       | Map.NO =>
d1142 1
a1142 1
			 Map.YES res => 
d1148 1
a1148 1
		       | Map.NO =>
d1167 1
a1167 1
	    | do_linearise_sub(offset, ((tag, proc)(*,padded_name*)) :: rest) =
d1169 1
a1169 6
		val (offset', done') =
		  linearise_proc(offset, offset, proc, [])
(* Replaced during code vector reform
		(* CT added this code for the double word alignment *)
                val offset'' = 8 + 8 + size padded_name + offset'
*)
d1193 4
a1196 3
	  do_linearise_sub(0, proc_list(*Lists.zip(proc_list,padded_name_list)*))
	  handle bad_offset bad_offset_block =>
	    do_linearise (subst_bad_offset_block(proc_list, bad_offset_block))
d1325 1
a1325 1
      fun do_blocks(_, [], _, _, _(*, _, _, _, _, _,_,_*)) = []
a1342 9
(*
		  gc_spill_size,
		  non_gc_spill_size,
		  needs_fp_spare,
		  non_gc_stack_size,
		  gc_stack_size,
		  gc_stack_area,
		  frame_size,
*)
a1344 3
(*
		  linkage_size ) =
*)
d1348 1
a1348 3
(*
	  val non_save_frame_size = gc_stack_size + non_gc_stack_size
*)
a1439 2
	  val lower_part_size = 65536 (* mips is 2^16 ; sparc is 2^12 ie 4096 *)
	  val upper_part_size = 65536  (* mips is 2^16 ; sparc is 2^20 ie 256*256*16 *)
d1441 1
a1441 1
	    (i div (upper_part_size div 4), 4*(i mod (lower_part_size div 4)))
d1443 1
a1443 1
	      (i div upper_part_size, (i mod lower_part_size))
d1448 1
a1448 1
		(i div upper_part_size, (i mod lower_part_size))
d2035 1
a2035 1
			     [move_regc(rd, rs1, "put tagged value into reg")],
d2723 1
a2723 1
			  Option.PRESENT tag, "Branch relative"),
d2942 2
a2943 3
		  in (* let *)
		    (
		     case target of
d2968 1
a2968 1
				  Option.PRESENT tag, "")
d3040 1
a3040 1
				   Option.PRESENT t, "table entry")
d3043 1
a3043 1
		      in (* let *)
d3051 1
a3051 1
				    Option.PRESENT tag, "table entry")
d3064 1
a3064 1
			  in (* let *)
d3112 1
a3112 1
		          add gc1 gc1 bytes "wish for "^bytes^" bytes"
d3127 1
a3127 1
			 add gc1 gc1 rd "wish for "^bytes^" bytes"
d3131 1
a3131 1
			 lw global gc_entry(implicit) "get gc entry code"
d3210 1
a3210 1
			     absent, "wish for "^makestring bytes) ::
d3223 1
a3223 1
			    move_regc(rd,MachTypes.zero_reg,"clear invalid data done in prev nop") ::
d3253 1
a3253 1
			      (Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, gc_entry), absent, "get gc entry code") ::
d3275 1
a3275 1
			  addu gc1 gc1 rd "wish for rd bytes"
d3279 1
a3279 1
			  lw global gc_entry(implicit) "get gc entry code"
d3341 1
a3341 1
			      absent, "wish for rd bytes") ::
d3353 1
a3353 1
			      absent, "get gc entry code") ::
d3459 1
a3459 1
				      ?nop "cant fill this"
d3462 1
a3462 1
				      nop "cant fill this"
d3464 1
a3464 1
				      nop "cant fill this"
d3549 7
a3555 1
			       
d3565 2
a3566 2
			      :: Mips_Assembly.nopc "cant fill this"
			      :: []
d3571 1
a3571 1
			      :: Mips_Assembly.nopc "cant fill this"
d3575 2
a3576 2
			      :: Mips_Assembly.nopc "cant fill this"
			      :: []
d3633 2
a3634 1
				  (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0), Option.PRESENT endTag, "")
d3696 1
a3696 1
			   lw global implicit 4*raise_code 'do all the work of getting to the handler'
d3698 1
a3698 1
			   lw global implicit 4*leaf_raise_code 'do all the work of getting to the handler'
d3711 1
a3711 1
		      absent, "Do all the work of getting to the handler")
d3830 3
d3841 1
d3844 1
a3844 1
	      MirTypes.FP.Map.NO => MirTypes.FP.Map.define(map, fp, true)
d3872 1
a3872 1
	       MirTypes.GC.Map.NO => MirTypes.GC.Map.define(map, r, true)
d3878 1
a3878 1
	       MirTypes.GC.Map.NO => MirTypes.GC.Map.define(map, r, true)
a3948 3
	  fun ch f s =
	    (Set.map f s; false) handle MachTypes.NeedsPreserve => true

d3999 1
a3999 1
                 NewMap.YES((a, b, c),_, is_exn) =>
a4136 9
(*
				     gc_spill_size,
				     non_gc_spill_size,
				     needs_fp_spare,
				     non_gc_stack_size,
				     gc_stack_size,
				     gc_stack_area,
				     frame_size,
*)
d4139 1
a4139 2
				     callee_saves(*,
				     linkage_size*)))
d4258 1
a4258 1
	      val _ = diagnostic_output 3 (fn _ => ["Rescheduled at block level, now doing proc level\n"])
a4262 1

d4350 1
a4350 1
				 NewMap.YES((ty,leaf,annotations),runtime_env, is_exn) =>
@


1.39
log
@Abstraction of debug information
@
text
@d8 3
d3687 7
a3693 2
		| MirTypes.NEW_HANDLER tag =>
		    ([], opcode_list, block_list, final_result)
@


1.38
log
@Changes to PROC_PARAMS
@
text
@d8 3
d147 1
a147 1
  sharing MirTables.MirTypes.Option = MirTables.MirTypes.RuntimeEnv.Option = MirRegisters.Option
a151 2
  sharing type MirTables.MirTypes.RuntimeEnv.debugger_env = 
    MirTables.MirTypes.Debugger_Types.Debugger_Env.debugger_env
d165 1
a165 1
  structure RuntimeEnv = MirTypes.RuntimeEnv
d1379 1
a1379 1
                  Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
d1381 2
a1382 2
                     (fn value => (spill := Option.SOME2(value);value)) (symbolic_value i))
                | Option.SOME1(ref(Option.SOME2(i)),name) => 
d1385 1
a1385 1
                | Option.SOME2(i) => symbolic_value i
d1405 4
a1408 1
                  Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
d1410 2
a1411 4
                     (fn value => (spill := Option.SOME2(value);value)) (symbolic_value i))
                | Option.SOME1(ref(Option.SOME2(i)),name) => ((*output(std_out,"\n name = "^name^"\n");*)
							      i)
                | Option.SOME2(i) => symbolic_value i
d1434 2
a1435 2
		  Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
		    (fn value => (spill := Option.SOME2(value);value)) 
d1437 2
a1438 2
		  | Option.SOME1(ref(Option.SOME2(i)),name) => i
		  | Option.SOME2(i) => symbolic_value i
@


1.37
log
@Remove dependence on mir optimiser for fp registers used
Remove dependence on mir optimiser for gc registers used as well
@
text
@d8 4
d3823 1
a3823 1
		   {leaf, spill_sizes, stack_allocated, ...},
@


1.36
log
@Use non-exception detecting arithmetic for the present
@
text
@d8 3
d3819 1
a3819 3
		   {leaf, registers_used = Option.PRESENT
		    {fp, gc, non_gc},
		    spill_sizes, stack_allocated, ...},
d3833 101
a3933 2
	  val fps = Set.map (fn r => MirTypes.FP.Map.apply'(fp_map, r)) fp
	  val gcs = Set.map (fn r => MirTypes.GC.Map.apply'(gc_map, r)) gc
d3974 1
a3974 1
		(Set.map f s; false) handle MachTypes.NeedsPreserve => true
d3977 1
a3977 1
	    val needs_preserve = (*not opt_leaf_fns*) true (* Leaf not don properly yet *)
d3981 1
d3984 1
a4166 1
	| proc_cg _ = Crash.impossible "mach_cg.proc_cg"
@


1.35
log
@Fix loading of large tagged integers
@
text
@d8 3
d1790 1
a1790 1
			      ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
d1812 10
@


1.34
log
@Added register lists to BRANCH_AND_LINK, TAIL_CALL and ENTER instructions.
@
text
@d8 3
d1441 1
a1441 1
	    (i div (upper_part_size * 4), 4*(i mod (lower_part_size div 4)))
d1485 1
a1485 1
		    (Mips_Assembly.ADDU, reg, reg,
@


1.33
log
@Modifications to include number of callee saves in wordsets
Fixed bugs in BIC, NOT and array length calculations
@
text
@d8 4
d2846 1
a2846 1
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.REG reg_operand,debug_information) =>
d2857 1
a2857 1
		| MirTypes.BRANCH_AND_LINK(_, MirTypes.TAG tag,_) =>
d2898 1
a2898 1
		| MirTypes.TAIL_CALL(_, target) => let
d3489 1
a3489 1
		| MirTypes.ENTER =>
@


1.32
log
@Fix alignment and size calculation for arrays and bytearrays
@
text
@d8 3
d1857 105
a1961 56
		  let
		    val rd = lookup_reg_operand reg_operand
		    val (opcode, gp_operand') =
		      case binary_op of
			MirTypes.ADD => (Mips_Assembly.ADD, gp_operand')
		      | MirTypes.SUB => (Mips_Assembly.SUB, gp_operand')
		      | MirTypes.MULU => Crash.unimplemented"MirTypes.MULU"
		      | MirTypes.MULS => Crash.unimplemented"MirTypes.MULS"
		      | MirTypes.DIVU => Crash.unimplemented"MirTypes.DIVU"
		      | MirTypes.DIVS => Crash.unimplemented"MirTypes.DIVS"
		      | MirTypes.MODU => Crash.unimplemented"MirTypes.MODU"
		      | MirTypes.MODS => Crash.unimplemented"MirTypes.MODS"
		      | MirTypes.AND => (Mips_Assembly.AND, gp_operand')
		      | MirTypes.OR => (Mips_Assembly.OR, gp_operand')
		      | MirTypes.BIC => 
			  (case gp_operand' of 
			     MirTypes.GP_IMM_ANY imm =>
			       (Mips_Assembly.AND, MirTypes.GP_IMM_ANY (~imm))
			   | _ => Crash.impossible"mach_cg:BIC imm match failed")
			  (* ANDN *)
		      | MirTypes.EOR => (Mips_Assembly.XOR, gp_operand')
		      | MirTypes.LSR => (Mips_Assembly.SRL, gp_operand')
		      (* Temporary conversion into SRA from SRL *)
		      (* And back again *)
		      | MirTypes.ASL => (Mips_Assembly.SLL, gp_operand')
		      | MirTypes.ASR => (Mips_Assembly.SRA, gp_operand')

		    fun needs_reverse Mips_Assembly.SUB	= true
		    | needs_reverse Mips_Assembly.SRL	= true
		    | needs_reverse Mips_Assembly.SLL	= true
		    | needs_reverse Mips_Assembly.SRA	= true
		    | needs_reverse _ 			= false

		    val (gp_operand, gp_operand', redo) =
			if is_reg gp_operand then		(gp_operand, gp_operand', false)
			else if is_reg gp_operand' then
                      		if needs_reverse opcode then	(gp_operand, gp_operand', true)
                        	else				(gp_operand', gp_operand, false)
			else (* Both immediate so no problem *)
				(gp_operand, gp_operand', false)
		  in
		    if redo then
		      let
			val inter_reg =
			  case gp_operand' of
			    MirTypes.GP_GC_REG r =>
			      (if r = MirRegisters.global then
				 (* The nasty case *)
				 (case reg_operand of
				    MirTypes.GC_REG r' =>
				      if r = r' then
					Crash.impossible "source and dest global with large int"
				      else
					r'
				  | MirTypes.NON_GC_REG _ =>
				      Crash.impossible"BINARY doesn't deliver GC")
d1963 36
a1998 54
				 MirRegisters.global)
			  | _ => Crash.impossible "BINARY has non-gc register"
		      in
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					MirTypes.GC_REG inter_reg,
					gp_operand) ::
			 MirTypes.BINARY(binary_op, reg_operand,
					 MirTypes.GP_GC_REG inter_reg,
					 gp_operand') ::
			 opcode_list, block_list, final_result)
		      end
		    else
		      if is_reg gp_operand then
			let
			  val rs1 = lookup_gp_operand gp_operand
			in
			  if is_reg gp_operand' orelse
			    gp_check_range(gp_operand', true,
					   arith_imm_limit) then
			    let
			      val reg_or_imm =
				if is_reg gp_operand' then
				  Mips_Assembly.REG(lookup_gp_operand
						     gp_operand')
				else make_imm_format3 gp_operand'
			    in
			      ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				 (opcode, rd, rs1, reg_or_imm), absent, "")],
			       opcode_list, block_list, final_result)
			    end
			  else
			    let
			      val inter_reg =
				case gp_operand of
				  MirTypes.GP_GC_REG r =>
				    (if r = MirRegisters.global then
				       (* The nasty case *)
				       (case reg_operand of
					  MirTypes.GC_REG r' =>
					    if r = r' then
					      Crash.impossible
					      "source and dest global with large int"
					    else
					      r'
					| MirTypes.NON_GC_REG _ =>
					    Crash.impossible"BINARY doesn't deliver GC")
				     else
				       MirRegisters.global)
				| _ => Crash.impossible "BINARY has non-gc register"
			    in
			      ([],
			       MirTypes.UNARY(MirTypes.MOVE,
					      MirTypes.GC_REG inter_reg,
d2000 2
a2001 16
			       MirTypes.BINARY(binary_op, reg_operand,
					       gp_operand,
					       MirTypes.GP_GC_REG inter_reg) ::
			       opcode_list, block_list, final_result)
			    end
			end
		      else
			([],
			 MirTypes.UNARY(MirTypes.MOVE,
					MirTypes.GC_REG MirRegisters.global,
					gp_operand) ::
			 MirTypes.BINARY(binary_op, reg_operand,
					 MirTypes.GP_GC_REG MirRegisters.global,
					 gp_operand') ::
			 opcode_list, block_list, final_result)
		  end
d2031 7
d2042 3
d2046 1
a2046 3
			  ((Mips_Assembly.ARITHMETIC_AND_LOGICAL
			    (Mips_Assembly.XOR, rd, rs1, Mips_Assembly.IMM ~3), absent, "")
			   :: [],
d2050 14
a2063 4
			([], 
			 MirTypes.UNARY(MirTypes.MOVE, reg_operand, gp_operand)
			 :: opcode_list, 
			 block_list, final_result)
d3686 2
a3687 1
			 (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.global, MachTypes.dummy_reg,
d3857 8
a3864 8
 	     val needs_preserve = (*not opt_leaf_fns*) true (* Leaf not don properly yet *)
		orelse preserve_fps
		orelse (ch (fn r =>
		   MachTypes.check_reg(MirTypes.GC.Map.apply'(gc_map, r))) gc)
		orelse (ch (fn r =>
		   MachTypes.check_reg(MirTypes.NonGC.Map.apply'(non_gc_map, r))) non_gc)
		orelse Lists.exists check_instr_block block_list
	   end (* local *)
d3866 1
a3866 1
          val _ = 
d3966 1
a3966 1
	  val callee_save_area = Lists.length callee_saves 
d4042 2
a4043 1
	   not needs_preserve)
d4207 5
a4211 3
	     (fn ((tag, code),(_,spills,_,padded_name,_)) =>
		(Lists.assoc(tag, loc_refs),
		 spills,
d4261 1
a4261 1
		 end))
d4270 4
a4273 2
			     (procedure_name_list, tagged_code',
			      leaf_list, nop_offsets)),
d4283 2
a4284 2
                   makestring (Lists.reducel( fn(x,Code_Module.WORDSET(Code_Module.WORD_SET{2=tagged_code', ...})) =>
                                            (Lists.reducel (fn (x,(_,_,y)) => (size y) + x) (x,tagged_code'))
@


1.31
log
@fixed rest of ALLOCATE
@
text
@d8 3
d2728 23
d2752 4
a2755 4
				 (Mips_Assembly.OR, 
				  MachTypes.global, MachTypes.zero_reg, reg_or_imm), 
				 absent, "temporary register"),
				(Mips_Assembly.BRANCH (branch, rs1, MachTypes.global, 0),
d2757 1
a2757 1
				Mips_Assembly.nop], 
a2758 9
			  else
			    ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (test_instr, MachTypes.global,
				rs1, reg_or_imm),
			       absent, "Do the test"),
			      (Mips_Assembly.BRANCH(branch, MachTypes.global, MachTypes.zero_reg, 0),
			       Option.PRESENT tag, "Do the branch"),
			      Mips_Assembly.nop],
			    opcode_list, block_list, final_result)
d2968 1
a2968 1
			   (Mips_Assembly.BGEZAL, MachTypes.zero_reg, 4),
d3276 5
a3280 2
				   (Mips_Assembly.AND, rd, rd, Mips_Assembly.IMM ~7),
				   absent, "ignore primary tag")]
@


1.30
log
@Fix restore fp not allowed in delay slot for the second time
@
text
@a0 2
(* added ALLOCATE 12 -> 11 changes *)

d8 3
d3038 52
a3089 1

d3132 1
a3132 1
			       [(Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.global, rd, ~primary), absent, "Initialise secondary")])
d3176 1
a3176 1
			      (Mips_Assembly.BLTZ, MachTypes.global, MachTypes.dummy_reg, 7),
d3190 1
a3190 1
				 absent, "Tag object with primary") ::
d3194 2
a3195 2
				 absent, "Calculate end of object") ::
				(Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.zero_reg, rd, ~4), absent, "Zero unaligned extra word") ::
d3197 1
a3197 1
				 absent, "Tag object with primary") :: 
d3201 35
a3235 1
			   
d3238 1
a3238 1
			    val (primary, secondary, length_code) =
d3247 1
a3247 1
					absent, "Calculate length of Array")])                                
d3252 1
a3252 1
					absent, "Calculate length of ByteArray"),
d3256 6
d3264 1
a3264 3
			    ((Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			      (Mips_Assembly.AND, rd, rd, Mips_Assembly.IMM ~7),
			      absent, "Calculate aligned size in bytes") ::
d3267 1
a3267 1
			      absent, "try to get some heap") ::
d3270 1
a3270 1
			      absent, "Is GC needed?") ::
d3272 5
a3276 3
			      (Mips_Assembly.BLTZ, MachTypes.global, MachTypes.dummy_reg, 7), 
			      absent, "Skip call to GC if not") ::
			     Mips_Assembly.nop ::
d3279 1
a3279 1
			      absent, "get entry point of GC") ::
a3284 6
			     (Mips_Assembly.BRANCH 
			      (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 2), absent, "Skip next instruction") ::
			     Mips_Assembly.nop ::
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			      (Mips_Assembly.SUBU, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG rd),
			      absent, "Calculate address of new object") ::
d3287 1
a3287 1
			      absent, "Calculate end of object") ::
d3290 1
a3290 1
			      absent, "Zero last word in case it's unaligned") ::
d3297 3
a3299 2
			      absent, "calc secondary tag") ::
			     (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.global, rd, ~primary), absent, "") :: nil)
d3566 1
a3566 1
			   lw lr 8(sp) "reload the link register"
d3581 1
a3581 1
				Option.ABSENT, "restore lr"),
d3583 1
a3583 1
				Option.ABSENT, ""),
d3585 5
a3589 5
			 (Mips_Assembly.LOAD_AND_STORE(Mips_Assembly.LW, MachTypes.fp, MachTypes.sp, 0), 
				Option.ABSENT, "restore fp"),
			 (Mips_Assembly.JUMP (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr,MachTypes.dummy_reg, Debugger_Types.null_backend_annotation), 
				Option.ABSENT, "return"),
			 Mips_Assembly.nop],
@


1.29
log
@Fix problem with load_large_IMM_ANY_into_register
@
text
@d10 3
d3482 1
d3484 1
a3484 1
			   lw fp 0(sp) "restore fp in delay slot"
d3498 2
d3502 1
a3502 2
			 (Mips_Assembly.LOAD_AND_STORE(Mips_Assembly.LW, MachTypes.fp, MachTypes.sp, 0), 
				Option.ABSENT, "restore fp in delay slot")],
@


1.28
log
@unifying jon's changes & revising ALLOCATE.
@
text
@d10 3
d1435 1
a1435 1
	  (* load_large_IMM_ANY_into_register reg num =
d1446 2
a1447 2
	  fun load_large_IMM_ANY_into_register (reg, num) =
	    (case (split_int num) of
d1456 17
a1472 7
		[(Mips_Assembly.SETHI
		  (Mips_Assembly.LUI, reg, high),
		  absent, MachTypes.reg_to_string reg ^ " := " ^ makestring ((fn MirTypes.GP_IMM_ANY x=>x | _ => Crash.impossible"load_large_IMM_ANY failed") num) ^ ", loading large number"),
		 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
		  (Mips_Assembly.ADDU, reg, reg,
		   Mips_Assembly.IMM low),
		  absent, "")])
d1474 1
a1474 2
	    load_large_IMM_ANY_into_register (reg, MirTypes.GP_IMM_ANY num)

d1995 1
a1995 1
			(load_large_IMM_ANY_into_register(rd, gp_operand), opcode_list, block_list, final_result)
@


1.27
log
@Fix typos
@
text
@d1 2
d2655 2
a2656 2
		  let
		    val zero_virtual = case MirRegisters.zero of
d2658 59
a2716 50
			| _ => Crash.impossible "TEST: zero_virtual failed"
		    fun make_reg0_from_imm0 (MirTypes.GP_IMM_INT 0) = 
		      MirTypes.GP_GC_REG zero_virtual
		      | make_reg0_from_imm0 (MirTypes.GP_IMM_ANY 0) 
			= MirTypes.GP_GC_REG zero_virtual
		      | make_reg0_from_imm0 a = a
		    val (branch, short) = case cond_branch of
		      MirTypes.BNT => (Mips_Assembly.BEQ, false)
		    | MirTypes.BTA => (Mips_Assembly.BNE, false)
		    | MirTypes.BEQ => (Mips_Assembly.BEQ, true)
		    | MirTypes.BNE => (Mips_Assembly.BNE, true)
		    | MirTypes.BHI => Crash.impossible "MirTypes.Bcc unsigned not supported"
		    | MirTypes.BLS => Crash.impossible "MirTypes.Bcc unsigned not supported"
		    | MirTypes.BHS => Crash.impossible "MirTypes.Bcc unsigned not supported"
		    | MirTypes.BLO => Crash.impossible "MirTypes.Bcc unsigned not supported"
		    | MirTypes.BGT => (Mips_Assembly.BGTZ, false) (* unary *)
		    | MirTypes.BLE => (Mips_Assembly.BLEZ, false) (* unary *)
		    | MirTypes.BGE => (Mips_Assembly.BGEZ, false) (* unary *)
		    | MirTypes.BLT => (Mips_Assembly.BLTZ, false) (* unary *)
		    val (branch, gp_op, gp_op') =
		      case gp_operand of
			MirTypes.GP_GC_REG _ => (branch, gp_operand, make_reg0_from_imm0 gp_operand')
		      | MirTypes.GP_NON_GC_REG _ => (branch, gp_operand, make_reg0_from_imm0 gp_operand')
		      | _ => (Mips_Assembly.reverse_branch branch, gp_operand', make_reg0_from_imm0 gp_operand)
		    val _ = case gp_op of
		      MirTypes.GP_GC_REG _ => ()
		    | MirTypes.GP_NON_GC_REG _ => ()
		    | _ => Crash.impossible"Two constant operands to test"
		    val rs1 = lookup_gp_operand gp_op
		    val test_instr = case cond_branch of
		      MirTypes.BTA => Mips_Assembly.AND
		    | MirTypes.BNT => Mips_Assembly.AND
		    | _ => Mips_Assembly.SUB
		  in
		    if is_reg gp_op' orelse
		      gp_check_range(gp_op', true, arith_imm_limit) then
		      let
			val reg_or_imm =
			  if is_reg gp_op' then
			    Mips_Assembly.REG(lookup_gp_operand gp_op')
			  else
			    make_imm_format3 gp_op'
		      in
			if short then
			  if (is_reg gp_op') then
			    ([(Mips_Assembly.BRANCH
			       (branch, rs1, lookup_gp_operand gp_op', 0), 
			       Option.PRESENT tag, "Do the branch"),
			      Mips_Assembly.nop], 
			     opcode_list, block_list, final_result)
d2719 4
a2722 4
			       (Mips_Assembly.OR, 
				MachTypes.global, MachTypes.zero_reg, reg_or_imm), 
			       absent, "temporary register"),
			      (Mips_Assembly.BRANCH (branch, rs1, MachTypes.global, 0),
d2724 13
a2736 22
			      Mips_Assembly.nop], 
			     opcode_list, block_list, final_result)
			else
			  ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			     (test_instr, MachTypes.global,
			      rs1, reg_or_imm),
			     absent, "Do the test"),
			    (Mips_Assembly.BRANCH(branch, MachTypes.global, MachTypes.zero_reg, 0),
			     Option.PRESENT tag, "Do the branch"),
			    Mips_Assembly.nop],
			  opcode_list, block_list, final_result)
		      end
		    else
		      ([],
		       MirTypes.UNARY(MirTypes.MOVE,
				      MirTypes.GC_REG
				      MirRegisters.global,
				      gp_op') ::
		       MirTypes.TEST(cond_branch, tag, gp_op,
				     MirTypes.GP_GC_REG MirRegisters.global) ::
		       opcode_list, block_list, final_result)
		  end
d2765 1
a2765 1
		      add global r1 CODE_OFFSET "address to jump to"
d2789 1
a2789 1
	        (* T[TAIL_CALL bl_dest] => case bl_dest of
d2791 1
a2791 1
		           | leaf_case =
d2793 3
a2795 3
			        lw callee_closure 4(sp) "restore our own's caller closure"
				move_imm r 3
				jr r
d2798 8
a2805 4
			        restores
				move_imm r 3
				jr r "tail call"
				reset
d2807 4
a2810 3
			   | leaf case =
			        BANG!
			        lw callee_closure 4(sp) "restore our own's callers closure"
d2813 6
a2818 2
			   | otherwise =
			        restores
d2820 2
a2821 1
				lw fp 0(sp) 'reset fp to old fp'
d2823 23
a2845 11
		| MirTypes.TAIL_CALL(_, target) =>
		    let
		      val restores = restore_gcs
			@@ ((Mips_Assembly.LOAD_AND_STORE
			    (Mips_Assembly.LW, MachTypes.callee_closure, MachTypes.sp, 4), 
			    absent, "restore our own caller's closure") 
			   :: (Mips_Assembly.LOAD_AND_STORE
			       (Mips_Assembly.LW, MachTypes.lr, MachTypes.sp, 8), 
			       absent, "reset link")
			:: move_reg(MachTypes.sp, MachTypes.fp) 
			:: [])
d2847 1
a2847 1
				 (Mips_Assembly.LW, MachTypes.fp, MachTypes.sp, 0),
d2849 37
a2885 35
		    in (* let *)
		      (case target of 
			 MirTypes.REG reg =>
			   if not needs_preserve then
			     (* leaf case *)
			     Crash.unimplemented "tail call leaf case"
			   else (* non leaf case *)
			     let
			       val reg' = lookup_reg_operand reg
			     in (* let *)
			       restores
			       @@
			       [(Mips_Assembly.ARITHMETIC_AND_LOGICAL 
				 (Mips_Assembly.ADDU, MachTypes.global, (lookup_reg_operand reg), Mips_Assembly.IMM 3), 
				 absent, ""),
				reset,
				(Mips_Assembly.JUMP
				 (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.global,
				  MachTypes.dummy_reg,
				  Debugger_Types.null_backend_annotation), absent, "tail call"),
				Mips_Assembly.nop]
			     end (* let *)
		       | MirTypes.TAG tag =>
			   if not needs_preserve then
			     Crash.unimplemented "TAIL_CALL leaf failed"
			   else (* non-leaf case *)
			     restores
			     @@
			     [reset,
			      (Mips_Assembly.BRANCH
			       (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
			       Option.PRESENT tag, ""),
			      Mips_Assembly.nop]
			     , opcode_list, block_list, final_result)
		    end (* let *)
d3022 44
a3065 99
		 (* T[ALLOCATE allocate reg_operanbd gp_operand] => case gp_operand of
		      | GP_IMM_INT size =
		           | high == 0 = 
			      add gc1 gc1 bytes 'attempt to allocate some heap'
			      sub global gc1 gc2 'Is a GC required?'
			      bltz global 7 'skip call to GC if not'
			      nop
			      lw global gc_entry(implicit) 'fetch entry point of GC'
			      nop_code 'doubleword aligned branch follows shortly'
			      jalr lr global 'call GC'
			      move_immc global bytes 'size arg to gc'
			      ba 2 'skip next instruction'
			      add rd global primary 'tag result with primary'
			      add rd gc1 (primary-bytes) "tag result with primary"
		              | aligned =
			           header_code
		              | otherwise =
			           sw zero rd bytes-primary-4 'zero unaligned extra word'
		           | otherwise = 
			        lui rd high
				add rd rd low 'load large immediate size'
				add gc1 gc1 rd 'attempt to allocate some heap'
				sub global gc1 gc2 'is a GC required'
				bltz global 7 'skip call to GC if not required'
				nop
				lw global gc_entry(implicit) 'fetch entry point of GC'
				nop
				jalr lr global 'call gc'
				move_regc global rd 'pass arg size to gc'
				ba 2 'skip next instruction'
				nop
				sub global gc1 rd 'calculate address of new object'
			        | aligned = 
			             add rd global primary 'tag object with primary'
				     header_code
			        | otherwise =
				     add rd global rd 'calculate end of object'
				     sw zero ~4(rd) 'zero unaligned extra word'
				     add rd global primary 'tag object with primary'
				     header_code
			      where
			         (bytes, primary, aligned, header) = case header of
				    | ALLOC = 
				         | size == 2 = (8, PAIRPTR, true, 0)
					 | otherwise = (8 * ((size + 2) div 2), POINTER, size mod 2 <> 0, 64 * size + RECORD)
				    | ALLOC_STRING = ((size + 12) div 8) * 8, POINTER, true, 64 * size * STRING)
				    | ALLOC_REAL =
				         | fp_used == single = BANG! unimplemented ALLOC_REAL single
					 | fp_used == extended = BANG! unimplemented ALLOC_REAL extended
					 | fp_used == double = (16, POINTER, true, 64 * (16 - 4) + BYTEARRAY)
				    | ALLOC_REF = (8 + 8 * ((size + 2) div 2), REFPTR, size mod 2 <> 0, 64 * size + ARRAY)
				    | ALLOC_BYTEARRAY = ((size + 12) div 8) * 8, REFPTR, true, 64 * size + BYTEARRAY)

				  header_code =
				     | header == 0 = []
				     | otherwise =
				         load_large_number_into_register global header
					 sw global ~primary(rd) 'initialise header'
				  (high,low) = split_int bytes

		      | GP_GC_REG reg =
			   length_code
			   and rd rd ~7 'calculate aligned size in bytes'
			   addu gc1 gc1 rd 'try to get some heap'
			   sub global gc1 gc2 'is GC needed?'
			   bltz global 7 'skip call to GC if not'
			   nop
			   lw global gc_entry(implicit)
			   nop
			   jalr lr global 'call gc'
			   move_regc global rd 'pass arg size to gc'
			   ba 2 'skip next instruction'
			   nop
			   subu global gc1 rd 'calculate address of new object'
			   add rd global rd 'calculate end of object'
			   sw zero ~4(rd) 'zero last word in case its un-aligned'
			   add rd global primary 'tag object with primary'
			   sll global reg 4
			   add global global secondary 'calc header tag'
			   sw global ~primary(rd) 'init header tag'
			   where
			      (primary, secondary, length_code) = case allocate of
			         | ALLOC = BANG! ALLOC variable size
				 | ALLOC_STRING = BANG! ALLOC_STRING variable size
				 | ALLOC_REAL = BANG! ALLOC_REAL variable size
				 | ALLOC_REF = 
				      (REFPTR, ARRAY,
				         add rd reg (12+7))
				 | ALLOC_BYTEARRAY =
				      (REFPTR, BYTEARRAY,
				         srl rd reg 2 'calculate length of bytearray'
					 add rd reg (4+7))
		      | otherwise =
			   BANG! strange parameter to ALLOCATE
		    where
		      rd = reg_operand
		      (link,gc_entry) =
		         | needs_preserve = (lr, 4 * gc)
			 | otherwise =      (gc2, 4 * gc_leaf)
d3067 80
a3146 35
		  *)

		 | MirTypes.ALLOCATE(allocate, reg_operand, gp_operand) =>
		     let
                       val rd = lookup_reg_operand reg_operand

                       val (link, gc_entry) =
                         if needs_preserve then
                           (MachTypes.lr, 4 * Implicit_Vector.gc)
                         else
                           (MachTypes.gc2, 4 * Implicit_Vector.gc_leaf)

                       val allocation = case gp_operand of
			 MirTypes.GP_IMM_INT size => let
			       val (bytes, primary, aligned, header) =
				 case allocate of
				   MirTypes.ALLOC =>
				     if size = 2 then
				       (8, Tags.PAIRPTR, true, 0)
				     else
				       (8 * ((size+2) div 2), Tags.POINTER,
					size mod 2 <> 0, 64*size+Tags.RECORD)
				 | MirTypes.ALLOC_STRING =>
				     (((size+12) div 8) * 8,
				      Tags.POINTER, true, 64*size+Tags.STRING)
				 | MirTypes.ALLOC_REAL =>
				     (case MachTypes.fp_used
					of MachTypes.single   => Crash.unimplemented "ALLOC_REAL single"
				      | MachTypes.extended => Crash.unimplemented "ALLOC_REAL extended"
				      | MachTypes.double   =>
					  (16, Tags.POINTER, true,
					   64*(16 - 4) + Tags.BYTEARRAY))
				 | MirTypes.ALLOC_REF  =>
				     (8 + 8*((size+2) div 2),
				      Tags.REFPTR, size mod 2 <> 0, 64*size+Tags.ARRAY)
d3148 55
a3202 149
				     (((size+12) div 8) * 8, Tags.REFPTR, true,
				      64*size+Tags.BYTEARRAY)

			       val header_code =
				 if header = 0 then 
				   [] 
				 else
				   (load_large_number_into_register (MachTypes.global, header) @@ 
				    [(Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.global, rd, ~primary), absent, "Initialise header")])
				    
			       val (high, low) = split_int (MirTypes.GP_IMM_ANY bytes)
			     in
			       if high = 0 then
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
					(Mips_Assembly.ADD, MachTypes.gc1, MachTypes.gc1, Mips_Assembly.IMM bytes), 
				   	absent, "Attempt to allocate some heap") ::
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
					(Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2),
					absent, "Is a GC required?") ::
				 (Mips_Assembly.BRANCH 
					(Mips_Assembly.BLTZ, MachTypes.global, MachTypes.dummy_reg, 7),
					absent, "Skip call to GC if not") ::
				 Mips_Assembly.nop ::
				 (Mips_Assembly.LOAD_AND_STORE 
					(Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, gc_entry),
					absent, "Fetch entry point of GC") ::
				 (Mips_Assembly.nop_code, Option.ABSENT, "doubleword aligned branch follows shortly") ::
				 (Mips_Assembly.JUMP 
					(Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, MachTypes.global, Debugger_Types.null_backend_annotation), 
					absent, "Call GC") ::
				 move_immc(MachTypes.global, bytes, "Size arg to GC") ::
				 (Mips_Assembly.BRANCH
					(Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 2), absent, "Skip next instruction") ::
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
					(Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary), absent, "Tag result with primary") ::
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
					(Mips_Assembly.ADD, rd, MachTypes.gc1, Mips_Assembly.IMM (primary - bytes)), absent, "Tag result with primary") ::
				 (if aligned then
				    header_code
				  else
				    (Mips_Assembly.LOAD_AND_STORE 
					(Mips_Assembly.SW, MachTypes.zero_reg, rd, bytes - primary - 4), absent, "Zero unaligned extra word") ::
				    header_code)
			       else
				 (* should use this and get rid of high and low load_large_number_into_register  *)

				 (Mips_Assembly.SETHI (Mips_Assembly.LUI, rd, high), absent, "") ::
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
					(Mips_Assembly.ADD, rd, rd, Mips_Assembly.IMM low), absent, "Load large immediate size") ::
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
					(Mips_Assembly.ADD, MachTypes.gc1, MachTypes.gc1, Mips_Assembly.REG rd), absent, "Attempt to allocate some heap") ::
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
					(Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2), absent, "Is a GC required?") ::
				 (Mips_Assembly.BRANCH 
					(Mips_Assembly.BLTZ, MachTypes.global, MachTypes.dummy_reg, 7), absent, "Skip call to GC if not required") ::
				 Mips_Assembly.nop ::
				 (Mips_Assembly.LOAD_AND_STORE 
					(Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, gc_entry), absent, "Fetch entry point of GC") ::
				 Mips_Assembly.nop ::
				 (Mips_Assembly.JUMP 
					(Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, MachTypes.global, Debugger_Types.null_backend_annotation),
					absent, "Call GC") ::
				 move_regc(MachTypes.global, rd, "pass arg size to gc") ::
				 (Mips_Assembly.BRANCH (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 2), absent, "Skip next instruction") ::
				 Mips_Assembly.nop ::
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
				  (Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG rd),
				  absent, "Calculate address bof new object") ::
				 (if aligned then
				    (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary),
					absent, "Tag object with primary") ::
				    header_code
				  else
				    (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.REG rd),
					absent, "Calculate end of object") ::
				    (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.zero_reg, rd, ~4), absent, "Zero unaligned extra word") ::
				    (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary),
					absent, "Tag object with primary") :: 
				    header_code)
			     end
			   
			   | MirTypes.GP_GC_REG reg =>
			       let
                                  val (primary, secondary, length_code) =
                                    case allocate
                                      of MirTypes.ALLOC        => Crash.unimplemented "ALLOC variable size"
                                       | MirTypes.ALLOC_STRING => Crash.unimplemented "ALLOC_STRING variable size"
                                       | MirTypes.ALLOC_REAL   => Crash.unimplemented "ALLOC_REAL variable size"
                                       | MirTypes.ALLOC_REF    =>
                                         (Tags.REFPTR, Tags.ARRAY,
                                          [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                                            (Mips_Assembly.ADD, rd, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM (12+7)),
                                            absent, "Calculate length of Array")])                                
                                       | MirTypes.ALLOC_BYTEARRAY =>
                                         (Tags.REFPTR, Tags.BYTEARRAY,
                                          [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                                            (Mips_Assembly.SRL, rd, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM 2),
                                            absent, "Calculate length of ByteArray"),
                                           (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                                            (Mips_Assembly.ADD, rd, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM (4+7)),
                                            absent, "")])
                                in
                                  length_code @@
                                  ((Mips_Assembly.ARITHMETIC_AND_LOGICAL 
					(Mips_Assembly.AND, rd, rd, Mips_Assembly.IMM ~7),
					absent, "Calculate aligned size in bytes") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
					(Mips_Assembly.ADDU, MachTypes.gc1, MachTypes.gc1, Mips_Assembly.REG rd), 
					absent, "try to get some heap") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
					(Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2),
					absent, "Is GC needed?") ::
				   (Mips_Assembly.BRANCH
				   	(Mips_Assembly.BLTZ, MachTypes.global, MachTypes.dummy_reg, 7), 
					absent, "Skip call to GC if not") ::
				   Mips_Assembly.nop ::
				   (Mips_Assembly.LOAD_AND_STORE 
					(Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, gc_entry), 
					absent, "get entry point of GC") ::
				   Mips_Assembly.nop ::
				   (Mips_Assembly.JUMP 
					(Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, MachTypes.global, Debugger_Types.null_backend_annotation),
					absent, "call gc") ::
				   move_regc(MachTypes.global, rd, "pass arg size to gc") ::
				   (Mips_Assembly.BRANCH 
						(Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 2), absent, "Skip next instruction") ::
				   Mips_Assembly.nop ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
					(Mips_Assembly.SUBU, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG rd),
					absent, "Calculate address of new object") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
					(Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.REG rd),
					absent, "Calculate end of object") ::
				   (Mips_Assembly.LOAD_AND_STORE 
					(Mips_Assembly.SW, MachTypes.zero_reg, rd, ~4),
					absent, "Zero last word in case it's unaligned") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
					(Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary), absent, "Tag object with primary") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
					(Mips_Assembly.SLL, MachTypes.global, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM 4),
					absent, "") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, MachTypes.global, MachTypes.global, Mips_Assembly.IMM secondary),
					absent, "calc header tag") ::
				   (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.global, rd, ~primary), absent, "init header tag") :: nil)
			       end
			   | _ => Crash.impossible "Strange parameter to ALLOCATE"
                     in
                       (allocation, opcode_list, block_list, final_result)
                     end
d3210 19
a3228 19
		 | MirTypes.ADR(adr, reg_operand, tag) =>
		     let
		       val reg = lookup_reg_operand reg_operand
		     in
		       ((case adr of
			   MirTypes.LEA =>
			     [(Mips_Assembly.CALL
			       (Mips_Assembly.BGEZAL, MachTypes.zero_reg, 1),
			       absent, "Call self"),
			      (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (Mips_Assembly.ADD, reg, MachTypes.lr,
				Mips_Assembly.IMM 4),
			       Option.PRESENT tag, "Update gc pointer")]
			 | MirTypes.LEO =>
			     [(Mips_Assembly.LOAD_OFFSET
			       (Mips_Assembly.LEO, reg, 0),
			       Option.PRESENT tag,
			       "Get offset of tag from procedure start")]),
			   opcode_list, block_list, final_result)
d3230 10
a3239 10
		 (* Note that lr points to the call instruction *)
		 (* Thus lr + 4, as computed by the ADD *)
		 (* points to the ADD instruction, which is fixed *)
		 (* up during linearisation *)

		 (* Warning. If we ever make a leaf adr, we must ensure *)
		 (* handler continuations are done safely. This is not currently *)
		 (* true since they use o1 as the address. *)

                | MirTypes.INTERCEPT => (trace_dummy_instructions, opcode_list, block_list, final_result)
d3342 1
a3342 1

d3362 1
a3362 1

d3423 1
a3423 1
			      if n<0 then
d3475 12
a3486 14
		      (restore_fps @@ 
		       restore_gcs @@ 
		       [(Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, MachTypes.lr, MachTypes.sp, 8), 
			 Option.ABSENT, "reload the link register"),
			(Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, MachTypes.callee_closure, MachTypes.sp, 4), 
			 Option.ABSENT, "get the previous caller's closure"),
			(Mips_Assembly.ARITHMETIC_AND_LOGICAL(Mips_Assembly.ADDU,MachTypes.sp, MachTypes.fp, Mips_Assembly.IMM 0 ),
			 Option.ABSENT,"Restore previous sp"), 
			(Mips_Assembly.LOAD_AND_STORE(Mips_Assembly.LW, MachTypes.fp, MachTypes.sp, 0), 
			 Option.ABSENT, "Restore fp"),
			(Mips_Assembly.JUMP (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr,MachTypes.dummy_reg, Debugger_Types.null_backend_annotation), 
			 Option.ABSENT, "return"),
			Mips_Assembly.nop],
		       opcode_list, block_list, final_result)
d3488 4
a3491 4
		      ([(Mips_Assembly.JUMP 
			 (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr, MachTypes.dummy_reg, Debugger_Types.null_backend_annotation),
			 absent, "Return"), Mips_Assembly.nop],
		       opcode_list, block_list, final_result)
d3693 2
a3694 1
	     val needs_preserve = (*not opt_leaf_fns*) true (* Leaf not don properly yet *)
@


1.26
log
@Add fixes for bugs found during hello world stuff
@
text
@d2813 10
a2822 53
		    in
		      case target of
			MirTypes.REG reg =>
			  if not needs_preserve then
			    (* leaf case *)
			    Crash.unimplemented "tail call leaf case"
			 else (* non leaf case *)
			   (
			    restore_gcs
			    @@ 
			    [(Mips_Assembly.LOAD_AND_STORE
			      (Mips_Assembly.LW, MachTypes.callee_closure, MachTypes.sp, 4),
			      Option.ABSENT,
			      "restore our own's caller's closure"),
			     (Mips_Assembly.LOAD_AND_STORE
			      (Mips_Assembly.LW, MachTypes.lr, MachTypes.sp, 8),
			      Option.ABSENT,
			      "set link"),
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			      (Mips_Assembly.ADDU, MachTypes.sp, MachTypes.fp, Mips_Assembly.REG MachTypes.zero_reg), 
			      absent, ""),
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			      (Mips_Assembly.ADDU, MachTypes.global, (lookup_reg_operand reg), Mips_Assembly.IMM 3), 
			      absent, ""),
			     (Mips_Assembly.LOAD_AND_STORE
			      (Mips_Assembly.LW, MachTypes.fp, MachTypes.sp, 0),
			      absent, "reset fp to old fp"),
			     (Mips_Assembly.JUMP
			      (Mips_Assembly.JR,
			       Mips_Assembly.REG MachTypes.global, MachTypes.dummy_reg,
			       Debugger_Types.null_backend_annotation), absent,
			      "tail call"),
			     Mips_Assembly.nop
			     ], opcode_list, block_list, final_result)
=======
			    lw callee_closure 4(sp) "restore our own caller's closure"
			    lw lr 8(sp) "reset link"
			    move_reg sp fp
			 reset = lw fp 0(sp) "reset fp to old fp"
>>>>>>> new.sml

		 *)
		| MirTypes.TAIL_CALL(_, target) => let
		    val restores = restore_gcs
		      @@ ((Mips_Assembly.LOAD_AND_STORE
			  (Mips_Assembly.LW, MachTypes.callee_closure, MachTypes.sp, 4), 
			  absent, "restore our own caller's closure") 
			 :: (Mips_Assembly.LOAD_AND_STORE
			     (Mips_Assembly.LW, MachTypes.lr, MachTypes.sp, 8), 
			     absent, "reset link")
		      :: move_reg(MachTypes.sp, MachTypes.fp) 
		      :: [])
		    val reset = (Mips_Assembly.LOAD_AND_STORE
d2824 2
a2825 2
				 absent, "reset fp to old fp")
		  in (* let *)
d2836 10
a2845 6
			       @@ (move_imm(reg', 3)
				  :: (Mips_Assembly.JUMP
				      (Mips_Assembly.JR, Mips_Assembly.REG reg', MachTypes.dummy_reg,
				       Debugger_Types.null_backend_annotation), absent, "tail call")
				  :: reset 
			          :: [])
d2852 6
a2857 5
			     @@ ((Mips_Assembly.BRANCH
				 (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
				 Option.PRESENT tag, "")
				:: reset
				:: [])
d2859 1
a2859 2
		  end (* let *)

@


1.25
log
@cleared up redundant match patterns
@
text
@d8 3
d2771 1
a2771 1
		       (Mips_Assembly.ADD, MachTypes.global,
a2786 1

d2809 12
a2820 3
				reset
		      where
		         restores =
d2822 26
d2852 1
d3539 4
a3542 3
			    | initStackSlot(offset, 1, done) = saveInstr offset :: done
			    | initStackSlot(offset, n, done) = if n<0 then Crash.impossible "initStackSlot: failed"
							       else initStackSlot(offset+4, n-1, saveInstr offset :: done)
d3592 14
a3605 12
			(restore_fps @@ 
			 restore_gcs @@ 
			 [(Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, MachTypes.lr, MachTypes.sp, 8), 
				Option.ABSENT, "restore lr"),
			  (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, MachTypes.callee_closure, MachTypes.sp, 4), 
				Option.ABSENT, ""),
			  move_regc(MachTypes.sp, MachTypes.fp, "restore previous sp"),
			 (Mips_Assembly.JUMP (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr,MachTypes.dummy_reg, Debugger_Types.null_backend_annotation), 
				Option.ABSENT, "return"),
			 (Mips_Assembly.LOAD_AND_STORE(Mips_Assembly.LW, MachTypes.fp, MachTypes.sp, 0), 
				Option.ABSENT, "restore fp in delay slot")],
			 opcode_list, block_list, final_result)
d3607 4
a3610 4
		     ([(Mips_Assembly.JUMP 
			(Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr, MachTypes.dummy_reg, Debugger_Types.null_backend_annotation),
			absent, "return"), Mips_Assembly.nop],
			opcode_list, block_list, final_result)
d3812 1
a3812 1
	     val needs_preserve = not opt_leaf_fns
@


1.24
log
@revised changes
@
text
@d8 3
d2981 14
a2994 13
		  else (case allocate of
		    MirTypes.ALLOC =>
		      ([],
		       MirTypes.BINARY(MirTypes.SUB, reg_operand,
				       MirTypes.GP_GC_REG MirRegisters.fp,
				       MirTypes.GP_IMM_ANY
				       (gc_stack_alloc_offset +
					4 * (fp_offset + alloc_size) - Tags.PAIRPTR)) ::
		       (* Note tagging on pointer *)
		       opcode_list, block_list, final_result))
		  | _ => Crash.impossible "ALLOCATE_STACK strange allocate"

	        | MirTypes.ALLOCATE_STACK _ => Crash.impossible"ALLOCATE_STACK with no offset from fp"
@


1.23
log
@Update debugger information production
@
text
@d8 3
d12 1
a12 1
No reason?
d15 1
a15 1
No reason?
d203 1
d230 38
a382 1
  val absent = Option.ABSENT
d837 1
a837 1
		          | fault_range("fbranch ((tag - offset) div 4 - 1, true, branch_disp_limit) = b tag'
d964 2
a965 3
				(Mips_Assembly.ADD, rd,
				 MachTypes.zero_reg, Mips_Assembly.IMM disp),
				comment)
a1166 11
  (* move_reg: or rd, rs, $0 *)
  fun move_reg(rd, rs) =
    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
     (Mips_Assembly.OR, rd, rs, Mips_Assembly.REG MachTypes.zero_reg), absent, "")

  (* move_imm: or rd, $0, #imm *)
  fun move_imm(rd, imm) =
    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
     (Mips_Assembly.OR, rd, MachTypes.zero_reg, Mips_Assembly.IMM imm),
     absent, "")

d1427 2
a1428 2
	        |  (0,low)    = or reg zero low  'high part is zero get low part'
		|  (high,0)   = lui reg high     'low part is zero, get high part'
d1430 2
a1431 2
		      lui reg high 'get high part'
		      addu reg reg low 'get low part'
d1438 2
a1439 9
		[(Mips_Assembly.ARITHMETIC_AND_LOGICAL
		  (Mips_Assembly.OR, reg, MachTypes.zero_reg,
		   Mips_Assembly.REG MachTypes.zero_reg),
		  absent, MachTypes.reg_to_string reg ^" = 0")]
	    | (0, low) =>
		[(Mips_Assembly.ARITHMETIC_AND_LOGICAL
		  (Mips_Assembly.OR, reg, MachTypes.zero_reg,
		   Mips_Assembly.IMM low),
		  absent, "high part is zero, get low part")]
d1443 1
a1443 1
		  absent, "low part is zero, get high part")]
d1447 1
a1447 1
		  absent, "Get high part"),
d1451 1
a1451 1
		  absent, "Add in low part")])
d1455 1
d1878 1
a1878 2
					Crash.impossible
					"source and dest global with large int"
d1956 5
a1960 3
		      | isReg r1 | r1 == r2 = []
			              | otherwise = or r1 r2 "place tagged value into register"
		      | otherwise = load_imm_any_into_register r1 r2
a1964 2
		      val SETHI = Mips_Assembly.LUI
		      val ORI = Mips_Assembly.OR
d1969 4
a1972 5
			    []
			  else
			    [(Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			      (ORI, rd, rs1, Mips_Assembly.REG MachTypes.zero_reg), absent, "place tagged value into register")],
			    opcode_list, block_list, final_result)
d1975 1
a1975 5
			let val instr_list =
			  load_large_IMM_ANY_into_register (rd, gp_operand)
			in
			  (instr_list, opcode_list, block_list, final_result)
			end		
d1981 1
a1981 1
		| MirTypes.UNARY(MirTypes.NOT, reg_operand, gp_operand) =>
d1984 1
a1984 3
		      val opcode = Mips_Assembly.XOR
		      val simple_imm = Mips_Assembly.IMM ~3
		    in
d1986 1
a1986 1
   			let
d1988 4
a1991 3
			in
			  ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			     (opcode, rd, rs1, simple_imm), absent, "")],
d1993 1
a1993 1
			end
d1995 3
a1997 2
			([], MirTypes.UNARY(MirTypes.MOVE, reg_operand,
					    gp_operand) :: opcode_list,
d1999 2
a2000 1
		    end
d2002 3
a2004 6
		| MirTypes.NULLARY(MirTypes.CLEAN, reg_operand) =>
                    ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
                       (Mips_Assembly.OR, lookup_reg_operand reg_operand,
			MachTypes.zero_reg, Mips_Assembly.REG MachTypes.zero_reg),
                       absent, "Clean")],
                    opcode_list, block_list, final_result)
d2220 2
d2563 1
a2564 3
                         (Mips_Assembly.ADD,MachTypes.global,MachTypes.zero_reg,
                          Mips_Assembly.IMM 1),absent,""),
                        (Mips_Assembly.ARITHMETIC_AND_LOGICAL
d2601 1
a2601 3
                        (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			 (Mips_Assembly.ADD,MachTypes.global,MachTypes.zero_reg, 
			  Mips_Assembly.IMM 1),absent,""),
d2757 2
a2758 2
		      add global r1 CODE_OFFSET 'address to jump to'
		      jalr lr global debug 'call to tagged value'
d2760 1
a2760 1
		       bgezal zero 0 tag 'call' ???
d2781 1
a2781 24
		(* T[TAIL_CALL _ tag] =>
		      ba tag 'branch relative (tail call)'
		      nop
		   T[TAIL_CALL _ r1] =>
		      add global r1 CODE_OFFSET
		      jr global 'branch indirect'
		      nop
		| MirTypes.TAIL_CALL(_, MirTypes.REG reg) =>	
			     ([(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (Mips_Assembly.ADD, MachTypes.global,
				lookup_reg_operand reg, Mips_Assembly.IMM Tags.CODE_OFFSET),
			       absent, ""),
			      (Mips_Assembly.JUMP 
			       (Mips_Assembly.JR, 
				Mips_Assembly.REG MachTypes.global, MachTypes.dummy_reg,
				Debugger_Types.null_backend_annotation),
			       absent, "Branch indirect"),
			      Mips_Assembly.nop], opcode_list, block_list, final_result)
		| MirTypes.TAIL_CALL(_, bl_dest) =>
		    ( [(Mips_Assembly.BRANCH
			(Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
			Option.PRESENT tag, "Branch relative (tail call)"),
		       Mips_Assembly.nop], opcode_list, block_list, final_result)
		 *)
d2786 2
a2787 2
			        lw callee_closure 4(sp) 'restore our own's caller closure'
				addu r zero 3
d2791 4
a2794 7
			        restore_gcs
				lw callee_closure 4(sp) 'restore our own's caller's closure'
				lw lr 8(sp) 'set link'
				addu sp fp zero
				addu r zero 3
				jr r 'tail call'
				lw fp 0(sp) 'reset fp to old fp'
d2798 1
a2798 1
			        lw callee_closure 4(sp) 'restore our own's callers closyure'
d2802 1
a2802 4
			        restore_gcs
				lw callee_closure 4(sp) 'restore our own caller's closure'
				lw lr 8(sp) 'reset link'
				addu sp zero fp
d2804 9
a2812 1
				lw fp 0(sp) 'reset fp to old fp'
d2815 41
a2855 74
		    in
		     case target of
		       MirTypes.REG reg =>
			 if not needs_preserve then
			   (* leaf case *)
			   Crash.unimplemented "tail call leaf case"
(*
			   (
			    [
			     (Mips_Assembly.LOAD_AND_STORE
			      (Mips_Assembly.LW, MachTypes.callee_closure, MachTypes.sp, 4),
			      absent, "restore our own caller's closure"),
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADDU, lookup_reg_operand reg, MachTypes.zero_reg, Mips_Assembly.IMM 3),
			      absent, ""),
			     (Mips_Assembly.BRANCH
			      (Mips_Assembly.JR, lookup_reg_operand reg, MachTypes.dummy_reg, Debugger_Types.null_backend_annotation),
			      absent, ""),
			     Mips_Assembly.nop
			     ],
			    opcode_list, block_list, final_result)
*)
			 else (* non leaf case *)
			   (
			    restore_gcs
			    @@ [
			       (Mips_Assembly.LOAD_AND_STORE
				(Mips_Assembly.LW, MachTypes.callee_closure, MachTypes.sp, 4),
				Option.ABSENT,
				"restore our own's caller's closure"),
			       (Mips_Assembly.LOAD_AND_STORE
				(Mips_Assembly.LW, MachTypes.lr, MachTypes.sp, 8),
				Option.ABSENT,
				"set link"),
			       (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
				(Mips_Assembly.ADDU, MachTypes.sp, MachTypes.fp, Mips_Assembly.REG MachTypes.zero_reg), 
				absent, ""),
			       (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
				(Mips_Assembly.ADDU, (lookup_reg_operand reg), MachTypes.zero_reg, Mips_Assembly.IMM 3), 
				absent, ""),
			       (Mips_Assembly.JUMP
				(Mips_Assembly.JR, 
				 Mips_Assembly.REG (lookup_reg_operand reg), MachTypes.dummy_reg,
				 Debugger_Types.null_backend_annotation), absent,
				"tail call"),
			       (Mips_Assembly.LOAD_AND_STORE
				(Mips_Assembly.LW, MachTypes.fp, MachTypes.sp, 0),
				absent, "reset fp to old fp")
			       ], opcode_list, block_list, final_result)

		     | MirTypes.TAG tag =>
			 if not needs_preserve then
			   Crash.unimplemented "TAIL_CALL leaf failed"
			 else (* non-leaf case *)
			   (
			    restore_gcs
			    @@ [
			       (Mips_Assembly.LOAD_AND_STORE
				(Mips_Assembly.LW, MachTypes.callee_closure, MachTypes.sp, 4),
				Option.ABSENT,
				"restore our own caller's closure"),
			       (Mips_Assembly.LOAD_AND_STORE
				(Mips_Assembly.LW, MachTypes.lr, MachTypes.sp, 8),
				absent, ""),
			       (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				(Mips_Assembly.ADDU, MachTypes.sp, MachTypes.zero_reg, Mips_Assembly.REG MachTypes.fp),
				absent, ""),
			       (Mips_Assembly.BRANCH
				(Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
				Option.PRESENT tag, ""),
			       (Mips_Assembly.LOAD_AND_STORE
				(Mips_Assembly.LW, MachTypes.fp, MachTypes.sp, 0),
				absent, "reset fp to old fp")
			       ], opcode_list, block_list, final_result)
d2858 2
a2859 1
		(* T[SWITCH goto r1 tag_list] => 
d2861 5
d2867 21
a2887 6
			   bgezal 1 'call self'
			   add lr lr r1 'offset to into table'
			   lw global lr 20 ' get the offset from the table'      ???
			   nop 'lw delay'
			   add global lr 'offset to start of table'
			   jr zero global 'jump to destination'                  ???
d2889 41
a2929 10
			   tag_calculation
		      where
		         tag_calculation = ???
		 *)
		| MirTypes.SWITCH(computed_goto, reg_operand, tag_list) =>
(* untested *)
		    let
		      val reg = lookup_reg_operand reg_operand
		    in
		      ((if Lists.length tag_list <= 2 then
d2931 29
a2959 77
			    val (first_tag, tag_list) = case tag_list of
			      (x :: y) => (x, y)
			    | _ => Crash.impossible"empty switch tag list"

			    fun do_tests(done, []) = rev done
			      | do_tests(done, [tag]) =
				do_tests(Mips_Assembly.nop (* Final delay slot nop *) ::
					 (Mips_Assembly.BRANCH
					  (Mips_Assembly.BA,
					   MachTypes.dummy_reg,
					   MachTypes.dummy_reg, 0),
					  Option.PRESENT tag, "Do the branch") ::
					 done, [])
			      | do_tests(done, tag :: rest) =
				do_tests((Mips_Assembly.ARITHMETIC_AND_LOGICAL
					  (Mips_Assembly.SUB, MachTypes.global,
					   MachTypes.global, Mips_Assembly.IMM 4),
					  absent, "Do the test") ::
					 (Mips_Assembly.BRANCH
					  (Mips_Assembly.BEQ,
					   MachTypes.global,
					   MachTypes.zero_reg, 0),
					  Option.PRESENT tag, "Do the branch") :: done, rest)
			  in
			    (Mips_Assembly.BRANCH
					  (Mips_Assembly.BEQ,
					   MachTypes.global,
					   MachTypes.zero_reg, 0),
					  Option.PRESENT tag, "Do the branch") ::
			    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
					  (Mips_Assembly.SUB, MachTypes.global,
					   reg, Mips_Assembly.IMM 4),
					  absent, "Do the test") ::
			    do_tests([], tag_list)
			  end
			else
(* if length > 2
 bgezal $0 1 		; call self
 add lr lr reg		; offset to into table
 lw global lr 20	; get the offset from the table
 nop_code		; lw delay
 add global global lr	; offset to start of table
 jr $0 global		; jump to destination  !! BUG !!
 nop
*)			  (Mips_Assembly.CALL
			   (Mips_Assembly.BGEZAL, MachTypes.zero_reg, 1),
			   absent, "Call self") ::
			  (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			   (Mips_Assembly.ADD,
			    MachTypes.lr, MachTypes.lr,
			    Mips_Assembly.REG reg), absent,
			   "Offset to into table") ::
			  (Mips_Assembly.LOAD_AND_STORE
			   (Mips_Assembly.LW, MachTypes.global, MachTypes.lr, 20),
			   Option.ABSENT,
			   "Get the offset from the table") ::
			  (Mips_Assembly.nop_code,  (* skip across this one *)
			   Option.ABSENT, 
			   "lw delay") ::
			  (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			   (Mips_Assembly.ADD,
			    MachTypes.global, MachTypes.global,
			    Mips_Assembly.REG MachTypes.lr), absent,
			   "Offset to start of table") ::
			  (Mips_Assembly.JUMP
			   (Mips_Assembly.JR, 
			    Mips_Assembly.REG MachTypes.zero_reg, MachTypes.global,
			    Debugger_Types.null_backend_annotation), absent,
			   "Jump to destination") ::
			  Mips_Assembly.nop (*jump delay *)::
			  map
			  (fn tag =>
			   (Mips_Assembly.OFFSET 20,
			    Option.PRESENT tag, "tag + 20 - ."))
			  tag_list),
			  opcode_list, block_list, final_result)
		    end
d2966 2
a2967 1
		      | op == ALLOCATE = a real bummer, not yet completed
d2971 123
a3093 24
		  (if alloc_size + fp_offset > gc_stack_alloc_size then
		     Crash.impossible("Stack allocation of " ^
				      makestring alloc_size ^
				      " at offset " ^
				      makestring fp_offset ^
				      " requested, in total area of only " ^
				      makestring
				      gc_stack_alloc_size ^
				      "\n")
		   else();
		   case allocate of
		     MirTypes.ALLOC =>
		       ([],
			MirTypes.BINARY(MirTypes.SUB, reg_operand,
					MirTypes.GP_GC_REG MirRegisters.fp,
					MirTypes.GP_IMM_ANY
					(gc_stack_alloc_offset +
					 4 * (fp_offset + alloc_size) - Tags.PAIRPTR)) ::
			(* Note tagging on pointer *)
			opcode_list, block_list, final_result)
		   | _ => Crash.impossible"ALLOCATE_STACK strange allocate")
		 | MirTypes.ALLOCATE_STACK _ => Crash.impossible"ALLOCATE_STACK with no offset from fp"
		 | MirTypes.DEALLOCATE_STACK _ =>
		     ([], opcode_list, block_list, final_result)
d3159 1
a3159 3
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
					(Mips_Assembly.OR, MachTypes.global, MachTypes.zero_reg, Mips_Assembly.IMM bytes),
					absent, "Size argument for GC") ::
d3173 2
d3191 1
a3191 2
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
					(Mips_Assembly.OR, MachTypes.global, MachTypes.zero_reg, Mips_Assembly.REG rd), absent, "Size argument for GC") ::
d3195 2
a3196 2
					(Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG rd),
					absent, "Calculate address bof new object") ::
d3237 1
a3237 1
					absent, "Attempt to allocate some heap") ::
d3240 1
a3240 1
					absent, "Is a GC required?") ::
d3247 1
a3247 1
					absent, "Fetch entry point of GC") ::
d3251 2
a3252 3
					absent, "Call GC") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.OR, MachTypes.global, MachTypes.zero_reg, Mips_Assembly.REG rd),
					absent, "Size argument for GC") ::
d3254 1
a3254 1
						(Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 1), absent, "Skip next instruction") ::
d3271 2
a3272 2
					absent, "Calculate header tag") ::
				   (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.global, rd, ~primary), absent, "Initialise header tag") :: nil)
d3310 3
a3312 3
(* Warning. If we ever make a leaf adr, we must ensure *)
(* handler continuations are done safely. This is not currently *)
(* true since they use o1 as the address. *)
a3315 382
(* There are two versions of T[ENTER] and the original
    version and its accompanying source is commented out

		(* T[ENTER] => arggh
		      | not needs_preserve = (* leaf case *)
			   ([], opcode_list, block_list, final_result)
		      | otherwise = 
			   (result, opcode_list'', block_list'', final_result'')
		      where
		         result =
			    sw fp 0(sp) 'save current fp in previous frame'
			    check_for_stack_overflow_wrap
			 opcode_list'' = []
			 block_list''
			    | opcode_list' == [] = block_list'
			    | otherwise = BLOCK(end_tag, opcode_list') : block_list'
			 final_result'' = 
			    (non_ov_tag,
			       | immediate_size =
				    addiu sp sp ~frame_size 'create new frame'
			       | otherwise = 
				    sub global zero global  'negate frame size'
				    subu sp sp global 'create new frame'
			       sw callee 4(sp) 'save caller's closure'
			       sw lr 8(sp) 'save link'
			       addu callee caller 0 'copy into callee_closure'
			       save_gcs
			       save_fps
			       ba join_tag
			       nop
			    ),
			    (ov_tag, ov_tag_code),
			    final_result'
			 
			 check_for_stack_overflow_wrap
			    | immediate_size = []
			    | otherwise =
			         load_large_number_into_register(global, frame_size)
			    check_and_test_opcodes
		
			 check_and_test_opcodes
			    | non_save_frame_size <= 0 =
			         sub global slimit sp 'compare the required stack size with the calculated'
			    | otherwise = 
			         sub global sp 
				    | immediate_size = frame_size
				    | otherwise = global
				                                  'check the stack for underflow'
				 sub global slimit global 'compare the required stack size with the calculated'
			    test_opcodes
			 test_opcodes = 
			    blez global non_ov_tag 'unsigned stack overflow test'
			    addu fp sp 0 'update fp in delay slot'
			    ba ov_tag
			    nop
			 ov_tag_code
			    | immediate_size = 
			         or global zero #frame_size 'set the required size in global'
			    | otherwise = []
			    post_ov_code
			 post_ov_code = is a recoding of lazy evaluator's nightmare
			    lw fp 4*extend(implicit) 'get address of stack_overflow'
			    nop
			    jalr slimit fp 'do stack overflow'
			    nop
			    | immediate_size = ba non_ov_tag
			    | otherwise      = load_large_number_into_register(global, frame_size)
			    nop
			       
		         immediate_size = check_range(frame_size, true, arith_imm_limit)
		         initStackSlots reg slotSize
		            | check_range end_limit true arith_imm_limit =
			         initStackSlot register_save_size slotSize endInstrs
			    | otherwise = BANG!
			    where
			       (* initStackSlot: sw $0 reg offset for all stack slots *)
			       initStackSlot offset 0 done = done
			       initStackSlot offset 1 done = saveInstr 1 :: done
			       initStackSlot offset n done
			          | n<0 = BANG!
				  | otherwise = initStackSlot (offset+4) (n-1) (saveInstr offset :: done)
				  where
				     saveInstr offset = sw zero reg offset 'init stack slot'
		
			 gc_stack_slots = gc_spill_size + gc_stack_alloc_size
		
			 (opcode_list', block_list', final_result') = 
			    | not clean_stack = (opcode_list, block_list, 
						 (join_tag, initStackSlots sp gc_stack_slots) :: final_result)
			    | otherwise = (#1 [],
					   #2 BLOCK(end_tag, opcode_list) :: block_list, 
					   #3 (join_tag, opcodes) :: block :: final_result
					   )
			    where
			       clean_stack = not (gc_stack_slots (* div 4 *) <= 10)
			       block = (top_tag, store_loop)
			       store_loop = 
			          sub global global 4 'update pointer'
				  add caller caller 4 'update pointer'
				  bgtz global top_tag 'branch if not finished'
				  sw zero ~4(caller) 'init a stack slot using caller_closure as temp(delay slot)'
				  ba end_tag
				  nop
			       opcodes = 
			          add caller sp register_save_size
				  load_limit
			       load_limit
			          | check_range(the_limit,  true, arith_imm_limit) = 
				       move_imm(global, the_limit)
				  | otherwise = 
				       load_large_number_into_register global the_limit
				  ba top_tag
			          where
				     the_limit = 4 * (gc_spill_size + gc_stack_alloc_size)
		*)
		| MirTypes.ENTER =>
		    (* leaf case *)
		    if not needs_preserve then
		      ([], opcode_list, block_list, final_result)
		    else
		      let
			val top_tag = MirTypes.new_tag()
			val end_tag = MirTypes.new_tag()
			  
			(* initStackSlots: zeroes the stack slots prior to use *)
			fun initStackSlots reg slotSize = let
			  
			  fun saveInstr offset = (Mips_Assembly.LOAD_AND_STORE
				  (Mips_Assembly.SW, MachTypes.zero_reg, reg, offset), absent, "init stack slot")
			    
			  (* initStackSlot: sw $0 reg offset for all stack slots *)
			  fun initStackSlot(offset,0,done) = done
			    | initStackSlot(offset,1,done) = saveInstr 1 :: done
			    | initStackSlot(offset,n,done) =
			      if n<0 then
				Crash.impossible "initStackSlot: failed"
			      else initStackSlot(offset+4,n-1, saveInstr offset :: done)
				
			  (* endInstr: ba end_tag, nop *)
			  val endInstrs = [ (Mips_Assembly.BRANCH (*_ANNUL*)
				  (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0), 
			          Option.PRESENT end_tag, "finish cleaning stack"), Mips_Assembly.nop]
			  
			  val end_limit = register_save_size + (slotSize-1)*4

			in (* initStackSlots *)
			  if check_range(end_limit, true, arith_imm_limit) then
			    initStackSlot(register_save_size, slotSize, endInstrs)
			  else
			    Crash.impossible("initStackSlots: end_limit = " ^ makestring end_limit)
			end (* initStackSlots *)

			val gc_stack_slots = (gc_spill_size + gc_stack_alloc_size)

(* attempt at translation *)
			val join_tag = MirTypes.new_tag () (* stackOK in document *)
			val ov_tag = MirTypes.new_tag ()
			val non_ov_tag = MirTypes.new_tag ()
			local

			   val clean_stack = case (*gc_stack_size*) gc_stack_slots (*div 4*) <= 10 of
			        true => false
			      | false => true

			in (* local *)
			  val (opcode_list, block_list, final_result) = 
			    case clean_stack of
			      false => (opcode_list, block_list, (join_tag, initStackSlots MachTypes.sp  gc_stack_slots) :: final_result)
			    | true => let
				val store_loop = 
				  [ (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				     (Mips_Assembly.SUB, MachTypes.global, MachTypes.global, Mips_Assembly.IMM 4),
				     absent, "Update pointer"),
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				    (Mips_Assembly.ADD, MachTypes.caller_closure,
				     MachTypes.caller_closure, Mips_Assembly.IMM 4),
				    absent, "Update pointer"),
				   (Mips_Assembly.BRANCH
				    (Mips_Assembly.BGTZ, MachTypes.global, MachTypes.dummy_reg, 0),
				    Option.PRESENT top_tag,
				    "Branch if not finished"),
				   (Mips_Assembly.LOAD_AND_STORE
				    (Mips_Assembly.SW, MachTypes.zero_reg,
				     MachTypes.caller_closure,
				     ~4),
				    absent,
				    "Initialise a stack slot using caller_closure as temp(delay slot)"),
				   (Mips_Assembly.BRANCH
				    (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
				    Option.PRESENT end_tag, ""),
				   Mips_Assembly.nop]

				val load_limit = let
				  (* branch_out: ba top_tag *)
				  val branch_out =
				    [(Mips_Assembly.BRANCH (*_ANNUL*)
				      (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
				      Option.PRESENT top_tag, "")]
				  val the_limit = 4 * (gc_spill_size + gc_stack_alloc_size)
(* Not relevant on MIPS
				 if gc_stack_size mod 8 = 0 then
				   gc_stack_size
			         else
				   gc_stack_size+4
*)
				in (* load_limit *)
				  case check_range(the_limit, true, arith_imm_limit) of
				    true => move_imm(MachTypes.global, the_limit) :: branch_out
				  | false => 
				      load_large_number_into_register(MachTypes.global, the_limit) 
				      @@ branch_out
				end (* load_limit *)

				val opcodes = (Mips_Assembly.ARITHMETIC_AND_LOGICAL
					       (Mips_Assembly.ADD, MachTypes.caller_closure,
						MachTypes.sp,
						Mips_Assembly.IMM register_save_size), absent,
					       "") ::
				  load_limit

				val block = (top_tag, store_loop)
				in (* let *)
				   (
				    (*#1*)
				    [],
				    (*#2*)
				    MirTypes.BLOCK(end_tag, opcode_list) :: block_list,
				    (*#3*)
				    (join_tag,opcodes) :: block :: final_result
				    )
			      end (* let *)
			 end (* local *)
(* end of translation attempt *)

			val immediate_size =
			  check_range(frame_size, true, arith_imm_limit)

			(* test_opcodes: blez global non_ov_tag 'unsigned stack overflow test'
			                   addu fp sp 0 'update fp in delay slot'
					   ba ov_tag
					   nop
			 *)
			val test_opcodes =
			  [(Mips_Assembly.BRANCH (*_ANNUL*)
			    (Mips_Assembly.BLEZ, MachTypes.global, MachTypes.dummy_reg, 0),
			    Option.PRESENT non_ov_tag,
			    "Unsigned stack overflow test"),
			   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			    (Mips_Assembly.ADDU, MachTypes.fp, MachTypes.sp,
			     Mips_Assembly.IMM 0),
			    Option.ABSENT, "update fp in the delay slot"),
			   (Mips_Assembly.BRANCH (*_ANNUL*)
			    (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
			    Option.PRESENT ov_tag, ""),
			   Mips_Assembly.nop]
			val check_and_test_opcodes =
			  if non_save_frame_size <= 0 then
			    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			     (Mips_Assembly.SUB, MachTypes.global, 
			      MachTypes.stack_limit, Mips_Assembly.REG(MachTypes.sp)), 
			     absent,
			     "Compare the required stack size with the calculated") ::
			    test_opcodes
			  else
			    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			     (Mips_Assembly.SUB, MachTypes.global, MachTypes.sp,
			      if immediate_size then
				Mips_Assembly.IMM frame_size 
			      else
				Mips_Assembly.REG MachTypes.global),
			     absent, "Check the stack for underflow") ::
			    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			     (Mips_Assembly.SUB, MachTypes.global, MachTypes.stack_limit,
			      Mips_Assembly.REG MachTypes.global),
			     absent,
			     "Compare the required stack size with the calculated") ::
			    test_opcodes
			val check_for_stack_overflow_wrap =
			  if immediate_size then
			    check_and_test_opcodes
			  else
			    load_large_number_into_register(MachTypes.global,frame_size) @@
			    check_and_test_opcodes

			(* post_ov_code: is a recoding of lazy evaluator's nightmare
			       lw fp 4*extend(implicit) 'get address of stack_overflow'
			       nop
			       jalr slimit fp 'do stack overflow'
			       nop
			       | immediate_size = ba non_ov_tag
			       | otherwise      = load_large_number_into_register(global, frame_size)
			       nop
			 *)
			val post_ov_code = let
			  (* ba: plugs ba tag leaving subsequent nop to user to play with *)
			  val ba = fn t => (Mips_Assembly.BRANCH (*_ANNUL*) (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),Option.PRESENT t, "")
			in (* post_ov_code *)
			  (Mips_Assembly.LOAD_AND_STORE 
			   (Mips_Assembly.LW, MachTypes.fp, MachTypes.implicit, 4 * Implicit_Vector.extend), absent, "Get address of stack_overflow")
			  :: Mips_Assembly.nop
			  :: (Mips_Assembly.JUMP
			      (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.stack_limit, MachTypes.fp,
			       Debugger_Types.null_backend_annotation), absent, "do stack_overflow")
			  :: Mips_Assembly.nop
			  :: (case immediate_size of
				true => 
				  [ba non_ov_tag, Mips_Assembly.nop]
			      | false =>
				  load_large_number_into_register(MachTypes.global, frame_size) 
				  @@ [ba non_ov_tag, Mips_Assembly.nop]
			    )      
			end (* post_ov_code *)

			(* ov_tag_code: 
			      | immediate_size = or global zero frame_size 'set the required size in global'
			      | otherwise = ''
			 *)
			val ov_tag_code =
			  if immediate_size then
			    (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			     (Mips_Assembly.OR, MachTypes.global, MachTypes.zero_reg,
			      Mips_Assembly.IMM frame_size), 
			     absent, "Set the required size in global") :: post_ov_code
			  else
			    post_ov_code
		      in
			(* (result, opcode_list, block_list, final_result) *)
			((*#1*)
			 (Mips_Assembly.LOAD_AND_STORE
			  (Mips_Assembly.SW, MachTypes.fp, MachTypes.sp, 0),
			  Option.ABSENT, "save current fp in previous frame") ::
			 check_for_stack_overflow_wrap,
			 (*#2*) 
			 [],
			 (*#3*)
			 case opcode_list of
			   [] => block_list
			 | _  => MirTypes.BLOCK(end_tag, opcode_list) :: block_list,
			 (*#4*)
			 (non_ov_tag,
			  (if immediate_size then
			     [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (Mips_Assembly.ADDIU,
				MachTypes.sp, MachTypes.sp,
				Mips_Assembly.IMM(~frame_size)),
			       Option.ABSENT, "create new frame")]
			   else
			     [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (Mips_Assembly.SUB, MachTypes.global, MachTypes.zero_reg,
				Mips_Assembly.REG MachTypes.global), 
			       absent, "Negate the frame size"),
			      (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (Mips_Assembly.SUBU,
				MachTypes.sp, MachTypes.sp,
				Mips_Assembly.REG MachTypes.global),
			       Option.ABSENT, "create new frame")]
			     ) @@
			     (* Push the relevant frame stuff and copy caller_closure *)
			     [(Mips_Assembly.LOAD_AND_STORE
			       (Mips_Assembly.SW, MachTypes.callee_closure,
				MachTypes.sp, 4), Option.ABSENT,
			       "save caller's closure"),
			      (Mips_Assembly.LOAD_AND_STORE
			       (Mips_Assembly.SW, MachTypes.lr,
				MachTypes.sp, 8), Option.ABSENT,
			       "save link")] @@ 
			     [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (Mips_Assembly.ADDU, MachTypes.callee_closure,
				MachTypes.caller_closure, Mips_Assembly.IMM 0),
			       Option.ABSENT, "copy into callee_closure")] @@
			     (* Push the callee saves *)
			     save_gcs @@
			     save_fps @@
			     [(Mips_Assembly.BRANCH
			       (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0),
			       Option.PRESENT join_tag, ""),
			      Mips_Assembly.nop]) ::
			 (ov_tag,ov_tag_code)  ::
			 final_result)
		      end
*)
(* This is the new version of T[ENTER] *)
d3331 1
a3331 1
				   slt global slimit sp 'test for stak overflow'
d3335 1
a3335 1
			      | large_frame = 
d3343 2
a3344 2
			      medium_frame = non_save_frame_size < 32k
			      very_large_frame = non_save_frame_size > 32k
d3348 1
a3348 1
				      bne temp zero stackOKTag
d3350 2
a3351 2
				      bne global zero stackOKtag (* aka non_ov_tag *)
				 addu fp sp zero 'update frame pointer in delay slot'
d3358 1
a3358 1
				      ?nop 'cant fill this'
d3361 1
a3361 1
				      nop 'cant fill this'
d3363 1
a3363 1
				      nop 'cant fill this'
d3370 1
a3370 1
				 addu $callee-closure caller-closure zero 'register move'
d3382 1
a3382 1
				      sw arg 12(sp) *** which arg? callee-arg or caller-arg?
d3390 1
a3390 1
				    (* initStackSlot: sw zero reg offset for all stack slots *)
d3392 1
a3392 1
				    initStackSlot offset 1 done = saveinstr 1 :: done
d3397 1
a3397 1
				          saveInstr offset = sw zero reg offset 'init stack slot'
d3404 1
a3404 1
		    else
d3406 3
a3408 3
			val normal_frame = non_save_frame_size <= 0    (* checks are overlapping, use these checks lexically *)
			val medium_frame = non_save_frame_size < 32768 (* checks are overlapping *)
			val large_frame = non_save_frame_size > 32768  (* checks are overlapping *)
d3420 17
a3436 23
			   if normal_frame then 
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.SLT, MachTypes.global, MachTypes.stack_limit, Mips_Assembly.REG MachTypes.sp),
			      absent, "test for stack overflow")
			     :: []
			   else if medium_frame then
			     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.ADDIU, MachTypes.global, MachTypes.sp, Mips_Assembly.IMM (~frame_size)),
			      absent, "")
			     :: (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				 (Mips_Assembly.SLT, MachTypes.global, MachTypes.stack_limit, Mips_Assembly.REG MachTypes.global),
				 absent, "")
			     :: []
			   else (* large_frame *)
			     load_large_IMM_ANY_into_register(MachTypes.global, MirTypes.GP_IMM_ANY frame_size)
			     @@ (Mips_Assembly.nopc "tempReg ambiguity"
			     (* :: (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			      (Mips_Assembly.SUBU, MachTypes.tempReg, MachTypes.sp, MachTypes.global),
				 absent, "") *)
			     :: [])
			     (* ori global zero lo(frame_size) 'get frame_size into global'
			        lui global hi(frame_size)
				subu tempReg sp global *)
d3442 7
a3448 14
				Option.PRESENT stackOKTag, "Do the branch")
			      (* bne global zero stackOKTag (* aka non_ov_tag *) *)
			    else (* large_frame *) 
			      Mips_Assembly.nopc "tempReg ambiguity" 
			      (* (Mips_assembly.BRANCH
			       (Mips_Assembly.BNE, MachTypes.tempReg, MachTypes.zero_reg, 0),
			       Option.PRESENT stackOKTag, "") *)
			      (* bne temp zero stackOKTag *)
			    )
			  :: (Mips_Assembly.ARITHMETIC_AND_LOGICAL 
			   (Mips_Assembly.ADDU, MachTypes.fp, MachTypes.sp, Mips_Assembly.REG MachTypes.zero_reg), 
			  absent, "update frame pointer in delay slot")
			  :: []

d3454 1
a3454 3
			      :: (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.ORI, MachTypes.global, MachTypes.zero_reg, Mips_Assembly.IMM frame_size),
				  absent, "")
d3460 1
a3460 5
			      (* ?lw fp 16(implicit)
			         ?ori global zero frame_size
			         ?jalr slimit fp
			         ?nop 'cant fill this' *)
			    else (* large_frame *)
a3469 4
			      (* ?lw fp 16(implicit)
			         nop 'cant fill this'
				 jalr slimit fp
				 nop 'cant fill this' *)
d3475 3
a3477 3
			   (Mips_Assembly.LOAD_AND_STORE
			      (Mips_Assembly.SW, MachTypes.fp, MachTypes.sp, 0), absent, "")
			   :: check_for_stack_overflow
a3488 7
			  (* sw callee-closure 4(sp)
			     :: sw lr 8(sp)
			     :: (if debugging then 
			       (* [sw arg 12(sp)] *)
			     else
			       [] 
			   *)
d3497 3
a3499 5
			    | initStackSlot(offset, 1, done) = saveInstr 1 :: done
			    | initStackSlot(offset, n, done) = 
			      if n<0 then
				Crash.impossible "initStackSlot: failed"
			      else initStackSlot(offset+4, n-1, saveInstr offset :: done)
d3506 25
a3530 25
		      val gc_stack_slots = (gc_spill_size + gc_stack_alloc_size)
		     val stackOKTagCode =
			(if normal_frame orelse medium_frame then
			   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			    (Mips_Assembly.ADDIU, MachTypes.sp, MachTypes.sp, Mips_Assembly.IMM (~frame_size)),
			    absent, "")
			 else (* large_frame *)
			   (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			    (Mips_Assembly.SUBU, MachTypes.sp, MachTypes.sp, Mips_Assembly.REG MachTypes.global),
			    absent, "")
			 ) :: (
			       saveFrame
			       @@ [ (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				    (Mips_Assembly.ADDU, MachTypes.callee_closure, MachTypes.caller_closure, Mips_Assembly.REG MachTypes.zero_reg),
				    absent, "register move")
				  ]
			       @@ save_gcs
			       @@ initStackSlots MachTypes.sp gc_stack_slots
			       @@ ( (Mips_Assembly.BRANCH 
				    (Mips_Assembly.BA, MachTypes.dummy_reg, MachTypes.dummy_reg, 0), Option.PRESENT endTag, "")
				  :: Mips_Assembly.nop
				  :: []
				  )
			       )
		      in
d3532 1
a3532 1
		      end
d3538 5
a3542 5
			   lw lr 8(sp) 'reload the link register'
			   lw caller 4(sp) 'get the caller closure'
			   addu sp fp 0 'restore previous sp'
			   jr lr init 'return'
			   lw fp 0(sp) 'restore fp in delay slot'
d3544 1
a3544 1
			   jr lr init 'return'
d3552 4
a3555 5
				Option.ABSENT, "reload the link register"),
			  (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, MachTypes.caller_closure, MachTypes.sp, 4), 
				Option.ABSENT, "get the caller closure"),
			 (Mips_Assembly.ARITHMETIC_AND_LOGICAL(Mips_Assembly.ADDU,MachTypes.sp, MachTypes.fp, Mips_Assembly.IMM 0 ),
				Option.ABSENT,"Restore previous sp"), 
d3559 1
a3559 1
				Option.ABSENT, "Restore fp in delay slot")],
d3564 1
a3564 1
			absent, "Return"), Mips_Assembly.nop],
d3577 4
a3580 6
		(* T[RAISE r1] => 
		     | needsPreserve =
		          lw global implicit 4*raise_code 'do all the work of getting to the handler'
			  nop
			  jr global 'raise'
			  or caller r1 zero 'move arg to raise into arg reg'
d3582 4
a3585 4
			  lw global implicit 4*leaf_raise_code 'do all the work of getting to the hander'
			  nop
			  jalr lr 'raise'
			  or caller r1 zero 'move arg to raise into arg reg'
d3588 5
a3592 18
		    let
		      val code =
			if needs_preserve then
			  [(Mips_Assembly.LOAD_AND_STORE
			    (Mips_Assembly.LW, MachTypes.global,
			     MachTypes.implicit,
			     4 * Implicit_Vector.raise_code),
			    absent, "Do all the work of getting to the handler"),
			  Mips_Assembly.nop,
			  (Mips_Assembly.JUMP
			   (Mips_Assembly.JALR, 
			    Mips_Assembly.REG MachTypes.lr, MachTypes.dummy_reg,
			    Debugger_Types.null_backend_annotation),
			   absent, "Raise"),
			  (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			   (Mips_Assembly.OR, MachTypes.arg, lookup_reg_operand reg,
			    Mips_Assembly.REG MachTypes.zero_reg),
			   absent, "Move arg to raise into arg reg")]
d3594 8
a3601 16
			  [(Mips_Assembly.LOAD_AND_STORE
			    (Mips_Assembly.LW, MachTypes.global,
			     MachTypes.implicit,
			     4 * Implicit_Vector.leaf_raise_code),
			    absent, "Do all the work of getting to the handler"),
			  Mips_Assembly.nop,
			  (Mips_Assembly.JUMP
			   (Mips_Assembly.JR, 
			    Mips_Assembly.REG MachTypes.global, MachTypes.dummy_reg, 
			    Debugger_Types.null_backend_annotation),
			   absent, "Raise"),
			  (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			   (Mips_Assembly.OR, MachTypes.arg,
			    lookup_reg_operand reg,
			    Mips_Assembly.REG MachTypes.zero_reg),
			   absent,"Move arg to raise into arg reg")]
d3603 6
a3608 6
			  handle MachTypes.OutOfScope r =>
			    Crash.impossible ("Raise parameter was in " ^ MachSpec.print_register r ^ " in a leaf procedure")
*)
		     in
		       (code, opcode_list, block_list, final_result)
		    end
@


1.22
log
@No reason?
@
text
@d8 3
d4158 1
a4158 1
                 NewMap.YES((a, b, c),_) =>
d4163 1
a4163 1
                                            else true,c),runtime_env))))
d4168 2
a4169 1
                         procedure_name,((Debugger_Types.null_type,false,nil),runtime_env)))))
d4518 1
a4518 1
				 NewMap.YES((ty,leaf,annotations),runtime_env) =>
d4522 2
a4523 1
                                        ((ty,leaf,(count,debug)::annotations),runtime_env)))
@


1.21
log
@No reason?
@
text
@d8 3
d4581 6
a4586 1
			 e
@


1.20
log
@add new ENTER conventions
@
text
@d8 3
d127 1
d4578 1
a4578 5
			 ext_funs)
    in
     ((module, !debug_map), code_list)
    end
end
@


1.19
log
@cleaning up caller_arg and callee_arg
@
text
@d8 3
d3245 3
d3340 1
d3625 252
@


1.18
log
@added path change to accomodate new runtime structure
@
text
@d8 3
d3690 1
a3690 1
			   (Mips_Assembly.OR, MachTypes.caller_arg, lookup_reg_operand reg,
d3706 1
a3706 1
			   (Mips_Assembly.OR, MachTypes.caller_arg,
@


1.17
log
@Fix floating point spill sizes
@
text
@a7 6
Revision 1.16  1994/05/25  10:23:24  jont
Fix shift of constant by constant problems

Revision 1.15  1994/05/25  09:44:04  jont
Fix type mismatch following mir variable analyser fix from Richard

d58 2
a59 2
require "../rts/implicit";
require "../rts/tags";
d116 1
d132 21
a152 19
  fun contract_sexpr(Sexpr.NIL, [], acc) =
    Lists.reducel (fn (x, y) => y @@ x) ([], acc)
    | contract_sexpr(Sexpr.NIL, x :: xs, acc) = contract_sexpr(x, xs, acc)
    | contract_sexpr(Sexpr.ATOM x, to_do, acc) =
      contract_sexpr(Sexpr.NIL, to_do, x :: acc)
    | contract_sexpr(Sexpr.CONS(x, y), to_do, acc) =
      contract_sexpr(x, y :: to_do, acc)

  val contract_sexpr =
    fn x => contract_sexpr(x, [], [])

  fun find_nop_offsets(_, []) = ~1
    | find_nop_offsets(offset, (opcode, _) :: rest) =
      if opcode = Mips_Assembly.other_nop_code then
	offset
      else
	find_nop_offsets(offset+1, rest)

  val find_nop_offsets = fn (tag, code) => find_nop_offsets(0, code)
d154 1
d161 4
d167 1
a167 5
(*
 i-1 
	(* for mips, branch offset is measured from the delay slot, unlike the sparc *)
*)
      i (* It is up to the caller to get this stuff right *)
d171 1
a171 1
		 MLWorks.Integer.makestring i,
d173 1
a173 1
		 MLWorks.Integer.makestring pos_limit]);
d176 1
d178 5
a182 7
    | make_imm_fault(i, signed, max_pos) =
    let
      val _ = fault_range(i, signed, max_pos)
      val res = Mips_Assembly.IMM i
    in
      res
    end
d184 25
a208 9
  fun mantissa_is_zero mantissa =
    let
      val exp_mant = explode mantissa
      fun exp_mant_is_zero [] = true
      | exp_mant_is_zero("0" :: xs) = exp_mant_is_zero xs
      | exp_mant_is_zero _ = false
    in
      exp_mant_is_zero exp_mant
    end
d211 11
a221 11
  | binary_list_to_string(_, [], _, l) =
    Crash.impossible("Binary_list_to_string length not 8, remainder length " ^
		     MLWorks.Integer.makestring l)
  | binary_list_to_string(done, x :: xs, digit, power) =
    let
      val x = ord x - ord "0"
    in
      if power = 1 then
	binary_list_to_string(chr(digit + x) :: done, xs, 0, 128)
      else
	binary_list_to_string(done, xs, digit + x * power, power div 2)
d224 1
d228 6
a233 6
      | to_sub(digs_to_go, value, done) =
	let
	  val digit = chr(value mod 2 + ord"0")
	in
	  to_sub(digs_to_go - 1, value div 2, digit :: done)
	end
d238 8
a245 9
  fun n_zeroes(done, 0) = done
  | n_zeroes(done, n) = n_zeroes("0" :: done, n-1)

  fun adjust (error_info,x,location) (mantissa, exponent, max_exponent, bits) =
    if mantissa_is_zero mantissa then
      (mantissa, 0)
    else
      if exponent > 0 andalso exponent < max_exponent then
	(mantissa, exponent)
d247 2
a248 6
	(* Need to handle subnormal numbers *)
	if exponent >= max_exponent then
	  Info.error' 
          error_info
          (Info.FATAL,location,
           "Real number too big : " ^ x)
d250 6
a255 1
	  if exponent < ~bits then (implode(n_zeroes([], bits)), 0)
d257 4
a260 1
	    (implode(n_zeroes([], abs exponent)) ^ mantissa, 0)
d294 1
a294 1
	   n_zeroes([], 16) @@
d296 1
a296 1
	   n_zeroes([], 32)	   
d327 1
a327 1
  (* A function to return the terminating branch of a block if one exists *)
d349 3
a351 2
  fun rev_app([], acc) = acc
    | rev_app(x :: xs, acc) = rev_app(xs, x :: acc)
d353 2
a356 1
      val rev_opc = rev opcode_list
d358 1
a358 1
	case rev_opc of
d364 1
a364 2
	| _ =>
	    Crash.impossible"Remove trailing branch fails"
d614 1
a614 1
	     (fn (x, y) => Print.print("Tag " ^ MirTypes.print_tag x ^ ", value " ^ MLWorks.Integer.makestring y ^ "\n"))
a643 3
	    
	  fun rev_app([], y) = y
	    | rev_app(x :: xs, y) = rev_app(xs, x :: y)
d680 1
a680 1
			      " with offset " ^ MLWorks.Integer.makestring offset ^
d684 28
a711 5
		  fun invert_call_to_branch Mips_Assembly.BGEZAL =
		    Mips_Assembly.BLTZ
		    | invert_call_to_branch Mips_Assembly.BLTZAL =
		      Mips_Assembly.BGEZ

d729 1
a729 1
					   MLWorks.Integer.makestring disp,
d759 1
a759 1
				   MachTypes.zero_reg,
d779 6
a784 1

d798 27
d844 1
a844 1
					   MLWorks.Integer.makestring disp,
d874 1
a874 1
				   MachTypes.zero_reg,
d1107 1
a1107 4
  fun gp_from_reg(MirTypes.GC_REG x) = MirTypes.GP_GC_REG x
    | gp_from_reg(MirTypes.NON_GC_REG x) = MirTypes.GP_NON_GC_REG x

  fun reg_from_gp(MirTypes.GP_GC_REG x) = MirTypes.GC_REG x
d1109 1
a1109 1
    | reg_from_gp _ = Crash.impossible"reg_from_gp(IMM)"
d1111 1
d1116 1
d1163 1
a1163 38
  fun number_reg MachTypes.R0 = 0
    | number_reg MachTypes.R1 = 1
    | number_reg MachTypes.R2 = 2
    | number_reg MachTypes.R3 = 3
    | number_reg MachTypes.R4 = 4
    | number_reg MachTypes.R5 = 5
    | number_reg MachTypes.R6 = 6
    | number_reg MachTypes.R7 = 7
    | number_reg MachTypes.R8 = 8
    | number_reg MachTypes.R9 = 9
    | number_reg MachTypes.R10 = 10
    | number_reg MachTypes.R11 = 11
    | number_reg MachTypes.R12 = 12
    | number_reg MachTypes.R13 = 13
    | number_reg MachTypes.R14 = 14
    | number_reg MachTypes.R15 = 15
    | number_reg MachTypes.R16 = 16
    | number_reg MachTypes.R17 = 17
    | number_reg MachTypes.R18 = 18
    | number_reg MachTypes.R19 = 19
    | number_reg MachTypes.R20 = 20
    | number_reg MachTypes.R21 = 21
    | number_reg MachTypes.R22 = 22
    | number_reg MachTypes.R23 = 23
    | number_reg MachTypes.R24 = 24
    | number_reg MachTypes.R25 = 25
    | number_reg MachTypes.R26 = 26
    | number_reg MachTypes.R27 = 27
    | number_reg MachTypes.R28 = 28
    | number_reg MachTypes.R29 = 29
    | number_reg MachTypes.R30 = 30
    | number_reg MachTypes.R31 = 31
    | number_reg MachTypes.cond = Crash.impossible"number_reg: the condition codes"
    | number_reg MachTypes.heap = Crash.impossible"number_reg: the heap"
    | number_reg MachTypes.stack = Crash.impossible"number_reg: the stack"
    | number_reg MachTypes.nil_v = Crash.impossible"number_reg: the nil vector"

  fun compare_reg(r, s) = number_reg r < number_reg s
d1181 1
d1255 1
a1255 1
		  (*
d1263 1
a1263 1
		   *)
d1265 5
a1269 3
		  gcs_to_preserve(*,
		  linkage_size*)
		  ) =
d1272 3
d1282 2
a1283 1
		fun symbolic_value i = 
d1286 2
a1287 2
		     ("Spill slot " ^ MLWorks.Integer.makestring i ^
		      " requested, but only " ^ MLWorks.Integer.makestring gc_spill_size ^
d1291 2
a1292 1
		     ~(gc_spill_offset + 4 * (1 + i)))
d1305 1
a1305 1
		fun symbolic_value i = 
d1310 8
a1317 8
		      Crash.impossible
		      ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
		       " requested, but only " ^
		       MLWorks.Integer.makestring non_gc_spill_size ^
		       " allocated\n")
		    else
		      ();
		      ~(non_gc_spill_offset + 4 * (1 + offset + i))
d1331 16
a1346 16
		fun symbolic_value i =
		  let
		    val offset = if allow_fp_spare_slot then 1 else 0
		  in
		    (if i >= fp_spill_size then
		       Crash.impossible
		       ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
			" requested, but only " ^
			MLWorks.Integer.makestring non_gc_spill_size ^
			" allocated\n")
		     else
		       ();
		       ~(fp_spill_offset + float_value_size * (1 + i) +
			 offset * spare_size)
		       )
		  end
d1379 11
d1396 1
a1396 1
		  absent, "copy zero register")]
d1417 4
a1420 6
	  fun make_imm_format3(MirTypes.GP_IMM_INT i) =
	    make_imm_fault(4 * i, true, arith_imm_limit)
	    | make_imm_format3(MirTypes.GP_IMM_ANY i) =
	      make_imm_fault(i, true, arith_imm_limit)
	    | make_imm_format3(MirTypes.GP_IMM_SYMB symb) =
	      make_imm_fault(symbolic_value symb, true, arith_imm_limit)
d1423 10
a1432 9
	  fun make_imm_for_store(MirTypes.GP_IMM_ANY i) =
	      make_imm_fault(i, true, arith_imm_limit)
	    | make_imm_for_store(MirTypes.GP_IMM_SYMB symb) =
	      make_imm_fault(symbolic_value symb, true, arith_imm_limit)
	    | make_imm_for_store _ =
	      Crash.impossible"make_imm_for_store(bad value)"

	  val make_imm_for_store =
	    fn x => case make_imm_for_store x of
d1436 1
d1611 34
d1723 1
a1723 1
				 (Mips_Assembly.BLTZ, temp_reg, MachTypes.zero_reg, 0),
d1727 1
a1727 1
				 (Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 0),
d1762 24
a1907 3
(*
			Crash.impossible"Mach_Cg(BINARY) first arg not reg"
*)
d1917 5
d1944 4
d1955 1
a1955 1
			let
d1967 1
d1974 1
d1998 21
a2018 1
	        | MirTypes.UNARYFP(unary_fp_op, fp_operand, fp_operand') =>
d2051 21
d2100 17
d2158 7
d2174 1
a2174 1
				       MLWorks.Integer.makestring offset ^
d2176 1
a2176 1
				       MLWorks.Integer.makestring
d2193 1
d2262 1
d2264 1
d2268 1
d2316 1
d2417 9
d2466 43
d2542 1
a2542 1
			  MachTypes.fp_global, Mips_Assembly.REG MachTypes.zero_reg), absent,""), (*don't have to store&load!*)
d2597 3
d2605 1
a2605 1
			   Mips_Assembly.REG (lookup_reg_operand reg), MachTypes.zero_reg,
d2610 1
a2610 1
			[(Mips_Assembly.BRANCH(Mips_Assembly.BA, MachTypes.zero_reg,MachTypes.zero_reg,0),
d2615 2
d2700 1
d2726 8
d2744 1
d2751 10
a2760 6
		| MirTypes.TAIL_CALL(_, bl_dest) =>
		    let
		      val branch =
			(case bl_dest of
			   MirTypes.REG reg =>
			     [(Mips_Assembly.ARITHMETIC_AND_LOGICAL
d2766 1
a2766 1
				Mips_Assembly.REG MachTypes.global, MachTypes.zero_reg,
d2769 38
a2806 6
			      Mips_Assembly.nop]
			 | MirTypes.TAG tag =>
			     [(Mips_Assembly.BRANCH
			       (Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 0),
			       Option.PRESENT tag, "Branch relative (tail call)"),
			      Mips_Assembly.nop])
d2808 89
a2896 2
		      (branch, opcode_list, block_list, final_result)
		    end
d2898 1
d2913 2
a2914 2
					   MachTypes.zero_reg,
					   MachTypes.zero_reg, 0),
d2940 9
a2948 1
			  (Mips_Assembly.CALL
d2981 8
d2993 1
a2993 1
				      MLWorks.Integer.makestring alloc_size ^
d2995 1
a2995 1
				      MLWorks.Integer.makestring fp_offset ^
d2997 1
a2997 1
				      MLWorks.Integer.makestring
d3026 2
a3027 5
                       val allocation =
                         case gp_operand

                           of MirTypes.GP_IMM_INT size =>
			     let
d3057 1
a3057 3
				   (load_large_number_into_register 
				    (MachTypes.global, header)
				    @@ 
d3063 9
a3071 3
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, MachTypes.gc1, MachTypes.gc1, Mips_Assembly.IMM bytes), absent, "Attempt to allocate some heap") ::
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2), absent, "Is a GC required?") ::
				 (Mips_Assembly.BRANCH (Mips_Assembly.BLTZ, MachTypes.global, MachTypes.zero_reg, 7), absent, "Skip call to GC if not") ::
d3073 3
a3075 1
				 (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, gc_entry), absent, "Fetch entry point of GC") ::
d3077 12
a3088 6
				 (Mips_Assembly.JUMP (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, MachTypes.global, Debugger_Types.null_backend_annotation), absent, "Call GC") ::
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.OR, MachTypes.global, MachTypes.zero_reg, Mips_Assembly.IMM bytes), absent, "Size argument for GC") ::
				 (Mips_Assembly.BRANCH (Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 2), absent, "Skip next instruction") ::
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary), absent, "Tag result with primary") ::

				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, MachTypes.gc1, Mips_Assembly.IMM (primary - bytes)), absent, "Tag result with primary") ::
d3092 2
a3093 1
				    (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.zero_reg, rd, bytes - primary - 4), absent, "Zero unaligned extra word") ::
d3097 8
a3104 4
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, rd, Mips_Assembly.IMM low), absent, "Load large immediate size") ::
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, MachTypes.gc1, MachTypes.gc1, Mips_Assembly.REG rd), absent, "Attempt to allocate some heap") ::
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2), absent, "Is a GC required?") ::
				 (Mips_Assembly.BRANCH (Mips_Assembly.BLTZ, MachTypes.global, MachTypes.zero_reg, 7), absent, "Skip call to GC if not required") ::
d3106 2
a3107 1
				 (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, gc_entry), absent, "Fetch entry point of GC") ::
d3109 6
a3114 3
				 (Mips_Assembly.JUMP (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, MachTypes.global, Debugger_Types.null_backend_annotation), absent, "Call GC") ::
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.OR, MachTypes.global, MachTypes.zero_reg, Mips_Assembly.REG rd), absent, "Size argument for GC") ::
				 (Mips_Assembly.BRANCH (Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 2), absent, "Skip next instruction") ::
d3116 3
a3118 1
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG rd), absent, "Calculate address of new object") ::				 
d3120 2
a3121 1
				    (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary), absent, "Tag object with primary") ::
d3124 2
a3125 1
				    (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.REG rd), absent, "Calculate end of object") ::
d3127 2
a3128 1
				    (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary), absent, "Tag object with primary") :: 
d3154 12
a3165 4
                                  ((Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.AND, rd, rd, Mips_Assembly.IMM ~7), absent, "Calculate aligned size in bytes") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADDU, MachTypes.gc1, MachTypes.gc1, Mips_Assembly.REG rd), absent, "Attempt to allocate some heap") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SUB, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2), absent, "Is a GC required?") ::
				   (Mips_Assembly.BRANCH (Mips_Assembly.BLTZ, MachTypes.global, MachTypes.zero_reg, 7), absent, "Skip call to GC if not") ::
d3167 3
a3169 1
				   (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, gc_entry), absent, "Fetch entry point of GC") ::
d3171 7
a3177 3
				   (Mips_Assembly.JUMP (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, MachTypes.global, Debugger_Types.null_backend_annotation), absent, "Call GC") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.OR, MachTypes.global, MachTypes.zero_reg, Mips_Assembly.REG rd), absent, "Size argument for GC") ::
				   (Mips_Assembly.BRANCH (Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 1), absent, "Skip next instruction") ::
d3179 16
a3194 6
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SUBU, MachTypes.global, MachTypes.gc1, Mips_Assembly.REG rd), absent, "Calculate address of new object") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.REG rd), absent, "Calculate end of object") ::
				   (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.zero_reg, rd, ~4), absent, "Zero last word in case it's unaligned") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, rd, MachTypes.global, Mips_Assembly.IMM primary), absent, "Tag object with primary") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SLL, MachTypes.global, lookup_reg(MirTypes.GC.unpack reg, gc_array), Mips_Assembly.IMM 4), absent, "") ::
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.ADD, MachTypes.global, MachTypes.global, Mips_Assembly.IMM secondary), absent, "Calculate header tag") ::
d3201 7
d3239 111
d3351 4
a3354 24
		    (* Function Entry and Stack Push (non leaf)
		     sw $fp, #0($sp)     ; save caller fp
		     
		     ; set register testing for stack overflow
		     ; normal frame and a large frame

		     ; normal frame
		     
		     slt $global, $stack_limit, $sp	; test for stack overflow
		     
		     ; large frame
		
		     addiu $global, $sp, #-framesize
		     slt $global, $stack_limit, $global

		     ; 3a overflow test branch

		     bne $global, $zero, .stackOK
		     addu $fp, $sp, $zero		; update fp in delay slot

		     ; 
		     *)
		     
		    if needs_preserve then
d3358 29
a3386 27
			fun do_store(_, _, 0, done) = done
			  | do_store(reg, offset, 1, done) =
			    (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.zero_reg, reg, offset), absent, "Initialise a stack slot") :: done
			  | do_store(reg, offset, n, done) = if n < 0 then Crash.impossible"Do_store"
			    else do_store(reg, offset+4, n-1, (Mips_Assembly.LOAD_AND_STORE
					(Mips_Assembly.SW, MachTypes.zero_reg, reg, offset), absent,
					"Initialise one stack slots") :: done)
			(* revised version of n_stores running off sp *)
			fun n_stores no_of_stores =
			  (* Assumes area to be cleared immediately *)
			  (* above register save area *)
			  let
			    val end_limit = register_save_size + (no_of_stores-1)*4
			    val end_instrs =
			      [(Mips_Assembly.BRANCH (*_ANNUL*)
				(Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 0),
				Option.PRESENT end_tag,
				"Finish cleaning stack"),
			       Mips_Assembly.nop]
			  in
			    if check_range(end_limit, true,
					   arith_imm_limit) then
			      do_store(MachTypes.sp, register_save_size, no_of_stores,
				       end_instrs)
			    else
			      Crash.impossible("n_stores end_limit = " ^ MLWorks.Integer.makestring end_limit)
			  end
d3388 46
a3433 14
			val (clean_stack, opcodes, block) =
			  if (*gc_stack_size*) gc_stack_slots (*div 4*) <= 10 then
			    (false, n_stores gc_stack_slots, (top_tag, []))
			  else
			    let
			      val branch_out =
				[(Mips_Assembly.BRANCH (*_ANNUL*)
				  (Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 0),
				  Option.PRESENT top_tag,
				  "")]
			      val load_limit =
				let
				  val the_limit =
				    4 * (gc_spill_size + gc_stack_alloc_size)
d3435 4
a3438 4
				    if gc_stack_size mod 8 = 0 then
				      gc_stack_size
				    else
				      gc_stack_size+4
d3440 28
a3467 53
				in
				  if check_range(the_limit, true,
						 arith_imm_limit) then
				    move_imm(MachTypes.global,
					     the_limit) :: branch_out
				  else
				    load_large_number_into_register
				    (MachTypes.global, the_limit) @@ branch_out
				end
			      val load_start =
				(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				 (Mips_Assembly.ADD, MachTypes.caller_closure,
				  MachTypes.sp,
				  Mips_Assembly.IMM register_save_size), absent,
				 "") ::
				load_limit
			      val store_loop =
				[(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.SUB, MachTypes.global,
				   MachTypes.global, Mips_Assembly.IMM 4),
				  absent, "Update counter"),
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.ADD, MachTypes.caller_closure,
				   MachTypes.caller_closure, Mips_Assembly.IMM 4),
				  absent, "Update pointer"),
				 (Mips_Assembly.BRANCH
				  (Mips_Assembly.BGTZ, MachTypes.zero_reg, MachTypes.global, 0),
				  Option.PRESENT top_tag,
				  "Branch if not finished"),
				 (Mips_Assembly.LOAD_AND_STORE
				  (Mips_Assembly.SW, MachTypes.zero_reg,
				   MachTypes.caller_closure,
				   ~4),
				  absent,
				  "Initialise a stack slot using caller_closure as temp(delay slot)"),
				 (Mips_Assembly.BRANCH
				  (Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 0),
				  Option.PRESENT end_tag, ""),
				 Mips_Assembly.nop]
			    in
			      (true, load_start, (top_tag, store_loop))
			    end
			val (opcode_list, block_list, final_result) =
			  if clean_stack then
			    ([],
			     (MirTypes.BLOCK(end_tag, opcode_list)) ::
			     block_list,
			     block :: final_result)
			  else (opcode_list, block_list, final_result)

			val ov_tag = MirTypes.new_tag()  (* Overflow case *)
			val non_ov_tag = MirTypes.new_tag()
			(* Non overflow case *)
a3468 5
			val join_tag = MirTypes.new_tag() (* = .stackOK in the doc *)

			(* Need some stuff to create the frame and fill the relevant bits *)

			val final_result = (join_tag, opcodes) :: final_result
d3471 6
d3479 1
a3479 1
			    (Mips_Assembly.BLEZ, MachTypes.global, MachTypes.zero_reg, 0),
d3487 1
a3487 1
			    (Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 0),
d3519 33
a3551 27
			val post_ov_code = 
			  [(Mips_Assembly.BRANCH (*_ANNUL*)
			    (Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 0),
			    Option.PRESENT non_ov_tag, ""),
			   Mips_Assembly.nop]
			val post_ov_code =
			  if immediate_size then
			    post_ov_code
			  else
			    load_large_number_into_register(MachTypes.global, frame_size) @@
			    post_ov_code

			val post_ov_code =
			     (Mips_Assembly.LOAD_AND_STORE
			      (Mips_Assembly.LW, MachTypes.fp,
			       MachTypes.implicit,
			       4 * Implicit_Vector.extend),
			      absent, "Get address of stack_overflow") ::
			     Mips_Assembly.nop ::
			     (Mips_Assembly.JUMP
			      (Mips_Assembly.JALR,
			       Mips_Assembly.REG MachTypes.stack_limit, MachTypes.fp,
			       Debugger_Types.null_backend_annotation),
			      absent, "do stack_overflow") ::
			     Mips_Assembly.nop ::
			     post_ov_code

d3561 3
a3563 1
			((Mips_Assembly.LOAD_AND_STORE
d3567 1
d3569 45
a3613 44
			 (case opcode_list of
			    [] => block_list
			  | _ => 
			      MirTypes.BLOCK(end_tag,opcode_list) ::
			      block_list),
			    (non_ov_tag,
			     (if immediate_size then
				[(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.ADDIU,
				   MachTypes.sp, MachTypes.sp,
				   Mips_Assembly.IMM(~frame_size)),
				  Option.ABSENT, "create new frame")]
			      else
				[(Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.SUB, MachTypes.global, MachTypes.zero_reg,
				   Mips_Assembly.REG MachTypes.global), 
				  absent, "Negate the frame size"),
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.SUBU,
				   MachTypes.sp, MachTypes.sp,
				   Mips_Assembly.REG MachTypes.global),
				  Option.ABSENT, "create new frame")]) @@
				(* Push the relevant frame stuff and copy caller_closure*)
				[(Mips_Assembly.LOAD_AND_STORE
				  (Mips_Assembly.SW, MachTypes.callee_closure,
				   MachTypes.sp, 4), Option.ABSENT,
				  "save caller's closure"),
				 (Mips_Assembly.LOAD_AND_STORE
				  (Mips_Assembly.SW, MachTypes.lr,
				   MachTypes.sp, 8), Option.ABSENT,
				  "save link"),
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				  (Mips_Assembly.ADDU, MachTypes.callee_closure,
				   MachTypes.caller_closure, Mips_Assembly.IMM 0),
				  Option.ABSENT, "copy into callee_closure")] @@
				(* Push the callee saves *)
				save_gcs @@
				((save_fps @@
				 [(Mips_Assembly.BRANCH
				   (Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 0),
				   Option.PRESENT join_tag, ""),
				  Mips_Assembly.nop]))) ::
			    (ov_tag,ov_tag_code)  ::
			    final_result)
d3615 13
a3627 3
		    else
		      ([], opcode_list, block_list, final_result)

a3628 13
		(* Stack Pop and Return
		     (non leaf case)
			restore_fps
			restore_gcs
			lw $link, #8($sp)		; reload the link register
			lw $caller-closure, #4($sp)	; get the caller closure
			addu $sp, $fp, $0		; restore previous sp
			jr $link			; return
			lw $fp, #0($sp)			; restore fp in delay slot
		     (leaf case)
			jr $link			; return
		*)	
		   
d3632 10
a3641 5
			 [(Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, MachTypes.lr, MachTypes.sp, 8), Option.ABSENT, "reload the link register"),
			  (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.LW, MachTypes.caller_closure, MachTypes.sp, 4), Option.ABSENT, "getting the caller closure"),
			 (Mips_Assembly.ARITHMETIC_AND_LOGICAL(Mips_Assembly.ADDU,MachTypes.sp, MachTypes.fp, Mips_Assembly.IMM 0 ),Option.ABSENT,"Restore previous sp"), 
			 (Mips_Assembly.JUMP (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr,MachTypes.zero_reg, Debugger_Types.null_backend_annotation), Option.ABSENT, "return"),
			 (Mips_Assembly.LOAD_AND_STORE(Mips_Assembly.LW, MachTypes.fp, MachTypes.sp, 0), Option.ABSENT, "Restore fp in delay slot")],
d3644 3
a3646 1
		     ([(Mips_Assembly.JUMP (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr, MachTypes.zero_reg, Debugger_Types.null_backend_annotation), absent, "Return"), Mips_Assembly.nop],
d3648 1
d3651 1
d3659 12
d3683 1
a3683 1
			    Mips_Assembly.REG MachTypes.lr, MachTypes.global,
d3699 1
a3699 1
			    Mips_Assembly.REG MachTypes.global, MachTypes.zero_reg, 
d3715 6
d3787 2
d3839 1
d3845 4
a3848 3
(* Warning. If we ever make a leaf adr, we must ensure *)
(* handler continuations are done safely. This is not currently *)
(* true since they use o1 as the address. *)
d3857 23
a3879 10
	  val needs_preserve =
	    not (opt_leaf_fns) orelse
	    preserve_fps orelse
	    (ch (fn r =>
		 MachTypes.check_reg(MirTypes.GC.Map.apply'(gc_map, r))) gc)
	    orelse
	    (ch (fn r =>
		 MachTypes.check_reg(MirTypes.NonGC.Map.apply'(non_gc_map, r))) non_gc)
	    orelse
            Lists.exists check_instr_block block_list
d3904 2
d3913 1
a3913 1
(* This may need rewriting depending on how MIPs real to int and vice versa	*)
d3977 2
a3978 3
	  
	  val callee_saves =
	    Lists.qsort compare_reg (Lists.filterp check_reg (Set.set_to_list gcs))
d3986 4
a3989 2
	  (* linkage area in each frame for fp, closure, link *)
	  (* will be 4 when we get debugging working *)
d4060 3
d4291 1
a4291 1
                   MLWorks.Integer.makestring(Lists.reducel( fn(x,Code_Module.WORDSET(Code_Module.WORD_SET{2=tagged_code', ...})) =>
d4297 1
a4297 2
      fun make_external_refs(con, list) =
	map (fn (x, y) => con(y, x)) list
@


1.16
log
@Fix shift of constant by constant problems
@
text
@d8 3
d1147 2
a1148 1
     allow_fp_spare_slot   : bool (* Do we need a slot for float to int conversion? *)
d1219 2
a1220 1
		   allow_fp_spare_slot
d1244 1
a1244 2
		val symbolic_value = 
		  fn i => 
d1252 1
a1252 2
		     ~(gc_spill_offset + 4 * (1 + i))
		     )
d1265 1
a1265 2
		val symbolic_value = 
		  fn i => 
d1269 9
a1277 10
		    (if i >= non_gc_spill_size then
		       Crash.impossible
		       ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
			" requested, but only " ^
			MLWorks.Integer.makestring non_gc_spill_size ^
			" allocated\n")
		     else
		       ();
		       ~(non_gc_spill_offset + 4 * (1 + offset + i))
		       )
d1289 21
a1309 3
	      (case i of 
		 Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
		   ((*output(std_out,"\n name = "^name^"\n");*)
d1311 4
a1314 5
		    (~4 * (1 + non_gc_spill_size + i)))
	       | Option.SOME1(ref(Option.SOME2(i)),name) => ((*output(std_out,"\n name = "^name^"\n");*)
							     i)
	       (* This stuff still needs sorting out *)
	       | Option.SOME2(i) =>  ~(fp_spill_offset + 4 * (1 + i)))
d3346 1
a3346 1
	  val float_spill_size = case MachTypes.fp_used of
d3355 1
a3355 1
	    if total_fp_size <> 0 andalso float_spill_size = 4 andalso
d3364 1
a3364 1
	    non_gc_spill_size * 4 + float_spill_size * total_fp_size
d3392 1
a3392 1
	  val fp_save_offset = fp_spill_offset + fp_spill_size * float_spill_size
d3413 2
a3414 1
	     allow_fp_spare_slot = needs_fp_spare
@


1.15
log
@Fix type mismatch following mir variable analyser fix from Richard
@
text
@d8 3
d1780 12
a1791 1
		      else Crash.impossible"Mach_Cg(BINARY) first arg not reg"
@


1.14
log
@Rationalise stack layout information
Fix bug whereby spills were written in the wrong place
Fix bug whereby gc initialisation was starting and finishing too low
@
text
@d8 5
d3197 1
a3197 1
		    spill_sizes, stack_allocated},
@


1.13
log
@Fix code generation of LEO for mutually recursive function case
@
text
@d8 3
d1045 94
d1192 1
a1192 1
      fun do_blocks(_, [], _, _, _, _, _, _, _, _,_,_) = []
d1194 16
d1217 1
d1219 2
a1220 2
		  gcs_to_preserve,
		  linkage_size
d1223 1
a1224 1
	  fun gc_area_start_offset _ = ~(non_gc_stack_size + 4)
d1227 16
a1242 16
	  | symbolic_value MirTypes.NON_GC_SPILL_SIZE =
	    non_gc_stack_size
	  | symbolic_value(MirTypes.GC_SPILL_SLOT i) =
            let 
              val symbolic_value = 
                fn i => 
                (if i >= gc_spill_size then
                   Crash.impossible
                   ("Spill slot " ^ MLWorks.Integer.makestring i ^
                    " requested, but only " ^ MLWorks.Integer.makestring gc_spill_size ^
                    " allocated\n")
                 else
                   ();
                   ~(non_gc_stack_size + 4 * (1 + linkage_size + i))
                   )
            in
d1251 20
a1270 20
            end
	  | symbolic_value(MirTypes.NON_GC_SPILL_SLOT i) =
            let 
              val symbolic_value = 
                fn i => 
                let
                  val offset = if needs_fp_spare then 1 else 0
                in
                  (if i >= non_gc_spill_size then
                     Crash.impossible
                     ("non gc spill slot " ^ MLWorks.Integer.makestring i ^
                      " requested, but only " ^
                      MLWorks.Integer.makestring non_gc_spill_size ^
                      " allocated\n")
                   else
                     ();
                     ~4 * (1 + offset + i + linkage_size)
                     )
                end
            in
d1276 1
a1276 1
                     i)
d1278 11
a1288 11
            end
	  | symbolic_value(MirTypes.FP_SPILL_SLOT i) =
               (case i of 
                  Option.SOME1(spill as ref(Option.SOME1(i)),name) => 
                    ((*output(std_out,"\n name = "^name^"\n");*)
                     (fn value => (spill := Option.SOME2(value);value)) 
                            (~4 * (1 + non_gc_spill_size + i)))
                | Option.SOME1(ref(Option.SOME2(i)),name) => ((*output(std_out,"\n name = "^name^"\n");*)
                     i)
(* This stuff still needs sorting out *)
                | Option.SOME2(i) => ~4 * (1 + non_gc_spill_size + i + linkage_size))
d1384 1
a1384 1
	      fun really_do_restore_fps(_, []) = []
d1386 22
a1407 22
	          case MachTypes.fp_used of
			MachTypes.single =>
			  (Mips_Assembly.LOAD_AND_STORE_FLOAT
			   (Mips_Assembly.LWC1, fp, MachTypes.fp,
			    Mips_Assembly.IMM offset), Option.ABSENT,
			   "restore float") ::
			  Mips_Assembly.nop ::
			  really_do_restore_fps(offset+4, rest)
		      | MachTypes.double =>
			  (Mips_Assembly.LOAD_AND_STORE_FLOAT
			   (Mips_Assembly.LWC1, fp, 
			    MachTypes.fp,
			    Mips_Assembly.IMM offset), Option.ABSENT,
			   "restore float") :: 
			  (Mips_Assembly.LOAD_AND_STORE_FLOAT
			   (Mips_Assembly.LWC1, 
			    MachTypes.next_reg fp,
			    MachTypes.fp,
			    Mips_Assembly.IMM (offset+4)), Option.ABSENT,
			   "restore float") ::
			  really_do_restore_fps(offset+8, rest)
		      | MachTypes.extended => Crash.impossible "really_do_restore_fps: Extended floats not supported"
d1409 2
a1410 2
	      fun do_restore_fps(_, []) = []
	      | do_restore_fps a=really_do_restore_fps a
d1413 1
d1420 1
d1436 7
a1442 1
	  val save_fps = do_save_fps(~real_non_gc_stack_size, fps_to_preserve)
a1443 2
	  val restore_fps = do_restore_fps(~real_non_gc_stack_size, fps_to_preserve)
	  val callee_save_offset = frame_size - 4 * linkage_size
d1953 1
a1953 2
		    if 4 * (gc_spill_size + offset + 1) >
		      gc_stack_size then
d1958 1
a1958 1
				       (gc_stack_size div 4 - gc_spill_size) ^
d1966 1
a1966 1
				      (~(gc_stack_area + 4 * (offset + 1)))) ::
d2560 1
a2560 2
		  (if 4 * (gc_spill_size + alloc_size + fp_offset) >
		     gc_stack_size then
d2567 1
a2567 1
				      (gc_stack_size div 4 - gc_spill_size) ^
d2576 1
a2576 1
					(gc_stack_area +
d2794 1
a2794 1
			    val end_limit = linkage_size * 4 + (no_of_stores-1)*4
d2804 1
a2804 1
			      do_store(MachTypes.sp, linkage_size * 4, no_of_stores,
d2809 1
d2811 2
a2812 4
			  if gc_stack_size div 4 <= 10 then
			    (false,
			     n_stores(gc_stack_size div 4),
			     (top_tag, []))
d2823 2
d2829 1
d2842 2
a2843 1
				  MachTypes.sp, Mips_Assembly.IMM (linkage_size * 4)), absent,
d3271 3
d3290 2
d3314 3
d3324 2
d3327 3
a3329 2
	    non_gc_spill_size * 4 + float_spill_size * fp_spill_size
	    + float_spill_size * fp_save_size
d3337 1
a3337 38
	  
	  (* check_reg: returns true for a callee_save register *)
	  fun check_reg MachTypes.R0 = false
	    | check_reg MachTypes.R1 = false
	    | check_reg MachTypes.R2 = false
	    | check_reg MachTypes.R3 = false
	    | check_reg MachTypes.R4 = false
	    | check_reg MachTypes.R5 = false
	    | check_reg MachTypes.R6 = false
	    | check_reg MachTypes.R7 = false
	    | check_reg MachTypes.R8 = false
	    | check_reg MachTypes.R9 = false
	    | check_reg MachTypes.R10 = true
	    | check_reg MachTypes.R11 = true 
	    | check_reg MachTypes.R12 = true 
	    | check_reg MachTypes.R13 = true 
	    | check_reg MachTypes.R14 = true 
	    | check_reg MachTypes.R15 = true 
	    | check_reg MachTypes.R16 = false
	    | check_reg MachTypes.R17 = false
	    | check_reg MachTypes.R18 = false
	    | check_reg MachTypes.R19 = false
	    | check_reg MachTypes.R20 = false
	    | check_reg MachTypes.R21 = false
	    | check_reg MachTypes.R22 = false
	    | check_reg MachTypes.R23 = false
	    | check_reg MachTypes.R24 = true
	    | check_reg MachTypes.R25 = true
	    | check_reg MachTypes.R26 = false
	    | check_reg MachTypes.R27 = false
	    | check_reg MachTypes.R28 = false
	    | check_reg MachTypes.R29 = false
	    | check_reg MachTypes.R30 = false
	    | check_reg MachTypes.R31 = false
	    | check_reg MachTypes.cond = Crash.impossible"check_reg: the condition codes"
	    | check_reg MachTypes.heap = Crash.impossible"check_reg: the heap"
	    | check_reg MachTypes.stack = Crash.impossible"check_reg: the stack"
	    | check_reg MachTypes.nil_v = Crash.impossible"check_reg: the nil vector"
d3339 2
a3340 37
	  fun number_reg MachTypes.R0 = 0
	    | number_reg MachTypes.R1 = 1
	    | number_reg MachTypes.R2 = 2
	    | number_reg MachTypes.R3 = 3
	    | number_reg MachTypes.R4 = 4
	    | number_reg MachTypes.R5 = 5
	    | number_reg MachTypes.R6 = 6
	    | number_reg MachTypes.R7 = 7
	    | number_reg MachTypes.R8 = 8
	    | number_reg MachTypes.R9 = 9
	    | number_reg MachTypes.R10 = 10
	    | number_reg MachTypes.R11 = 11
	    | number_reg MachTypes.R12 = 12
	    | number_reg MachTypes.R13 = 13
	    | number_reg MachTypes.R14 = 14
	    | number_reg MachTypes.R15 = 15
	    | number_reg MachTypes.R16 = 16
	    | number_reg MachTypes.R17 = 17
	    | number_reg MachTypes.R18 = 18
	    | number_reg MachTypes.R19 = 19
	    | number_reg MachTypes.R20 = 20
	    | number_reg MachTypes.R21 = 21
	    | number_reg MachTypes.R22 = 22
	    | number_reg MachTypes.R23 = 23
	    | number_reg MachTypes.R24 = 24
	    | number_reg MachTypes.R25 = 25
	    | number_reg MachTypes.R26 = 26
	    | number_reg MachTypes.R27 = 27
	    | number_reg MachTypes.R28 = 28
	    | number_reg MachTypes.R29 = 29
	    | number_reg MachTypes.R30 = 30
	    | number_reg MachTypes.R31 = 31
	    | number_reg MachTypes.cond = Crash.impossible"number_reg: the condition codes"
	    | number_reg MachTypes.heap = Crash.impossible"number_reg: the heap"
	    | number_reg MachTypes.stack = Crash.impossible"number_reg: the stack"
	    | number_reg MachTypes.nil_v = Crash.impossible"number_reg: the nil vector"
	  fun compare_reg(r, s) = number_reg r < number_reg s
a3341 1
	  val callee_saves = Lists.qsort compare_reg (Lists.filterp check_reg (Set.set_to_list gcs))
d3343 1
d3346 1
d3348 4
a3351 2
	(* linkage area in each frame for fp, closure, link
	 * will be 4 when we get debugging working *)
d3353 7
d3362 17
d3382 1
d3390 2
d3393 2
a3394 2
				     callee_saves,
				     linkage_size))
@


1.12
log
@Added code generation of load_offset.
Added handling of case where load_offset can't be one instruction
similar to case where adr expands to more than one
@
text
@d8 5
d638 1
a638 1
	  fun linearise_proc(offset, [], done) = 
d640 1
a640 1
	    | linearise_proc(start, blocks as (block :: block_list), done) =
d818 2
a819 1
			     val disp = (res + i)
d919 2
a920 1
			     val disp = res + i
d976 1
a976 1
	      linearise_proc(next, block_list, so_far)
d983 1
a983 1
		  linearise_proc(offset, proc, [])
@


1.11
log
@Moved module types to separate file (code_module)
Fixed out of range branches and calls when compiling large functions
Recoded switch statements for semantic integrity
and to avoid long branch problems
@
text
@d8 6
d157 1
a157 1
       (*Crash.impossible"Immediate constant out of range"*)raise Match )
d806 38
a843 1
		       | Map.NO => Crash.impossible "Problem in _mach_cg.sml")
d908 22
d943 1
a943 1
			   Crash.impossible"Assoc do_opcode arith")
d2599 19
a2617 8
		     ([(Mips_Assembly.CALL
			(Mips_Assembly.BGEZAL, MachTypes.zero_reg, 1),
			absent, "Call self"),
		       (Mips_Assembly.ARITHMETIC_AND_LOGICAL
			(Mips_Assembly.ADD, lookup_reg_operand reg_operand, MachTypes.lr,
			 Mips_Assembly.IMM 4),
			Option.PRESENT tag, "Update gc pointer")],
		     opcode_list, block_list, final_result)
@


1.10
log
@Moved machpsec from mips to main
Fixed problem where store offset zero was returned as register 0
@
text
@d8 4
d43 1
d62 1
d94 1
a94 1
  type Module = MachTypes.Module
d139 3
a141 1
    if check_range(i, signed, pos_limit) then i-1 
d143 2
d151 1
a151 1
       Crash.impossible"Immediate constant out of range" )
d259 1
a259 1
  fun value_cg(i, MirTypes.SCON (Ident.STRING x),_) = MachTypes.STRING(i, x)
d269 1
a269 1
        MachTypes.REAL(i, encoding_function(sign, mantissa, exponent)) 
d277 1
a277 1
      MachTypes.MLVALUE (i,value)
d479 1
a479 1
  exception bad_adr of
d515 1
a515 1
	  val branches_double_word_aligned = true
d585 1
a585 1
	  val perform_branch_check = true
d602 25
d636 13
d650 1
a650 1
				 Option.PRESENT tag, comment), offset) =
d654 1
a654 3
                           val disp =
                             fault_range(( res - offset) div 4,
                                         true, branch_disp_limit)
d656 57
a712 1
                           (Mips_Assembly.BRANCH(branch, r1, r2, disp), comment)
d717 27
a743 38
		  | do_opcode((Mips_Assembly.FBRANCH(branch, i),
			       Option.PRESENT tag, comment), offset) =
		    (case lookup_env tag of
                       Map.YES res => 
                         let
                           val disp =
                             fault_range((res - offset) div 4,
                                         true, branch_disp_limit)
                         in
                           (Mips_Assembly.FBRANCH(branch, disp), comment)
                         end
                     | Map.NO =>
                         Crash.impossible"Assoc do_opcode fbranch")
		  | do_opcode((Mips_Assembly.CALL(Mips_Assembly.BGEZAL, r, i),
			       Option.PRESENT tag, comment), offset) =
                    (case lookup_env tag of
                       Map.YES res => 
                         let
                           val disp =
                             fault_range(( res + i - offset) div 4,
                                         true, call_disp_limit)
                         in
                           (Mips_Assembly.CALL(Mips_Assembly.BGEZAL, MachTypes.zero_reg, disp), comment)
                         end
                     | Map.NO => Crash.impossible "Problem in _mach_cg.sml")
		  | do_opcode((Mips_Assembly.ARITHMETIC_AND_LOGICAL
			       (Mips_Assembly.ADD, rd, rs1, Mips_Assembly.IMM i),
			       Option.PRESENT tag, comment), offset) =
                    (case lookup_env tag of
                       Map.YES res =>
                         let
                           val disp = res + i - offset
                         in
                           if check_range(disp, true, arith_imm_limit) then
                             (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                              (Mips_Assembly.ADD, rd, rs1, Mips_Assembly.IMM disp),
                              comment)
                           else
d747 5
a751 10
                                 (fn _ => ["Found bad ADR, substituting\n"])
                               fun drop(n, the_list) =
                                 if n < 0 then
                                   Crash.impossible"drop negative arg"
                                 else
                                   if n = 0 then the_list
                                   else
                                     case the_list of
                                       [] => Crash.impossible"drop bad list"
                                     | _ :: rest => drop(n-1, rest)
d754 3
d758 7
a764 6
                               val _ =
                                 if rs1 = rd then
                                   Crash.impossible"ADR has dest in lr"
                                 else ()
                               val new_comment = comment ^ " (expanded adr)"
                               val new_tail =
d766 2
a767 2
                                  (Mips_Assembly.LUI, rd, i),
                                  Option.PRESENT tag, new_comment) ::
d769 2
a770 2
                                  (Mips_Assembly.ADD_AND_MASK, rd,
                                   Mips_Assembly.IMM(i + 4), rd),
d773 22
a794 17
                                  (Mips_Assembly.ADD, rd, rs1,
                                   Mips_Assembly.REG rd),
                                  absent, new_comment) :: tail
			       fun rev_app([], y) = y
				 | rev_app(x :: xs, y) = rev_app(xs, x :: y)

                               fun copy_n(n, from, acc) =
                                 if n < 0 then
                                   Crash.impossible"copy_n negative arg"
                                 else
                                   if n = 0 then
                                     rev_app(acc, new_tail)
                                   else
                                     case from of
                                       (x :: xs) =>
					 copy_n(n-1, xs, x :: acc)
                                     | _ => Crash.impossible"copy_n short list"
d796 2
a797 2
                               raise bad_adr(block_tag,
                                             copy_n(head_size, opcode_list, []))
d799 65
a863 3
                         end
                     | Map.NO =>
                         Crash.impossible"Assoc do_opcode arith")
d865 30
a894 33
		  | do_opcode((Mips_Assembly.SPECIAL_ARITHMETIC
			       (_, rd, Mips_Assembly.IMM i,
				rs1),
			       Option.PRESENT tag, comment), offset) =
                    (case lookup_env tag of
                       Map.YES res =>
                         let
                           val disp =
                             make_imm_fault
                             ((res + i - offset) mod 1024,
                              true, arith_imm_limit)
                         in
                           (Mips_Assembly.ARITHMETIC_AND_LOGICAL
                            (Mips_Assembly.ADD, rd, rs1, disp),
                            comment)
                         end
                     | Map.NO =>
                         Crash.impossible"Assoc do_opcode arith")

		  | do_opcode((Mips_Assembly.SETHI(_, rd, i),
			       Option.PRESENT tag, comment), offset) =
                    (case lookup_env tag of
                       Map.YES res => 
                         let
                           val disp = res + i - offset
                           val disp = (disp div 1024) mod (1024 * 1024 * 4)
                         (* Ensure positive *)
                         in
                           (Mips_Assembly.SETHI(Mips_Assembly.LUI, rd, disp),
                            comment)
                         end
                     | Map.NO =>
                         Crash.impossible"Assoc do_opcode arith")
a895 4
                    | do_opcode((opcode, Option.ABSENT, comment), offset) =
                      (opcode, comment)
                    | do_opcode _ = Crash.impossible"Bad tagged instruction"
                      
d926 1
a926 1
	  fun subst_bad_adr_block(proc_list, block as (tag, opcode_list)) =
d940 2
a941 2
	  handle bad_adr bad_adr_block =>
	    do_linearise (subst_bad_adr_block(proc_list, bad_adr_block))
d2293 74
a2366 52
		    ((if Lists.length tag_list <= 2 then
			let
			  val reg = lookup_reg_operand reg_operand
			  val (numbered_tag_list, _) =
			    Lists.number_from(tag_list, 0, 4, fn x=> x)
			  fun do_tests(done, []) = rev done
			  | do_tests(done, (tag, imm) :: (rest as _ :: _)) =
			    do_tests((Mips_Assembly.BRANCH (Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 0),
				      Option.PRESENT tag, "Do the branch") ::
				     (Mips_Assembly.ARITHMETIC_AND_LOGICAL
				      (Mips_Assembly.SUB, MachTypes.zero_reg, reg, Mips_Assembly.IMM imm),
				      absent, "Do the test") :: done, rest)
			  | do_tests(done, (tag, imm) :: rest) =
			    do_tests((Mips_Assembly.BRANCH (* was annulled *)
				      (Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 0),
				      Option.PRESENT tag, "Do the branch") ::
				     (Mips_Assembly.nop_code, absent,
				      "No test required in final case") ::
				     done, rest)
			in
			  do_tests([], numbered_tag_list)
			end
		      else
			(Mips_Assembly.CALL
			 (Mips_Assembly.BGEZAL, MachTypes.zero_reg, 2),
			 absent, "Call self") ::
			(Mips_Assembly.ARITHMETIC_AND_LOGICAL
			 (Mips_Assembly.ADD,
			  MachTypes.lr, MachTypes.lr,
			  Mips_Assembly.IMM(4*4)), absent,
			 "Offset to start of table") :: (* delay slot *)
			(Mips_Assembly.nop_code,  (* skip across this one *)
			 Option.ABSENT, 
			 "doubleword aligned branch follows shortly") ::
			(Mips_Assembly.ARITHMETIC_AND_LOGICAL (* jump is to here *)
			 (Mips_Assembly.ADD,
			  MachTypes.lr, MachTypes.lr,
			  Mips_Assembly.REG (lookup_reg_operand reg_operand)), absent,
			 "Offset to start of table") ::
			(Mips_Assembly.JUMP
			 (Mips_Assembly.JALR, 
			  Mips_Assembly.REG MachTypes.zero_reg, MachTypes.lr,
                          Debugger_Types.null_backend_annotation), absent,
			 "Branch into table") ::
			Mips_Assembly.nop ::
			map
			(fn tag =>
			 (Mips_Assembly.BRANCH (* was annulled *)
			  (Mips_Assembly.BA, MachTypes.zero_reg, MachTypes.zero_reg, 0), 
			  Option.PRESENT tag, ""))
			tag_list),
			opcode_list, block_list, final_result)
d3462 1
a3462 1
	  (MachTypes.WORDSET(MachTypes.WORD_SET
d3474 1
a3474 1
                   MLWorks.Integer.makestring(Lists.reducel( fn(x,MachTypes.WORDSET(MachTypes.WORD_SET{2=tagged_code', ...})) =>
d3483 5
a3487 5
      val ext_elements = make_external_refs(MachTypes.EXTERNAL, ext_refs)
      val ext_vars = make_external_refs(MachTypes.VAR, vars)
      val ext_exns = make_external_refs(MachTypes.EXN, exns)
      val ext_strs = make_external_refs(MachTypes.STRUCT, strs)
      val ext_funs = make_external_refs(MachTypes.FUNCT, funs)
d3490 1
a3490 1
	MachTypes.MODULE(value_elements @@
@


1.9
log
@Fixing some store instruction problems
@
text
@d8 3
d38 1
a38 1
require "machspec";
@


1.8
log
@Bring into line with debugger changes
@
text
@d8 3
d798 7
d1010 1
a1010 1
	    make_imm_fault(i, true, arith_imm_limit)
d1016 6
d1713 24
a1736 19
			if is_reg gp_operand orelse
			  gp_check_range(gp_operand, true, arith_imm_limit) then
			  let
			    val reg_or_imm =
			      if is_reg gp_operand then
				Mips_Assembly.REG(lookup_gp_operand gp_operand)
			      else make_imm_for_store gp_operand
			  in
			    (*output(std_out,"\n rd = "^MachTypes.reg_to_string rd^"  rs1 = "^MachTypes.reg_to_string rs1^(case reg_or_imm of
			     Mips_Assembly.IMM(n) => "imm = "^MLWorks.Integer.makestring n
			| _ => "")^"\n");*)
			    (case reg_or_imm of
			      Mips_Assembly.IMM(n) =>
			    (((Mips_Assembly.LOAD_AND_STORE(load_or_store, rd, rs1,
							     n )), absent, "")
			      :: noop_if_needed,
			     opcode_list, block_list, final_result)
			    | _ => Crash.impossible "Store, expecting immediate offset")
			  end
@


1.7
log
@Add comments, and fix a few bugs in the function entry code.
@
text
@a7 3
Revision 1.6  1994/03/01  14:30:44  io
No reason?

d300 1
a300 1
	   (Mips_Assembly.SLL, MachTypes.zero_reg, MachTypes.zero_reg, _), _, _) ::
d1006 1
a1006 1
	  fun do_save_fps(_, []) = []	
a1027 1

d1084 1
d1130 1
a1130 1
	  fun do_everything (_, tag, [], done, [], final_result) = (tag, contract_sexpr done) :: final_result
d2736 10
a2745 10
      let
        fun less_than_three_opcodes_that_are_not_comments([],occ) = true 
          | less_than_three_opcodes_that_are_not_comments(MirTypes.COMMENT _ :: rest,occ) = 
            less_than_three_opcodes_that_are_not_comments(rest,occ)
          | less_than_three_opcodes_that_are_not_comments(_,2) = false
          | less_than_three_opcodes_that_are_not_comments(h::t,occ) = 
            less_than_three_opcodes_that_are_not_comments(t,occ+1)
      in
        less_than_three_opcodes_that_are_not_comments(opcode_list,0)
      end
d2747 1
a2747 1
	fun append_small_exit(MirTypes.BLOCK(tag, opcode_list), block_list) =
d2751 2
a2752 2
	      (fn (MirTypes.BRANCH(MirTypes.BRA, MirTypes.TAG t)) => tag = t 
		| _ => false) opc_list then
d2757 8
a2764 4
		fun get_new_opc_list((comm as MirTypes.COMMENT _) :: rest) = comm :: (get_new_opc_list rest)
		|   get_new_opc_list(MirTypes.BRANCH(MirTypes.BRA, MirTypes.TAG t) :: rest) =
		  if t = tag then	rest
		  else	Crash.impossible"get_new_opc fails to find proper branch"
d2767 3
a2769 3
		fun rev_app([], y) = y
		|   rev_app(x, []) = x
		|   rev_app(x::xs, ys) = rev_app(xs, x::ys)
d2809 2
a2810 1
	    Set.set_to_list(Set.setdiff(fps, #fp MachSpec.corrupted_by_callee)) 
d2830 2
a2831 1
	  fun check_instr_block(MirTypes.BLOCK(_, instr_list)) = Lists.exists check_instr instr_list
d2846 1
a2846 1
              val Debugger_Types.INFO (i,_) = !debug_map
d2854 1
a2854 1
                                            else true,c),runtime_env)),debug_polyvariables))
d2859 1
a2859 1
                         procedure_name,((Debugger_Types.null_type,false,nil),runtime_env)),debug_polyvariables)))
d3007 1
a3007 1
	  val linkage_size = 3 
d3026 1
d3229 1
a3229 1
                              val Debugger_Types.INFO (i,b) = !debug_map
d3236 1
a3236 1
                                        ((ty,leaf,(count,debug)::annotations),runtime_env)),b)
@


1.6
log
@No reason?
@
text
@d8 3
d475 6
d855 8
d1093 40
d1169 6
d2456 1
a2456 1
				   MachTypes.global, Mips_Assembly.IMM 4),
d2458 2
a2459 2
				 (Mips_Assembly.BRANCH (*_ANNUL*)
				  (Mips_Assembly.BLTZ, MachTypes.zero_reg, MachTypes.global, 0),
d2468 1
a2468 1
				 (Mips_Assembly.BRANCH (*_ANNUL*)
d2595 1
a2595 1
				  (Mips_Assembly.ADDIU,
d2597 1
a2597 1
				   Mips_Assembly.IMM(~frame_size)),
d2778 8
d3005 2
a3022 2
(* 3 assumes no debuggin gstuff *)

d3069 9
@


1.5
log
@Updates to entry sequence
@
text
@d8 3
d300 1
a300 1
	   (Mips_Assembly.SLL, MachTypes.R0, MachTypes.R0, _), _, _) ::
d992 1
a992 3
	  fun do_save_fps(_, []) = []
	  | do_save_fps _ = Crash.unimplemented "FP save"
(*	
d1014 1
a1014 1
*)
d1066 1
a1066 9
(*
	  val _ = case fps_to_preserve of
	    [] => ()
	  | _ => Print.print("Preserving " ^
			     MLWorks.Integer.makestring(Lists.length fps_to_preserve) ^
			     " floating point registers\n")
*)
	  val save_fps =
	    do_save_fps(~real_non_gc_stack_size, fps_to_preserve)
d1068 1
a1068 2
	  val restore_fps =
	    do_restore_fps(~real_non_gc_stack_size, fps_to_preserve)
d1070 2
a1071 5
	  val save_gcs =
	    do_save_gcs(~callee_save_offset, gcs_to_preserve)

	  val restore_gcs =
	    do_restore_gcs(~callee_save_offset, gcs_to_preserve)
d1076 1
a1076 3
	  fun do_everything
	    (_, tag, [], done, [], final_result) =
	    (tag, contract_sexpr done) :: final_result
d2676 10
a2685 10
        let
          fun less_than_three_opcodes_that_are_not_comments([],occ) = true 
            | less_than_three_opcodes_that_are_not_comments(MirTypes.COMMENT _ :: rest,occ) = 
              less_than_three_opcodes_that_are_not_comments(rest,occ)
            | less_than_three_opcodes_that_are_not_comments(_,2) = false
            | less_than_three_opcodes_that_are_not_comments(h::t,occ) = 
              less_than_three_opcodes_that_are_not_comments(t,occ+1)
        in
          less_than_three_opcodes_that_are_not_comments(opcode_list,0)
        end
d2687 1
a2687 1
      fun append_small_exit(MirTypes.BLOCK(tag, opcode_list), block_list) =
d2691 2
a2692 3
	      (fn (MirTypes.BRANCH(MirTypes.BRA, MirTypes.TAG t)) => tag = t
	      | _ => false)
	      opc_list then
d2697 4
a2700 8
		fun get_new_opc_list((comm as MirTypes.COMMENT _) :: rest) =
		  comm :: get_new_opc_list rest
		| get_new_opc_list(MirTypes.BRANCH(MirTypes.BRA,
						   MirTypes.TAG t) ::
				   rest) =
		  if t = tag then rest
		  else
		    Crash.impossible"get_new_opc fails to find proper branch"
d2703 3
a2705 3
		fun rev_app([], x) = x
		| rev_app(y, []) = y
		| rev_app(y :: ys, x) = rev_app(ys, y :: x)
d2737 1
a2737 3
	    Set.set_to_list(Set.setdiff(fps,
					#fp MachSpec.corrupted_by_callee))
	    
d2757 1
a2757 2
	  fun check_instr_block(MirTypes.BLOCK(_, instr_list)) =
	    Lists.exists check_instr instr_list
d2853 1
a2853 1
	  (* check_reg: returns true for all callee_save registers *)
d2933 1
a2933 1
	  val linkage_size = 3
@


1.4
log
@bringing into line with other sources, porting MirTypes.RTS and .ENTER
@
text
@a96 4
  (* This stuff needs to change *)

  val (I2, O3, O4) = (MachTypes.R8, MachTypes.R9, MachTypes.R10)

d134 1
a134 1
  fun make_imm_fault(0, signed, max_pos) = Mips_Assembly.REG MachTypes.R0
d622 1
a622 1
                           (Mips_Assembly.CALL(Mips_Assembly.BGEZAL, MachTypes.R0, disp), comment)
d788 1
a788 1
     (Mips_Assembly.OR, rd, rs, Mips_Assembly.REG MachTypes.R0), absent, "")
d792 1
a792 1
     (Mips_Assembly.OR, rd, MachTypes.R0, Mips_Assembly.IMM imm),
d951 2
a952 2
		  (Mips_Assembly.OR, reg, MachTypes.R0,
		   Mips_Assembly.REG MachTypes.R0),
d956 1
a956 1
		  (Mips_Assembly.OR, reg, MachTypes.R0,
d1130 1
a1130 1
		    val temp_reg = MachTypes.R1
d1198 1
a1198 1
				 (test, temp_reg, MachTypes.R0, 0),
d1204 1
a1204 1
				 (Mips_Assembly.BLTZ, temp_reg, MachTypes.R0, 0),
d1208 1
a1208 1
				 (Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 0),
d1378 1
a1378 1
			      (ORI, rd, rs1, Mips_Assembly.REG MachTypes.R0), absent, "place tagged value into register")],
d1410 1
a1410 1
			MachTypes.R0, Mips_Assembly.REG MachTypes.R0),
d1843 1
a1843 1
                         (Mips_Assembly.ADD,MachTypes.global,MachTypes.R0,
d1854 1
a1854 1
			  MachTypes.fp_global, Mips_Assembly.REG MachTypes.R0), absent,""), (*don't have to store&load!*)
d1883 1
a1883 1
			 (Mips_Assembly.ADD,MachTypes.global,MachTypes.R0, 
d1902 1
a1902 1
			  rd, Mips_Assembly.REG MachTypes.R0), absent,""), (*don't have to store&load!*)
d1914 1
a1914 1
			   Mips_Assembly.REG (lookup_reg_operand reg), MachTypes.R0,
d1919 1
a1919 1
			[(Mips_Assembly.BRANCH(Mips_Assembly.BA, MachTypes.R0,MachTypes.R0,0),
d1981 1
a1981 1
				MachTypes.R1, MachTypes.R0, reg_or_imm), 
d1983 1
a1983 1
			      (Mips_Assembly.BRANCH (branch, rs1, MachTypes.R1, 0),
d1989 1
a1989 1
			     (test_instr, MachTypes.R1,
d1992 1
a1992 1
			    (Mips_Assembly.BRANCH(branch, MachTypes.R1, MachTypes.R0, 0),
d2034 1
a2034 1
		       (Mips_Assembly.ADD, MachTypes.R1,
d2038 1
a2038 1
		       (Mips_Assembly.JALR, Mips_Assembly.REG MachTypes.lr, MachTypes.R1, debug_information),
d2044 1
a2044 1
		      (Mips_Assembly.BGEZAL, MachTypes.R0, 0),
d2054 1
a2054 1
			       (Mips_Assembly.ADD, MachTypes.R1,
d2059 1
a2059 1
				Mips_Assembly.REG MachTypes.R1, MachTypes.R0,
d2065 1
a2065 1
			       (Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 0),
d2079 1
a2079 1
			    do_tests((Mips_Assembly.BRANCH (Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 0),
d2082 1
a2082 1
				      (Mips_Assembly.SUB, MachTypes.R0, reg, Mips_Assembly.IMM imm),
d2086 1
a2086 1
				      (Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 0),
d2096 1
a2096 1
			 (Mips_Assembly.BGEZAL, MachTypes.R0, 2),
d2113 1
a2113 1
			  Mips_Assembly.REG MachTypes.R0, MachTypes.lr,
d2120 1
a2120 1
			  (Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 0), 
d2205 2
a2206 2
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SUB, MachTypes.R1, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2), absent, "Is a GC required?") ::
				 (Mips_Assembly.BRANCH (Mips_Assembly.BLTZ, MachTypes.R1, MachTypes.R0, 7), absent, "Skip call to GC if not") ::
d2211 2
a2212 2
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.OR, MachTypes.global, MachTypes.R0, Mips_Assembly.IMM bytes), absent, "Size argument for GC") ::
				 (Mips_Assembly.BRANCH (Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 2), absent, "Skip next instruction") ::
d2219 1
a2219 1
				    (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.R0, rd, bytes - primary - 4), absent, "Zero unaligned extra word") ::
d2225 2
a2226 2
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SUB, MachTypes.R1, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2), absent, "Is a GC required?") ::
				 (Mips_Assembly.BRANCH (Mips_Assembly.BLTZ, MachTypes.R1, MachTypes.R0, 7), absent, "Skip call to GC if not required") ::
d2231 2
a2232 2
				 (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.OR, MachTypes.global, MachTypes.R0, Mips_Assembly.REG rd), absent, "Size argument for GC") ::
				 (Mips_Assembly.BRANCH (Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 2), absent, "Skip next instruction") ::
d2240 1
a2240 1
				    (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.R0, rd, ~4), absent, "Zero unaligned extra word") ::
d2269 2
a2270 2
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.SUB, MachTypes.R1, MachTypes.gc1, Mips_Assembly.REG MachTypes.gc2), absent, "Is a GC required?") ::
				   (Mips_Assembly.BRANCH (Mips_Assembly.BLTZ, MachTypes.R1, MachTypes.R0, 7), absent, "Skip call to GC if not") ::
d2275 2
a2276 2
				   (Mips_Assembly.ARITHMETIC_AND_LOGICAL (Mips_Assembly.OR, MachTypes.global, MachTypes.R0, Mips_Assembly.REG rd), absent, "Size argument for GC") ::
				   (Mips_Assembly.BRANCH (Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 1), absent, "Skip next instruction") ::
d2280 1
a2280 1
				   (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.R0, rd, ~4), absent, "Zero last word in case it's unaligned") ::
d2292 1
a2292 1
			(Mips_Assembly.BGEZAL, MachTypes.R0, 1),
d2340 1
a2340 1
			    (Mips_Assembly.LOAD_AND_STORE (Mips_Assembly.SW, MachTypes.R0, reg, offset), absent, "Initialise a stack slot") :: done
d2343 1
a2343 1
					(Mips_Assembly.SW, MachTypes.R0, reg, offset), absent,
d2353 1
a2353 1
				(Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 0),
d2374 1
a2374 1
				  (Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 0),
d2395 1
a2395 1
				 (Mips_Assembly.ADD, I2,
d2404 4
d2409 1
a2409 1
				  (Mips_Assembly.BLTZ, MachTypes.R0, MachTypes.global, 0),
d2413 3
a2415 3
				  (Mips_Assembly.SW, I2,
				   MachTypes.global,
				   0),
d2417 1
a2417 1
				  "Initialise a stack slot (delay slot)"),
d2419 1
a2419 1
				  (Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 0),
d2437 4
a2440 1
			val join_tag = MirTypes.new_tag()
d2446 1
a2446 1
			    (Mips_Assembly.BLEZ, MachTypes.R1, MachTypes.R0, 0),
d2449 4
a2452 1
			   Mips_Assembly.nop,
d2454 1
a2454 1
			    (Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 0),
d2460 1
a2460 1
			     (Mips_Assembly.SUB, MachTypes.R1, 
d2471 1
a2471 1
				Mips_Assembly.REG O3),
d2474 2
a2475 2
			     (Mips_Assembly.SUB, MachTypes.R1, MachTypes.stack_limit,
			      Mips_Assembly.REG(MachTypes.global)),
d2483 1
a2483 1
			    load_large_number_into_register(O3,frame_size) @@
d2488 1
a2488 1
			    (Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 0),
d2495 1
a2495 1
			    load_large_number_into_register(O3, frame_size) @@
d2498 1
a2498 1
		val post_ov_code =
d2500 1
a2500 1
			      (Mips_Assembly.LW, MachTypes.global,
d2507 1
a2507 1
			       Mips_Assembly.REG O4, MachTypes.global,
d2509 1
a2509 1
			      absent, "Do stack_overflow") ::
a2512 20

(*			io: functionalising simons version
			val post_ov_code = let
			    val acc = [(Mips_Assembly.BRANCH (*_ANNUL*)
			    	(Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 0),
			    	Option.PRESENT non_ov_tag, ""),
			   	Mips_Assembly.nop]
			    val acc1 = if immediate_size then [] else load_large_number_into_register(O3, frame_size)
			    val acc2 =   (Mips_Assembly.LOAD_AND_STORE 
				(Mips_Assembly.LW, MachTypes.global, MachTypes.implicit, 4*Implicit_Vector.extend),
				absent, "Get address of stack_overflow") ::
			     	Mips_Assembly.nop ::
			     (Mips_Assembly.JUMP 
				(Mips_Assembly.JALR, Mips_Assembly.REG O4, MachTypes.global, Debugger_Types.null_backend_annotation),
			      	absent, "Do stack_overflow") :: Mips_Assembly.nop :: [] 
			in
			  acc2 @@ acc1 @@ acc	
			end
*)

d2516 1
a2516 1
			     (Mips_Assembly.OR, O3, MachTypes.R0, 
d2518 1
a2518 1
			     absent, "Set the required size in R9") :: post_ov_code
d2522 4
a2525 1
			(check_for_stack_overflow_wrap,
d2533 1
a2533 3
			     (if immediate_size
				then []
			      else 
d2535 29
a2563 3
				  (Mips_Assembly.SUB, O3, MachTypes.R0,
				   Mips_Assembly.REG(O3)), 
				  absent, "Negate the frame size")]) @@
d2566 1
a2566 1
				   (Mips_Assembly.BA, MachTypes.R0, MachTypes.R0, 0),
d2595 1
a2595 1
			 (Mips_Assembly.JUMP (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr,MachTypes.R0, Debugger_Types.null_backend_annotation), Option.ABSENT, "return"),
d2599 1
a2599 1
		     ([(Mips_Assembly.JUMP (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr, MachTypes.R0, Debugger_Types.null_backend_annotation), absent, "Return"), Mips_Assembly.nop],
d2627 1
a2627 1
			    Mips_Assembly.REG MachTypes.R0),
d2638 1
a2638 1
			    Mips_Assembly.REG MachTypes.global, MachTypes.R0, 
d2644 1
a2644 1
			    Mips_Assembly.REG MachTypes.R0),
@


1.3
log
@minor path change
@
text
@d8 3
d97 2
d674 1
a674 1
                                  Option.ABSENT, new_comment) :: tail
d847 1
a847 1
      fun do_blocks(_, [], _, _, _, _, _, _, _, _) = []
d856 3
a858 1
		  fps_to_preserve
d861 1
a861 1
	  val non_save_frame_size = frame_size - 64
d878 1
a878 1
                   ~(non_gc_stack_size + 4 * (1 + i))
d905 1
a905 1
                     ~4 * (1 + offset + i)
d925 2
a926 1
                | Option.SOME2(i) => ~4 * (1 + non_gc_spill_size + i))
d993 4
a996 2
	  fun do_save_instrs(_, []) = []
	    | do_save_instrs(offset, fp :: rest) =
d1002 1
a1002 1
		   "save float") :: do_save_instrs(offset+4, rest)
d1015 32
a1046 31
		  do_save_instrs(offset+8, rest)
	      | MachTypes.extended =>
		  Crash.impossible "do_save_instrs: Extended floats not supported"

	  fun really_do_restore_instrs(_, []) = []
	    | really_do_restore_instrs(offset, fp :: rest) =
	      case MachTypes.fp_used of
		MachTypes.single =>
		  (Mips_Assembly.LOAD_AND_STORE_FLOAT
		   (Mips_Assembly.LWC1, fp, MachTypes.fp,
		    Mips_Assembly.IMM offset), Option.ABSENT,
		   "restore float") ::
		  Mips_Assembly.nop ::
		  really_do_restore_instrs(offset+4, rest)
	      | MachTypes.double =>
		  (Mips_Assembly.LOAD_AND_STORE_FLOAT
		   (Mips_Assembly.LWC1, fp, 
		    MachTypes.fp,
		    Mips_Assembly.IMM offset), Option.ABSENT,
		   "restore float") :: 
		  (Mips_Assembly.LOAD_AND_STORE_FLOAT
		   (Mips_Assembly.LWC1, 
		    MachTypes.next_reg fp,
		    MachTypes.fp,
		    Mips_Assembly.IMM (offset+4)), Option.ABSENT,
		   "restore float") ::
		  really_do_restore_instrs(offset+8, rest)
	      | MachTypes.extended =>
		  Crash.impossible "really_do_restore_instrs: Extended floats not supported"
	  fun do_restore_instrs(_, []) = []
	    | do_restore_instrs a=really_do_restore_instrs a
d1055 14
d1077 1
a1077 1
	    do_save_instrs(~real_non_gc_stack_size, fps_to_preserve)
d1080 8
a1087 2
	    do_restore_instrs(~real_non_gc_stack_size, fps_to_preserve)

d1203 1
a1203 1
				 Option.PRESENT new_tag, "Do the branch on ok"),
d1209 2
a1210 2
				 Option.PRESENT tag, "Else go to exception"),
				Mips_Assembly.nop,
d1213 1
a1213 1
				 Option.PRESENT new_tag, "This branch removed on linearisation?"),
d1276 5
a1280 5
		    fun needs_reverse Mips_Assembly.SUB = true
		    | needs_reverse Mips_Assembly.SRL = true
		    | needs_reverse Mips_Assembly.SLL = true
		    | needs_reverse Mips_Assembly.SRA = true
		    | needs_reverse _ = false
d1283 6
a1288 12
		      if is_reg gp_operand then
			(gp_operand, gp_operand', false)
		      else
                        if is_reg gp_operand'
                          then
                            if needs_reverse opcode then
                              (gp_operand, gp_operand', true)
                            else 
                              (gp_operand', gp_operand, false)
                        else 
                          (* Both immediate so no problem *)
                          (gp_operand, gp_operand', false)
d1382 1
a1382 1
			      (ORI, rd, rs1, Mips_Assembly.REG MachTypes.R0), absent, "")],
d1432 4
a1435 8
		    | (MachTypes.extended, MirTypes.FADD) => 
			Crash.impossible "Extended floats not supported"
		    | (MachTypes.extended, MirTypes.FSUB) =>
			Crash.impossible "Extended floats not supported"
		    | (MachTypes.extended, MirTypes.FMUL) =>
			Crash.impossible "Extended floats not supported"
		    | (MachTypes.extended, MirTypes.FDIV) =>
			Crash.impossible "Extended floats not supported"
d1446 13
a1458 26
			  (MachTypes.single, MirTypes.FSQRT) =>
			    Crash.impossible "no hardware square root"
			| (MachTypes.single, MirTypes.FMOVE) =>
			    (Mips_Assembly.MOV_S, 0)
			| (MachTypes.single, MirTypes.FABS) =>
			    (Mips_Assembly.ABS_S, 0)
			| (MachTypes.single, MirTypes.FNEG) =>
			    (Mips_Assembly.NEG_S, 0)
			| (MachTypes.double, MirTypes.FSQRT) =>
			    Crash.impossible "no hardware square root"
			| (MachTypes.double, MirTypes.FMOVE) =>
			    (Mips_Assembly.MOV_D, 0)
			| (MachTypes.double, MirTypes.FABS) =>
			    (Mips_Assembly.ABS_D, 0)
			| (MachTypes.double, MirTypes.FNEG) =>
			    (Mips_Assembly.NEG_D, 0)
			| (MachTypes.extended, MirTypes.FSQRT) =>
			    Crash.impossible "Extended floats not supported"
			| (MachTypes.extended, MirTypes.FMOVE) =>
			    Crash.impossible "Extended floats not supported"
			| (MachTypes.extended, MirTypes.FABS) =>
			    Crash.impossible "Extended floats not supported"
			| (MachTypes.extended, MirTypes.FNEG) =>
			    Crash.impossible "Extended floats not supported"
			| _ =>
			    Crash.impossible"Bad unary fp generated"
d1460 1
a1460 2
		      | add_moves(rd, rs2, moves) =
			let
d1497 1
a1497 1
                      (Mips_Assembly.FBRANCH(Mips_Assembly.BC1T, 0), Option.PRESENT tag, ""),
d1527 1
a1527 2
			      | MachTypes.extended => 
				  Crash.impossible "Extended floats not supported")
d1538 1
a1538 1
                       (Mips_Assembly.FBRANCH(Mips_Assembly.BC1T, 0), Option.PRESENT tag, "") ::
d1566 1
a1566 2
		| MirTypes.STACKOP _ =>
		    Crash.impossible"Offset missing on STACK_OP"
d1692 9
a1700 18
			(MachTypes.single, MirTypes.FLD) =>
			  (Mips_Assembly.LWC1, false, [Mips_Assembly.nop])
		      | (MachTypes.single, MirTypes.FST) =>
			  (Mips_Assembly.SWC1, false, [])
		      | (MachTypes.single, MirTypes.FLDREF) =>
			  (Mips_Assembly.LWC1, false, [Mips_Assembly.nop])
		      | (MachTypes.single, MirTypes.FSTREF) =>
			  (Mips_Assembly.SWC1, false, [])
		      | (MachTypes.double, MirTypes.FLD) =>
			  (Mips_Assembly.LWC1, false, [Mips_Assembly.nop])
		      | (MachTypes.double, MirTypes.FST) =>
			  (Mips_Assembly.SWC1, false, [])
		      | (MachTypes.double, MirTypes.FLDREF) =>
			  (Mips_Assembly.LWC1, false, [Mips_Assembly.nop])
		      | (MachTypes.double, MirTypes.FSTREF) =>
			  (Mips_Assembly.SWC1, false, [])
		      | (MachTypes.extended, _) =>
			  Crash.impossible "Extended floats not supported"
d1704 10
a1713 10
		    fun gp_op_is_large(arg as MirTypes.GP_IMM_ANY i) =
		      gp_check_range(arg, true, arith_imm_limit) andalso
		      gp_check_range(MirTypes.GP_IMM_INT(i+8), true,
				     arith_imm_limit)
		    | gp_op_is_large(MirTypes.GP_IMM_INT i) =
		      gp_op_is_large(MirTypes.GP_IMM_ANY(i*4))
		    | gp_op_is_large(arg as MirTypes.GP_IMM_SYMB symb) =
		      gp_op_is_large(MirTypes.GP_IMM_ANY(symbolic_value symb))
		    | gp_op_is_large(MirTypes.GP_GC_REG _) = true
		    | gp_op_is_large(MirTypes.GP_NON_GC_REG _) = true
d1756 3
a1758 1
			      let val MirTypes.GP_IMM_ANY i = gp_operand 
d1930 3
a1932 1
		    val Option.PRESENT zero_virtual = MirRegisters.zero
d1953 3
a1955 6
			MirTypes.GP_GC_REG _ => 
			  (branch, gp_operand, make_reg0_from_imm0 gp_operand')
		      | MirTypes.GP_NON_GC_REG _ => 
			  (branch, gp_operand, make_reg0_from_imm0 gp_operand')
		      | _ => (Mips_Assembly.reverse_branch branch, 
			      gp_operand', make_reg0_from_imm0 gp_operand)
d2018 9
a2026 18
			(MachTypes.single, MirTypes.FBEQ) 
			=> (Mips_Assembly.C_EQ_S, Mips_Assembly.BC1T)
		      | (MachTypes.single, MirTypes.FBNE) 
			=> (Mips_Assembly.C_EQ_S, Mips_Assembly.BC1F)
		      | (MachTypes.single, MirTypes.FBLE) 
			=> (Mips_Assembly.C_OLE_S, Mips_Assembly.BC1T)
		      | (MachTypes.single, MirTypes.FBLT) 
			=> (Mips_Assembly.C_OLT_S, Mips_Assembly.BC1T)
		      | (MachTypes.double, MirTypes.FBEQ) 
			=> (Mips_Assembly.C_EQ_D, Mips_Assembly.BC1T)
		      | (MachTypes.double, MirTypes.FBNE) 
			=> (Mips_Assembly.C_EQ_D, Mips_Assembly.BC1F)
		      | (MachTypes.double, MirTypes.FBLE) 
			=> (Mips_Assembly.C_OLE_D, Mips_Assembly.BC1T)
		      | (MachTypes.double, MirTypes.FBLT) 
			=> (Mips_Assembly.C_OLT_D, Mips_Assembly.BC1F)
		      | (MachTypes.extended, _) 
			=> Crash.impossible "Extended floats not supported"
d2152 1
a2152 2
		 | MirTypes.ALLOCATE_STACK _ =>
		     Crash.impossible"ALLOCATE_STACK with no offset from fp"
d2312 22
a2333 2
                | MirTypes.INTERCEPT =>
		    (trace_dummy_instructions, opcode_list, block_list, final_result)
d2335 3
a2337 1
		| MirTypes.ENTER =>
d2344 4
a2347 13
			    (Mips_Assembly.LOAD_AND_STORE
			     (Mips_Assembly.SW, MachTypes.R0,
			      reg,
			      offset), absent,
			     "Initialise a stack slot") :: done
			  | do_store(reg, offset, n, done) =
			    if n < 0 then Crash.impossible"Do_store"
			    else
			      do_store(reg, offset+4, n-1,
				       (Mips_Assembly.LOAD_AND_STORE
					(Mips_Assembly.SW, MachTypes.R0,
					 reg,
					 offset), absent,
d2354 1
a2354 1
			    val end_limit = 64 + (no_of_stores-1)*4
d2364 1
a2364 1
			      do_store(MachTypes.sp, 64, no_of_stores,
d2367 1
a2367 3
			      Crash.impossible
			      ("n_stores end_limit = " ^
			       MLWorks.Integer.makestring end_limit)
d2372 1
a2372 2
			     n_stores((*gc_area_start_offset(),*)
				      gc_stack_size div 4),
d2400 1
a2400 1
				  MachTypes.sp, Mips_Assembly.IMM 64), absent,
d2452 1
a2452 1
			  if non_save_frame_size = 0 then
d2479 2
a2480 1
			val post_ov_code =
d2491 2
a2492 1
			val post_ov_code =
d2506 21
d2563 25
a2587 9
		    let val return =
		      [(Mips_Assembly.JUMP (Mips_Assembly.JR, Mips_Assembly.REG MachTypes.lr, MachTypes.R0, Debugger_Types.null_backend_annotation), absent, "Return"),
		       Mips_Assembly.nop]
		    in
		      if needs_preserve then
			(restore_fps @@ return, opcode_list, block_list, final_result)
		      else
			(return,  opcode_list, block_list, final_result)
		    end
d2640 1
a2640 5
		| MirTypes.COMMENT string =>
		    Crash.impossible"MirTypes.COMMENT not filtered out"
(*
 ([], opcode_list, block_list, final_result)
*)
d2706 1
a2706 2
		| get_new_opc_list _ =
		  Crash.impossible"get_new_opc fails to find proper branch"
d2740 1
d2801 1
a2801 2
	  fun move_first (_, []) =
	      Crash.impossible "move_first"
d2805 1
a2805 1

d2860 79
d2941 2
a2942 1
	  val frame_size = gc_stack_size + non_gc_stack_size + 64
d2955 4
a2958 1
				     fps_to_preserve))
@


1.2
log
@Deleted old SPARC comments and fixed type errors
@
text
@d4 1
a4 1
 based on Revision 1.61
d7 4
a10 1
 $Log$
d28 1
a28 1
require "mach_cg";
@


1.1
log
@Initial revision
@
text
@d1 8
a8 12
(* _mach_cg.sml the functor *)
(* mips version, based on Sparc _mach_cg, Revision 1.161  1993/08/06  14:31:34  

;;; Copyright 1991 Harlequin Ltd.
;;; $Log$

$Log: _mach_cg.sml,v $
Revision 1.1  93/09/02  16:19:17  simon
Initial revision

Copyright (c) 1993 Harlequin Ltd.
*)
d44 1
a44 1

d48 1
a48 2
  sharing MirTables.MirTypes.Option = MirTables.MirTypes.RuntimeEnv.Option

d79 3
a81 3
    [(Mips_Assembly.other_nop_code,MirTypes.Option.ABSENT,"Dummy instructions for tracing"),
     (Mips_Assembly.other_nop_code,MirTypes.Option.ABSENT,"Dummy instructions for tracing"),
     (Mips_Assembly.other_nop_code,MirTypes.Option.ABSENT,"Dummy instructions for tracing")]
d238 1
a238 1
      let
d246 6
a251 2
        MachTypes.REAL(i, encoding_function(sign, mantissa, exponent))
      end
d256 1
a256 1
  type half_op = Mips_Assembly.opcode * MirTypes.tag MirTypes.Option.opt
d260 1
a260 1
  val absent = MirTypes.Option.ABSENT
d274 1
a274 1
	  ((_, MirTypes.Option.PRESENT tag, _), true) => (tag, true)
d294 1
a294 2
	  (Mips_Assembly.BRANCH _, _, _) :: rest => 
	    rest
d457 1
a457 1
  MirTypes.tag * (Mips_Assembly.opcode * MirTypes.tag MirTypes.Option.opt * string) list
d509 1
a509 1
		     :: (Mips_Assembly.nop_code, MirTypes.Option.ABSENT, "doubleword aligned branch follows") 
d583 1
a583 1
				 MirTypes.Option.PRESENT tag, comment), offset) =
d597 1
a597 1
			       MirTypes.Option.PRESENT tag, comment), offset) =
d610 1
a610 1
			       MirTypes.Option.PRESENT tag, comment), offset) =
d623 1
a623 1
			       MirTypes.Option.PRESENT tag, comment), offset) =
d658 1
a658 1
                                  MirTypes.Option.PRESENT tag, new_comment) ::
d662 1
a662 1
                                  MirTypes.Option.PRESENT tag, new_comment) ::
d666 1
a666 1
                                  MirTypes.Option.ABSENT, new_comment) :: tail
d692 1
a692 1
			       MirTypes.Option.PRESENT tag, comment), offset) =
d709 1
a709 1
			       MirTypes.Option.PRESENT tag, comment), offset) =
d723 1
a723 1
                    | do_opcode((opcode, MirTypes.Option.ABSENT, comment), offset) =
d796 1
a796 1
    (Options.OPTIONS {compiler_options = Options.COMPILEROPTIONS {debug, opt_leaf_fns, ...},
d988 1
a988 1
		    Mips_Assembly.IMM offset), MirTypes.Option.ABSENT,
d994 1
a994 1
		    Mips_Assembly.IMM offset), MirTypes.Option.ABSENT,
d1000 1
a1000 1
		    Mips_Assembly.IMM (offset+4)), MirTypes.Option.ABSENT,
d1012 1
a1012 1
		    Mips_Assembly.IMM offset), MirTypes.Option.ABSENT,
d1020 1
a1020 1
		    Mips_Assembly.IMM offset), MirTypes.Option.ABSENT,
d1026 1
a1026 1
		    Mips_Assembly.IMM (offset+4)), MirTypes.Option.ABSENT,
d1169 1
a1169 1
				 MirTypes.Option.PRESENT new_tag, "Do the branch on ok"),
d1175 1
a1175 1
				 MirTypes.Option.PRESENT tag, "Else go to exception"),
d1179 1
a1179 1
				 MirTypes.Option.PRESENT new_tag, "This branch removed on linearisation?"),
d1487 1
a1487 1
                      (Mips_Assembly.FBRANCH(Mips_Assembly.BC1T, 0), MirTypes.Option.PRESENT tag, ""),
d1529 1
a1529 1
                       (Mips_Assembly.FBRANCH(Mips_Assembly.BC1T, 0), MirTypes.Option.PRESENT tag, "") ::
d1534 1
a1534 1
				   MirTypes.Option.PRESENT offset) =>
d1864 1
a1864 1
                        (Mips_Assembly.FBRANCH(Mips_Assembly.BC1F, 0), MirTypes.Option.PRESENT tag, ""),
d1872 1
a1872 1
			 MirTypes.Option.PRESENT tag, ""),
d1881 1
a1881 1
                        (Mips_Assembly.FBRANCH(Mips_Assembly.BC1F, 7), MirTypes.Option.ABSENT, ""),
d1924 1
a1924 1
			  MirTypes.Option.PRESENT tag, "Branch relative"),
d1929 1
a1929 1
		    val MirRegisters.Option.PRESENT zero_virtual = MirRegisters.zero
d1979 1
a1979 1
			       MirTypes.Option.PRESENT tag, "Do the branch"),
d1988 1
a1988 1
			       MirTypes.Option.PRESENT tag, "Do the branch"),
d1997 1
a1997 1
			     MirTypes.Option.PRESENT tag, "Do the branch"),
d2041 1
a2041 1
		       MirTypes.Option.PRESENT tag, "Do the branch"),
d2058 1
a2058 1
		      MirTypes.Option.PRESENT tag, "Call"),
d2079 1
a2079 1
			       MirTypes.Option.PRESENT tag, "Branch relative (tail call)"),
d2093 1
a2093 1
				      MirTypes.Option.PRESENT tag, "Do the branch") ::
d2100 1
a2100 1
				      MirTypes.Option.PRESENT tag, "Do the branch") ::
d2117 1
a2117 1
			 MirTypes.Option.ABSENT, 
d2134 1
a2134 1
			  MirTypes.Option.PRESENT tag, ""))
d2138 1
a2138 1
					  MirTypes.Option.PRESENT fp_offset) =>
d2223 1
a2223 1
				 (Mips_Assembly.nop_code, MirTypes.Option.ABSENT, "doubleword aligned branch follows shortly") ::
d2311 1
a2311 1
			MirTypes.Option.PRESENT tag, "Update gc pointer")],
d2355 1
a2355 1
				MirTypes.Option.PRESENT end_tag,
d2379 1
a2379 1
				  MirTypes.Option.PRESENT top_tag,
d2410 1
a2410 1
				  MirTypes.Option.PRESENT top_tag,
d2420 1
a2420 1
				  MirTypes.Option.PRESENT end_tag, ""),
d2444 1
a2444 1
			    MirTypes.Option.PRESENT non_ov_tag,
d2449 1
a2449 1
			    MirTypes.Option.PRESENT ov_tag, ""),
d2482 1
a2482 1
			    MirTypes.Option.PRESENT non_ov_tag, ""),
d2531 1
a2531 1
				   MirTypes.Option.PRESENT join_tag, ""),
d2632 1
a2632 1
      fun exit_block [] = MirTypes.Option.ABSENT
d2637 1
a2637 1
	  then MirTypes.Option.PRESENT block
d2689 1
a2689 1
		   {leaf, registers_used = MirTypes.Option.PRESENT
d2699 2
a2700 2
	      MirTypes.Option.ABSENT => block_list
	    | MirTypes.Option.PRESENT exit_block =>
d2745 1
a2745 1
              val Debugger_Types.INFO i = !debug_map
d2753 1
a2753 1
                                            else true,c),runtime_env))))
d2758 1
a2758 1
                         procedure_name,((Debugger_Types.null_type,false,nil),runtime_env)))))
d2793 1
a2793 1
	      MirTypes.Option.PRESENT{gc = gc_spill_size,
d2802 1
a2802 1
	    MirTypes.Option.PRESENT stack_extra => stack_extra
d2900 1
a2900 1
			    MirTypes.Option.PRESENT tag =>
d2902 1
a2902 1
			  | MirTypes.Option.ABSENT => " no tag") ^
d2972 1
a2972 1
				 MirTypes.Option.PRESENT tag =>
d2974 1
a2974 1
			       | MirTypes.Option.ABSENT => " no tag") ^
d3036 1
a3036 1
                              val Debugger_Types.INFO i = !debug_map
d3042 2
a3043 2
                                     (NewMap.define(i, unpadded_name, 
                                        ((ty,leaf,(count,debug)::annotations),runtime_env)))
@
